[
  {
    "text1": "The effects of the rapid technological revolution occurring in our society are undeniable.In the health area, the quick growth of Information Technologies has had a particularand striking impact as it has led to an urgent need to improve the health care provided tothe population. It is imperative that care delivery becomes an increasingly computerizedprocess in order to facilitate not only the work of all health professionals, but the livesof all users.However, it is necessary that this phenomenon of clinical informatization is evaluated,in order to make it possible to determine the current state of health institutions, asmonitored, so that a path of gradual progression can be defined and followed, andinternal flows, processes and systems can be improved.In Portugal, many initiatives have been implemented, such as the National Strategyfor the Health Information Ecosystem 2020, in particular the SNS Sem Papel. Theobjective is to improve access to the National Health System and to expedite the sharingof clinical information by eliminating paper in hospital institutions. Obstacles andresistance to change can naturally occur as these initiatives are implemented.Thus, the emergence of entities such as HIMSS Analytics, capable of creating maturitymodels that provide a clear and concise method, capable of helping institutions toachieve their goals, becomes crucial. Within the scope of this dissertation, two maturitymodels created by this entity, EMRAM and AMAM, were studied in order to understandtheir dynamics and scrutinize how they possibilitate the gradual improvement of theanalytics of the institutions and the progressive dematerialization of their systems, flowsand processes.",
    "text2": "Clinical records are a fundamental component of the correct treatment and follow-up of patients. The management of patient flow is complex and in the current pandemic times, the work organization must be increasingly focused and oriented towards simple and effective records. Communication among the different departments is fundamental and must ensure that data and information flows without breaks. The provision of health care to patients is a vital importance in a society and the more advanced the medicine is the better is the treatment. The impact of technologies drastically benefits the treatment chosen by the doctor and the respective diagnoses, so the more information the doctor has regarding of the state of health and all kinds of interventions of his patients, the more prepared he will be to face and the more appropriate the methods will be used for each one. The main objective of this dissertation is to study the applicability of tools to develop a web platform to be used in the management of information to health professionals. An organic platform that can be molded to various situations and that are capable to supporting clinical records where each health professional is able to visualize the tasks according to their specialty, such as physiotherapy and rehabilitation professionals. A web platform that allows any professional in the area, a simple registration and access, offering a practical history of patients with all the necessary information and all the interventions they have done.",
    "similarity": 0.30929119357097196
  },
  {
    "text1": "The Fast Fourier Transform is a family of algorithms indispensable for the computation of the Discrete FourierTransform. As a result, these transforms are the core of many applications in several areas and are required to becomputed efficiently in many scenarios.The continuous evolution of GPUs has increased the popularity of parallelizable algorithm implementations onthis type of hardware. Traditionally GPUs were associated to graphics background, however, with the popularizationof the compute functionality of this hardware, most modern GPUs now have this capability, hence, algorithmsnow are more likely to be implemented in the general-purpose compute pipeline of GPUs. As a result, manyapplications take advantage of compute programming in GPGPU-capable frameworks such as GLSL, a high-levelshading language frequently used in the context of computer graphics.In this dissertation we provide, refine and compare GPU-driven implementations of the family of FFT algorithmsin GLSL, with the goal to provide programmers with efficient and simplified compute kernels for this transform,from the classic Cooley-Tukey algorithm to more suitable algorithms for the GPU such as the Stockham algorithmwith higher radix.Accordingly, we also use the cuFFT NVIDIA framework for reference in the comparisons of the GLSL algorithmsimplementations with the goal to analyse their significance on the tradeoff of using specialized implementations ofthe FFT algorithms or integrating dedicated software tools for any case of application.Finally, we demonstrate how all improvements discussed in this dissertation culminate in performance improvement in a real-time rendering technique that heavily depends on multiple of these transforms in the Nau3D engineas a case of study.",
    "text2": "The security of most digital systems is under serious threats due to major technology breakthroughswe are experienced in nowadays. Lattice-based cryptosystems are one of the mostpromising post-quantum types of cryptography, since it is believed to be secure againstquantum computer attacks. Their security is based on the hardness of the Shortest VectorProblem and Closest Vector Problem.Lattice basis reduction algorithms are used in several fields, such as lattice-based cryptographyand signal processing. They aim to make the problem easier to solve by obtainingshorter and more orthogonal basis. Some case studies work with numbers with hundredsof digits to ensure harder problems, which require Multiple Precision (MP) arithmetic. Thisdissertation presents a novel integer representation for MP arithmetic and the algorithmsfor the associated operations, MpIM. It also compares these implementations with other libraries,such as GNU Multiple Precision Arithmetic Library, where our experimental resultsdisplay a similar performance and for some operations better performances.This dissertation also describes a novel lattice basis reduction module, LattBRed, whichincluded a novel efficient implementation of the Qiao’s Jacobi method, a Lenstra-LenstraLovasz(LLL) algorithm and associated parallel implementations, a parallel variant of the ´Block Korkine-Zolotarev (BKZ) algorithm and its implementation and MP versions of thethe Qiao’s Jacobi method, the LLL and BKZ algorithms.Experimental performances measurements with the set of implemented modifications ofthe Qiao’s Jacobi method show some performance improvements and some degradationsbut speedups greater than 100 in Ajtai-type bases.",
    "similarity": 0.3017394492423008
  },
  {
    "text1": "Biomedical literature is composed of a large and ever increasing number of publications, written in natural language. Patents are a relevant fraction of these publications, considered important sources of information due to all the curated information available in the documents, from the granting process. Although being real technological libraries, their unstructured data turns the search of information within these documents a challenging task. Biomedical text mining is a scientific field that explores this task, creating methodologies to search and structure the information in the biomedical literature.Information retrieval is one of the biomedical text mining tasks, in which the relevant information is obtained from an extensive collection of documents using several text retrieval methodologies. Getting all the information available on a patent document requires the download of the respective PDF document, that is then converted into a machine-readable text by technologies as Optical Character Recognition (OCR).In this project, an information retrieval, and a PDF to text conversion system were developed building a “patent pipeline” which was integrated into @note2, an open-source computational framework for biomedical text mining. The patent pipeline can be disintegrated into four different tasks: the patent search, the retrieval of patent metadata, the retrieval of their PDF files, and the extraction of all the information from these documents.A set of patents from the BioCreative V CHEMDNER task was used to test the developed pipeline, evaluating the framework performance and the real capacity to retrieve the requested patents and extract their unstructured information. The results were promising, bringing to the scientific community the published patent information and allowing the posterior implementation of other biomedical text mining processes over these documents.",
    "text2": "Biomedical Text Mining (BTM) seeks to derive high-quality information from literature in the biomedical domain, by creating tools/methodologies that can automate time-consuming tasks when searching for new information. This encompasses both Information Retrieval, the discovery and recovery of relevant documents, and Information Extraction, the capability to extract knowledge from text. In the last years, SilicoLife, with the collaborationof the University of Minho, has been developing @Note2, an open-source Java-based multiplatform BTM workbench, including libraries to perform the main BTM tasks, also provid ing user-friendly interfaces through a stand-alone application.This work addressed the development of a web-based software platform that is able toaddress some of the main tasks within BTM, supported by the existing core libraries fromthe @Note project. This included the improvement of the available RESTful server, providingsome new methods and APIs, and improving others, while also developing a web-basedapplication through calls to the API provided by the server and providing a functionaluser-friendly web-based interface.This work focused on the development of tasks related with Information Retrieval, addressing the efficient search of relevant documents through an integrated interface. Also, atthis stage the aim was to have interfaces to visualize and explore the main entities involvedin BTM: queries, documents, corpora, annotation processes entities and resources.",
    "similarity": 0.3042609480531607
  },
  {
    "text1": "Biomedical literature is composed of a large and ever increasing number of publications, written in natural language. Patents are a relevant fraction of these publications, considered important sources of information due to all the curated information available in the documents, from the granting process. Although being real technological libraries, their unstructured data turns the search of information within these documents a challenging task. Biomedical text mining is a scientific field that explores this task, creating methodologies to search and structure the information in the biomedical literature.Information retrieval is one of the biomedical text mining tasks, in which the relevant information is obtained from an extensive collection of documents using several text retrieval methodologies. Getting all the information available on a patent document requires the download of the respective PDF document, that is then converted into a machine-readable text by technologies as Optical Character Recognition (OCR).In this project, an information retrieval, and a PDF to text conversion system were developed building a “patent pipeline” which was integrated into @note2, an open-source computational framework for biomedical text mining. The patent pipeline can be disintegrated into four different tasks: the patent search, the retrieval of patent metadata, the retrieval of their PDF files, and the extraction of all the information from these documents.A set of patents from the BioCreative V CHEMDNER task was used to test the developed pipeline, evaluating the framework performance and the real capacity to retrieve the requested patents and extract their unstructured information. The results were promising, bringing to the scientific community the published patent information and allowing the posterior implementation of other biomedical text mining processes over these documents.",
    "text2": "Social networks have allowed, over the past few years, the appearance of new ways to shareopinions and ideas in texts, providing a basis for studying opinions on a large scale. The tools for the retrieval and analysis of sentiments, contained in this information, are still underdevelopment, limited by access restrictions and technical difficulties in the development ofnew methods, which involve natural language processing and text mining. This work aimsto develop tools to recover and analyze sentiments present in social networking texts.A case study using Twitter will be used for validation. During this process, data obtained from this social network was stored in a document oriented database, Elasticsearch,organized by topics helping its use in the following phases. Then, the data went througha set of pre-processing steps, to maximize the value of their content, seeking to improvethe chances of obtaining a correct classification. Finally, the processed textual data weresubmitted to the algorithm chosen for classification, Naive Bayes. The results obtained overtwo different datasets show that the pre-treatment of data is very important regarding tothe classification of sentiments in texts.Overall, a computational architecture has been developed that can foster sentiment analysis applications over social network data from Twitter",
    "similarity": 0.3165372404992375
  },
  {
    "text1": "Biomedical literature is composed of a large and ever increasing number of publications, written in natural language. Patents are a relevant fraction of these publications, considered important sources of information due to all the curated information available in the documents, from the granting process. Although being real technological libraries, their unstructured data turns the search of information within these documents a challenging task. Biomedical text mining is a scientific field that explores this task, creating methodologies to search and structure the information in the biomedical literature.Information retrieval is one of the biomedical text mining tasks, in which the relevant information is obtained from an extensive collection of documents using several text retrieval methodologies. Getting all the information available on a patent document requires the download of the respective PDF document, that is then converted into a machine-readable text by technologies as Optical Character Recognition (OCR).In this project, an information retrieval, and a PDF to text conversion system were developed building a “patent pipeline” which was integrated into @note2, an open-source computational framework for biomedical text mining. The patent pipeline can be disintegrated into four different tasks: the patent search, the retrieval of patent metadata, the retrieval of their PDF files, and the extraction of all the information from these documents.A set of patents from the BioCreative V CHEMDNER task was used to test the developed pipeline, evaluating the framework performance and the real capacity to retrieve the requested patents and extract their unstructured information. The results were promising, bringing to the scientific community the published patent information and allowing the posterior implementation of other biomedical text mining processes over these documents.",
    "text2": "Invasive fungal infections caused by Candida are associated with high mortality and morbidity rates in hospitalized patients. Iron plays a major role in these infections, as they are exacerbated underiron overload conditions. In this context, it is important to understand the association between iron levels and invasive fungal infections, as it can serve as an indicator of the severity of the disease, andeventually it can help establish measures to improve treatment efficacy.Nowadays, manually inferring these associations from biomedical documents is a time consuming task, due to the high amount of available scientific text data. As such, these tasks naturally benefit from the Biomedical Text Mining field, which includes a wide variety of methods for automatic extraction of high-quality information from biomedical text documents.In this work, relevant documents related to iron overload and fungal infections were retrieved from PubMed to build a corpus. Then, both Named Entity Recognition and Relation Extractionprocesses were executed using the @Note text mining tool. Finally, relevant sentences were manually extracted and a curated dataset with documents containing those sentences was created.Since the number of publications obtained about Candida and iron overload was very low, the analysis was made taking into account all fungi. A total of 15 publications were considered relevant and 168 relevant associations were extracted.Although associations of iron levels with both severity of infection and treatment efficacy were not extracted, it was possible to conclude that, in many cases, iron overload is a predictor for fungal infections, and patients’ iron levels highly affect treatment efficacy.The Biomedical Text Mining process described in the present thesis enabled the creation of a dataset of relevant biomedical publications containing interesting associations between fungal infections, drugs and associated diseases in a clinical context of iron overload, although in the future this process could be improved, especially regarding dictionaries, in order to obtain a higher number of relevant publications.",
    "similarity": 0.31821135475185747
  },
  {
    "text1": "Critical software can be potentially dangerous if not well verified, leading to serious failures. Accordingly, there is a need for improved validation and verification methods in order to have guarantees about the software final product. The aim of this project is to define a more linear and organized verification and validation plan to, formally, verify the most critical parts of the OBDH (On-Board Data Handling) subsystem of ITASAT, supported by the Alloy formal language.Alloy supports the description of systems whose state involves complex relational structure. The application of Alloy and Alloy Analyzer was motivated by the need for a formal specification that is more closely tailored to state-machines, and more amenable to automatic analysis. Structural and behavioural properties are described declaratively, by conjoining relations and constrains, making it possible to develop and analyze a model incrementally. Due to the high cost of using these methods, they are mainly used in the development of high-critical software where safety and security are crucial. This dissertation presents a set of guidelines for analysis and modelling of software systems which support the creation of a formal model and allow some extra behaviours such as synchronization, interruptions and flags. A new tool, ModelMaker, was developed in order to create models using these guidelines in a more interactive way.",
    "text2": "Risk assessment is an important topic for financial institution nowadays, especially in the context of loan applications or loan requests and credit scoring. Some of these institutions have already implemented their own custom credit scoring systems to evaluate their clients’ risk supporting the loan application decision with this indicator. In fact, the information gathered by financial institutions constitutes a valuable source of data for the creation of information assets from which credit scoring mechanisms may be developed.Historically, most financial institutions support their decision mechanisms on regression algorithms, however, these algorithms are no longer considered the state of the art on decision algorithms. This fact has led to the interest on the research of new types of learning algorithms from machine learning able to deal with the credit scoring problem.The work presented in this dissertation has as an objective the evaluation of state of the art algorithms for credit decision proposing new optimization to improve their performance. In parallel, a suggestion system on credit scoring is also proposed in order to allow the perception of how algorithm produce decisions on clients’ loan applications, provide clients with a source of research on how to improve their chances of being granted with a loan and also develop client profiles that suit specific credit conditions and credit purposes.At last, all the components studied and developed are combined on a platform able to deal with the problem of credit scoring through an experts system implemented upon a multi-agent system. The use of multi-agent systems to solve complex problems in today’s world is not a new approach. Nevertheless, there has been a growing interest in using its properties in conjunction with machine learning and data mining techniques in order to build efficient systems. The work presented aims to demonstrate the viability and utility of this type of systems for the credit scoring problem.",
    "similarity": 0.3298813681801758
  },
  {
    "text1": "Critical software can be potentially dangerous if not well verified, leading to serious failures. Accordingly, there is a need for improved validation and verification methods in order to have guarantees about the software final product. The aim of this project is to define a more linear and organized verification and validation plan to, formally, verify the most critical parts of the OBDH (On-Board Data Handling) subsystem of ITASAT, supported by the Alloy formal language.Alloy supports the description of systems whose state involves complex relational structure. The application of Alloy and Alloy Analyzer was motivated by the need for a formal specification that is more closely tailored to state-machines, and more amenable to automatic analysis. Structural and behavioural properties are described declaratively, by conjoining relations and constrains, making it possible to develop and analyze a model incrementally. Due to the high cost of using these methods, they are mainly used in the development of high-critical software where safety and security are crucial. This dissertation presents a set of guidelines for analysis and modelling of software systems which support the creation of a formal model and allow some extra behaviours such as synchronization, interruptions and flags. A new tool, ModelMaker, was developed in order to create models using these guidelines in a more interactive way.",
    "text2": "We are facing a period where software projects have a huge dimension involvingsmall resources, high risk and a wide range of available approaches. In thisscenario the Software Development Methodologies (SDMs) can prove to be auseful ally, but very dangerous and even fatal if misused. The big issue aroundthis matter is how to choose the appropriated SDM that ts a speci c project.In the given scope, this dissertation describes a framework for comparing SDMsdelivering a set of procedures that should be followed when the choice of anSDM is made. The dissertation approaches the framework by applying it to agroup of SDMs that were selected by their popularity and signi cance. Thisexercise is done to prove the concept of the framework and to provide a basecomparison, with each chosen SDM, that can, and should, be extended by thosewho choose to use the framework.The classi cation is achieved by de ning a scale that goes from total satisfactionto no satisfaction, with an intermediate level of partial satisfaction, that is appliedto a set of keys. These keys are based in SWEBOK (Software EngineeringBody Of Knowledge) that describes and explains the di erent Knowledge Areas(KA) stating their common issues and best practices. To explain the framework,the dissertation analyzes each KA and evaluates the selected SDMs byassessing how their approach complies with SWEBOK's knowledge areas, usingthe previous stated scale.The framework delivered can be enriched by its user who should provide weightsto each KA regarding the project in which the SDM will be used and previousexperiences",
    "similarity": 0.31054303180819565
  },
  {
    "text1": "Critical software can be potentially dangerous if not well verified, leading to serious failures. Accordingly, there is a need for improved validation and verification methods in order to have guarantees about the software final product. The aim of this project is to define a more linear and organized verification and validation plan to, formally, verify the most critical parts of the OBDH (On-Board Data Handling) subsystem of ITASAT, supported by the Alloy formal language.Alloy supports the description of systems whose state involves complex relational structure. The application of Alloy and Alloy Analyzer was motivated by the need for a formal specification that is more closely tailored to state-machines, and more amenable to automatic analysis. Structural and behavioural properties are described declaratively, by conjoining relations and constrains, making it possible to develop and analyze a model incrementally. Due to the high cost of using these methods, they are mainly used in the development of high-critical software where safety and security are crucial. This dissertation presents a set of guidelines for analysis and modelling of software systems which support the creation of a formal model and allow some extra behaviours such as synchronization, interruptions and flags. A new tool, ModelMaker, was developed in order to create models using these guidelines in a more interactive way.",
    "text2": "Software applications evolve over the years at a cost: their architecture modularity tends to be degraded. This happens mainly because software application maintenance often leads to architectural degradation. In this context, software architects need to elaborate strategies for detecting architectural degradation symptoms and thus maintaining the software architectural quality. The elaborations of these strategies often rely on tools with domain-specific languages (DSLs), which help them to specify software architecture rules. These tools also enforce the adherence of these rules in the evolving program. However, their adoption in mainstream software development is largely dependent on the usability of the language. Unfortunately, it is also often hard to identify their usability strengths and weaknesses early, as there is no guidance on how to objectively reveal them. Usability is a multi-faceted quality characteristic, which is challenging to quantify before a DSL is actually used by its stakeholders. There is even less support and experience on how to quantitatively evaluate the usability of DSLs used in software maintenance tasks. To this end in this dissertation, a usability measurement framework was developed based on the Cognitive Dimensions of Notations (CDN). The framework was evaluated both qualitatively and quantitatively using two textual DSLs for architecture rules in the context of two evolving object-oriented systems. The results suggested that the proposed metrics were useful: (1) to early identify the DSL usability limitations to be addressed, (2) to reveal specific features of the DSLs favoring software maintenance tasks, and (3) to successfully analyze eight usability dimensions that are critical in many DSLs. However, along with these results this evaluation also revealed that this kind of tools lack support for communication among the stakeholders, creating a gap in the software development. To solve this problem we proposed heuristics for tools that use DSLs for detecting architecture degradation symptoms. These heuristics will permit the exchange of information between the stakeholders, thereby, also increasing the tool usability. Finally, we chose TamDera as the tool to implement these heuristics in our study domain. Therefore, we implemented in the new version of TamDera the communication support for the stakeholders by using a new architecture and a new environment with the developed heuristics.",
    "similarity": 0.3271380005036515
  },
  {
    "text1": "E-commerce is constantly expanding, leading to greater market competitiveness. The number ofonline platforms offering products or services is increasing; so there is a growing need for companiesto stand out from the competition, which leads to the application of various marketing strategies.However, not all are adequate and mismanagement, as well as a bad investment of these strategies,may prejudice companies.Hence the implementation of recommendation systems in e-commerce platforms, as a safe andeconomical strategy. By investing in a good recommendation mechanism, one can provide betteruser experience, taking his interests into account. As a result, more traffic on the platforms isensured, which may result in a higher sales rate and, consequently, a higher number of revenues.However, to develop a recommendation system, the first step must consist in obtaining informationabout the sales platform, where data about its users and products/services form the basis of recom mendations. But not all information is useful, which can influence the accuracy of the forecastingmodels used by the system to produce results.Following this perspective, a data analysis methodology is proposed, as well as an architecture ofa recommendation system, which allows to extract and treat relevant data, in order to integrate arecommendation engine for most e-commerce platforms.",
    "text2": "The high growth in the use of digital identities creates the need to develop mechanismsthat can protect the personal data of each individual. The way identity is treated todayprevents each of us from being able to control our personal information. This is due to thecentralized architecture in which the personal data are inserted, that is, all these data are kepttogether and controlled by the entities responsible for providing the most varied services,which is wrong since the identity belongs to the person and thus it must be responsiblefor controlling that identity. Centralized identity management brings within itself severalproblems, whether intentional (that is, data correlation for profiling) or unintentional (thatis, data breach).To face this problem, multiple entities across the world are developing decentralizedidentity managment systems based on a self-sovereign identity architecture where eachindividual is responsible for managing and storing a set of credentials, each with parts oftheir personal information. A self-sovereign identity architecture allows users to provide onlysmall parts of their personal information or even to omit any type of personal identification,using cryptographic techniques like selective disclosure and zero-knowledge proofs, whichallows them to have more control over their privacy.Taking into account the current problems of digital identity, this dissertation aims toexplore the state of the art and develop a proof of concept, through the implementation ofa system based on self-sovereign identity, which is able to cover the use cases for digitalidentity. Thus, this document shows the architecture implemented, with a blockchain,responsible for the storage of all public data, and a user agent, responsible for facilitating allinteractions of the various users with the developed system.The proof of concept developed allows not only to validate that it is possible to correctmany of the problems associated with centralized identity management, but also to explorenew cryptographic strategies in order to improve the way each of us manages our ownidentity.",
    "similarity": 0.30384843688167795
  },
  {
    "text1": "Falls are one of the most common causes of injuries in the elderly population. As a result, treatment costs havealso increased. Recent efforts to restore lower limb function in these populations have seen an increase in theuse of wearable robotic systems, however, fall prevention measures in these systems require early detection ofloss of balance to be effective. In short, the development of technologies, such as a brain-computer interface, thatis capable of recognizing situations at risk of falling based on the loss of balance caused by several factors, isessential. Previous studies have investigated whether kinematic variables contain information about an impendingfall, but few have examined the potential of using electroencephalography (EEG) as a predictor of falling and howthe brain responds to prevent a fall. Perceived disturbances of balance are always accompanied by a specificcortical activation, called disturbance-evoked potential (PEP).In this study, the recognition of daily activities (walking, lifting, crouching, going up and down stairs) was alsopart of the initial objective, however, due to the challenges encountered, the object of study of the present workwas focused on the recognition and binary classification of the presence of loss of balance (PEPs) in brain signals.Thus, this dissertation intends to take the first steps toward the decoding of brain activity in response to imbalancedevents. Initially, to acquire the data, an experimental protocol was designed, so that the participants, using EEG,were submitted to gliding-like perturbations while walking on the treadmill. Two healthy subjects were exposed toa glide-like perturbation, and these perturbations occurred interspersed over a period lasting 30 to 60 seconds.Each subject performed 2 experiments, that is, perturbations provoked while the individual walked on the treadmill:i) at a speed of 1.6 km/h and ii) at a speed of 2.5 km/h.Based on the approached methods, the perturbation evoked potential (PEP) components were found between70-155 ms after the onset of the external perturbation. To decode pre-processed EGG data, four (4) artificial neuralnetworks were tested and different network architecture parameters and electrode layouts were compared. Overall,the convolutional neural network trained to predict EEG balance disturbances had a far superior classificationperformance than the other architectures, whose mean accuracy was 91.51 ˘ 2.91%, using a short windowlength of 200 ms. The electrode layout composed of 5 channels (Fz, C3, Cz, C4, and Pz) presented the shortestexecution time to train the model, whose average value was 196 ˘ 44.24ms. In addition, it was possible to verifythat the use of a single electrode (Cz) obtained satisfactory precision results (86.47 +/- 0.03%). These discoveriesmay contribute to the development of a system capable of detecting equilibrium disturbances in real-time.",
    "text2": "Falls represent one of the biggest causes of deaths related to unintentional injuries. The increasing numberof occurrences is associated a continuously expanding elderly population, along with its detrimental effectson the survival and well-being of those aged 65 and above, has turned the issue of falls into a globalpublic health concern. It is estimated that 684,000 people worldwide lose their lives due to falls, whichhappen approximately 37.3 million times annually. As a result, the financial expenses associated withhospitalisations are significant and present a complex challenge.The Electroencephalogram (EEG) technique is widely utilised to assess brain electrical activity anddetect indicators of balance disruptions, such as Perturbation Evoked Potentials (PEPs), in brain signals.This is possible because EEG data provides insights into motor planning and intention, making it a valuabletool for monitoring both falls and Activities of Daily Living (ADLs). Accordingly, this dissertation will establishtwo experimental protocols: one for simulating slip-like incidents and another for ADLs, with the aim ofcollecting EEG data. The primary goal of this dissertation is to leverage Artificial Intelligence (AI)-basedsystems to identify slip-like perturbations and various ADLs using the data from both protocols. The ultimateobjective is to integrate these algorithms into assistive robotic devices, e.g. exoskeletons.In the context of the methods employed, the PEP components were identified within a time frameof 75–137 ms after the external perturbation onset. To analyse the pre-processed EEG data, four distinctartificial neural networks were evaluated, each with varying network architecture parameters. Among thesearchitectures, the Convolutional Neural Network (CNN)-Long Short-Term Memory (LSTM) model, trainedto predict EEG perturbations, exhibited superior classification performance, achieving an accuracy rate of86% when using a short time window of 100 ms. In contrast, for classifying ADL, the best result obtainedwas 53% accuracy, and this was also achieved using the CNN-LSTM architecture.",
    "similarity": 0.31232385884620023
  },
  {
    "text1": "Os dispositivos móveis, em particular os tablets e smartphones, alcançaram uma enormepopularidade ao longo dos últimos anos devido à sua grande versatilidade e multifuncionalidade,conquistando deste modo, meritoriamente um espaço de destaque no nosso dia-a-dia, tanto anível pessoal como profissional. Neste contexto, os utentes das bibliotecas da Universidade doMinho não são uma exceção, e os SDUM (Serviços de Documentação da Universidade do Minho)no cumprimento da sua missão, definiu como uma das linhas gerais proporcionar aos utentesuma melhor qualidade de assistência, com o desenvolvimento de uma aplicação móvel de gestãode empréstimos e reservas de publicações em posse.Contudo, existe um ainda um grande entrave no mercado do desenvolvimento de aplicações paradispositivos móveis, devido à sua fragmentação em termos de plataformas móveis utilizadas (iOs,Android, Windows Phone, etc.). Esta diversificação exige um maior esforço no desenvolvimentodas aplicações, de modo que obriga o desenvolvimento das mesmas para cada plataforma móvelem particular. É neste sentido que as abordagens de desenvolvimento multiplataforma ganharamrelevância, permitindo o desenvolvimento de aplicações para várias plataformas a partir de umúnico código fonte.O principal objetivo desta dissertação é desenvolver uma aplicação de apoio a gestão deempréstimos e reservas nas bibliotecas da Universidade do Minho. Os objetivos intercalados são:realização de estudos sobre as abordagens e ferramentas de desenvolvimento multiplataforma,adotar métodos de engenharia de requisitos e conceção, implementação e teste da solução final(fundamental no processo de correção de falhas, de modo que a permitir uma solução final commaior qualidade). A primeira fase do modelo de processo de engenharia de requisitos consiste nolevantamento/definição e priorização de requisitos, que tem como objetivo conhecer as técnicasde levantamento, assim como identificar e aplicar as que melhor se adequam a este projeto. Apósa execução da fase de Analise e negociação, efetuou-se a documentação dos requisitos a um nívelde detalhe apropriado, como consta no Anexo B – Documento de Especificação de Requisitos.",
    "text2": "Com o crescimento significativo de utilizadores de dispositivos móveis, nos últimos anos,mais do que a necessidade apareceu a oportunidade de criar novas plataformas e serviçosdigitais que não só facilitam o quotidiano das pessoas, evitando deslocamentos, filas deespera e complicações desnecessárias, como tornam a comunicação das pessoas com asinstituições num processo mais rápido e cómodo. Como tal, estas alternativas estão gradualmentea complementar, em alguns casos mesmo a substituir, os métodos antigos.Esta dissertação propõe uma solução digital, na forma de uma aplicação móvel, para aproximaras populações às suas instituições públicas recorrendo a gamification, isto é, transformandoo processo de comunicação com uma Câmara Municipal ou Junta de Freguesia,por exemplo, recorrendo ao uso de elementos de jogos como conquistas, atribuição derecompensas, classificações, entre outras, com o objetivo de estimular a comunicação doutilizador com essas instituições permitindo que este possa ao mesmo tempo divertir-see competir com os outros, enquanto explora e ajuda a sua cidade. Para tal, além de umserviço de participação de ocorrências na cidade, os utilizadores têm à sua disposição todauma narrativa que os leva a completar missões, participar em eventos e conhecer gentenova bem como a conhecer verdadeiramente a sua própria cidade. Por sua vez, a instituiçãopública responsável pela manutenção e administração do sistema tem à sua disposição umaplataforma de administração para manter o conteúdo da aplicação atualizado para os seusutilizadores.No decorrer desta dissertação está documentado todo o processo de desenvolvimento daaplicação móvel e do servidor web, que a suporta, assim como todas as decisões tomadase as razões que as justificam. O documento contém, ainda, exemplos e explicações do funcionamentoda aplicação, considerações finais sobre o projeto e ideias para trabalho futuro.Nas considerações finais é feita uma comparação dos objetivos inicialmente traçados parao projeto e o resultado alcançado, provando que os mesmos foram cumpridos com sucesso.",
    "similarity": 0.30385784744274036
  },
  {
    "text1": "With the widespread availability of high-throughput technologies, it is now possibleto study the behavior of dozens or even hundreds of gene/proteins through asingle experiment. Still, these experiments provide only the gene/protein expressionvalues, telling nothing about their interactions with each other. To understandthese interactions, network inference methods need to be applied. By understandingsuch interactions, new light can be shed into biological processes and, in particular,into disease’s mechanisms of action, providing new insights for drug design: whichgenes/proteins should be targeted in order to cure/prevent a specific disease.In this thesis, we developed and tested two alternative extensions for a previouslydeveloped model based on linear programming. Such model infers signal transductionnetworks from perturbation steady-state data. The extensions now developed takeadvantage of perturbation time-series data, which further improves the resolution ofcausal relationships between genes/proteins.In a first phase, we use artificial networks with simulated data to test the performanceof both extensions in different conditions. Additionally, we compare their performanceto the original model and to a state-of-the-art model for perturbation timeseriesdata, DDEPN. Overall, our second extension exhibits a better performance,and significantly higher sensitivity. This extension assumes a given gene/protein canonly influence its targets if it is in an active form.In a second phase, we use two experimental datasets related to ERBB signalingand evaluate the resulting networks: 1) by finding literature support for the inferrededges, and 2) by using a network assembled with Ingenuity IPA as true network todo a quantitative assessment. Our results are further compared to DDEPN and theoriginal model in a quantitative way. Quantitatively, our second model extension isshown to perform better than both the original model and DDEPN. Qualitatively,we find literature support for most of the inferred edges in both datasets, while alsoinferring a few plausible edges for which no literature evidence was found.",
    "text2": "The recent sequencing techniques and omics approaches are generating huge amounts of data that can provide ways to extract meaningful knowledge, by resorting to appropriate computational tools. One important technique resorts to the use of genome scale model reconstructions. These models are widely used in Metabolic Engineering, attempting to optimize an organism's functions, genetically modifying it to produce compounds of industrial interest.Another area that became widely important within the fields of Systems Biology and Bioinformatics was network analysis and visualization. Networks can provide a way to better understand the relationships between biological entities, by allowing their visual representation. However, biological networks usually comprise a large number of entities and interactions, that cannot be easily interpreted by the human eye. Integrating visualization and analysis is, therefore, a goal of high interest in several scientific areas, and this has been tackled by several visualization tools available. However, regarding the integration of metabolic engineering techniques with metabolic network visualization, there are still few examples of success. Usually, it is necessary to use more than one tool and the agility of the methods is limited.In this work, a metabolic network visualization framework is presented, with the goal of being a tool that will help researchers in metabolic engineering projects. This framework is divided in two layers: the first deals with the importation and exportation of networks in different formats, while the other layer provides all the visualization and edition features. A metabolic layout is based on the reactions contained in the metabolic model, and it can represent just a part of the metabolism of an organism. To have the possibility to use the same layout in different models, a strategy was defined to map the entities of the visualization with the entities of the model. The layouts are displayed in a bipartite graph, with different node types and colors. It is possible to visualize additional information of the network by clicking the nodes. Some of the features include dragging, zooming and highlighting. On top of all this, it is also possible to apply filters and overlap information over these networks. The filters can change what is visible in the network, while the overlaps allow defining new labels, colors and shapes to the nodes, and new colors and thickness to the edges. Finally, the framework was also integrated within OptFlux, an open-source software to support metabolic engineering available at www.optflux.org, to provide a connection between visualization and metabolic simulation methods.",
    "similarity": 0.328972066714449
  },
  {
    "text1": "In today’s world the utilization of Deep Learning (DL) is intrinsically integrated in the activity of severalenterprises and industries. It allows us to extract knowledge from data, detect patterns and make pre dictions, increasing the competitivity and quality of the services provided. However, the DL frameworks(e.g., TensorFlow, PyTorch, Apache MxNet) require not only considerable of computational power, but alsoefficient data storage, since they need to deal with large amounts of data. In particular, in each iteration ofthe DL model train different batches of the training dataset are accessed to be processed and incorporatedin the model. The retrieval of this data can be a bottleneck to the performance of the system, since thedatasets are getting increasingly bigger, reaching sizes in the order of TBs.In the case of multi-node DL this becomes increasingly critical since there are many compute nodestraining models, possibly with the same dataset, resulting in more requests directed to the shared filesystem competing with each other. If data could be stored nearer to the computational nodes and thosenodes shared the data with one another, it would reduce the I/O pressure in the shared storage systemand potentially reduce the time taken by these accesses and, consequently, the training time.This thesis presents DistMonarch, a DL framework agnostic system that takes advantage of the storagesystem hierarchy by copying data to levels closer to each compute node and allows the nodes to sharedata with each other, in a transparent manner. Results show that using this system reduces accesses tothe shared file system by up to 90% and training time of some models and configurations by up to 48%.",
    "text2": "Deep Learning (DL) has become fundamental to the advancement of several areas, such as computervision, natural language processing and expert systems. Utilizing DL techniques demands vast amountsof data and processing power, which raises challenges to the training performance of DL models. High Performance Computing (HPC) systems are becoming increasingly popular to support DL training, byoffering extensive computing capabilities, however, due to convenience and usability, many DL jobs runningon these infrastructures resort to the shared Parallel File System (PFS) for storing and accessing trainingdata. Under such scenario, where multiple Input/Output (I/O)-intensive applications operate concurrently,the PFS can quickly get saturated with simultaneous storage requests and become a critical performancebottleneck, leading to throughput variability and performance loss.To solve these issues, this dissertation presents a storage middleware agnostic to any DL solution,Monarch, that deploys storage tiering to accelerate DL models’ training performance and decrease the I/Opressure imposed over the PFS. It leverages from existing storage tiers of supercomputers (e.g., computenode’s local storage, shared PFS), as well as the I/O patterns of DL solutions to improve data placementacross storage tiers. Furthermore, this middleware is non-intrusive and easily installed in HPC centers,thus enabling its wide adoption and applicability.The performance and applicability of Monarch are validated with the TensorFlow and PyTorch DLframeworks. Results show that, when the training dataset can only be partially stored at the local storagetier, Monarch decreases TensorFlow’s and PyTorch’s training time by up to 28% and 37% for I/O-intensivemodels, respectively. Furthermore, Monarch can reduce the number of I/O operations submitted to thePFS by up to 56%.",
    "similarity": 0.32659648140508046
  },
  {
    "text1": "With the rise of data, the creation of algorithms capable of using that data is an evolution that appearsnaturally. Taking advantage of those algorithms, impressive advances have been made in the abilityfor a computer to recognize objects. Nevertheless, even after all those advances, further ones can stillbe achieved.With the reduction of infrared cameras prices and at the same time the increase in the picture qualityof those same cameras, they are becoming reliable solutions for commercial applications. Theseimages provide an all new kind of information that is not available with the use of only the traditionalvisible light images. As such, in this work, it is tested if the additional usage of infrared images, incomplement with the visible image, has any kind of influence in the results for object detection fordifferent levels of illumination, in the interior of a vehicle.In order to test this influence, several tests are done in equivalent conditions and the results betweenusing infrared images and visible light images compared. In addition to that, there were also experimentsdone in the usage of both types of images at the same time as a way to improve detection.It was also documented the influence of some more traditional modifications over the images of thetraining set, such as data augmentation and changes in the number of classes.To keep the results of the experiments as comparable as possible, a training methodology wasplanned and used in all of the training processes of the algorithms.",
    "text2": "Nowadays, we have the ability to trace everything, to extract valuable data from wherever we want, all tokeep us connected and to improve our lifestyle. This huge amount of information, produced every day,needs to be treated, manipulated, and analysed, requiring convincing data structures to do so.Dataframes, regularly used worldwide, are powerful data structures used to analyse and manipulatedata of any kind. A Dataframe organizes data into a 2-dimensional table of rows and columns, similar toSQL tables or CSV files. Furthermore, it can span alongside thousands of computers or servers, makingit easier to work with huge amounts of data, called big data, using distributed systems and parallel computing.This Dataframe’s distributed nature led to the rise of distinct scalable and parallel Dataframe tools. Themost used Dataframe tool, pandas, only performs on sequential execution and has some limitations whenthere is the need to handle huge volumes of data, and some tools such as Modin, Polars, RAPIDS, andso forth, appeared in order to overcome those limitations. The vast offer of these scalable tools broughtthe need to make an analysis and comparison between these frameworks and pandas, studying theirbehaviour and results with different workflows. This comparison is not linear and there is a need to usea benchmarking tool, in order to produce a homogeneous and reliable evaluation of the different frameworks.To perform this analysis, we worked with several workflows, manipulating real and synthetically produceddata on distributed and parallel environments and on different hardware configurations.We designed and developed a benchmarking tool that supports a set of Dataframe frameworks, is flexibleto the addition of new frameworks, and is able to perform micro-benchmarking evaluation with the analysisof a group of individual and common operations used on data science, and macro-benchmarking evaluation with the analysis of workflows that represent a set of chained operations. Both of these evaluationsaggregate performance and energy consumption results for each framework.",
    "similarity": 0.30114265927977835
  },
  {
    "text1": "With the rise of data, the creation of algorithms capable of using that data is an evolution that appearsnaturally. Taking advantage of those algorithms, impressive advances have been made in the abilityfor a computer to recognize objects. Nevertheless, even after all those advances, further ones can stillbe achieved.With the reduction of infrared cameras prices and at the same time the increase in the picture qualityof those same cameras, they are becoming reliable solutions for commercial applications. Theseimages provide an all new kind of information that is not available with the use of only the traditionalvisible light images. As such, in this work, it is tested if the additional usage of infrared images, incomplement with the visible image, has any kind of influence in the results for object detection fordifferent levels of illumination, in the interior of a vehicle.In order to test this influence, several tests are done in equivalent conditions and the results betweenusing infrared images and visible light images compared. In addition to that, there were also experimentsdone in the usage of both types of images at the same time as a way to improve detection.It was also documented the influence of some more traditional modifications over the images of thetraining set, such as data augmentation and changes in the number of classes.To keep the results of the experiments as comparable as possible, a training methodology wasplanned and used in all of the training processes of the algorithms.",
    "text2": "The continuous social and economic development has led, over time, to an increase inconsumption, as well as a greater demand from the consumer for what he buys. In thissense retailers have the need to respond to these challenges and explore new opportunities.Naturally, the selling price of a product assumes a fundamental role in the purchasedecision, and in that way the retailers must carefully analyze and define the best price foreach product, based on several factors, such as: perceived value of the product, positioningof the product, the company strategy, competition.Faced with all these challenges, the use of Information Systems is essential for retailers sothat it can support them in the pricing decision. These information systems are becomingincreasingly complex, including demand forecasts, and making recommendations based onbalanced buying patterns due by the economic evolution of markets.In a first phase the ideia was to make a study on two main price recommendation systems:Rules Motors and Price Optimization. As the objective of the dissertation is to change thealgorithm of Regular Price Optimization of the software tool Profimetrics, part of the studywas conducted according to the methodology of the tool. After an analysis of the company’scurrent algorithm, the changes were made to perfect it. Subsequently, we used the casestudy methodology, in the application of the algorithm developed to a retail company.Through this case study it was possible to make a brief diagnosis in order to comparethe current algorithm of the company with the developed algorithm.",
    "similarity": 0.3034489056649722
  },
  {
    "text1": "With the rise of data, the creation of algorithms capable of using that data is an evolution that appearsnaturally. Taking advantage of those algorithms, impressive advances have been made in the abilityfor a computer to recognize objects. Nevertheless, even after all those advances, further ones can stillbe achieved.With the reduction of infrared cameras prices and at the same time the increase in the picture qualityof those same cameras, they are becoming reliable solutions for commercial applications. Theseimages provide an all new kind of information that is not available with the use of only the traditionalvisible light images. As such, in this work, it is tested if the additional usage of infrared images, incomplement with the visible image, has any kind of influence in the results for object detection fordifferent levels of illumination, in the interior of a vehicle.In order to test this influence, several tests are done in equivalent conditions and the results betweenusing infrared images and visible light images compared. In addition to that, there were also experimentsdone in the usage of both types of images at the same time as a way to improve detection.It was also documented the influence of some more traditional modifications over the images of thetraining set, such as data augmentation and changes in the number of classes.To keep the results of the experiments as comparable as possible, a training methodology wasplanned and used in all of the training processes of the algorithms.",
    "text2": "Computer networks security is becoming an important and challenging topic. In particular, onecurrently witnesses increasingly complex attacks which are also bound to become more and moresophisticated with the advent of artificial intelligence technologies.Intrusion detection systems are a crucial component in network security. However, the limitednumber of publicly available network datasets and their poor traffic variety and attack diversity are amajor stumbling block in the proper development of these systems.In order to overcome such difficulties and therefore maximise the detection of anomalies in thenetwork, it is proposed the use of Adversarial Deep Learning techniques to increase the amount andvariety of existing data and, simultaneously, to improve the learning ability of the classification modelsused for anomaly detection.This master’s dissertation main goal is the development of a system that proves capable of improving the detection of anomalies in the network through the use of Adversarial Deep Learning techniques,in particular, Generative Adversarial Networks. With this in mind, firstly, a state-of-the-art analysis anda review of existing solutions were addressed. Subsequently, efforts were made to build a modular solution to learn from imbalanced datasets with applications not only in the field of anomaly detection inthe network, but also in all areas affected by imbalanced data problems. Finally, it was demonstratedthe feasibility of the developed system with its application to a network flow dataset.",
    "similarity": 0.3006339228638398
  },
  {
    "text1": "Internet of Things (IoT) systems generate massive amounts of time series data that need to be storedfor historical analysis. As a result, Database Management Systems (DBMSs) for these scenarioshave particular requirements in their ability to ingest large amounts of data and to optimise aggregation,filtering and time-ranged queries over this data, which are essential for historical analysis.Through the use of Fog Computing, combining both Edge and Cloud layers, it is possible to achievereduced latency and increased scalability, privacy and connectivity through the Edge, while still benefitingfrom the enhanced computing and storage power of the Cloud. This has led to the development of FogDBMSs. Database benchmarking allows standardising performance assessment and comparison of different solutions. However, current time series database benchmarking tools are not designed for multi-layer architectures, such as the ones used by Edge-Cloud hybrid DBMSs. This thesis proposes MulletBench, a benchmarking tool that is able to evaluate the internal load balancing capabilities of a multi-layer Time Series Database Management System (TSDBMS). This is achieved by integrating automated deployment features, per-node and per-layer performance and system resource metrics, allowing for a more detailed analysis of the SUTs’ performance than previously possible. The performance of InfluxDB and IoTDB is evaluated using the developed tool, comparing their performance in multiple workloads and deployment scenarios. Results show that the Edge layer can be used to improve performance by distributing the workload over multiple layers and performing downsampling at the Edge layer, increasing overall throughput and reducing latency at the Cloud. These conclusions are enabled by MulletBench’s novel features, and would not have been possible with previously existing solutions.",
    "text2": "The Edge Computing paradigm aims at leveraging the computational and storage capabilities of Internet of Things (IoT) devices, while resorting to Cloud Computing services for more demanding processingtasks that cannot be done at commodity devices. However, deploying distributed services across Edgeand Cloud nodes raises new challenges that must be addressed. Namely, the choice of what nodes runeach service component may be critical for ensuring an efficient service for users. For example, if twocritical components, that must frequently exchange data, are placed in different geographic locations, thewhole performance of the service will be affected. Therefore, these geographically dispersed environmentsdemand new orchestration and distribution systems for hybrid Cloud and Edge environments, based ongeographic location, service demand, business objectives, laws, and regulations.This thesis proposes Geolocate, a generic scheduler for workload orchestration and distribution acrossheterogeneous and geographically distant nodes. In more detail, it provides the design and implementationof a scheduling and placement algorithm based on nodes’ geographic location and resource availabilityand a fully functional prototype, integrating Geolocale with KubeEdge, an edge computing orchestrationplatform based on Kubernetes.The experimental results show that as the network latency and amount of data being transmittedbetween nodes increases, so does the response time for applications resorting to these distributed deployments. Our evaluation of an e-commerce application shows that the use of Geolocate can reduce, relativeto KubeEdge’s default-scheduler, the average response time for requests by about 85%.",
    "similarity": 0.30960295475530936
  },
  {
    "text1": "Internet of Things (IoT) systems generate massive amounts of time series data that need to be storedfor historical analysis. As a result, Database Management Systems (DBMSs) for these scenarioshave particular requirements in their ability to ingest large amounts of data and to optimise aggregation,filtering and time-ranged queries over this data, which are essential for historical analysis.Through the use of Fog Computing, combining both Edge and Cloud layers, it is possible to achievereduced latency and increased scalability, privacy and connectivity through the Edge, while still benefitingfrom the enhanced computing and storage power of the Cloud. This has led to the development of FogDBMSs. Database benchmarking allows standardising performance assessment and comparison of different solutions. However, current time series database benchmarking tools are not designed for multi-layer architectures, such as the ones used by Edge-Cloud hybrid DBMSs. This thesis proposes MulletBench, a benchmarking tool that is able to evaluate the internal load balancing capabilities of a multi-layer Time Series Database Management System (TSDBMS). This is achieved by integrating automated deployment features, per-node and per-layer performance and system resource metrics, allowing for a more detailed analysis of the SUTs’ performance than previously possible. The performance of InfluxDB and IoTDB is evaluated using the developed tool, comparing their performance in multiple workloads and deployment scenarios. Results show that the Edge layer can be used to improve performance by distributing the workload over multiple layers and performing downsampling at the Edge layer, increasing overall throughput and reducing latency at the Cloud. These conclusions are enabled by MulletBench’s novel features, and would not have been possible with previously existing solutions.",
    "text2": "Nowadays, most companies resort to data analytics frameworks to extract value from theincreasing amounts of digital information. These systems give substantial competitive ad vantages to companies since they allow to support situations such as possible marketingdecisions or predict user behaviors.Therefore, organizations tend to leverage the cloud to store and perform analytics overthe data. Database services in the cloud present significant advantages as a high levelof efficiency and flexibility, and the reduction of costs inherent to the maintenance andmanagement of private infrastructures. The problem is that these services are often a targetfor malicious attacks, which means that sensitive and private personal information can becompromised.The current secure analytical processing solutions use a limited set of cryptographictechniques or technologies, which makes it impossible to explore different trade-offs ofperformance, security, and functionality requirements for different applications. Moreover,these systems also do not explore the combination of multiple cryptographic techniquesand trusted hardware to protect sensitive data.The work presented here addresses this challenge, by using cryptographic schemes andthe Intel SGX technology to protect confidential information, ensuring a practical solutionwhich can be adapted to applications with different requirements. In detail, this dissertationbegins by exposing a baseline study about cryptographic schemes and the Intel SGX tech nology, followed by the state-of-the-art revision about secure data analytics frameworks.A new solution based on the Apache Spark framework, called SafeSpark, is proposed. Itprovides a modular and extensible architecture and prototype, which allows protecting in formation and processing analytical queries over encrypted data, using three cryptographicschemes and the SGX technology. We validated the prototype with an experimental evalu ation, where we analyze the performance costs of the solution and also its resource usage.For this purpose, we use the TPC-DS benchmark to evaluate the proposed solution, andthe results show that it is possible to perform analytical processing on protected data witha performance impact between 1.13x and 4.1x.",
    "similarity": 0.3000453720508167
  },
  {
    "text1": "Internet of Things (IoT) systems generate massive amounts of time series data that need to be storedfor historical analysis. As a result, Database Management Systems (DBMSs) for these scenarioshave particular requirements in their ability to ingest large amounts of data and to optimise aggregation,filtering and time-ranged queries over this data, which are essential for historical analysis.Through the use of Fog Computing, combining both Edge and Cloud layers, it is possible to achievereduced latency and increased scalability, privacy and connectivity through the Edge, while still benefitingfrom the enhanced computing and storage power of the Cloud. This has led to the development of FogDBMSs. Database benchmarking allows standardising performance assessment and comparison of different solutions. However, current time series database benchmarking tools are not designed for multi-layer architectures, such as the ones used by Edge-Cloud hybrid DBMSs. This thesis proposes MulletBench, a benchmarking tool that is able to evaluate the internal load balancing capabilities of a multi-layer Time Series Database Management System (TSDBMS). This is achieved by integrating automated deployment features, per-node and per-layer performance and system resource metrics, allowing for a more detailed analysis of the SUTs’ performance than previously possible. The performance of InfluxDB and IoTDB is evaluated using the developed tool, comparing their performance in multiple workloads and deployment scenarios. Results show that the Edge layer can be used to improve performance by distributing the workload over multiple layers and performing downsampling at the Edge layer, increasing overall throughput and reducing latency at the Cloud. These conclusions are enabled by MulletBench’s novel features, and would not have been possible with previously existing solutions.",
    "text2": "Nowadays, we have the ability to trace everything, to extract valuable data from wherever we want, all tokeep us connected and to improve our lifestyle. This huge amount of information, produced every day,needs to be treated, manipulated, and analysed, requiring convincing data structures to do so.Dataframes, regularly used worldwide, are powerful data structures used to analyse and manipulatedata of any kind. A Dataframe organizes data into a 2-dimensional table of rows and columns, similar toSQL tables or CSV files. Furthermore, it can span alongside thousands of computers or servers, makingit easier to work with huge amounts of data, called big data, using distributed systems and parallel computing.This Dataframe’s distributed nature led to the rise of distinct scalable and parallel Dataframe tools. Themost used Dataframe tool, pandas, only performs on sequential execution and has some limitations whenthere is the need to handle huge volumes of data, and some tools such as Modin, Polars, RAPIDS, andso forth, appeared in order to overcome those limitations. The vast offer of these scalable tools broughtthe need to make an analysis and comparison between these frameworks and pandas, studying theirbehaviour and results with different workflows. This comparison is not linear and there is a need to usea benchmarking tool, in order to produce a homogeneous and reliable evaluation of the different frameworks.To perform this analysis, we worked with several workflows, manipulating real and synthetically produceddata on distributed and parallel environments and on different hardware configurations.We designed and developed a benchmarking tool that supports a set of Dataframe frameworks, is flexibleto the addition of new frameworks, and is able to perform micro-benchmarking evaluation with the analysisof a group of individual and common operations used on data science, and macro-benchmarking evaluation with the analysis of workflows that represent a set of chained operations. Both of these evaluationsaggregate performance and energy consumption results for each framework.",
    "similarity": 0.3011080332409972
  },
  {
    "text1": "Internet of Things (IoT) systems generate massive amounts of time series data that need to be storedfor historical analysis. As a result, Database Management Systems (DBMSs) for these scenarioshave particular requirements in their ability to ingest large amounts of data and to optimise aggregation,filtering and time-ranged queries over this data, which are essential for historical analysis.Through the use of Fog Computing, combining both Edge and Cloud layers, it is possible to achievereduced latency and increased scalability, privacy and connectivity through the Edge, while still benefitingfrom the enhanced computing and storage power of the Cloud. This has led to the development of FogDBMSs. Database benchmarking allows standardising performance assessment and comparison of different solutions. However, current time series database benchmarking tools are not designed for multi-layer architectures, such as the ones used by Edge-Cloud hybrid DBMSs. This thesis proposes MulletBench, a benchmarking tool that is able to evaluate the internal load balancing capabilities of a multi-layer Time Series Database Management System (TSDBMS). This is achieved by integrating automated deployment features, per-node and per-layer performance and system resource metrics, allowing for a more detailed analysis of the SUTs’ performance than previously possible. The performance of InfluxDB and IoTDB is evaluated using the developed tool, comparing their performance in multiple workloads and deployment scenarios. Results show that the Edge layer can be used to improve performance by distributing the workload over multiple layers and performing downsampling at the Edge layer, increasing overall throughput and reducing latency at the Cloud. These conclusions are enabled by MulletBench’s novel features, and would not have been possible with previously existing solutions.",
    "text2": "The trend of increasing size of datasets in storage-based applications has promoted the research of newmethods and technologies for efficiently storing, processing, and analyzing large amounts of data. As aresult, Log Structured Merge (LSM) Key-Value Stores (KVSs) have been highly adopted since theirdesign allows high write throughput and enforces sequential disk access patterns. Additionally, with theadvent of Non-Volatile Main Memory (NVMM), new storage technologies have emerged that offerfaster access times compared to traditional block-based storage devices, thus accelerating KVSs.However, while NVMM devices offer faster access to data, they are typically limited in capacity and areoften more expensive. To address this trade-off, contemporary storage solutions harness the capabilities ofheterogeneous storage devices in two fundamental manners: caching and tiering. In this dissertation, weshow that, on one hand, read-dominated workloads benefit from a caching approach, but their performancedegrades under tiering. On the other hand, for write-dominated workloads, the tiering approach presentsbetter performance, while storing the entire dataset on NVMM actually degrades performance.To overcome these challenges, this dissertation proposes KEIGO, a novel storage middleware that al lows LSM-based KVS to efficiently use storage hierarchies composed of NVMM and block-based devices.KEIGO is aware of the different I/O operations done by the KVS (e.g., foreground requests, and backgroundflushes and compactions) and the characteristics of the underlying devices (e.g., concurrency, read/writeasymmetry). This knowledge serves as a pivotal factor in optimizing KEIGO’s performance in the face ofdynamic and mixed production workloads such as those observed in Nutanix and Meta. Moreover, KEIGOrequires minimal code modifications to integrate into production-ready LSM KVSs.Conducted experiments show that KEIGO significantly enhances the throughput of LSM KVS solu tions, including RocksDB, Speedb, and LevelDB, by as much as 12.4×. Furthermore, it substantiallyreduces tail latency by up to 21.3× over both general-purpose storage solutions and LSM KVSs builtfrom the ground up for hierarchical storage.",
    "similarity": 0.3045186980609419
  },
  {
    "text1": "Internet of Things (IoT) systems generate massive amounts of time series data that need to be storedfor historical analysis. As a result, Database Management Systems (DBMSs) for these scenarioshave particular requirements in their ability to ingest large amounts of data and to optimise aggregation,filtering and time-ranged queries over this data, which are essential for historical analysis.Through the use of Fog Computing, combining both Edge and Cloud layers, it is possible to achievereduced latency and increased scalability, privacy and connectivity through the Edge, while still benefitingfrom the enhanced computing and storage power of the Cloud. This has led to the development of FogDBMSs. Database benchmarking allows standardising performance assessment and comparison of different solutions. However, current time series database benchmarking tools are not designed for multi-layer architectures, such as the ones used by Edge-Cloud hybrid DBMSs. This thesis proposes MulletBench, a benchmarking tool that is able to evaluate the internal load balancing capabilities of a multi-layer Time Series Database Management System (TSDBMS). This is achieved by integrating automated deployment features, per-node and per-layer performance and system resource metrics, allowing for a more detailed analysis of the SUTs’ performance than previously possible. The performance of InfluxDB and IoTDB is evaluated using the developed tool, comparing their performance in multiple workloads and deployment scenarios. Results show that the Edge layer can be used to improve performance by distributing the workload over multiple layers and performing downsampling at the Edge layer, increasing overall throughput and reducing latency at the Cloud. These conclusions are enabled by MulletBench’s novel features, and would not have been possible with previously existing solutions.",
    "text2": "File systems are widely used for storing digital information, as they offer abstractions thatallow data to be intuitively separated and organized through files and directories, accordingto the requirements of applications and users. The continuous growth of data volume andcomplexity leads to the constant evolution of these systems. However, the complexity ofintegration of new features and lack of continuous support, leads to many file systems notbeing adopted in practice.In this sense, stackable file systems have emerged, which allow the development of complexfile systems, providing existing systems with new functionalities through independentprocessing layers. Despite this, the development of these systems presents some challenges,namely in terms of speed of implementation, portability, and resilience, since they aredeveloped in kernel. In this way, later solutions emerged that allowed the development offile systems in user space, thus mitigating some of the problems identified in the developmentof this type of file systems. However, these solutions have not been properly explored in thedevelopment of remote file systems.Therefore, this dissertation presents RSafeFS, a platform that extends the SafeFS system toallow developing modular, flexible and extensible remote file systems in user space. Theproposed solution enables extensible remote file system implementations that adjust to therequirements of different types of applications and storage workloads. It was then necessaryto develop a layer that would allow an RSafeFS instance to operate as a system server, anda communication layer, based on remote procedure calls (RPCs), to allow interoperabilitybetween client and server instances. To demonstrate the ease of integration of new features,taking advantage of the modularity and flexibility of RSafeFS, the developed prototype wasequipped with two layers of caching, namely data and metadata, which aim to improvesystem peformance. The results obtained with this prototype reveal that the file systemsdeveloped through RSafeFS obtain performances comparable to remote storage solutionsbased on FUSE. Furthermore, with the processing layers developed it is possible to adjustthe system to different types of workloads, allowing, for example, to improve systemperformance by 1.5× in certain workloads.",
    "similarity": 0.30102052379753214
  },
  {
    "text1": "Atualmente, os sistemas críticos estão cada vez mais presentes no nosso dia-a-dia, fazendoaumentar a necessidade de os assegurar cada vez mais e reduzindo o risco de acidente oufalha. A industria espacial e automóvel são exemplos de indústrias que usam esses sistemase que necessitam de os ver assegurados. Consequentemente, têm de ser tomadas medidaspara garantir a segurança de um sistema ao nível de software e hardware.A injeção de falhas é uma das respostas a esse problema, fazendo uso das suas diferentestécnicas para poder avaliar e validar sistemas críticos. A injeção de falhas pode ser consideradauma técnica de teste ao software, onde as falhas podem ser injetadas ao nível do softwareou hardware e cujos resultados podem ser monitorizados de forma a avaliar como é que osistema reagiu a tais falhas. Scan-Chain Implemented Fault Injection é a técnica de injeçãode falhas que proporciona uma maior acessibilidade, observabilidade e controlabilidade. Comesta técnica, os níveis de hardware e de integração de sistemas podem ser validados.O csXception® é um ambiente de injeção de falhas automatizado desenvolvido pela CriticalSoftware S.A para avaliar e validar sistemas críticos. A sua arquitetura é dinâmica e baseadaem plug-ins de injeção de falhas. Devido à crescente presença dos microcontroladores ARM®Cortex-M3 na industria automóvel, surgiu a necessidade de criar um novo plug-in de injeçãode falhas para o csXception®.Assim, o objectivo principal desta dissertação de mestrado é o desenvolvimento de umnovo plug-in de injeção de falhas para o csXception®, que permita injetar falhas em microcontroladoresARM® Cortex-M3, contextualizar o novo plug-in com a norma ISO-26262 e utilizarum caso de estudo para mostrar alguns dos resultados obtidos.",
    "text2": "A evolução tecnológica das últimas décadas generalizou o uso de software para a substituição ou suporte de múltiplos processos das empresas e, evidenciou novas perspectivas para o desenvolvimento de soluções com altos níveis de performance, disponibilidade, escalabilidade e flexibilidade. No contexto Vortal (empresa líder no mercado de contratação electrónica português com a plataforma VortalNext>), esta generalização levou à necessidade da existência mecanismos que permitam aos seus clientes a personalização/criação de áreas de trabalho dedicadas.Tendo esta necessidade como foco, são avaliados os diferentes componentes da plataforma Next>, a metodologia de desenvolvimento atualmente utilizada (Model Driven Architecture) e quais as melhores aproximações para o desenvolvimento de aplicações no âmbito de uma plataforma web, focando as suas vantagens e desvantagens a nível arquitetural e aplicacional.Concluiu-se que todas as soluções estudadas são adequados ao desenvolvimento de aplicações web, sendo o seu grau de adequação variável com o contexto de utilização. São soluções diferentes relativamente à complexidade de implementação, aos recursos necessários, aos riscos envolvidos e à simplicidade de utilização por parte do grupo de utilizadores finais.Por fim, é apresentada a arquitetura de um Software Development Kit (são estudadas outras opções, sendo esta a que oferece mais estabilidade aplicacional e mais vantagens competitivas) e a sua integração no ecossistema aplicacional e arquitetural da plataforma maximizando, não apenas a flexibilidade e funcionalidade para o cliente final, como também a segurança, robustez e fiabilidade do ecossistema da plataforma. A arquitetura definida em conjunto com o modelo de negócio apresentado formam a linha de ação indicada para garantir a existência de aplicações personalizadas a serem executadas no ecossistema VortalNext>.",
    "similarity": 0.3063633215814656
  },
  {
    "text1": "Atualmente, os sistemas críticos estão cada vez mais presentes no nosso dia-a-dia, fazendoaumentar a necessidade de os assegurar cada vez mais e reduzindo o risco de acidente oufalha. A industria espacial e automóvel são exemplos de indústrias que usam esses sistemase que necessitam de os ver assegurados. Consequentemente, têm de ser tomadas medidaspara garantir a segurança de um sistema ao nível de software e hardware.A injeção de falhas é uma das respostas a esse problema, fazendo uso das suas diferentestécnicas para poder avaliar e validar sistemas críticos. A injeção de falhas pode ser consideradauma técnica de teste ao software, onde as falhas podem ser injetadas ao nível do softwareou hardware e cujos resultados podem ser monitorizados de forma a avaliar como é que osistema reagiu a tais falhas. Scan-Chain Implemented Fault Injection é a técnica de injeçãode falhas que proporciona uma maior acessibilidade, observabilidade e controlabilidade. Comesta técnica, os níveis de hardware e de integração de sistemas podem ser validados.O csXception® é um ambiente de injeção de falhas automatizado desenvolvido pela CriticalSoftware S.A para avaliar e validar sistemas críticos. A sua arquitetura é dinâmica e baseadaem plug-ins de injeção de falhas. Devido à crescente presença dos microcontroladores ARM®Cortex-M3 na industria automóvel, surgiu a necessidade de criar um novo plug-in de injeçãode falhas para o csXception®.Assim, o objectivo principal desta dissertação de mestrado é o desenvolvimento de umnovo plug-in de injeção de falhas para o csXception®, que permita injetar falhas em microcontroladoresARM® Cortex-M3, contextualizar o novo plug-in com a norma ISO-26262 e utilizarum caso de estudo para mostrar alguns dos resultados obtidos.",
    "text2": "O rápido crescimento da complexidade dos sistemas de software exige, agora mais do que nunca, uma validação rigorosa dos mesmos por forma a manter ou até mesmo aumentar a confiança nestes sistemas. Em particular nos sistemas críticos, onde as falhas podem ter consequências catastróficas podendo até incluir a perca de várias vidas humanas, é de externa importância o desenvolvimento de técnicas capazes de garantir altos níveis de confiança para estes sistemas.Nesta tese é proposta a utilização de uma técnica formal para a verificação de programas Ada, que pretende aumentar a confiança em sistemas cuja implementação seja realizada nesta linguagem de programação. Mais precisamente, pretende-se a aplicação da técnica de verificação de modelos para a análise do código fonte de programas concorrentes Ada, com especial foco para o domínio dos sistemas críticos.A verificação de modelos é uma técnica bem-sucedida no que diz respeito à garantia de um aumento de fiabilidade destes sistemas. No entanto, a aplicação desta técnica a sistemas de software enfrenta ainda vários obstáculos, e as ferramentas e técnicas para ajudar a ultrapassar estes obstáculos estão ainda a ser desenvolvidas. A ferramenta desenvolvida no contexto desta tese (ATOS) visa responder a problemas como (i) a construção de modelos a partir de programas e (ii) a especificação de propriedades para estes modelos de acordo com as pretendidas para os programas.A construção manual de modelos que simulam o comportamento de programas é um processo complexo, temporalmente dispendioso, e sujeito a falhas devido à complexidade destes sistemas. De forma a ultrapassar este problema o ATOS propõe a extração automática de modelos a partir de programas Ada. Por outro lado, o mapeamento das propriedades desejadas dos programas em propriedades dos modelos pode ser urna tarefa com um grau de complexidade elevado, pois requer entre outros a utilização de um formalismo logico ao qual a maioria dos programadores não está acostumada. 0 ATOS ajuda no mapeamento destas propriedades, oferecendo vários mecanismos de suporte à sua especificação.",
    "similarity": 0.31855299606356613
  },
  {
    "text1": "Atualmente, os sistemas críticos estão cada vez mais presentes no nosso dia-a-dia, fazendoaumentar a necessidade de os assegurar cada vez mais e reduzindo o risco de acidente oufalha. A industria espacial e automóvel são exemplos de indústrias que usam esses sistemase que necessitam de os ver assegurados. Consequentemente, têm de ser tomadas medidaspara garantir a segurança de um sistema ao nível de software e hardware.A injeção de falhas é uma das respostas a esse problema, fazendo uso das suas diferentestécnicas para poder avaliar e validar sistemas críticos. A injeção de falhas pode ser consideradauma técnica de teste ao software, onde as falhas podem ser injetadas ao nível do softwareou hardware e cujos resultados podem ser monitorizados de forma a avaliar como é que osistema reagiu a tais falhas. Scan-Chain Implemented Fault Injection é a técnica de injeçãode falhas que proporciona uma maior acessibilidade, observabilidade e controlabilidade. Comesta técnica, os níveis de hardware e de integração de sistemas podem ser validados.O csXception® é um ambiente de injeção de falhas automatizado desenvolvido pela CriticalSoftware S.A para avaliar e validar sistemas críticos. A sua arquitetura é dinâmica e baseadaem plug-ins de injeção de falhas. Devido à crescente presença dos microcontroladores ARM®Cortex-M3 na industria automóvel, surgiu a necessidade de criar um novo plug-in de injeçãode falhas para o csXception®.Assim, o objectivo principal desta dissertação de mestrado é o desenvolvimento de umnovo plug-in de injeção de falhas para o csXception®, que permita injetar falhas em microcontroladoresARM® Cortex-M3, contextualizar o novo plug-in com a norma ISO-26262 e utilizarum caso de estudo para mostrar alguns dos resultados obtidos.",
    "text2": "Atualmente, o maior desafio no desenvolvimento de software é referente à a portabilidade das aplicações para as várias plataformas disponíveis, especialmente pela crescente heterogeneidade nos componentes de hardware, de middleware e de software base.O desenho de modelos abstratos de software é uma das formas mais elegantes e eficientes para solucionar este desafio. A Model-Driven Software Engineering (MDSE) ́é uma metodologia de desenvolvimento em que os modelos são chave em todo o ciclo de vida do projeto, desde a captura de requisitos, passando pelas fases de modelação e desenvolvimento, e por fim nos processos de teste e instalação.O objetivo primário desta dissertação foca-se na construção de uma ferramenta, o MDA SMART, capaz de interpretar modelos abstratos de software, parametrizáveis, e de gerar automaticamente código fonte para várias plataformas. A ferramenta, caracterizada por uma arquitetura robusta e extensível, é idealizada para permitir a manipulação de modelosde forma ágil, para ser modular o suficiente para integrar novos perfis meta-modelo e para escalar eficientemente para novas plataformas.O MDA SMART resulta da articulação de uma Domain-Specific Language (DSL) para a gestão dos meta-modelos e consequentes processos de transformação. Na utilização da DSL são obtidos processos de transformação rigorosos, com elevado desempenho e que visam maximizar a consistência e portabilidade dos modelos através de medidas ajustadas a destoarem a heterogeneidade entre as plataformas. Adicionalmente, a ferramenta visa compatibilizar os modelos de lógica de negócio com os referentes às interfaces gráficas que, conjugados, vão permitir a obtenção de modelos e código fonte com alto nível de consistência e completude.",
    "similarity": 0.33368545086203333
  },
  {
    "text1": "Atualmente, os sistemas críticos estão cada vez mais presentes no nosso dia-a-dia, fazendoaumentar a necessidade de os assegurar cada vez mais e reduzindo o risco de acidente oufalha. A industria espacial e automóvel são exemplos de indústrias que usam esses sistemase que necessitam de os ver assegurados. Consequentemente, têm de ser tomadas medidaspara garantir a segurança de um sistema ao nível de software e hardware.A injeção de falhas é uma das respostas a esse problema, fazendo uso das suas diferentestécnicas para poder avaliar e validar sistemas críticos. A injeção de falhas pode ser consideradauma técnica de teste ao software, onde as falhas podem ser injetadas ao nível do softwareou hardware e cujos resultados podem ser monitorizados de forma a avaliar como é que osistema reagiu a tais falhas. Scan-Chain Implemented Fault Injection é a técnica de injeçãode falhas que proporciona uma maior acessibilidade, observabilidade e controlabilidade. Comesta técnica, os níveis de hardware e de integração de sistemas podem ser validados.O csXception® é um ambiente de injeção de falhas automatizado desenvolvido pela CriticalSoftware S.A para avaliar e validar sistemas críticos. A sua arquitetura é dinâmica e baseadaem plug-ins de injeção de falhas. Devido à crescente presença dos microcontroladores ARM®Cortex-M3 na industria automóvel, surgiu a necessidade de criar um novo plug-in de injeçãode falhas para o csXception®.Assim, o objectivo principal desta dissertação de mestrado é o desenvolvimento de umnovo plug-in de injeção de falhas para o csXception®, que permita injetar falhas em microcontroladoresARM® Cortex-M3, contextualizar o novo plug-in com a norma ISO-26262 e utilizarum caso de estudo para mostrar alguns dos resultados obtidos.",
    "text2": "O recurso a ferramentas de geração automática de código permite economizar tempo quando se desenvolvem soluções de software, factor importante em questões de produtividade.Existe um conjunto de padrões de conceção [Gamma et al., 1995] que representam soluções genéricas para problemas relativos ao desenvolvimento de aplicações de software, numa perspetiva orientada aos objetos. Para cada um deles pode ser vista a sua estrutura de classes, métodos e relacionamentos, bem como as situações mais adequadas para a sua utilização. Bastará consultar o catálogo de padrões de conceção [Gamma et al., 1995] e utilizar aquele que mais se adequar à resolução de determinado problema que surja no desenvolvimento de um novo programa.A existência de uma aplicação de software capaz de fazer a geração automática do código associado aos padrões de conceção, agiliza o desenvolvimento de novas aplicações, porque fornece de imediato o respetivo código.O que se propõe com o desenvolvimento desta dissertação é uma solução de software, capaz de efetuar a geração automática de código para os padrões de conceção catalogados em [Gamma et al., 1995]. Juntamente com o programa desenvolvido, é também apresentado um levantamento do estado da arte sobre os padrões de conceção, considerando também situações atuaisda sua aplicabilidade. Em seguida, é descrita a especificação da aplicação elaborada, bem como o seu processo de desenvolvimento, acompanhado de um exemplo de utilização. Por fim, encontram-se dois casos de estudo, servindo para provar que o programa elaborado pode ser utilizado em contextos reais.",
    "similarity": 0.3124262314825967
  },
  {
    "text1": "Microglia are a type of glial cell residing in the central nervous system and represent about 10 to15% of the brain cell population. These cells don’t produce electrical impulses and are responsible forfundamental physiological and pathological processes, as they represent the first line of immune defencewithin the central nervous system. Thus, the quantification of these cells is essential in a clinical context,as it allows better monitoring and planning of treatments for different pathologies.Conventional cell counting involves a specific set of tools and devices developed for this purpose.This process is time-consuming and imprecise due to being heavily dependent on the operator. Currently,most processes are performed manually. However, other approaches have been studied and developedto improve the counting process, making it less time-consuming, more efficient and reduce the errorassociated with factors external to the counting. That said, the objective of this dissertation is to study thebest approach to automate the quantification of microglial cells, ranging from classical to deep learningmethodologies. Combined with the appropriate image processing and analysis techniques, the classicalapproach proves to be an adequate solution. However, in recent years, approaches based on deep learninghave shown promising performance in various image analysis tasks, such as classification, detection andsegmentation.The approaches developed to automate the quantification process were tested on a set of images builtin partnership with researchers from the School of Medicine of the University of Minho. As for the classicalmethodology approach, a protocol was developed within ImageJ, which was combined with image processingtechniques that allowed the automation of the counting process. Based on Convolutional NeuralNetworks, the classification problem referring to a deep learning methodology obtained an accuracy of0.9021 and managed to classify the 661 images in 5 minutes and 44 seconds. The two approaches, consideredoptimal within each methodology, are competitive with the state-of-the-art methods, as they allowedfor the automation of the quantification process, and showed a significant improvement in reproducibility,efficiency and reduced error associated with human factors.",
    "text2": "Personalized medicine is a constantly growing area. Important goals of this field are early diagnosis and the discovery of new personalized treatments. Gene expression data play a key role at this level, as variations in these data can often offer explanations for some phenotypes. To this end, Machine Learning (ML) models capable of predicting biologically relevant information, have been widely used. Deep Learning (DL) is a branch of ML that has become popular over the past few years. The increasing amounts of data that have been generated, and the growing use of this type of models in biomedical areas, have been accelerating the analysis of biological processes associated with cancer and other complex diseases.In this work, we focused on developing a framework that allows to create and evaluate distinct work-flows for the application of a variety of machine and deep learning models, working over gene expression data, including different options regarding data preprocessing pipelines, distinct ML and DL models, including traditional ML models, Dense Neural Networks, Convolutional Neural Networks and Variational Autoencoders. The framework has been validated using different case studies, where the data sources were two of the main repositories of gene expression data (TCGA and GTEx). The goal of each case study was to predict important variables for clinical application. A variety of models were developed and evaluated for each case study, generally with competitive performance. For the first case study, the task was to predict the type of cancer from TCGA data, and the best performing DL model was a dense neural network, being outperformed by a logistic regression model. In the second case, where the task was to predict the hypoxia score, the best DL model was a two dimensional convolutional neural network (2D CNN), being outperformed by the LightGBM model. As for the third case study, where the objective was to predict the aneuploidy score, the best model was an one dimensional convolutional neural network (1D CNN). For the fourth case, where the task was to predict body mass index, the best model was again a 1D CNN. Finally, in the fifth case study, where the main goal was to predict gene expression for a set of genes based on landmark genes, the best DL model was found by an 1D CNN, still slightly outperformed by linear regression. Some of the DL models developed in this work show promising results. However, these need to be improved in the future as they are not clinically applicable at this time. This framework can be reused for new problems and can be easily expanded.",
    "similarity": 0.3029447409157569
  },
  {
    "text1": "Microglia are a type of glial cell residing in the central nervous system and represent about 10 to15% of the brain cell population. These cells don’t produce electrical impulses and are responsible forfundamental physiological and pathological processes, as they represent the first line of immune defencewithin the central nervous system. Thus, the quantification of these cells is essential in a clinical context,as it allows better monitoring and planning of treatments for different pathologies.Conventional cell counting involves a specific set of tools and devices developed for this purpose.This process is time-consuming and imprecise due to being heavily dependent on the operator. Currently,most processes are performed manually. However, other approaches have been studied and developedto improve the counting process, making it less time-consuming, more efficient and reduce the errorassociated with factors external to the counting. That said, the objective of this dissertation is to study thebest approach to automate the quantification of microglial cells, ranging from classical to deep learningmethodologies. Combined with the appropriate image processing and analysis techniques, the classicalapproach proves to be an adequate solution. However, in recent years, approaches based on deep learninghave shown promising performance in various image analysis tasks, such as classification, detection andsegmentation.The approaches developed to automate the quantification process were tested on a set of images builtin partnership with researchers from the School of Medicine of the University of Minho. As for the classicalmethodology approach, a protocol was developed within ImageJ, which was combined with image processingtechniques that allowed the automation of the counting process. Based on Convolutional NeuralNetworks, the classification problem referring to a deep learning methodology obtained an accuracy of0.9021 and managed to classify the 661 images in 5 minutes and 44 seconds. The two approaches, consideredoptimal within each methodology, are competitive with the state-of-the-art methods, as they allowedfor the automation of the quantification process, and showed a significant improvement in reproducibility,efficiency and reduced error associated with human factors.",
    "text2": "The population density in the urban environment has increased significantly, consequentlyincreasing the number of vehicles and people on the public road. Possible monitoring ofthis flow allows better problem management, and the enhancement of solutions in a smartcity context, solutions that promote regular traffic in a city.This work presents a solution for counting vehicles and people in a video to use thesolution developed in cities of Portugal. The solution combines deep learning techniquesand traditional computer vision techniques, combining object detection, classification, ob ject tracking, and fingerprint concepts. For each concept is presented the state of the arttechniques and techniques used in similar problems.To choose the best fingerprint methods, a comparative study of different techniques wasproduced. With a dataset of vehicle and people images, the following techniques were con sidered: Fourier Transform, Scale Invariant Feature Transform (SIFT), Color Co-occurrenceHistogram (CCoH), and Autoencoders, of which CCoH showed better results.The solution pipeline consists of the YOLOv3 algorithm for the object detection part, hav ing the algorithm a convolutional neuronal network for object classification; Kalman Filterfor object tracking was chosen in conjunction with the CCoH technique for object finger print. The pipeline ends with the matching of the newly detected objects with previouslydetected objects, using the Hungarian algorithm for this correspondence.In order to extract features using the defined pipeline, a python library has been devel oped, allowing visualization of its operation and easy integration with video sources (videofiles and cameras). Object counting, area definition, line intersection, heatmap’s, and objectcollision are examples of features that can be obtained by the library.As a global solution, a web application was developed, including a frontend application,a backend, a relational database, and a service to perform video processing with the helpof the developed library. The web application is in use and in a production environment.",
    "similarity": 0.30067902248931877
  },
  {
    "text1": "Microglia are a type of glial cell residing in the central nervous system and represent about 10 to15% of the brain cell population. These cells don’t produce electrical impulses and are responsible forfundamental physiological and pathological processes, as they represent the first line of immune defencewithin the central nervous system. Thus, the quantification of these cells is essential in a clinical context,as it allows better monitoring and planning of treatments for different pathologies.Conventional cell counting involves a specific set of tools and devices developed for this purpose.This process is time-consuming and imprecise due to being heavily dependent on the operator. Currently,most processes are performed manually. However, other approaches have been studied and developedto improve the counting process, making it less time-consuming, more efficient and reduce the errorassociated with factors external to the counting. That said, the objective of this dissertation is to study thebest approach to automate the quantification of microglial cells, ranging from classical to deep learningmethodologies. Combined with the appropriate image processing and analysis techniques, the classicalapproach proves to be an adequate solution. However, in recent years, approaches based on deep learninghave shown promising performance in various image analysis tasks, such as classification, detection andsegmentation.The approaches developed to automate the quantification process were tested on a set of images builtin partnership with researchers from the School of Medicine of the University of Minho. As for the classicalmethodology approach, a protocol was developed within ImageJ, which was combined with image processingtechniques that allowed the automation of the counting process. Based on Convolutional NeuralNetworks, the classification problem referring to a deep learning methodology obtained an accuracy of0.9021 and managed to classify the 661 images in 5 minutes and 44 seconds. The two approaches, consideredoptimal within each methodology, are competitive with the state-of-the-art methods, as they allowedfor the automation of the quantification process, and showed a significant improvement in reproducibility,efficiency and reduced error associated with human factors.",
    "text2": "Parkinson’s Disease (PD) is a neurodegenerative disorder of the central nervous system. Resting tremor, akinesia, and bradykinesia (slow movements), rigidity, shuffling walking, and postural instabilityare some of the symptoms that not only negatively impacts patients’ life, but also the life of people aroundthem.Current approaches for monitoring patients’ motor autonomy are limited to the observer and self reported methods. The observer-based examinations, patients perform a set of standard PD examinations.The self-reported method relies on patients’ daily activities diaries. These approaches are commonly used,but are limited to a few sessions per year, they do not address common motor daily tasks, and their results are object of subjective interpretation by the clinical expert.By combining kinematic-driven data from wearable sensor with AI, the main goal of this dissertation is to develop an automatic software for recognition of human activities (e.g., walking, standing, turning, sitting, and lying) in PD to assist the clinical experts with objective and concrete data.A data collection protocol was developed and captured, resulting in a database comprised of data collected from eighteen PD patients who performed three trials of six different daily activities: walk; 180º turning; sit on chair; get up from chair; lay on bed and get up from bed.A Deep Learning (DL) framework based on Convolutional Neural Network capable of recognizing daily activities was developed and attained a performance of F1 Score equal to 0.90892.As a complementary goal an automatic software for human walk initial contact (IC) and final contact (FC) recognition using kinematic data was also developed. IC and FC are tremendously important to provide patient on-demand motor assistance and estimation of walking-associated metrics.A Deep Learning framework based on Bidirectional Long Short-Term Memory Neural Networkcapable of walking IC/FC events detection was developed and attained a performance of MCC Score equal to 0.538386.Promising results were attained for both DL frameworks, however, this dissertation suggests that there is still room for further improvements. Enriching the dataset with more data from different patient, data balancing and feature extraction techniques, experimenting new models’ architectures should be considered in future works.",
    "similarity": 0.30512113244753275
  },
  {
    "text1": "Microglia are a type of glial cell residing in the central nervous system and represent about 10 to15% of the brain cell population. These cells don’t produce electrical impulses and are responsible forfundamental physiological and pathological processes, as they represent the first line of immune defencewithin the central nervous system. Thus, the quantification of these cells is essential in a clinical context,as it allows better monitoring and planning of treatments for different pathologies.Conventional cell counting involves a specific set of tools and devices developed for this purpose.This process is time-consuming and imprecise due to being heavily dependent on the operator. Currently,most processes are performed manually. However, other approaches have been studied and developedto improve the counting process, making it less time-consuming, more efficient and reduce the errorassociated with factors external to the counting. That said, the objective of this dissertation is to study thebest approach to automate the quantification of microglial cells, ranging from classical to deep learningmethodologies. Combined with the appropriate image processing and analysis techniques, the classicalapproach proves to be an adequate solution. However, in recent years, approaches based on deep learninghave shown promising performance in various image analysis tasks, such as classification, detection andsegmentation.The approaches developed to automate the quantification process were tested on a set of images builtin partnership with researchers from the School of Medicine of the University of Minho. As for the classicalmethodology approach, a protocol was developed within ImageJ, which was combined with image processingtechniques that allowed the automation of the counting process. Based on Convolutional NeuralNetworks, the classification problem referring to a deep learning methodology obtained an accuracy of0.9021 and managed to classify the 661 images in 5 minutes and 44 seconds. The two approaches, consideredoptimal within each methodology, are competitive with the state-of-the-art methods, as they allowedfor the automation of the quantification process, and showed a significant improvement in reproducibility,efficiency and reduced error associated with human factors.",
    "text2": "Neurodegenerative diseases impair the functioning of the brain and are characterized by alterations in the morphology of specific brain regions. Some of the main disorders include Alzheimer's, Parkinson's, and Huntington's diseases, and the number of cases increases exponentially since ageing is one of the main risk factors. Trying to identify the areas in which this type of disease appears is something that can have a very positive impact in this area of Medicine and can guarantee a more appropriate treatment or allow the improvement of the quality of life of patients. With the current technological advances, computer tools are capable of performing a structural or functional analysis of neuroimaging data from Magnetic Resonance Images(MRI). Therefore, Medical Informatics uses these techniques to create and manage medical neuroimaging data to improve the diagnosis and management of these patients. MRI is the image type used in the analysis of the brain area and points to a promising and reliable diagnostic tool since it allows high-quality images in various planes or strategies and MRI methods are fundamental diagnostic tools in clinical practice, allowing the diagnosis of pathologic processes such as stroke or brain tumours. However, structural MRI has limitations for the diagnosis of neurodegenerative disorders since it mainly identifies atrophy of brain regions.Currently, there is increased interest in informatics applications capable of monitoring and quantifying human brain imaging alterations, with potential for neurodegenerative disorders diagnosis and monitoring. One of these applications is Radiomics, which corresponds to a methodolog ythat allows the extraction of features from images of a given region of the brain. Specific quantitative metrics from MRI are acquired by this tool, and they correspond to a set of features, including texture, shape, among others. To standardize Radiomics application, specific libraries have been proposed to be used by the bioinformatics and biomedical communities, such as PyRadiomics, which corresponds to an open source Python package for extracting Radiomics of MRIs.Therefore, this dissertation was developed based on magnetic resonance images and the study of DeepLearning (DL) techniques to assist researchers and neuroradiologists in the diagnosis and prediction of neurodegenerative disease development. Two different main tasks were made: first, a segmentation, using FreeSurfer, of different regions of the brain and then, a model was build from radiomic features extracted from each part of the brain and interpreted for knowledge extraction.",
    "similarity": 0.329419912009125
  },
  {
    "text1": "This document reports the development of a Master’s Thesis, included in the second yearof the Master’s Degree in Informatics Engineering at Universidade do Minho in Braga,Portugal. The main goal for this project was to identify which characteristics influence the recognition and identification of a programming language, considering both its typical source codeelements and its linguistic style. In other words, which elements contribute the most tothe characterization of a language? How many structural elements of a language may bemodified without losing its identity? In order to achieve these goals, a comprehensive bibliographic research was made, ranging from basic concepts such as programming languages and how they work, to several state-of-the-art studies that have been conducted in the same context of this project. Complementary to this research, a set of programming languages was also chosen as a study subject, which resulted in a detailed review and categorization of their characteristics.After the definition of a general approach, a survey was developed and conducted togather programmers’ answers on how they identify and recognize programming languages.In addition to the survey, a machine learning model was also used to evaluate how thesetwo facets (human versus machine) compared to each other. This dual approach providedinsights into which syntactic and semantic elements have a greater influence on the identityof a programming language. This Master’s project resulted in an overall picture of programming languages’ characteristics and the relative influence they have on both programmers’ and AI-driven recognition. This result may serve as support for language engineers and project managers who wish to reduce attrition when defining or designing new languages for a project, domain, or context.",
    "text2": "This document presents a Thesis and describes the underlying work which was developedalong the second year of the Master Degree in Informatics Engineering offered by Departamentode Informática of Universidade do Minho and accomplished at Syone SBS Software –Tecnologia e Serviços de Informática, S.A..In the past few years, some attempts to automatically screening CVs with resource toNatural Language Processing have been made not only to save recruiters’ time, but alsoto spare them the most tedious task of the recruitment process and, consequently, smooththeir job. However, the majority is still very primitive, misclassifies a lot of CVs and needs adeeper study.Therefore, the aim of this Master’s Project is precisely to develop an algorithm that iscapable of automatically ranking candidates’ CVs according to their similarity regarding thejob offer they applied for.Thus, a general architecture was proposed where CVs and job offers are preprocessed, inorder to obtain the respective texts proper to be further processed. That said, two differentapproaches were followed, in order to find the similarity between the documents in question.To do so, the first approach resorted to several Machine Learning algorithms and similaritymeasures, while the second approach structured the initial documents to compare theirrespective information.After that, tests were conducted to evaluate both approaches and enable the comparisonbetween them. Finally, the conclusions were drawn and also reported in this dissertation.",
    "similarity": 0.3229429306348578
  },
  {
    "text1": "This document reports the development of a Master’s Thesis, included in the second yearof the Master’s Degree in Informatics Engineering at Universidade do Minho in Braga,Portugal. The main goal for this project was to identify which characteristics influence the recognition and identification of a programming language, considering both its typical source codeelements and its linguistic style. In other words, which elements contribute the most tothe characterization of a language? How many structural elements of a language may bemodified without losing its identity? In order to achieve these goals, a comprehensive bibliographic research was made, ranging from basic concepts such as programming languages and how they work, to several state-of-the-art studies that have been conducted in the same context of this project. Complementary to this research, a set of programming languages was also chosen as a study subject, which resulted in a detailed review and categorization of their characteristics.After the definition of a general approach, a survey was developed and conducted togather programmers’ answers on how they identify and recognize programming languages.In addition to the survey, a machine learning model was also used to evaluate how thesetwo facets (human versus machine) compared to each other. This dual approach providedinsights into which syntactic and semantic elements have a greater influence on the identityof a programming language. This Master’s project resulted in an overall picture of programming languages’ characteristics and the relative influence they have on both programmers’ and AI-driven recognition. This result may serve as support for language engineers and project managers who wish to reduce attrition when defining or designing new languages for a project, domain, or context.",
    "text2": "This document is a report for the final project of the Master’s in Informatics Engineeringdegree, accomplished at Universidade do Minho in Braga, Portugal.The project consists, in a first phase, on the study of many snapshots of programs archivedby Nuno Fonseca for his doctoral Thesis \"Contributos para a Monitorização do Desempenho deEstudantes de Programação\" at the Universidade de Coimbra.This study’s main goal is to analyse the code snapshots and explore as much as possible theknowledge that can be extracted from that repository in order to understand the students’behavior while solving problems by computer.The research begins with the gathering and analysis of different types of tools whose purposeis to analyze code, both to assist students in learning and to help teachers in evaluation.After this research, the data provided by professor Nuno Fonseca is deeply analysed andadapted to fit this project’s requirements and fulfill the proposed goals.Finally, a web application that allows the teacher to conduct a comprehensive and systematicanalysis of the learning progression of their students was developed. All documentationassociated with this application was also produced.The outcomes of this thesis are expected to contribute to the field of code teaching tools,with the research made in this field and the resulting web application.",
    "similarity": 0.30194051611022016
  },
  {
    "text1": "This document reports the development of a Master’s Thesis, included in the second yearof the Master’s Degree in Informatics Engineering at Universidade do Minho in Braga,Portugal. The main goal for this project was to identify which characteristics influence the recognition and identification of a programming language, considering both its typical source codeelements and its linguistic style. In other words, which elements contribute the most tothe characterization of a language? How many structural elements of a language may bemodified without losing its identity? In order to achieve these goals, a comprehensive bibliographic research was made, ranging from basic concepts such as programming languages and how they work, to several state-of-the-art studies that have been conducted in the same context of this project. Complementary to this research, a set of programming languages was also chosen as a study subject, which resulted in a detailed review and categorization of their characteristics.After the definition of a general approach, a survey was developed and conducted togather programmers’ answers on how they identify and recognize programming languages.In addition to the survey, a machine learning model was also used to evaluate how thesetwo facets (human versus machine) compared to each other. This dual approach providedinsights into which syntactic and semantic elements have a greater influence on the identityof a programming language. This Master’s project resulted in an overall picture of programming languages’ characteristics and the relative influence they have on both programmers’ and AI-driven recognition. This result may serve as support for language engineers and project managers who wish to reduce attrition when defining or designing new languages for a project, domain, or context.",
    "text2": "The present document identifies and details the research and development held under the scopeof a MSc Thesis pertaining to the scientific area of pedagogic tools for teaching support, ontolo gies and learning resources. This masters thesis in Informatics Engineering was developed in theUniversity of Minho, Braga.The purpose of the project is to study the learning process of adults and how it connects to Learn ing Resources (LRs) in order to understand if a learning resource used to teach ComputationalThinking (CT) to children, is suitable for adult learners. This approach ought to take into accountadult learning theory to set its requirements, as well as CT principles and learning resourcesclassification.To this end, an approach to the Adequacy of Learning Resources in Adult Education was createdwhich comprises the ontology OntoAL that describes in detail the domain of Adult Learning(AL) including the theory of AL and a classification of both the adult learner and the learningresources. This ontology was developed in OntoDL and Prolog. In addition, we analyze theexperiment conducted as part of the validation of this approach and the OntoAL ontology.Therefore, in this document, it is presented the state of the art pertaining to this field, exploringthe concepts of learning resources, computational thinking, ontologies and adult learning andeducation. Furthermore, it is rendered an introduction of the subject and the project, detailingthe context of the problem, the objectives to be accomplished and the research hypothesis ofsaid thesis. Next, it is presented the state of the art regarding Computational Thinking, AdultLearning and Education, Ontologies and Learning Resources. Thereafter, it is put forward thework proposal. Then it is introduced the OntoAL ontology in both OntoDL and Prolog (detailingthe process of its development and the choices made), the questionnaires that were created aswell as the analysis of the responses that we obtained. Lastly, there are listed the conclusions andthe future work.",
    "similarity": 0.3233481557078291
  },
  {
    "text1": "Os sistemas de informação representam uma parte importante dentro das organizações e oseu papel, para o fornecimento de informação a tempo e onde é necessária, é crítico. Nos últimosanos, o recurso a estes sistemas tem aumentado exponencialmente, sendo possível encontra-los empraticamente todas as áreas da ação humana.A área da saúde não é alheia a esta tendência e tem-se observado um aumento bastanteacentuado na quantidade de dados processados e armazenados.Assegurar que a informação essencial para o correto funcionamento da instituição estádisponível e tem um elevado grau de qualidade são missões da Informática Médica.As ferramentas de Business Intelligence entram nesta área com uma elevada relevância, poispermitem a análise de dados e da informação que estes potencialmente representam, através dorecurso a diversas metodologias, aplicações e tecnologias.O registo clínico electrónico, para os dados do projeto “Cirurgia Segura Salva Vidas”, pode serpotencialmente vital para a qualidade e segurança do paciente no Bloco Operatório, uma vez que estedefine etapas e passos a serem realizados pelos profissionais envolvidos com o objetivo de reduzir onúmero de eventos adversos.Avaliar a qualidade da informação deste registo torna-se, por isso, particularmenteinteressante, principalmente quando se ponderam as potenciais consequências que a informaçãoextraída deste registo pode ter na instituição.Os indicadores utilizados permitiram retirar conclusões sobre a qualidade da informaçãoencontrada nos registo da cirurgia segura no CHAA e considera-se que a ferramenta de BusinessIntelligence, Pentaho Community, foi aplicada com sucesso no sector da saúde. As necessidades efalhas de informação presentes no CHAA foram identificadas.",
    "text2": "A implementação da interoperabilidade nos Sistemas de Informação Hospitalar(SIH) é cada vez mais um requisito e não uma opção. A Agênciapara a Integração, Difusão e Arquivo de Informação Médica e Clínica (AIDA)consiste numa plataforma de interoperabilidade hospitalar desenvolvida porinvestigadores da Universidade do Minho e que se encontra instalada no CentroHospitalar do Porto (CHP). A AIDA assegura a interoperabilidade entreos SIH e para alémdisto, assegura também a confidencialidade, integridade edisponibilidade dos dados. A AIDA deve possuir um elevado nível de disponibilidadee um funcionamento eficiente 24 horas por dia. Um pequeno períodode paragem poderá trazer graves consequências para a qualidade dos serviçosprestados. Esta plataforma possui mecanismos de recuperação e tolerânciade falhas, contudo devido à sua elevada importância, é preciso agir antes daocorrência das falhas, evitando sérios danos. Os processos de monitorizaçãoe prevenção de falhas devem ser implementados nos “órgãos vitais” da AIDA,que são as base de dados, máquinas e agentes inteligentes.Uma vez que a prevenção de falhas em base de dados da AIDA já tersido alvo de estudo, esta dissertação aborda a monitorização e prevenção defalhas nas máquinas e agentes. Para prever as falhas, foram criados modelosbaseados no Modified Early Warning Score (MEWS). Este modelo através darecolha frequente dos valores dos sinais vitais, calcula um conjunto de scorespara determinar o nível de risco a que o paciente está submetido.Foram desenvolvidos sistemas de monitorização de prevenção para as máquinase agentes que permitem não só prevenir falhas, mas também observare avaliar o comportamento destes componentes através de dashboards de monitorização.A prevenção de falhas nos agentes foi baseada na frequência comque estes registam as suas atividades nos seus ficheiros log, enquanto que paraas máquinas a prevenção foi baseada em indicadores de desempenho como amemória e o CPU. Apurou-se que os componentes, em geral, encontram-secom os seus principais recursos bem balanceados e que os sistemas de prevençãodesenvolvidos detetaram situações críticas com sucesso, contribuindopara um aumento da integridade e disponibilidade da AIDA do CHP.",
    "similarity": 0.3331829986149584
  },
  {
    "text1": "Os sistemas de informação representam uma parte importante dentro das organizações e oseu papel, para o fornecimento de informação a tempo e onde é necessária, é crítico. Nos últimosanos, o recurso a estes sistemas tem aumentado exponencialmente, sendo possível encontra-los empraticamente todas as áreas da ação humana.A área da saúde não é alheia a esta tendência e tem-se observado um aumento bastanteacentuado na quantidade de dados processados e armazenados.Assegurar que a informação essencial para o correto funcionamento da instituição estádisponível e tem um elevado grau de qualidade são missões da Informática Médica.As ferramentas de Business Intelligence entram nesta área com uma elevada relevância, poispermitem a análise de dados e da informação que estes potencialmente representam, através dorecurso a diversas metodologias, aplicações e tecnologias.O registo clínico electrónico, para os dados do projeto “Cirurgia Segura Salva Vidas”, pode serpotencialmente vital para a qualidade e segurança do paciente no Bloco Operatório, uma vez que estedefine etapas e passos a serem realizados pelos profissionais envolvidos com o objetivo de reduzir onúmero de eventos adversos.Avaliar a qualidade da informação deste registo torna-se, por isso, particularmenteinteressante, principalmente quando se ponderam as potenciais consequências que a informaçãoextraída deste registo pode ter na instituição.Os indicadores utilizados permitiram retirar conclusões sobre a qualidade da informaçãoencontrada nos registo da cirurgia segura no CHAA e considera-se que a ferramenta de BusinessIntelligence, Pentaho Community, foi aplicada com sucesso no sector da saúde. As necessidades efalhas de informação presentes no CHAA foram identificadas.",
    "text2": "A crescente utilização dos Sistemas de Informação (SI) nas unidades desaúde tem um papel muito importante para garantir a qualidade das mesmas.Com as Tecnologias da Informação e da Comunicação (TIC), os dadosarmazenados estão estruturados e organizados de forma a possibilitar umautilização rápida e e caz. O aumento de informações em formato eletrónicono processo de Registo Clínico (RC) apesar de diminuir em grande escalaerros que resultavam da utilização de dados mal entendidos, trouxe um desa o aos técnicos de informática médica. Esse desa o passa por melhorar aqualidade da prestação de cuidados de saúde utilizando a informação armazenada.É neste âmbito que surgem as normas e sistemas de nomenclatura quepossibilitam uma uniformização do RC de forma a evitar dados ambíguose permitir a comunicação entre diferentes pro ssionais de saúde e serviçoshospitalares. Estas normas são divididas conforme a sua nalidade, havendonormas de comunicação, imagem e representação.Pretende-se, neste contexto, implementar o Systematized Nomenclatureof Medicine (SNOMED) na Agência de Interoperação, Difusão e Arquivo(AIDA) no Centro Hospitalar do Alto Ave (CHAA) de forma a utilizar as suaspotencialidades no processo de uniformização do Registo Clínico Eletrónico(RCE).",
    "similarity": 0.32205817174515233
  },
  {
    "text1": "Os sistemas de informação representam uma parte importante dentro das organizações e oseu papel, para o fornecimento de informação a tempo e onde é necessária, é crítico. Nos últimosanos, o recurso a estes sistemas tem aumentado exponencialmente, sendo possível encontra-los empraticamente todas as áreas da ação humana.A área da saúde não é alheia a esta tendência e tem-se observado um aumento bastanteacentuado na quantidade de dados processados e armazenados.Assegurar que a informação essencial para o correto funcionamento da instituição estádisponível e tem um elevado grau de qualidade são missões da Informática Médica.As ferramentas de Business Intelligence entram nesta área com uma elevada relevância, poispermitem a análise de dados e da informação que estes potencialmente representam, através dorecurso a diversas metodologias, aplicações e tecnologias.O registo clínico electrónico, para os dados do projeto “Cirurgia Segura Salva Vidas”, pode serpotencialmente vital para a qualidade e segurança do paciente no Bloco Operatório, uma vez que estedefine etapas e passos a serem realizados pelos profissionais envolvidos com o objetivo de reduzir onúmero de eventos adversos.Avaliar a qualidade da informação deste registo torna-se, por isso, particularmenteinteressante, principalmente quando se ponderam as potenciais consequências que a informaçãoextraída deste registo pode ter na instituição.Os indicadores utilizados permitiram retirar conclusões sobre a qualidade da informaçãoencontrada nos registo da cirurgia segura no CHAA e considera-se que a ferramenta de BusinessIntelligence, Pentaho Community, foi aplicada com sucesso no sector da saúde. As necessidades efalhas de informação presentes no CHAA foram identificadas.",
    "text2": "Cada vez mais a relação entre as tecnologias da informação e a saúde seestreitam. Concretamente, na neuroimagiologia, essa ligação tem vindo a tornar-se cada vezmais importante principalmente após o surgimento da imagem de Ressonância Magnética(MRI – Magnetic Ressonance Imaging).Com o desenvolvimento da tecnologia, para além das aquisições MRI convencionais, surgiramoutras técnicas como a aquisição de imagens de tensor de difusão (DTI – Diffusion TensorImaging) e da MRI funcional (fMRI). Estas técnicas permitem a obtenção de uma imageminterior do corpo. Um dos órgãos mais estudados com estas imagens é o cérebro, que é alvode vários estudos mas que devido à sua complexidade ainda é bastante desconhecido.Enquanto que com a MRI estrutural pode-se efetuar uma análise volumétrica às diferentesestruturas do cérebro, com a DTI é possível verificar a integridade da substância brancaatravés das fibras virtualmente criadas que representam o movimento das moléculas de água.Vários estudos referem os benefícios de uma análise multimodal com estas duas técnicas.Para tratamento e análise destas imagens é necessário uma gestão de várias aplicaçõesinformáticas que processam os dados e corregistam as imagens de forma automática. Um dosgrandes desafios consta, não só na utilização individual de cada ferramenta na qual é exigidoalgum conhecimento técnico, como na combinação das várias aplicações que apresentam osdados resultantes em diferentes formatos.Uma solução passa pela pesquisa e definição de fluxos de trabalho para que exista umaabordagem simples dos procedimentos a ter com as várias ferramentas e da sua combinaçãocom outras. No entanto, esta solução não impedirá o gasto de recursos de tempo e o trabalhomoroso de um estudo que contenha vários sujeitos.Assim, neste trabalho, para além de serem apresentados os vários fluxos de trabalho possíveispara análise multimodal, será exposto um módulo automatizado que será inserido numaaplicação de multimodalidade já existente: BrainCat.A presente dissertação apresenta um meio de facilitar as análises multimodais para que aqualidade quer a nível de investigação científica quer a nível dos diagnósticos clínicos aumente.",
    "similarity": 0.3294030156131957
  },
  {
    "text1": "Os sistemas de informação representam uma parte importante dentro das organizações e oseu papel, para o fornecimento de informação a tempo e onde é necessária, é crítico. Nos últimosanos, o recurso a estes sistemas tem aumentado exponencialmente, sendo possível encontra-los empraticamente todas as áreas da ação humana.A área da saúde não é alheia a esta tendência e tem-se observado um aumento bastanteacentuado na quantidade de dados processados e armazenados.Assegurar que a informação essencial para o correto funcionamento da instituição estádisponível e tem um elevado grau de qualidade são missões da Informática Médica.As ferramentas de Business Intelligence entram nesta área com uma elevada relevância, poispermitem a análise de dados e da informação que estes potencialmente representam, através dorecurso a diversas metodologias, aplicações e tecnologias.O registo clínico electrónico, para os dados do projeto “Cirurgia Segura Salva Vidas”, pode serpotencialmente vital para a qualidade e segurança do paciente no Bloco Operatório, uma vez que estedefine etapas e passos a serem realizados pelos profissionais envolvidos com o objetivo de reduzir onúmero de eventos adversos.Avaliar a qualidade da informação deste registo torna-se, por isso, particularmenteinteressante, principalmente quando se ponderam as potenciais consequências que a informaçãoextraída deste registo pode ter na instituição.Os indicadores utilizados permitiram retirar conclusões sobre a qualidade da informaçãoencontrada nos registo da cirurgia segura no CHAA e considera-se que a ferramenta de BusinessIntelligence, Pentaho Community, foi aplicada com sucesso no sector da saúde. As necessidades efalhas de informação presentes no CHAA foram identificadas.",
    "text2": "Os avanços tecnológicos verificados nos dia de hoje assim como a quantidadede informação e comunicação que lhes estão associados, atribuem umpapel de grande importância aos sistemas de monitorização. É no seio destaevolução, que a competição existente entre os vários setores de mercado nãoestão acessíveis a erros e falhas, principalmente ao nível dos equipamentostecnológicos. Assim, neste contexto de intolerância, assiste-se a uma proliferaçãoe a uma utilização cada vez maior de sistemas de monitorização eprevenção.Mais importante que monitorizar é prevenir. Ter a capacidade de evitaruma falha, e permitir a resolução de algum problema atempadamente é umamais valia para o desempenho, atribuindo fiabilidade e qualidade ao serviço.A gestão e a verificação de equipamentos, bem como de processos associadosaos mesmos permitem um maior controlo e domínio dum sistema.Assim esta dissertação tem como objetivo principal a implementação dumsistema para monitorizar a atividade de um ou mais sistemas multi-agente,com capacidade para intervir e avisar o administrador do sistema quandoocorre um problema.O sistema construído, que assenta numa estrutura formada por três unidadesdistintas, unidade de análise, unidade de processamento e unidade deinterface com o utilizador, permitem a implementação de processos para trocae integração de informação, exercendo assim uma comunicação fundamentalentre sistemas e utilizadores . É um sistema direcionado principalmenteà gestão e monitorização do desempenho de diferentes equipamentos assimcomo dos processos em execução nos mesmos. Este trabalho foi desenvolvido em colaboração com um Hospital no Norte do País e o ambiente escolhidopara a implementação da plataforma foi unicamente laboratorial.A concretização deste projeto esteve dividida em quatro fases: Início,Pesquisas, Construção da Aplicação e Escrita da Dissertação. Na primeirafase, o Início, foi feito o levantamento dos principais requisitos para o sistema,definição dos objetivos, e elaboração de um plano de trabalho. Na segundafase, Pesquisas, procedeu-se ao levantamento de informação sobre os conceitosteóricos relacionados com o tema em causa, como artigos científicos quedão suporte ao tema, entre outros trabalhos já publicados na mesma área.No final desta etapa já se encontravam definidas as ideias base da aplicaçãoa construir de acordo com as necessidades. Na terceira fase deste projeto, aConstrução englobou a modelação e implementação da plataforma de monitorização,de acordo com as especificações definidas anteriormente. A quartaetapa englobou a escrita da dissertação, o que incluiu um enquadramentodos conceitos teóricos em função da aplicação desenvolvida.",
    "similarity": 0.30645198522622347
  },
  {
    "text1": "A crescente evolução tecnológica verificada nas últimas décadas e a necessidade de criação e implementação de novas soluções de software, levam a que o papel dos testes de software assuma, cada vez mais,uma maior relevância no respetivo ambiente de desenvolvimento. Boas ferramentas de gestão e monitorização de testes, assim como, de geração de relatórios de estados e resultados associados aos mesmostestes, melhoram o processo de desenvolvimento tornando-o melhor e mais completo a todos os níveis.O principal objetivo da presente dissertação de mestrado é criar uma nova aplicação de geração de relatórios em páginas Confluence, utilizando como fonte de dados, os testes gerados a partir do Xray. O Xrayé uma aplicação de gestão e monitorização de testes de software em instâncias JIRA. O desenvolvimentoda aplicação implica o estudo das diferentes estratégias de desenvolvimento de software disponíveis noecossistema Atlassian.A aplicação Xray foi analisada em detalhe, com especial foco nos relatórios de testes de softwaredisponibilizados, o que permitiu a formulação de uma proposta de solução para o problema em questão. De seguida, foram analisadas diferentes frameworks de desenvolvimento de software para produtosAtlassian, culminando na escolha da ferramenta Forge face a todas as vantagens e desvantagens a elaassociadas.De igual modo, é apresentado todo o processo de desenvolvimento da aplicação, assim como asestratégias adotadas para a correta implementação de cada um dos relatórios propostos.",
    "text2": "O número de soluções utilizadas pelas empresas para fornecer serviços aos clientes e para fazer a gestão dos processos internos é cada vez maior. Este aumento provocou o aparecimento de novos problemas no que diz respeito à manutenção e à integração de novos serviços, uma vez que grande parte das aplicações não conseguem viver isoladamente. Com o objetivo de conseguir a integração de diferentes aplicações, surgiu o conceito de Enterprise Service Bus (ESB) — uma infraestrutura de conectividade que permite a comunicação entre aplicações, que podem ter diferenças a nível das plataformas em que são executadas, das linguagens de programação em que são escritas e dos modelos de dados que utilizam. A Eurotux Informática, S.A., é uma empresa especialista no planeamento, integração e implementação de sistemas informáticos, onde, devido à existência de diferentes interdependências entre aplicações de apoio ao negócio, surgiu a necessidade de implementar uma solução de integração utilizando um Barramento de Serviços. Assim, nesta Dissertação de Mestrado, para além do estudo dos padrões de integração de aplicações, é apresentado o processo de planeamento e implementação de uma solução de integração de aplicações num contexto empresarial.",
    "similarity": 0.301414721013059
  },
  {
    "text1": "A recente popularidade dos ambientes de grelhas introduziu a necessidade de suportar a execução robusta de aplicações numa gama alargada de recursos computacionais. Em contextos de grelhas computacionais, onde a fiabilidade e disponibilidade dos recursos não é garantida, as aplicações deverão ser capazes de suportar dois requisitos fundamentais: 1) tolerância a faltas; 2) adaptação aos recursos disponíveis. As técnicas tradicionais utilizam uma abordagem \"caixa-negra\", onde a camada intermédia de software (mediador) é a única responsável por assegurar estes dois requisitos. Estes tipos de abordagens possibilitam o suporte a estes serviços com uma intervenção mínima do programador, mas limitam a utilização de conhecimento sobre as características da aplicação, visando a otimização destes serviços. Nesta tese são apresentadas abordagens orientadas aos aspetos para suportar tolerância a faltas e adaptação dinâmica aos recursos em grelhas computacionais.Nas abordagens propostas, as aplicações são aprimoradas com capacidades de tolerância a faltas e de adaptação dinâmica através da ativação de módulos adicionais. A abordagem de tolerância a faltas utiliza a estratégia de ponto de controlo e restauro, enquanto a adaptação dinâmica utiliza uma variação da técnica de sobre-decomposição. Ambas são portáveis entre sistemas operativos e restringem a quantidade de alterações necessárias no código base das aplicações. Além disso, as aplicações poderão adaptar de uma execução sequencial para uma configuração multi-cluster. A adaptação pode ser realizada efetuando o ponto de controlo da aplicação e restaurando-a em diferentes máquinas, ou então, realizada em plena execução da aplicação.",
    "text2": "O uso de painéis de digital signage ou displays (ou, em português, painéis digitais) está cada vez mais a ser implementado nos locais públicos e semipúblicos, uma vez que é uma forma actual de apresentar, de um modo dinâmico, informação, publicidade e conteúdos de entretenimento. Desta forma, as pessoas expostas a esta tecnologia passam a ter um acesso mais rápido e actualizado à informação sobre tudo o que as rodeia.Os ecrãs dos displays têm evoluído no sentido da melhoria da sua qualidade. Além disso, a descida dos preços torna esta tecnologia bastante mais acessível para ser aplicada em vários sectores, nomeadamente na indústria, no comércio, na educação, na saúde, etc., substituindo os meios tradicionais publicitários e informativos, baseados em papel.Uma rede de painéis digitais permite a actualização dos seus conteúdos de forma remota, com base num servidor central que controla toda a informação apresentada na rede, enquanto que nos meios tradicionais a actualização de conteúdos é muito mais cara, demorada e de difícil gestão.Como as pessoas olham pouco tempo para os painéis digitais, exige-se um esforço muito grande no estudo do local onde estes são instalados e na modelação dos conteúdos a serem apresentados, de forma a que o ambiente se torne o mais atractivo possível e, deste modo, se promova a atenção de quem passa pelos painéis. Também existem displays que usam tecnologias mais sofisticadas, permitindo a adaptação automática dos conteúdos apresentados em função do contexto envolvente, fazendo com que a informação seja mais direccionada ao público, sem a necessidade de controlo humano.Dado o crescente sucesso, à escala planetária, da digital signage, têm surgindo cada vez mais soluções de software aplicadas nesta vertente. Por conseguinte, o tema principal desta dissertação incidirá sobre o desenvolvimento de uma aplicação web para painéis de digital signage, sugerida pela empresa Ubisign, com o objectivo de permitir configurar visualizações com informação sobre eventos provenientes do Google Calendar.Uma vez que a promoção de eventos geralmente exige custos elevados de design e produção, é necessário minimizá-los no contexto das redes de digital signage. Para tal, existem determinadas ferramentas on-line de gestão de eventos, como o Google Calendar, com a função de permitir que o utilizador especifique eventos que vão ocorrer e efectue o seu escalonamento com base em calendários. Do ponto de vista de um developer, estas ferramentas evitam a necessidade de implementar outros softwares de gestão de eventos, permitindo também desenvolver outras aplicações que comuniquem com estas ferramentas, através de APIs apropriadas e bem documentadas.Para tirar partido disto, a aplicação a desenvolver terá de recorrer à API Google Calendar para disponibilizar, de forma personalizada, informação sobre eventos que estejam planeados para um dado sítio com uma rede de digital signage instalada e, para esse efeito, terá de ser integrada no serviço Ubisign.com.",
    "similarity": 0.3033224106479292
  },
  {
    "text1": "A recente popularidade dos ambientes de grelhas introduziu a necessidade de suportar a execução robusta de aplicações numa gama alargada de recursos computacionais. Em contextos de grelhas computacionais, onde a fiabilidade e disponibilidade dos recursos não é garantida, as aplicações deverão ser capazes de suportar dois requisitos fundamentais: 1) tolerância a faltas; 2) adaptação aos recursos disponíveis. As técnicas tradicionais utilizam uma abordagem \"caixa-negra\", onde a camada intermédia de software (mediador) é a única responsável por assegurar estes dois requisitos. Estes tipos de abordagens possibilitam o suporte a estes serviços com uma intervenção mínima do programador, mas limitam a utilização de conhecimento sobre as características da aplicação, visando a otimização destes serviços. Nesta tese são apresentadas abordagens orientadas aos aspetos para suportar tolerância a faltas e adaptação dinâmica aos recursos em grelhas computacionais.Nas abordagens propostas, as aplicações são aprimoradas com capacidades de tolerância a faltas e de adaptação dinâmica através da ativação de módulos adicionais. A abordagem de tolerância a faltas utiliza a estratégia de ponto de controlo e restauro, enquanto a adaptação dinâmica utiliza uma variação da técnica de sobre-decomposição. Ambas são portáveis entre sistemas operativos e restringem a quantidade de alterações necessárias no código base das aplicações. Além disso, as aplicações poderão adaptar de uma execução sequencial para uma configuração multi-cluster. A adaptação pode ser realizada efetuando o ponto de controlo da aplicação e restaurando-a em diferentes máquinas, ou então, realizada em plena execução da aplicação.",
    "text2": "A capacidade de agregar dados é uma característica fundamental na conceção de sistemas de informação escaláveis, que permite a determinação de propriedades globais importantes de forma descentralizada, para a coordenação de aplicações distribuídas, ou para fins de monitorização.Agregados simples como mínimos/ máximos, contagens, somas e médias foram já extensivamente estudados no passado. No entanto, este tipo de agregados pode não ser suficiente para caracterizar distribuições de dados enviesadas e na presença de valores atípicos (outliers), tornando-se então relevante a determinação de uma estimativa dos valores na rede (e.g. histograma, função de distribuição cumulativa), dado que métricas como médias ou desvio padrão escondem em muitos casos alterações na propriedade monitorizada que são relevantes para decisão de controlo.São ainda relativamente escassos os trabalhos que se focam sobre a agregação de métricas mais expressivas. Uma proposta recente nesse domínio [SNSP10] refere atingir uma precisão nas estimativas superior à atingida em abordagens anteriores. Trata-se de um algoritmo para a determinação de funções cumulativas de distribuições.Apesar do contributo, essa proposta mostra limitações na tolerância a faltas e no suporte à monitorização contínua de propriedades, dado que para acompanhar alterações dos valores amostrados, a estratégia usada exige que o protocolo seja reiniciado periodicamente. Para além disso, os pressupostos dessa abordagem não admitem a perda de mensagens nem a sua duplicação.Assim, e tomando como ponto de partida o actual estado da arte, é apresentado nesta tese um algoritmo distribuído para a determinação de funções cumulativas de probabilidade em redes de larga escala. As suas principais vantagens são a imunidade à perda de mensagens, a velocidade de convergência e a precisão que se obtém na aproximação à distribuição original. É simultaneamente adaptável a alterações no valor amostrado e resiliente a dinamismo no número de nodos na rede. Usa também um mecanismo de quiesciência dos nodos assim que a variação local da estimativa é inferior a um determinado limiar. Nessa circunstância, o nodo deixa de transmitir. Isto leva à diminuição do número de mensagens trocadas entre nodos.As distribuições determinadas em todos os nodos permitem a tomada de decisões que tirem partido do facto de se estar a agregar uma função probabilística. Assim o nodo pode excluir outliers ou observar determinados quantis da propriedade. Para além disso, cada nodo da rede possui uma estimativa global sobre o estado geral da propriedade distribuída, o que lhe permite também a tomada de decisões com base em conhecimento local.São apresentados nesta tese resultados de simulação que confirmam a validade da abordagem seguida. É também apresentada uma revisão da literatura relacionada cujo âmbito incluiu as técnicas mais representativas da agregação de dados para métricas escalares e as técnicas de agregação de dados para métricas complexas.",
    "similarity": 0.3288114531286406
  },
  {
    "text1": "A iminente escassez de recursos naturais e o constante aumento populacional tem assolado o presente século. Tal crescente habitacional contribui para uma concentração nos grandes centros urbanos e, consequentemente, um maior nível de poluição quer em contextos habitacionais como industriais. Nesta vertente, as Estações de Tratamento de Águas Residuais, desempenham um papel crucial no controlo do nível de qualidade da água que é reutilizada ou descarregada para o exterior. Estas instalações recebem ininterruptamente cargas de afluentes extremamente poluentes que são provenientes da rede pública de esgotos e que carecem de um tratamento faseado para a purificação das mesmas. Porém, para garantir a qualidade da água que é reaproveitada ou devolvida ao meio ambiente, é necessária monitorização contínua destas estações de forma a permitir o processo de tomada de decisão. Posto isto, esta dissertação visa implementar modelos de Machine Learning com o intuito de detetar possíveis anomalias nas substâncias presentes no efluente destas infraestruturas. Assim sendo, são aplicados modelos como Isolation Forest (IF), One Class Support Vector Machine (OCSVM) e Long Short-Term Memory Autoencoder (LSTM-AE) para identificar os registos do Azoto Total, Nitratos e pH que possam ser anómalos. No caso em específico das LSTM-AE, são considerados três thresholds para classificar os registos, dos quais, dois utilizam valores estáticos e um consiste em valores dinâmicos. De entre os melhores modelos candidatos, no global, os modelos de IF e OCSVM alcançaram resultados superiores aos modelos baseados em LSTM-AE. No que diz respeito aos thresholds, as abordagens com valores estáticas de forma geral, atingiram resultados ligeiramente superiores. Em suma, os vários cenários aplicados permitiram concluir que os modelos concebidos conseguiram detetar as várias anomalias presentes nas substâncias referidas.",
    "text2": "A monitorização da qualidade da água é uma tarefa fundamental que tem de ser incluída em qualquerprocesso operacional de uma Estação de Tratamento de Águas Residuais (ETAR), pois permite verificarse os efluentes, quando descarregados no meio ambiente, cumprem os valores padrão definidos por lei.Se estes valores não forem monitorizados com eficácia, a poluição da água continua a intensificar-se e,consequentemente, a água torna-se cada vez mais escassa. Devido ao problema da poluição da água,tem-se verificado um aumento na escassez da água, em Portugal, durante as últimas décadas.A introdução de abordagens de Machine Learning (ML) neste tipo de operações pode vir a serbastante importante, devido à sua capacidade de melhorar a eficiência da monitorização da qualidade daágua e da previsão das substâncias da mesma. Uma das principais características que esta abordagemoferece é a interpretação de padrões e tendências nos dados, que não são facilmente identificáveis poroutras técnicas, e ainda a interpretação de relações não lineares nos dados.Deste modo, este trabalho visa a implementação de modelos de ML baseados em ConvolutionalNeural Networks (CNN), Long Short-Term Memory (LSTM), Transformer, e Transformer-LSTM,para a previsão dos valores da condutividade e do caudal, no afluente duma ETAR, de modo a apoiara monitorização da qualidade da água, e a celeridade do processo de tomada de decisão neste tipo deinfraestruturas. Diante dos melhores modelos candidatos obtidos, verificou-se que os modelos baseadosem Transformer alcançaram os melhores resultados na previsão da condutividade, nas duas abordagensconsideradas (multivariate e univariate), enquanto que os modelos baseados em CNN alcançaram omelhor desempenho na previsão do caudal, também nas duas abordagens supramencionadas.",
    "similarity": 0.3240744663516376
  },
  {
    "text1": "Machine Learning (ML) and Data Science can solve different real-world problems. Businesses arebecoming increasingly interested in these approaches, and as technology evolves, new challenges canbe identified, mostly regarding the ML models development, deployment cycle and data cleansing, whichcan significantly decrease the accuracy and viability of ML software systems. Development and Operations(DevOps) practices have become popular in operating software systems at scale successfully, but theyneed to be adapted to deliver the best results when applied to ML systems. This led to the emergenceof Machine Learning and Operations (MLOps), a development culture specific for ML systems, derivedfrom DevOps principles. What MLOps attempts to address is the unification of the development cycle ofML based software systems while striving for automation and monitoring, in order to allow continuousintegration and delivery. With this thesis, the goal is to study different available frameworks and methodsfor ML systems, in order to develop an automated ML pipeline to ingest and manipulate high volumesof data. A sensorial system, which simulates the interior of a vehicle, gathers enough data to feed thepipeline. Alongside the development of the ML system, a visual interface which allows control over theoverall system and its data is created.",
    "text2": "In the last years, the number of Machine Learning algorithms and their parameters has increased significantly.This allows for more accurate models to be found, but it also increases the complexity of the task of training amodel, as the search space expands significantly.As datasets keep growing in size, traditional approaches based on extensive search start to become costlyin terms of computational resources and time, especially in data streaming scenarios. With this growth, newchallenges in Machine Learning started to appear. The speed at which data arrives and different ways of storingdata are forcing organizations to address and explore new ways of adapting fast enough so their ML modelsdon’t become obsolete.This dissertation aims to develop an approach based on meta-learning that tackles two main challenges: predict ing the performance metrics of a future model and recommending the best algorithm/configuration for traininga model for a specific Machine Learning problem. Throughout this dissertation, all the study objectives andquestions, along with the relevant contextualization will be exposed.The proposed solution, when compared to an AutoML approach is up to 130x faster and only 2% worse in termsof average model quality, showing it is a good solution for scenarios in which models need to be updated regularly,such as in streaming scenarios with Big Data, in which some accuracy can be traded for a much shorter modeltraining time.",
    "similarity": 0.3024543751018413
  },
  {
    "text1": "One of the biggest problems for business owners, of both big and small companies, is thecorrect forecast of its financial evolution. This means that the owners in question need tospend a lot of time studying the economic issues that involve these situations and/or payspecialized workers to do a thorough study on the area. In addition, it becomes a constant,chronic and seasonal problem that demands to be solved. If there was a prediction systemcapable of forecasting and advising the owner of the company with enough precision to bereliable, one could save time, money and, above all, test or simulate the future with differentparameters. This project then aims to complete a framework capable of encapsulating all thedata-science work and knowledge needed to create good enough machine learning modelsthat provide these predictions even to those without data-science knowledge and to anygeneric business. This framework goes by the name Generic Predictive Machine (GPM). Itsperformance, both in terms of accuracy of results and execution time in various differentsituations, as well as the process leading to its development and the development itself arethoroughly documented. The problem of having to create a generic system arises as everybusiness’ data is inherently different and assumptions cannot be made on the developer’send. Therefore the final application allows for the solving of a vast array of problemseven if not related to economics and requires little knowledge about Machine Learning.The problem as a whole serves too as a vehicle for a deeper study on machine learningitself. Touching upon important aspects like, how far can such a system learn beyond thecapabilities of the human who programmed it, how faster can it do it and what can it teachus about the inherent patterns in data that sometimes remain unnoticed to the human eye.In the process of answering these questions many works on the area are referenced thattouch specific points of the theory behind machine learning, a final novel conclusion is thenderived from the knowledge found among all related works as to take a step forward in thetheory of machine learning as a whole.",
    "text2": "The introduction of Machine Learning (ML) on the orbit of the resolution of problemstypically associated within the human behaviour has brought great expectations tothe future. In fact, the possible development of machines capable of learning, in asimilar way as of the humans, could bring grand perspectives to diverse areas likehealthcare, the banking sector, retail, and any other area in which we could avoid theconstant attention of a person dedicated to the solving of a problem; furthermore, thereare those problems that are still not at the hands of humans to solve - these are nowat the disposal of intelligent machines, bringing new possibilities to the humankinddevelopment.ML algorithms, specifically Deep Learning (DL) methods, lack a bigger acceptance bypart of the community, even though they are present in various systems in our dailybasis. This lack of confidence, mandatory to let systems make big, important decisionswith great impact in the everyday life is due to the difficulty on understanding thelearning mechanisms and previsions that result by the same - some algorithms representthemselves as ”black boxes”, translating an input into an output, while not being totallytransparent to the outside. Another complication rises, when it is taken into accountthat the same algorithms are trained to a specific task and in accordance to the trainingcases found on their development, being more susceptible to error in a real environment- one can argue that they do not constitute a true Artificial Intelligence (AI).Following this line of thought, this dissertation aims at studying a new theory,Hierarchical Temporal Memory (HTM), that can be placed in the area of MachineIntelligence (MI), an area that studies the capacity of how the software systems canlearn, in an identical way to the learning of a human being. The HTM is still a freshtheory, that lays on the present perception of the functioning of the human neocortexand assumes itself as under constant development; at the moment, the theory dictatesthat the neocortex zones are organized in an hierarchical structure, being a memorysystem, capable of recognizing spatial and temporal patterns. In the course of thisproject, an analysis was made to the functioning of the theory and its applicabilityto the various tasks typically solved with ML algorithms, like image classification, sound recognition and time series forecasting. At the end of this dissertation, after theevaluation of the different results obtained in various approaches, it was possible toconclude that even though these results were positive, the theory still needs to mature,not only in its theoretical basis but also in the development of libraries and frameworksof software, to capture the attention of the AI community.",
    "similarity": 0.31199445983379503
  },
  {
    "text1": "Nos dias que correm, é cada vez mais frequente o recurso à tecnologia para a resolução de problemas nas mais diversas atividades, nos mais variados setores. O setor da educação não é, pois, uma exceção. Nesse setor, um dos aspetos que tem vindo a obter alguma relevância aborda a temática dos ITS — Intelligent Tutoring Systems, apesar da timidez das diversas aproximações realizadas, em especial ao nível do ensino de nível académico. Atualmente, está em curso na Universidade do Minho o desenvolvimento de um ITS, denominado Leonardo, cujo objetivo principal é o auxílio dos alunos no seu processo de aprendizagem e formação. Este sistema pretende fornecer um acompanhamento personalizado ao utilizador, tanto em termos do seu processo de formação, como, posteriormente, em termos do processo de avaliação correspondente. Nesta dissertação apresenta-se o desenvolvimento de um sistema de profiling para apoio ao processo de avaliação, que possibilita a construção do perfil do utilizador (do estudante) à medida que este interage com o sistema ao longo do tempo. Este sistema de profiling representa um dos módulos do sistema Leonardo e, através das devidas interações com os restantes módulos, serve de base de apoio a todas as decisões que são tomadas no sistema, uma vez que estabelece o perfil do utilizador pelo qual o sistema se deve reger ao adaptar os conteúdos a disponibilizar.",
    "text2": "Sendo certo que o recurso à tecnologia no ensino é cada vez mais notório, a utilização de sistemas informáticos de tutoria continua aquém do seu potencial, ainda que seja um tema abordado há já algumas décadas. Assim, surgiu a iniciativa Leonardo e o respetivo desenvolvimento de uma ferramenta computacional para sistemas de avaliação de conhecimento, com vista a ser aplicada, pelo menos, no suporte de processos de avaliação de alunos, na Universidade do Minho. De entre os módulos que caracterizam estes agentes de software, no contexto desta dissertação, destacam se a base de conhecimento, o mecanismo de raciocínio e o modelo do estudante. Dado que o esforço maior recai em habilitar os tutores artificiais à adaptação, em tempo real, da avaliação ao nível de conhecimento atual dos alunos, surge a necessidade de desenvolvimento de um mecanismo de raciocínio, que seja capaz de determinar, criteriosamente, o que deve ser apresentado de seguida num dado momento avaliativo. O trabalho desta dissertação focou-se na conceção e implementação de um sistema de avaliação baseado em conhecimento para o sistema Leonardo, com a capacidade de ajustar de forma dinâmica, à medida da perícia e conhecimento dos estudantes alvos do processo de avaliação, o seu comportamento, acompanhando de perto a evolução do processo de aprendizagem dos estudantes. Essencialmente, neste trabalho implementou-se a “máquina” de raciocínio para o sistema Leonardo poder sustentar de forma efetiva a avaliação de estudantes ao longo do tempo, numa ou mais áreas do conhecimento.",
    "similarity": 0.3233537791848041
  },
  {
    "text1": "In an ever more connected world, smart cities are becoming ever more present in our society. In these smartcities, use cases in which innovations that will benefit its inhabitants are also growing, improving their quality of life.One of these areas is safety, in which Machine Learning (ML) models reveal potential in real-time video-streamanalysis in order to determine if violence exists in them.These ML approaches concern the field of Computer Vision, a field responsible for traducing digital imagesand videos, and be able to extract knowledge and understandable information from them, in order to be usedin diverse contexts. Some of the available alternatives to recognise actions in video streams are based on MLapproaches, such as Deep Learning (DL), that grew in popularity in the last years, as it was realised that it hadmassive potential in several applications that could benefit from having a machine recognising diverse humanactions.In this project, the creation of a ML model that can determine if violence exists in a video-stream is proposed.This model will leverage technology being used in State of the Art methods, such as video classifiers, but alsoaudio classifiers, and Early/Late Fusion (EF / LF) schemes that allow the merging different modalities, in the caseof the present work: audio and video. Conclusions will also be drawn as to the accuracy rates of the differenttypes of classifiers, to determine if any other type of classifiers should have more prominence in the State of theArt.This document begins with an introduction to the work being conducted, in which both the its context, mo tivation and objectives are explained. Afterwards, the methodology used in order to more efficiently conductthe research in this Thesis is clarified. Following that, the State of the Art concerning ML based approaches toAction Recognition and Violence Detection is explored. After being brought to date in what are the State of theArt approaches, one is able to move forward to the following chapter, in which the Training method that will beemployed to train the models that were seen as the best candidates to detect violence is detailed. Subsequently,the selected models are scrutinized in an effort to better understand their architecture, and why they are suitedto detect violence. Afterwards, the results achieved by these models are explored, in order to better comprehendhow well these performed. Lastly, the conclusions that were reached after conducting this research are stated,and possibilities for expanding this work further are also presented.The obtained results prove the success and prevalence of video classifiers, and also show the efficacy ofmodels that make use of some kind of fusion.",
    "text2": "Nowadays, cybernetic attacks are a real threat that can compromise any individual,organization or company’s integrity. Every day new cases are reported, that show thereal damage cyber criminals can cause. Sensitive data exposure, identity theft, servicemalfunctioning or shutdown are just a few of the most common threats, which in manycases might impact companies either with financial loss or by damaging their reputation.Population, in general, is becoming each time more aware of the risks of using electronicdevices connected to the web and so are companies. With the rise of this awareness, over thelast years, cyber security has become a major concern for Software companies.This threat also led to the birth of the Software vulnerability detection market. Companiesstarted commercializing Software and advisory to other companies, in order to keep themless exposed to cybernetic risks. There are many mechanisms and technologies used bythese companies to identify vulnerabilities in applications. The most popular technologyused to detect vulnerabilities is SAST (Static Application Security Testing) as it focus onthe detection of vulnerabilities at the early stages of Software development. However, thisrequires the analysis of the source code, which in many cases, is huge and thus such analysisis too time consuming.Being that the context and motivation for this dissertation, the goal is to investigate thepossibility of performing source code analysis in a faster way, relying on machine learningapproaches. Code embeddings, classification algorithms and clustering algorithms were themain approaches explored in this work.Along the project, it was realized that some approaches performed better than others, in thetask of detecting software vulnerabilities. Clustering algorithms, according to the performedexperiments, are not suitable for the problem. Classification algorithms produced results thatcan be considered worthy of further investigation, but did not meet the established goals.After some failed attempts, this project demonstrated that it is possible to train a predictionmodel, based on code2seq approach, capable of detecting vulnerabilities in source code,with better performance and accuracy than classic SAST solutions (according to a specific setof experiments). Moreover, the used approach allows to easily extend the developed work tofind vulnerabilities in any programming language.",
    "similarity": 0.3102022780832679
  },
  {
    "text1": "In an ever more connected world, smart cities are becoming ever more present in our society. In these smartcities, use cases in which innovations that will benefit its inhabitants are also growing, improving their quality of life.One of these areas is safety, in which Machine Learning (ML) models reveal potential in real-time video-streamanalysis in order to determine if violence exists in them.These ML approaches concern the field of Computer Vision, a field responsible for traducing digital imagesand videos, and be able to extract knowledge and understandable information from them, in order to be usedin diverse contexts. Some of the available alternatives to recognise actions in video streams are based on MLapproaches, such as Deep Learning (DL), that grew in popularity in the last years, as it was realised that it hadmassive potential in several applications that could benefit from having a machine recognising diverse humanactions.In this project, the creation of a ML model that can determine if violence exists in a video-stream is proposed.This model will leverage technology being used in State of the Art methods, such as video classifiers, but alsoaudio classifiers, and Early/Late Fusion (EF / LF) schemes that allow the merging different modalities, in the caseof the present work: audio and video. Conclusions will also be drawn as to the accuracy rates of the differenttypes of classifiers, to determine if any other type of classifiers should have more prominence in the State of theArt.This document begins with an introduction to the work being conducted, in which both the its context, mo tivation and objectives are explained. Afterwards, the methodology used in order to more efficiently conductthe research in this Thesis is clarified. Following that, the State of the Art concerning ML based approaches toAction Recognition and Violence Detection is explored. After being brought to date in what are the State of theArt approaches, one is able to move forward to the following chapter, in which the Training method that will beemployed to train the models that were seen as the best candidates to detect violence is detailed. Subsequently,the selected models are scrutinized in an effort to better understand their architecture, and why they are suitedto detect violence. Afterwards, the results achieved by these models are explored, in order to better comprehendhow well these performed. Lastly, the conclusions that were reached after conducting this research are stated,and possibilities for expanding this work further are also presented.The obtained results prove the success and prevalence of video classifiers, and also show the efficacy ofmodels that make use of some kind of fusion.",
    "text2": "Personalized medicine is a constantly growing area. Important goals of this field are early diagnosis and the discovery of new personalized treatments. Gene expression data play a key role at this level, as variations in these data can often offer explanations for some phenotypes. To this end, Machine Learning (ML) models capable of predicting biologically relevant information, have been widely used. Deep Learning (DL) is a branch of ML that has become popular over the past few years. The increasing amounts of data that have been generated, and the growing use of this type of models in biomedical areas, have been accelerating the analysis of biological processes associated with cancer and other complex diseases.In this work, we focused on developing a framework that allows to create and evaluate distinct work-flows for the application of a variety of machine and deep learning models, working over gene expression data, including different options regarding data preprocessing pipelines, distinct ML and DL models, including traditional ML models, Dense Neural Networks, Convolutional Neural Networks and Variational Autoencoders. The framework has been validated using different case studies, where the data sources were two of the main repositories of gene expression data (TCGA and GTEx). The goal of each case study was to predict important variables for clinical application. A variety of models were developed and evaluated for each case study, generally with competitive performance. For the first case study, the task was to predict the type of cancer from TCGA data, and the best performing DL model was a dense neural network, being outperformed by a logistic regression model. In the second case, where the task was to predict the hypoxia score, the best DL model was a two dimensional convolutional neural network (2D CNN), being outperformed by the LightGBM model. As for the third case study, where the objective was to predict the aneuploidy score, the best model was an one dimensional convolutional neural network (1D CNN). For the fourth case, where the task was to predict body mass index, the best model was again a 1D CNN. Finally, in the fifth case study, where the main goal was to predict gene expression for a set of genes based on landmark genes, the best DL model was found by an 1D CNN, still slightly outperformed by linear regression. Some of the DL models developed in this work show promising results. However, these need to be improved in the future as they are not clinically applicable at this time. This framework can be reused for new problems and can be easily expanded.",
    "similarity": 0.30071288903372984
  },
  {
    "text1": "In an ever more connected world, smart cities are becoming ever more present in our society. In these smartcities, use cases in which innovations that will benefit its inhabitants are also growing, improving their quality of life.One of these areas is safety, in which Machine Learning (ML) models reveal potential in real-time video-streamanalysis in order to determine if violence exists in them.These ML approaches concern the field of Computer Vision, a field responsible for traducing digital imagesand videos, and be able to extract knowledge and understandable information from them, in order to be usedin diverse contexts. Some of the available alternatives to recognise actions in video streams are based on MLapproaches, such as Deep Learning (DL), that grew in popularity in the last years, as it was realised that it hadmassive potential in several applications that could benefit from having a machine recognising diverse humanactions.In this project, the creation of a ML model that can determine if violence exists in a video-stream is proposed.This model will leverage technology being used in State of the Art methods, such as video classifiers, but alsoaudio classifiers, and Early/Late Fusion (EF / LF) schemes that allow the merging different modalities, in the caseof the present work: audio and video. Conclusions will also be drawn as to the accuracy rates of the differenttypes of classifiers, to determine if any other type of classifiers should have more prominence in the State of theArt.This document begins with an introduction to the work being conducted, in which both the its context, mo tivation and objectives are explained. Afterwards, the methodology used in order to more efficiently conductthe research in this Thesis is clarified. Following that, the State of the Art concerning ML based approaches toAction Recognition and Violence Detection is explored. After being brought to date in what are the State of theArt approaches, one is able to move forward to the following chapter, in which the Training method that will beemployed to train the models that were seen as the best candidates to detect violence is detailed. Subsequently,the selected models are scrutinized in an effort to better understand their architecture, and why they are suitedto detect violence. Afterwards, the results achieved by these models are explored, in order to better comprehendhow well these performed. Lastly, the conclusions that were reached after conducting this research are stated,and possibilities for expanding this work further are also presented.The obtained results prove the success and prevalence of video classifiers, and also show the efficacy ofmodels that make use of some kind of fusion.",
    "text2": "Achieving great and undeniable success in a great variety of industries and businesses has made the term Big Data very popular among the scientific community. Big Data (BD) refers to the ever fast-growing research area in Computer Science (CS) that comprises many work areas across the world. The healthcare sector is widely known to be highly proficient inthe production of big quantities of data. It can go from health information, such as thepatient’s blood pressure and cholesterol levels, to more private and sensitive data, such asthe medical procedures history or the report of ongoing diseases.The application of sophisticated techniques enables a profound and rigorous analysis ofdata, something a human cannot do in real-time. However, a machine is capable of rapidlycollect, group, storage and examine vast amounts of data and extract unknown and possi bly interesting knowledge from it. The algorithms used can discover hidden relationshipsbetween attributes that prove to be very useful for a corporation’s work. Buried structureswithin the produced data can also be detected by these techniques. Machine Learning (ML)methods can be adjusted and modelled to different input representations - this adaptabilityis one of the factors that contributes to its blooming prosperity.The main goal is to make predictions on data, by building utterly efficient models that canaccurately take in the data and thus predict a certain outcome. This is especially importantto the healthcare industry since it can considerably improve the lives of many patients.Everything from detecting a type of disease, predicting the chance of morbidity after ahospital stay, to aid in the decision making of treatment strategies are vital to patients aswell as to clinicians.Any improvement over established methods that have been previously studied, testedand published are an asset that will improve the patient’s satisfaction about the healthcareperformance in medical institutions. This can be achieved by refining those algorithms orimplementing new approaches that will make better predictions on the given data.The main objective of this dissertation is to propose ML approaches having acknowledged and evaluated the existent methods used in clinical data. In order to fulfill this goal,an analysis of the state of the art of medical knowledge repositories and scientific paperspublished related to the selected keywords selected was performed. In this line of work,it is crucial to understand, compare and discuss the results obtained to those previouslypublished. Thus, one of the goals is to suggest new ways of solving those problems andmeasuring them up against the existent ones.",
    "similarity": 0.31656775696648387
  },
  {
    "text1": "In an ever more connected world, smart cities are becoming ever more present in our society. In these smartcities, use cases in which innovations that will benefit its inhabitants are also growing, improving their quality of life.One of these areas is safety, in which Machine Learning (ML) models reveal potential in real-time video-streamanalysis in order to determine if violence exists in them.These ML approaches concern the field of Computer Vision, a field responsible for traducing digital imagesand videos, and be able to extract knowledge and understandable information from them, in order to be usedin diverse contexts. Some of the available alternatives to recognise actions in video streams are based on MLapproaches, such as Deep Learning (DL), that grew in popularity in the last years, as it was realised that it hadmassive potential in several applications that could benefit from having a machine recognising diverse humanactions.In this project, the creation of a ML model that can determine if violence exists in a video-stream is proposed.This model will leverage technology being used in State of the Art methods, such as video classifiers, but alsoaudio classifiers, and Early/Late Fusion (EF / LF) schemes that allow the merging different modalities, in the caseof the present work: audio and video. Conclusions will also be drawn as to the accuracy rates of the differenttypes of classifiers, to determine if any other type of classifiers should have more prominence in the State of theArt.This document begins with an introduction to the work being conducted, in which both the its context, mo tivation and objectives are explained. Afterwards, the methodology used in order to more efficiently conductthe research in this Thesis is clarified. Following that, the State of the Art concerning ML based approaches toAction Recognition and Violence Detection is explored. After being brought to date in what are the State of theArt approaches, one is able to move forward to the following chapter, in which the Training method that will beemployed to train the models that were seen as the best candidates to detect violence is detailed. Subsequently,the selected models are scrutinized in an effort to better understand their architecture, and why they are suitedto detect violence. Afterwards, the results achieved by these models are explored, in order to better comprehendhow well these performed. Lastly, the conclusions that were reached after conducting this research are stated,and possibilities for expanding this work further are also presented.The obtained results prove the success and prevalence of video classifiers, and also show the efficacy ofmodels that make use of some kind of fusion.",
    "text2": "Today, AI is very important in our lives as its used all around us without our knowledge. From simple things such as personal assistants like Alexa and Siri, and advertising algorithms focusing on our tastes -Netflix on the recommendation of movies or, even more common, the presentation of advertising basedon our search history -, to robots and to smart houses, cities or even vehicles. The presence of AI isincreasing and even if we are still far away from our ’General AI’ ideology, a machine capable of anythingautonomously, each day we get closer.In the last decade multiple applications of AI have been through breakthroughs. For example, the firstimplementations of autonomous vehicles were introduced by Tesla and other companies. A number ofdiscoveries must have been made to achieve this revolution of AI performance and, among them, is two ofthe most important developments: Object Detection and Semantic Segmentation, closely related to eachother. These are responsible for understanding the environment so the machine can take actions, beingthe latter an improvement of the first in terms of sensibility error associated to each entity detected as wellas being able to detect its corresponding type, in a pixel level. These machines require more and moredata to analyse, having many types of sensors in order to collect information, such as radars, cameras,LiDAR, among others.This work falls in the study of the use of Semantic Segmentation techniques and its application oncategorising data from image related sensors in order to explain its breakthroughs and challenges, as wellas improving and overcoming such obstacles. Data will consist mainly of scans from outdoor/self-drivingcars POV (KITTI360) with the ability to be used with other types of data such as indoor scans (COCO), toexplain both road and more day-to-day images semantic compositions, applied on a state-of-art solution.Consecutively we will perform a process of optimisation in order to reduce computation costs. Currentlythe works of DeepLab (with the research of deeplabv3[1]) have achieved a high success on SemanticSegmentation overcoming previous problems such as handling component boundaries with more refinedlines while keeping it fairly easy to run on more less powerful machines, being the start point for this work.",
    "similarity": 0.3106371191135734
  },
  {
    "text1": "In an ever more connected world, smart cities are becoming ever more present in our society. In these smartcities, use cases in which innovations that will benefit its inhabitants are also growing, improving their quality of life.One of these areas is safety, in which Machine Learning (ML) models reveal potential in real-time video-streamanalysis in order to determine if violence exists in them.These ML approaches concern the field of Computer Vision, a field responsible for traducing digital imagesand videos, and be able to extract knowledge and understandable information from them, in order to be usedin diverse contexts. Some of the available alternatives to recognise actions in video streams are based on MLapproaches, such as Deep Learning (DL), that grew in popularity in the last years, as it was realised that it hadmassive potential in several applications that could benefit from having a machine recognising diverse humanactions.In this project, the creation of a ML model that can determine if violence exists in a video-stream is proposed.This model will leverage technology being used in State of the Art methods, such as video classifiers, but alsoaudio classifiers, and Early/Late Fusion (EF / LF) schemes that allow the merging different modalities, in the caseof the present work: audio and video. Conclusions will also be drawn as to the accuracy rates of the differenttypes of classifiers, to determine if any other type of classifiers should have more prominence in the State of theArt.This document begins with an introduction to the work being conducted, in which both the its context, mo tivation and objectives are explained. Afterwards, the methodology used in order to more efficiently conductthe research in this Thesis is clarified. Following that, the State of the Art concerning ML based approaches toAction Recognition and Violence Detection is explored. After being brought to date in what are the State of theArt approaches, one is able to move forward to the following chapter, in which the Training method that will beemployed to train the models that were seen as the best candidates to detect violence is detailed. Subsequently,the selected models are scrutinized in an effort to better understand their architecture, and why they are suitedto detect violence. Afterwards, the results achieved by these models are explored, in order to better comprehendhow well these performed. Lastly, the conclusions that were reached after conducting this research are stated,and possibilities for expanding this work further are also presented.The obtained results prove the success and prevalence of video classifiers, and also show the efficacy ofmodels that make use of some kind of fusion.",
    "text2": "In traffic environments, road signs have a key role to control, warn, and command or prohibitthe driver of certain actions. Traffic sign maintenance is essential to prevent negativeevents. In order for these traffic signs to play the role they were designed for, periodic onsiteinspections are essential and followed out to determine if signs are in good conditionand visible, both during the day and night. However, periodic inspections are time and costconsuming.Another issue is related to the drivers’ awareness to the traffic signs on the road. Manyfactors, both internal and external to the driver, may potentially contribute to him missing asign. Given the purpose of this dissertation, we will focus primarily on the external factorssuch as the sign being damaged or occluded, or distractions caused by the many gadgetsinside the vehicle. Due to all these extraneous influences, a traffic sign recognition systemmay help the driver to respect these signs and increase significantly their safety, as well asthe others around them.Some high-end vehicles already have such a warning system, at least for danger signs.However, drivers with these vehicles represent a small fraction of the total driving force.This dissertation aims at bringing such a system to a much broader audience.Smartphones are one of the most used devices by society today, mostly due to the manyfunctionalities they provide in day to day life and their relative accessible monetary value.The increased computational power and cameras’ quality improvement of these devicesover the years make them good candidates to support the access to this kind of technologyto all. In other words, smartphones of this day and age have the necessary resources to beused as instruments for sign recognition.Hence, we propose a dual purpose community based approach. On the one hand, eachdriver can use his mobile device to detect, recognize and geolocate traffic signs, contributingto the traffic sign central repository. Detection is performed using Cascade Classifiers,while a Convolutional Neural Network supports the recognition phase. The repository,based on the information received from the clients, can be used to provide sign statusreports and to enable more direct and timely inspection instead of relying on prescheduledglobal inspections. On the other hand, drivers would have access to the database of trafficsigns, therefore being able to receive real-time notifications regarding traffic signs such asspeed limit signs, school proximity, or road construction signs. Hence, allowing the systemto perform its function even if the recognition phase is not active when used in a lowcomputational power device.",
    "similarity": 0.30385719125530597
  },
  {
    "text1": "In an ever more connected world, smart cities are becoming ever more present in our society. In these smartcities, use cases in which innovations that will benefit its inhabitants are also growing, improving their quality of life.One of these areas is safety, in which Machine Learning (ML) models reveal potential in real-time video-streamanalysis in order to determine if violence exists in them.These ML approaches concern the field of Computer Vision, a field responsible for traducing digital imagesand videos, and be able to extract knowledge and understandable information from them, in order to be usedin diverse contexts. Some of the available alternatives to recognise actions in video streams are based on MLapproaches, such as Deep Learning (DL), that grew in popularity in the last years, as it was realised that it hadmassive potential in several applications that could benefit from having a machine recognising diverse humanactions.In this project, the creation of a ML model that can determine if violence exists in a video-stream is proposed.This model will leverage technology being used in State of the Art methods, such as video classifiers, but alsoaudio classifiers, and Early/Late Fusion (EF / LF) schemes that allow the merging different modalities, in the caseof the present work: audio and video. Conclusions will also be drawn as to the accuracy rates of the differenttypes of classifiers, to determine if any other type of classifiers should have more prominence in the State of theArt.This document begins with an introduction to the work being conducted, in which both the its context, mo tivation and objectives are explained. Afterwards, the methodology used in order to more efficiently conductthe research in this Thesis is clarified. Following that, the State of the Art concerning ML based approaches toAction Recognition and Violence Detection is explored. After being brought to date in what are the State of theArt approaches, one is able to move forward to the following chapter, in which the Training method that will beemployed to train the models that were seen as the best candidates to detect violence is detailed. Subsequently,the selected models are scrutinized in an effort to better understand their architecture, and why they are suitedto detect violence. Afterwards, the results achieved by these models are explored, in order to better comprehendhow well these performed. Lastly, the conclusions that were reached after conducting this research are stated,and possibilities for expanding this work further are also presented.The obtained results prove the success and prevalence of video classifiers, and also show the efficacy ofmodels that make use of some kind of fusion.",
    "text2": "This thesis was developed as part of a curricular internship at Bosch Car Multimédia SA, in collaboration with the University of Minho, More specifically, an exploratory research thesis aligned with an R&D project that is being developed internally and whose objective is to detect impacts on vehicles that cause damage based on data obtained through sensors, The usefulness of the work developed in this thesis and the project in which it is inserted, in a real context, would be to help vehicle rental companies and car-sharing services to better monitor the conditions of vehicles in their fleets, This would be achieved by placing a device in vehicles that continuously monitored their status, reducing the need for validation and human interaction after use, The main focus of this thesis was to explore how the fusion of information from different sensors could improve the decision-rnaking capabilities of a system whose purpose is to determine whether impacts on the exterior of a vehicle, captured with a set of sensors, resulted in damage, This conjugation of sensory information is known as sensor fusion. ft is a process of combining information from different homogeneous and heterogeneous sensors to obtain a better representation of what is being observed, The approach chosen to achieve this goal consisted of training a set of Machine Learning (ML) algorithms with two distinct datasets, one based only on one data source and the other multiple sources combined. Each pair of models was further evaluated on unseen data, and their performances were compared based on the va lues obtained, Based on the results obtained, it can be said that the application of sensor fusion allowed for better learning by the models, which led to greater robustness in data never seen before. Of the four chosen algorithms, XGBoost, Random Forest (RF), Support Vector Machine (SVM), and Artificial Neural Network (ANN), all had at least one of the evaluation metrics, the Matthews Correlation Coefficient (MCC) and number of False Positive (FP)s in the test set, superior in model-based fused data. Of these, XGBoost and ANN stand out where the results were significantly better in both metrics,",
    "similarity": 0.30881155165998264
  },
  {
    "text1": "In an ever more connected world, smart cities are becoming ever more present in our society. In these smartcities, use cases in which innovations that will benefit its inhabitants are also growing, improving their quality of life.One of these areas is safety, in which Machine Learning (ML) models reveal potential in real-time video-streamanalysis in order to determine if violence exists in them.These ML approaches concern the field of Computer Vision, a field responsible for traducing digital imagesand videos, and be able to extract knowledge and understandable information from them, in order to be usedin diverse contexts. Some of the available alternatives to recognise actions in video streams are based on MLapproaches, such as Deep Learning (DL), that grew in popularity in the last years, as it was realised that it hadmassive potential in several applications that could benefit from having a machine recognising diverse humanactions.In this project, the creation of a ML model that can determine if violence exists in a video-stream is proposed.This model will leverage technology being used in State of the Art methods, such as video classifiers, but alsoaudio classifiers, and Early/Late Fusion (EF / LF) schemes that allow the merging different modalities, in the caseof the present work: audio and video. Conclusions will also be drawn as to the accuracy rates of the differenttypes of classifiers, to determine if any other type of classifiers should have more prominence in the State of theArt.This document begins with an introduction to the work being conducted, in which both the its context, mo tivation and objectives are explained. Afterwards, the methodology used in order to more efficiently conductthe research in this Thesis is clarified. Following that, the State of the Art concerning ML based approaches toAction Recognition and Violence Detection is explored. After being brought to date in what are the State of theArt approaches, one is able to move forward to the following chapter, in which the Training method that will beemployed to train the models that were seen as the best candidates to detect violence is detailed. Subsequently,the selected models are scrutinized in an effort to better understand their architecture, and why they are suitedto detect violence. Afterwards, the results achieved by these models are explored, in order to better comprehendhow well these performed. Lastly, the conclusions that were reached after conducting this research are stated,and possibilities for expanding this work further are also presented.The obtained results prove the success and prevalence of video classifiers, and also show the efficacy ofmodels that make use of some kind of fusion.",
    "text2": "The process of Automatic Speech Recognition (ASR) opens doors to a vast amount of possibleimprovements in customer experience. The use of this type of technology has increasedsignificantly in recent years, this change being the result of the recent evolution in ASRsystems. The opportunities to use ASR are vast, covering several areas, such as medical,industrial, business, among others. We must emphasize the use of these voice recognitionsystems in telecommunications companies, namely, in the automation of consumer assistanceoperators, allowing the service to be routed to specialized operators automatically throughthe detection of matters to be dealt with through recognition of the spoken utterances. Inrecent years, we have seen big technological breakthrough in ASR, achieving unprecedentedaccuracy results that are comparable to humans. We are also seeing a move from whatis known as the Traditional approach of ASR systems, based on Hidden Markov Models(HMM), to the newer End-to-End ASR systems that obtain benefits from the use of deepneural networks (DNNs), large amounts of data and process parallelization.The literature review showed us that the focus of this previous work was almost exclusivelyfor the English and Chinese languages, with little effort being made in the development ofother languages, as it is the case with Portuguese. In the research carried out, we did notfind a model for the European Portuguese (EP) dialect that is freely available for generaluse. Focused on this problem, this work describes the development of a End-to-End ASRsystem for EP. To achieve this goal, a set of procedures was followed that allowed us topresent the concepts, characteristics and all the steps inherent to the construction of thesetypes of systems. Furthermore, since the transcribed speech needed to accomplish our goalis very limited for EP, we also describe the process of collecting and formatting data from avariety of different sources, most of them freely available to the public. To further try andimprove our results, a variety of different data augmentation techniques were implementedand tested. The obtained models are based on a PyTorch implementation of the Deep Speech2 model.Our best model achieved an Word Error Rate (WER) of 40.5%, in our main test corpus,achieving slightly better results to those obtained by commercial systems on the same data.Around 150 hours of transcribed EP was collected, so that it can be used to train other ASRsystems or models in different areas of investigation. We gathered a series of interestingresults on the use of different batch size values as well as the improvements provided bythe use of a large variety of data augmentation techniques. Nevertheless, the ASR theme is vast and there is still a variety of different methods and interesting concepts that we couldresearch in order to seek an improvement of the achieved results.",
    "similarity": 0.31420431750883565
  },
  {
    "text1": "Q-Learning is one of the most popular reinforcement learning algorithms. It can solve different complex problemswith interesting tasks where decisions have to be made, all the while using the same algorithm with no interfer ence from the developer about specific strategies. This is achieved by processing a reward received after eachdecision is made.In order to evaluate the performance of Q-Learning on different problems, video games prove to be a greatasset for testing purposes, as each game has its own unique mechanics and some kind of objective that needsto be learned. Furthermore, the results from testing different algorithms on the same conditions can be easilycompared.This thesis presents a study on Q-Learning, from its origins and how it operates, showcasing various state ofthe art techniques used to improve the algorithm and detailing the procedures that have become standard whentraining Q-Learning agents to play video games for the Atari 2600.Our implementation of the algorithm following the same techniques and procedures is ran on different videogames. The training performance is compared to the one obtained in articles that trained on the same gamesand attained state of the art performance.Additionally, we explored crafting new reward schemes modifying game default rewards. Various customrewards were created and combined to evaluate how they affect performance.During these tests, we found that the use of rewards that inform about both good and bad behaviour led tobetter performance, as opposed to rewards that only inform about good behaviour, which is done by default insome games.It was also found that the use of more game specific rewards could attain better results, but these also requireda more careful analysis of each game, not being easily transferable into other games.As a more general approach, we tested reward changes that could incentivize exploration for games that wereharder to navigate, and thus harder to learn from. We found that not only did these changes improve exploration,but they also improved the performance obtained after some parameter tuning.These algorithms are designed to teach the agent to accumulate rewards. But how does this relate to gamescore? To assess this question, we present some preliminary experiments showing the relationship between theevolution of reward accumulation and game score.",
    "text2": "In the last few decades, an increasing growth of Internet usage was witnessed worldwide.However, infrastructures do not always allow the existence of Internet connectivity everywhere.Therefore, to address this issue, the concept of Delay Tolerant Networks (DTNs) wasdeveloped. DTNs purpose is to provide a different level of intermittent connectivity, dissimulatingconnection problems that arise in complex connectivity scenarios. Examples of suchscenarios are, for instance, cities, where cars exchange information about their location; inunderdeveloped countries, where Internet is inexistent; in freeways, where is not viable toprovide infrastructures for a continuous connectivity, but cars, tolls, and services need to beaware of each other. Thus, DTNs constitute a possible solution for all the aforementionedcommunication environments.However, DTNs still faces some obstacles in terms of delivering a service with quality as itlacks specific mechanisms, such as traffic differentiation. Traffic differentiation is essential toprovide different levels of service quality regarding delivering of messages. Current proposalsto improve service delivery through traffic differentiation on DTNs are still under developmentor lack the proper testing and simulation. The main focus of these proposals is on buffermanagement mechanisms at each DTN node, instead of message prioritisation mechanisms.Message prioritisation allows some messages to be prioritised over others, improving thedelivery rate and, therefore, increasing the probability of a message being correctly delivered.The present thesis implements traffic differentiation in DTNs based on prioritisation strategies,assuming a clear alternative to other buffer management proposals and message prioritisation.Using The One simulation tool, three popular DTNs routing protocols (Epidemic,Spray & Wait, and PRoPHET) are adapted to comply with traffic differentiation. The DTNstraffic prioritisation objective is achieved by designing, implementing and testing four distinctalgorithms that classify and order messages according to their priority levels. Thesealgorithms are based and extend some traditional traffic differentiation mechanisms, namelythe well-known Priority Queuing and Weighted Round Robin strategies.Results from the simulation tests corroborate that the delivery rate of the messages isaffected according to their priorities. Specifically, the simulation shows an increase in thedelivery rate of high priority messages, with low impact on the total number of messages delivered,comparatively to the same scenario without differentiation capabilities. To conclude,DTNs can effectively benefit from traffic differentiation based on message prioritisation techniques,being a promising approach to improve service quality levels in such scenarios.",
    "similarity": 0.309333392905013
  },
  {
    "text1": "Q-Learning is one of the most popular reinforcement learning algorithms. It can solve different complex problemswith interesting tasks where decisions have to be made, all the while using the same algorithm with no interfer ence from the developer about specific strategies. This is achieved by processing a reward received after eachdecision is made.In order to evaluate the performance of Q-Learning on different problems, video games prove to be a greatasset for testing purposes, as each game has its own unique mechanics and some kind of objective that needsto be learned. Furthermore, the results from testing different algorithms on the same conditions can be easilycompared.This thesis presents a study on Q-Learning, from its origins and how it operates, showcasing various state ofthe art techniques used to improve the algorithm and detailing the procedures that have become standard whentraining Q-Learning agents to play video games for the Atari 2600.Our implementation of the algorithm following the same techniques and procedures is ran on different videogames. The training performance is compared to the one obtained in articles that trained on the same gamesand attained state of the art performance.Additionally, we explored crafting new reward schemes modifying game default rewards. Various customrewards were created and combined to evaluate how they affect performance.During these tests, we found that the use of rewards that inform about both good and bad behaviour led tobetter performance, as opposed to rewards that only inform about good behaviour, which is done by default insome games.It was also found that the use of more game specific rewards could attain better results, but these also requireda more careful analysis of each game, not being easily transferable into other games.As a more general approach, we tested reward changes that could incentivize exploration for games that wereharder to navigate, and thus harder to learn from. We found that not only did these changes improve exploration,but they also improved the performance obtained after some parameter tuning.These algorithms are designed to teach the agent to accumulate rewards. But how does this relate to gamescore? To assess this question, we present some preliminary experiments showing the relationship between theevolution of reward accumulation and game score.",
    "text2": "The increasing pervasiveness and lower cost of electronic devices equipped with sensorsis leading to a greater and cheaper availability of localized information. The advent ofthe internet has brought phenomena such as crowd-sourced maps and related data. Thecombination of the availability of mobile information, community built maps, with theadded convenience of retrieving information over the internet creates the opportunity tocontextualize data in new ways.This work takes that opportunity and attempts to generalize the detection of drivingevents which are deemed problematic as a function of contextual factors, such as neighbouringbuildings, areas, amenities, the weather, and the time of day, week or month.In order to research the problem at hand, the issue is first contextualized properly, providingan overview of important factors, namely Smart Cities, Data Fusion, and MachineLearning.That is followed by a chapter concerning the state of the art, that showcases relatedprojects and how the various facets of road traffic expression are being approached.The focus is then turned to creating a solution. At first this consists in aggregating dataso as to create a richer context than would be present otherwise, this includes the retrievalfrom different services, as well as the composition of a unique view of the same drivingsituation with new dimensions added to it. And then Models were created using differentMachine Learning methods, and a comparison of results according to selected and justifiedevaluation metrics was made. The compared Methods are Decision Tree, Naive Bayes, andSupport Vector Machine.The different types of information were evaluated on their own as potential classifiers andthen were evaluated together, leading to the conclusion that the various types combinedallow for the creation of better models capable of finding problems with more confidencein such results.According to the tests performed the chosen approach can improve the performanceover a baseline approach and point out problematic situations with a precision of over 90%.As expected by not using factors concerning the driver state or acceleration the scope ofproblems which are detected is limited in domain.",
    "similarity": 0.3065894224725902
  },
  {
    "text1": "Ao longo dos últimos anos, tem aumentado exponencialmente a utilização de Tecnologiasde Informação (TIs) e de ferramentas computacionais em vários setores económicos, incluindoo setor da saúde, por serem defendidas como tecnologias que podem transformare melhorar radicalmente a prestação de cuidados de saúde.O principal objetivo das instituições de saúde é prestar os melhores cuidados de saúdeaos seus utentes, garantindo, assim, a prestação de serviços de qualidade e a consequentesatisfação dos utentes, bem como reduzir os custos e desperdícios desnecessários associados.Portanto, as decisões devem ser tomadas rapidamente mas, igualmente, eficazmente.Acredita-se, assim, que o futuro realmente bem sucedido das TIs no setor da saúdepassa então pelo desenho e pela implementação de sistemas user-friendly, incluindo Sistemasde Apoio à Decisão Clínica (SADCs), personalizados e focados no paciente, bem comoa receptibilidade dos profissionais de saúde aos mesmos. Abrange, igualmente, o uso detecnologias emergentes na sua conceção, incluindo Business Intelligence (BI), de modo a tirarreal partido da informação disponível.Deste modo, no âmbito deste projeto de dissertação, foram desenhadas, desenvolvidase exploradas uma nova geração de ferramentas Web de Business Intelligence para o apoio àdecisão e a prática clínica em unidades hospitalares. Englobou, em particular, o desenvolvimentode uma plataforma de BI versátil, incluindo a sua aplicação a dois casos práticosdiferentes, notadamente no apoio à decisão nas listas de espera de consultas e de cirurgias,assim como nos cuidados de Ginecologia e Obstetrícia (GO), e de uma ferramenta decodificação clínica ICD-9-CM (International Classification of Diseases, Ninth Revision, ClinicalModification).Assim, as ferramentas foram projetadas de modo a auxiliar os profissionais de saúde doCentro Hospitalar do Porto (CHP) no seu trabalho diário, incluindo a lidar com pacientesem condições delicadas e determinadas situações que requerem uma tomada de decisãoeficiente, bem como a codificação clínica de episódios de altas hospitalares.",
    "text2": "A alocação adequada de órgãos para transplantação é crítica e crucial. No entanto, o número de órgãos a ser doados não é suficiente dada a quantidade de pacientes em lista de espera. Assim, a determinação do maior número possível de potenciais dadores, de forma eficiente e eficaz torna-se essencial e pode contribuir para melhorar a taxa de sucesso de transplantação de órgãos.Ao longo dos últimos anos, a utilização de Tecnologias de Informação (TIs) e de ferramentas computacionais em vários setores económicos, incluindo o setor da saúde, cresceu exponencialmente, já que têm potencial para transformar e melhorar a prestação de cuidados de saúde. Assim, e aliando a necessidade da eficiência na descoberta de potenciais dadores com a emergência das TIs na saúde, surge a necessidade de uma plataforma Web de apoio à decisão clínica. O objetivo desta plataforma é automatizar o processo de descoberta de informaçãoútil e acionável, através da utilização de tecnologias como Business Intelligence(BI) e Data Mining (DM), ajudando na tomada de decisão clínica diária. Assim, esta éresponsável pela recolha, gestão, armazenamento e sinalização de potenciais dadores.No âmbito deste projeto de dissertação, foi redesenhada e otimizada a plataforma Web Organite, atualmente implementada no Centro Hospitalar do Porto (CHP). Envolveu transformações tanto no design da interface do utilizador, como no modo como a informação está organizada na plataforma, de forma a melhorar a experiência do utilizador e a interação com os dados clínicos. Foi ainda desenvolvida uma metodologia, com base em técnicas de Data Mining, para construir um modelo preditivo que avalia quais os pacientes que dão entrada no hospital que têm maior probabilidade em serpotenciais dadores de órgãos. O objetivo é tornar mais simples e eficaz o processo de identificação de potenciais dadores, contribuindo positivamente na tomada de decisão do Gabinete de Coordenação de Colheita e Transplantação (GCCT), e impactando na redução da lista de doentes que aguarda um transplante.",
    "similarity": 0.3554952665063469
  },
  {
    "text1": "Either to improve the drivers knowledge about the road, or focusing on the current development of autonomous vehicles, most car manufacturers began offering driving assistancesystems in their vehicles. A crucial part of the monitoring task performed by those systems isthe detection and reaction over found traffic signs. Since the decision flow of those solutionsis reliant on the information gathered from the found signs, these systems deeply rely on theirrecognition stage.To achieve high-accuracy classification rates at nearly real-time, recognition is usually implemented using machine learning techniques, such as state of the art Convolution NeuralNetworks (CNNs). However, these methods demand a large amount of data for their learningprocess. Due to the lack of large traffic signs repositories, these systems are restricted to oneof the few available datasets. A significant decrease in accuracy was observed when using arecognition model trained with samples from a given country and latter used to classify signsfrom another country, thus supporting the need for country-specific repositories and trainedmodels. Traffic signs reveal several differences when compared to the same functional signover different countries. Those changes, although similar for the human perception, causea significant disturbance in the classification abilities learned by a given machine learningmodel.Aiming to overcome this issue, this dissertation proposes a semi autonomous tool to createtraffic sign repositories, for almost any given country. The created dataset is intended to laterbe applied to train country-specific models, with traffic sign images from the country wherethe recognition model is going to be used. To achieve this, a pipeline based on an Ensemblearchitecture joining several computer vision techniques is proposed. The combination ofvarious methods allows to improve the recognition rates and, more importantly, decrease thenumber of false positives gathered in the produced repositories.Finally, the pipeline was used to create the first Portuguese traffic sign repository, havingcurrently around 33000 labelled signs.",
    "text2": "Currently, Advanced Driver Assistance Systems (ADAS) have been gradually increasing theirpresence in everyday life, thanks in part to its ability to recognize several distinct typesof objects in the road, namely, traffic signs. These systems employ Convolutional NeuralNetworks (CNNs), a type of classification algorithms that relies on an enormous amount ofdata in order to be effective. Current traffic sign datasets suffer from a scarcity of samplesdue to the necessity of compiling and labeling them manually. Such task is highly resourceand time consuming. Thus, researches resort to other mechanisms to deal with this problem,such as increasing the architectural complexity of the neural networks or performing dataaugmentation.This work addresses the data shortage issue by exploring the feasibility of developing asynthetic dataset. Such set would not require gathering and labelling manually thousandsof real word traffic sign images, requiring only easily collectable information and no humanintervention.The only data required is a set of templates for each sign given that a particular sign mayhave more than one template. This is required to cope with outdated pictograms that arestill present in streets and roads.We apply several colour and geometric processing methods to the templates aiming toachieve a look similar to real signs, from the CNN point of view. One of such methods isthe usage of Perlin noise to both simulate shadows and avoid the clean and homogeneouslook that templates have.Two use cases for synthetic data usage are presented: considering the synthetic datasetas a standalone training set, and merging synthetic data with real samples when real datais available. The first option provided results that not only clearly surpass any previousattempt on using synthetic data for traffic sign recognition, but are also encouraginglyplacing the accuracies obtained close to state-of-the-art results, with much simpler networks.The second approach provided results on three distinct test datasets that consistently beatstate-of-the-art results, either in accuracy or in simplicity of the network.",
    "similarity": 0.3159122651830816
  },
  {
    "text1": "A evolução tecnológica das últimas décadas generalizou o uso de software para a substituição ou suporte de múltiplos processos das empresas e, evidenciou novas perspectivas para o desenvolvimento de soluções com altos níveis de performance, disponibilidade, escalabilidade e flexibilidade. No contexto Vortal (empresa líder no mercado de contratação electrónica português com a plataforma VortalNext>), esta generalização levou à necessidade da existência mecanismos que permitam aos seus clientes a personalização/criação de áreas de trabalho dedicadas.Tendo esta necessidade como foco, são avaliados os diferentes componentes da plataforma Next>, a metodologia de desenvolvimento atualmente utilizada (Model Driven Architecture) e quais as melhores aproximações para o desenvolvimento de aplicações no âmbito de uma plataforma web, focando as suas vantagens e desvantagens a nível arquitetural e aplicacional.Concluiu-se que todas as soluções estudadas são adequados ao desenvolvimento de aplicações web, sendo o seu grau de adequação variável com o contexto de utilização. São soluções diferentes relativamente à complexidade de implementação, aos recursos necessários, aos riscos envolvidos e à simplicidade de utilização por parte do grupo de utilizadores finais.Por fim, é apresentada a arquitetura de um Software Development Kit (são estudadas outras opções, sendo esta a que oferece mais estabilidade aplicacional e mais vantagens competitivas) e a sua integração no ecossistema aplicacional e arquitetural da plataforma maximizando, não apenas a flexibilidade e funcionalidade para o cliente final, como também a segurança, robustez e fiabilidade do ecossistema da plataforma. A arquitetura definida em conjunto com o modelo de negócio apresentado formam a linha de ação indicada para garantir a existência de aplicações personalizadas a serem executadas no ecossistema VortalNext>.",
    "text2": "O rápido crescimento da complexidade dos sistemas de software exige, agora mais do que nunca, uma validação rigorosa dos mesmos por forma a manter ou até mesmo aumentar a confiança nestes sistemas. Em particular nos sistemas críticos, onde as falhas podem ter consequências catastróficas podendo até incluir a perca de várias vidas humanas, é de externa importância o desenvolvimento de técnicas capazes de garantir altos níveis de confiança para estes sistemas.Nesta tese é proposta a utilização de uma técnica formal para a verificação de programas Ada, que pretende aumentar a confiança em sistemas cuja implementação seja realizada nesta linguagem de programação. Mais precisamente, pretende-se a aplicação da técnica de verificação de modelos para a análise do código fonte de programas concorrentes Ada, com especial foco para o domínio dos sistemas críticos.A verificação de modelos é uma técnica bem-sucedida no que diz respeito à garantia de um aumento de fiabilidade destes sistemas. No entanto, a aplicação desta técnica a sistemas de software enfrenta ainda vários obstáculos, e as ferramentas e técnicas para ajudar a ultrapassar estes obstáculos estão ainda a ser desenvolvidas. A ferramenta desenvolvida no contexto desta tese (ATOS) visa responder a problemas como (i) a construção de modelos a partir de programas e (ii) a especificação de propriedades para estes modelos de acordo com as pretendidas para os programas.A construção manual de modelos que simulam o comportamento de programas é um processo complexo, temporalmente dispendioso, e sujeito a falhas devido à complexidade destes sistemas. De forma a ultrapassar este problema o ATOS propõe a extração automática de modelos a partir de programas Ada. Por outro lado, o mapeamento das propriedades desejadas dos programas em propriedades dos modelos pode ser urna tarefa com um grau de complexidade elevado, pois requer entre outros a utilização de um formalismo logico ao qual a maioria dos programadores não está acostumada. 0 ATOS ajuda no mapeamento destas propriedades, oferecendo vários mecanismos de suporte à sua especificação.",
    "similarity": 0.3069142732176702
  },
  {
    "text1": "A evolução tecnológica das últimas décadas generalizou o uso de software para a substituição ou suporte de múltiplos processos das empresas e, evidenciou novas perspectivas para o desenvolvimento de soluções com altos níveis de performance, disponibilidade, escalabilidade e flexibilidade. No contexto Vortal (empresa líder no mercado de contratação electrónica português com a plataforma VortalNext>), esta generalização levou à necessidade da existência mecanismos que permitam aos seus clientes a personalização/criação de áreas de trabalho dedicadas.Tendo esta necessidade como foco, são avaliados os diferentes componentes da plataforma Next>, a metodologia de desenvolvimento atualmente utilizada (Model Driven Architecture) e quais as melhores aproximações para o desenvolvimento de aplicações no âmbito de uma plataforma web, focando as suas vantagens e desvantagens a nível arquitetural e aplicacional.Concluiu-se que todas as soluções estudadas são adequados ao desenvolvimento de aplicações web, sendo o seu grau de adequação variável com o contexto de utilização. São soluções diferentes relativamente à complexidade de implementação, aos recursos necessários, aos riscos envolvidos e à simplicidade de utilização por parte do grupo de utilizadores finais.Por fim, é apresentada a arquitetura de um Software Development Kit (são estudadas outras opções, sendo esta a que oferece mais estabilidade aplicacional e mais vantagens competitivas) e a sua integração no ecossistema aplicacional e arquitetural da plataforma maximizando, não apenas a flexibilidade e funcionalidade para o cliente final, como também a segurança, robustez e fiabilidade do ecossistema da plataforma. A arquitetura definida em conjunto com o modelo de negócio apresentado formam a linha de ação indicada para garantir a existência de aplicações personalizadas a serem executadas no ecossistema VortalNext>.",
    "text2": "Atualmente, o maior desafio no desenvolvimento de software é referente à a portabilidade das aplicações para as várias plataformas disponíveis, especialmente pela crescente heterogeneidade nos componentes de hardware, de middleware e de software base.O desenho de modelos abstratos de software é uma das formas mais elegantes e eficientes para solucionar este desafio. A Model-Driven Software Engineering (MDSE) ́é uma metodologia de desenvolvimento em que os modelos são chave em todo o ciclo de vida do projeto, desde a captura de requisitos, passando pelas fases de modelação e desenvolvimento, e por fim nos processos de teste e instalação.O objetivo primário desta dissertação foca-se na construção de uma ferramenta, o MDA SMART, capaz de interpretar modelos abstratos de software, parametrizáveis, e de gerar automaticamente código fonte para várias plataformas. A ferramenta, caracterizada por uma arquitetura robusta e extensível, é idealizada para permitir a manipulação de modelosde forma ágil, para ser modular o suficiente para integrar novos perfis meta-modelo e para escalar eficientemente para novas plataformas.O MDA SMART resulta da articulação de uma Domain-Specific Language (DSL) para a gestão dos meta-modelos e consequentes processos de transformação. Na utilização da DSL são obtidos processos de transformação rigorosos, com elevado desempenho e que visam maximizar a consistência e portabilidade dos modelos através de medidas ajustadas a destoarem a heterogeneidade entre as plataformas. Adicionalmente, a ferramenta visa compatibilizar os modelos de lógica de negócio com os referentes às interfaces gráficas que, conjugados, vão permitir a obtenção de modelos e código fonte com alto nível de consistência e completude.",
    "similarity": 0.32047894107277763
  },
  {
    "text1": "A evolução tecnológica das últimas décadas generalizou o uso de software para a substituição ou suporte de múltiplos processos das empresas e, evidenciou novas perspectivas para o desenvolvimento de soluções com altos níveis de performance, disponibilidade, escalabilidade e flexibilidade. No contexto Vortal (empresa líder no mercado de contratação electrónica português com a plataforma VortalNext>), esta generalização levou à necessidade da existência mecanismos que permitam aos seus clientes a personalização/criação de áreas de trabalho dedicadas.Tendo esta necessidade como foco, são avaliados os diferentes componentes da plataforma Next>, a metodologia de desenvolvimento atualmente utilizada (Model Driven Architecture) e quais as melhores aproximações para o desenvolvimento de aplicações no âmbito de uma plataforma web, focando as suas vantagens e desvantagens a nível arquitetural e aplicacional.Concluiu-se que todas as soluções estudadas são adequados ao desenvolvimento de aplicações web, sendo o seu grau de adequação variável com o contexto de utilização. São soluções diferentes relativamente à complexidade de implementação, aos recursos necessários, aos riscos envolvidos e à simplicidade de utilização por parte do grupo de utilizadores finais.Por fim, é apresentada a arquitetura de um Software Development Kit (são estudadas outras opções, sendo esta a que oferece mais estabilidade aplicacional e mais vantagens competitivas) e a sua integração no ecossistema aplicacional e arquitetural da plataforma maximizando, não apenas a flexibilidade e funcionalidade para o cliente final, como também a segurança, robustez e fiabilidade do ecossistema da plataforma. A arquitetura definida em conjunto com o modelo de negócio apresentado formam a linha de ação indicada para garantir a existência de aplicações personalizadas a serem executadas no ecossistema VortalNext>.",
    "text2": "O recurso a ferramentas de geração automática de código permite economizar tempo quando se desenvolvem soluções de software, factor importante em questões de produtividade.Existe um conjunto de padrões de conceção [Gamma et al., 1995] que representam soluções genéricas para problemas relativos ao desenvolvimento de aplicações de software, numa perspetiva orientada aos objetos. Para cada um deles pode ser vista a sua estrutura de classes, métodos e relacionamentos, bem como as situações mais adequadas para a sua utilização. Bastará consultar o catálogo de padrões de conceção [Gamma et al., 1995] e utilizar aquele que mais se adequar à resolução de determinado problema que surja no desenvolvimento de um novo programa.A existência de uma aplicação de software capaz de fazer a geração automática do código associado aos padrões de conceção, agiliza o desenvolvimento de novas aplicações, porque fornece de imediato o respetivo código.O que se propõe com o desenvolvimento desta dissertação é uma solução de software, capaz de efetuar a geração automática de código para os padrões de conceção catalogados em [Gamma et al., 1995]. Juntamente com o programa desenvolvido, é também apresentado um levantamento do estado da arte sobre os padrões de conceção, considerando também situações atuaisda sua aplicabilidade. Em seguida, é descrita a especificação da aplicação elaborada, bem como o seu processo de desenvolvimento, acompanhado de um exemplo de utilização. Por fim, encontram-se dois casos de estudo, servindo para provar que o programa elaborado pode ser utilizado em contextos reais.",
    "similarity": 0.30097346386300683
  },
  {
    "text1": "A Internet of Things (IoT) é uma das áreas tecnológicas que necessita de sistemas distribuídos quesuportem o armazenamento e acesso à enorme quantidade de dados constantemente produzidos porcentenas a milhares de dispositivos. Até agora, a maioria dos sistemas desenvolvidos encontravam-seadaptados a instalações em centro de dados, impulsionados pela adoção de serviços de computação emnuvem, porém, o sistema distribuído Large Scale File System (LSFS), veio mudar o paradigma atual emover o armazenamento distribuído para infraestruturas totalmente descentralizadas. Este é um sistemade ficheiros peer-to-peer não estruturado, parcialmente compatível com a interface POSIX, que permite arealização de leituras por parte de múltiplos utilizadores, mas escritas por parte de um só utilizador. Foiconstruído para atingir alta disponibilidade e resiliência e encontra-se preparado para escalar para infraes truturas do futuro. Todavia, o LSFS não apresenta operações essenciais de um sistema de ficheiros, comoa eliminação ou modificação de dados, a grande carga que é exercida sobre a rede tem consequênciasnegativas no sistema como um todo e a forma como este foi avaliado levanta várias questões.Com o propósito de resolver estes desafios, desenvolveu-se o improved Large Scale File System(iLSFS), um sistema de ficheiros que estende o sistema LSFS, dotando-o de uma melhor usabilidade, maspreservando todas as suas características fundamentais como a escalabilidade, a resiliência e a disponi bilidade. Para isso, o sistema adota soluções, como Tombstones, que viabilizam a eliminação de dadose a disponibilização de uma interface com maior compatibilidade com o standard POSIX, implementamétodos, como Version Vectors, que permitem o controlo de concorrência entre múltiplos utilizadores, emecanismos, como caches, que ajudam a mitigar o problema de saturação da rede.Os resultados obtidos, demonstram que o iLSFS, com todas as funcionalidades introduzidas, apre senta uma melhor usabilidade sem, no entanto, comprometer significativamente o desempenho. Quandointroduzido num caso de estudo real, demonstra-se que o sistema é capaz de escalar para ambientes delarga escala, com centenas de nodos, e mesmo quando submetido a cenários de instabilidade, onde aocorrência de falhas aleatórias é a norma, o iLSFS mostra-se capaz de tolerar a falha de uma grandequantidade de nodos de armazenamento, sem que esta provoque uma disrupção do seu funcionamento.",
    "text2": "A eficiência e desempenho das operações de Entrada/Saída(E/S) são aspetos fundamentais na implementação de sistemas de armazenamento. A maioria das soluções atuais são implementadas emkernel, obrigando a trocas de contexto entre espaço de utilizador e kernel por parte das aplicações. Estas trocas de contexto são custosas e, por isso, limitam o desempenho do sistema de armazenamento.A plataforma Storage Performance Development Kit (SPDK) disponibiliza uma forma de construir estessistemas evitando o acesso a kernel, realizando todas as operações de E/S necessárias diretamente doespaço de utilizador para o disco físico.Contudo, os dados continuam a ter que ser guardados com garantias de persistência. Assim sendo,os sistemas construídos com SPDK devem se tolerantes a faltas para garantir resiliência em cenários defalta. A inexistência de uma ferramenta capaz de testar essa resiliência em sistemas de armazenamentoconstruídos com SPDK é um problema para os programadores que querem testar a resiliência dos seussistemas.De forma a resolver este problema, esta dissertação propõe o Fault Injector in SPDK (FISPDK), umaferramenta que estende o SPDK e fornece injeção de faltas determinística ao nível do block device. Parainjetar faltas deterministicamente, FISPDK utiliza diferenciação de pedidos E/S de forma a identificar quaispedidos devem (ou não) ser injetados com uma falta. Para isso, o FISPDK implementa mecanismos depropagação de contexto, que permitem passar informação da aplicação para os níveis mais baixos daspilhas de E/S, e é baseado numa extensão da block device Application Programming Interface (API)original do SPDK. Para providenciar injeção de faltas, o FISPDK apresenta um block device virtual queinterceta pedidos E/S e injeta corrupção de dados ou atraso neles. O block device virtual pode serconfigurado pelos utilizadores para apontar os tipos de faltas e quais os pedidos que devem ser injetadoscom essas faltas.Uma avaliação compreensiva do FISPDK demonstra que a nossa solução consegue injetar faltas deforma determinística e avaliar a tolerância a faltas de sistemas de armazenamento que usam SPDK, semadicionar uma sobrecarga significativa à pilha de armazenamento.",
    "similarity": 0.3031651347267691
  },
  {
    "text1": "Over the past few years, we have seen an exponential increase in the amount of data produced. This increase indata is due, in large part, to the massive use of sensors, as well as the immense amount of existing applications.Due to this factor, and in order to obtain relevant information through the data, companies, institutions and thescientific community are constantly looking for new solutions to be able to respond to the challenges.One of the areas where evolution is most needed is the area of healthcare, an area on which we all dependas a society. Every day, traditional healthcare information systems produce a large amount of data, making itcomplex to manage. Much of this data is produced by IoT devices, such as vital signs monitors, and in manycases can be critical to the patient’s health, as in the case of Intensive Care Units.In this sense, the main objective of this dissertation is to expose the advantages and disadvantages of theapplicability of microservices architectures and the use of Apache Kafka in the health area, more specificallyin Intensive Care Units where the information flow is critical. In order to support these objectives, a Proof ofConcept was developed, based on a future real applicability, which will support the carrying out of analyzes andtests.",
    "text2": "The continuous social and economic development has led, over time, to an increase inconsumption, as well as a greater demand from the consumer for what he buys. In thissense retailers have the need to respond to these challenges and explore new opportunities.Naturally, the selling price of a product assumes a fundamental role in the purchasedecision, and in that way the retailers must carefully analyze and define the best price foreach product, based on several factors, such as: perceived value of the product, positioningof the product, the company strategy, competition.Faced with all these challenges, the use of Information Systems is essential for retailers sothat it can support them in the pricing decision. These information systems are becomingincreasingly complex, including demand forecasts, and making recommendations based onbalanced buying patterns due by the economic evolution of markets.In a first phase the ideia was to make a study on two main price recommendation systems:Rules Motors and Price Optimization. As the objective of the dissertation is to change thealgorithm of Regular Price Optimization of the software tool Profimetrics, part of the studywas conducted according to the methodology of the tool. After an analysis of the company’scurrent algorithm, the changes were made to perfect it. Subsequently, we used the casestudy methodology, in the application of the algorithm developed to a retail company.Through this case study it was possible to make a brief diagnosis in order to comparethe current algorithm of the company with the developed algorithm.",
    "similarity": 0.3124275268955743
  },
  {
    "text1": "Over the past few years, we have seen an exponential increase in the amount of data produced. This increase indata is due, in large part, to the massive use of sensors, as well as the immense amount of existing applications.Due to this factor, and in order to obtain relevant information through the data, companies, institutions and thescientific community are constantly looking for new solutions to be able to respond to the challenges.One of the areas where evolution is most needed is the area of healthcare, an area on which we all dependas a society. Every day, traditional healthcare information systems produce a large amount of data, making itcomplex to manage. Much of this data is produced by IoT devices, such as vital signs monitors, and in manycases can be critical to the patient’s health, as in the case of Intensive Care Units.In this sense, the main objective of this dissertation is to expose the advantages and disadvantages of theapplicability of microservices architectures and the use of Apache Kafka in the health area, more specificallyin Intensive Care Units where the information flow is critical. In order to support these objectives, a Proof ofConcept was developed, based on a future real applicability, which will support the carrying out of analyzes andtests.",
    "text2": "One of the reasons for the increased number of visits to emergency departments is theprimary health care inability to handle urgent needs and provide all the health servicesneeded to assess complex conditions. A significant amount of these visits are due to theabnormal flow of patients whose clinical condition is of low severity and could ideally beresolved with self-care and primary health care.The crowding in emergency departments causes operational and logistical problems andhas undesirable consequences for patients, health professionals and hospitals. Delays intreatment interventions and increased mortality, medical errors and waiting times are just aphew examples of critical consequences that can occur, resulting in a significant barrier tothe quality of health care delivery.With the advances in technology, several institutions have found in self-service an alternativefor the patient’s collection of health information autonomously. These devices can be usedby low clinical severity patients (with the blue, green or yellow bracelets from Manchestertriage) to reduce waiting time in the emergency departments.This dissertation proposes a technological solution to improve both the time and qualityof the anamnesis procedure performed by medical staff in the emergency department. Theintroduction of a self-service kiosk in the emergency department waiting room will make itpossible to quickly and intuitively collect the patient’s past medical history, usual medication,main complaint symptoms and vital signs. Subsequently, this data will be made availableto the physician before each clinical observation. The hypothesis considered is that byproviding a selective, structured and uniform anamnesis information’s presentation of eachpatient, medical staff observation can proceed much faster and accurately, focusing on theconfirmation of the most relevant aspects. The primary purpose of this solution is to reducethe period of clinical observation and thus improve the response capacity of the emergencydepartment with the same resources.",
    "similarity": 0.30862188365650967
  },
  {
    "text1": "Smoothed-particle Hydrodynamics (SPH) is a particle-based simulation considered by many to be the maincandidate for fluid simulation. This model was developed by R.A. Gingold and J.J. Monaghan in 1977 and hadthe purpose of solving astrophysical problems. Over the years, Monaghan has revisited SPH (1985, 1988, 1992and so on) and it also gained traction with other researchers who discovered new applications for the model suchas ballistics, volcanology, oceanography, and so on. Among the fields there is one we are particularly interestedin, and that is Fluid Simulation.This work aims to implement SPH using efficient data structures that allow a real-time simulation to run on theGraphics Processing Unit (GPU). According to the literature, the z-order indexing method and the hash map arethe most suitable structures for this purpose. It is intended to see its impact and in which situations one will bebetter suited to use than the other.With said implementation, several tests were performed in order to analyze the robustness and stability of themethod. With these tests it was possible to compare the two data structures used.The implemented SPH showed realistic and robust results in most cases, being able to handle multiple scenesof varying levels of complexity. Despite the good results, it showed some difficulties in maintaining stability insome boundaries (boundaries with great curvature or sharp edges) and also showed some difficulties in sceneswith two fluids with different densities.As for the data structures, it was possible to observe that both are efficient and support real-time simulationswith more than 1 million particles (using a NVIDIA RTX 3080). In the case of z-order, it proved to be the methodwith the best performance when compared to the hash map under the same conditions, that is, scenes with thesame number of particles and the same simulation volume. This is due to the larger data locality that z-order has.On the other hand the hash map was a bit slower (when compared with the z-order under the same conditions)but allowed for greater freedom when creating a scene. When comparing the two methods with the same numberof particles but different simulation volumes we can see that the hash map catches up with the z-order methodas the particles spread across the simulation.With the two data structures analyzed it is possible to draw some conclusions. The z-order method is recom mended when we have a limited and relatively small simulation volume. In case there is no simulation volume,or it is very large, it is recommended to use a hash map since the performance deficit seems to disappear as thesimulation volume gets bigger and the particles spread across the volume.",
    "text2": "The applications’ development paradigm has faced changes in recent years, with modern development being characterized by the need to continuously deliver new software iterations. With great affinity with those principles,microservices is a software architecture which features characteristics that potentially promote multiple qualityattributes often required by modern, large-scale applications. Its recent growth in popularity and acceptance inthe industry made this architectural style often described as a form of modernizing applications that allegedlysolves all the traditional monolithic applications’ inconveniences. However, there are multiple worth mentioning costs associated with its adoption, which seem to be very vaguely described in existing empirical research, being often summarized as \"the complexity of a distributed system\". The adoption of microservices provides theagility to achieve its promised benefits, but to actually reach them, several key implementation principles haveto be honored. Given that it is still a fairly recent approach to developing applications, the lack of establishedprinciples and knowledge from development teams results in the misjudgment of both costs and values of thisarchitectural style. The outcome is often implementations that conflict with its promised benefits. In order toimplement a microservices-based architecture that achieves its alleged benefits, there are multiple patterns andmethodologies involved that add a considerable amount of complexity. To evaluate its impact in a concrete andempirical way, one same e-commerce platform was developed from scratch following a monolithic architecturalstyle and two architectural patterns based on microservices, featuring distinct inter-service communication anddata management mechanisms. The effort involved in dealing with eventual consistency, maintaining a communication infrastructure, and managing data in a distributed way portrayed significant overheads not existent in thedevelopment of traditional applications. Nonetheless, migrating from a monolithic architecture to a microservicesbasedis currently accepted as the modern way of developing software and this ideology is not often contested, nor the involved technical challenges are appropriately emphasized. Sometimes considered over-engineering,other times necessary, this dissertation contributes with empirical data from insights that showcase the impact of the migration to microservices in several topics. From the trade-offs associated with the use of specific patterns, the development of the functionalities in a distributed way, and the processes to assure a variety of quality attributes, to performance benchmarks experiments and the use of observability techniques, the entire development process is described and constitutes the object of study of this dissertation.",
    "similarity": 0.3004382180645747
  },
  {
    "text1": "Smoothed-particle Hydrodynamics (SPH) is a particle-based simulation considered by many to be the maincandidate for fluid simulation. This model was developed by R.A. Gingold and J.J. Monaghan in 1977 and hadthe purpose of solving astrophysical problems. Over the years, Monaghan has revisited SPH (1985, 1988, 1992and so on) and it also gained traction with other researchers who discovered new applications for the model suchas ballistics, volcanology, oceanography, and so on. Among the fields there is one we are particularly interestedin, and that is Fluid Simulation.This work aims to implement SPH using efficient data structures that allow a real-time simulation to run on theGraphics Processing Unit (GPU). According to the literature, the z-order indexing method and the hash map arethe most suitable structures for this purpose. It is intended to see its impact and in which situations one will bebetter suited to use than the other.With said implementation, several tests were performed in order to analyze the robustness and stability of themethod. With these tests it was possible to compare the two data structures used.The implemented SPH showed realistic and robust results in most cases, being able to handle multiple scenesof varying levels of complexity. Despite the good results, it showed some difficulties in maintaining stability insome boundaries (boundaries with great curvature or sharp edges) and also showed some difficulties in sceneswith two fluids with different densities.As for the data structures, it was possible to observe that both are efficient and support real-time simulationswith more than 1 million particles (using a NVIDIA RTX 3080). In the case of z-order, it proved to be the methodwith the best performance when compared to the hash map under the same conditions, that is, scenes with thesame number of particles and the same simulation volume. This is due to the larger data locality that z-order has.On the other hand the hash map was a bit slower (when compared with the z-order under the same conditions)but allowed for greater freedom when creating a scene. When comparing the two methods with the same numberof particles but different simulation volumes we can see that the hash map catches up with the z-order methodas the particles spread across the simulation.With the two data structures analyzed it is possible to draw some conclusions. The z-order method is recom mended when we have a limited and relatively small simulation volume. In case there is no simulation volume,or it is very large, it is recommended to use a hash map since the performance deficit seems to disappear as thesimulation volume gets bigger and the particles spread across the volume.",
    "text2": "The 2D convection-diffusion is a well-known problem in scientific simulation that often usesa direct method to solve a system of N linear equations, which requires N3 operations.This problem can be solved using a more efficient computational method, known as thealternating direction implicit (ADI). It solves a system of N linear equations in 2N times withN operations each, implemented in two steps, one to solve row by row, the other column bycolumn. Each N operation is fully independent in each step, which opens an opportunity toan embarrassingly parallel solution. This method also explores the way matrices are stored incomputer memory, either in row-major or column-major, by splitting each iteration in two.The major bottleneck of this method is solving the system of linear equations. Thesesystems of linear equations can be described as tridiagonal matrices since the elements arealways stored on the three main diagonals of the matrices. Algorithms tailored for tridiagonalmatrices, can significantly improve the performance. These can be sequential (i.e. the Thomasalgorithm) or parallel (i.e. the cyclic reduction CR, and the parallel cyclic reduction PCR).Current vector extensions in conventional scalar processing units, such as x86-64 andARM devices, require the vector elements to be in contiguous memory locations to avoidperformance penalties. To overcome these limitations in dot products several approachesare proposed and evaluated in this work, both in general-purpose processing units and inspecific accelerators, namely NVidia GPUs.Profiling the code execution on a server based on x86-64 devices showed that the ADImethod needs a combination of CPU computation power and memory transfer speed. Thisis best showed on a server based on the Intel manycore device, KNL, where the algorithmscales until the memory bandwidth is no longer enough to feed all 64 computing cores. Adual-socket server based on 16-core Xeon Skylakes, with AVX-512 vector support, proved tobe a better choice: the algorithm executes in less time and scales better.The introduction of GPU computing to further improve the execution performance (andalso using other optimisation techniques, namely a different thread scheme and sharedmemory to speed up the process) showed better results for larger grid sizes (above 32Ki x32Ki). The CUDA development environment also showed a better performance than usingOpenCL, in most cases. The largest difference was using a hybrid CR-PCR, where the OpenCLcode displayed a major performance improvement when compared to CUDA. But even withthis speedup, the better average time for the ADI method on all tested configurations on aNVidia GPU was using CUDA on an available updated GPU (with a Pascal architecture) andthe CR as the auxiliary method.",
    "similarity": 0.318186703601108
  },
  {
    "text1": "In the last decades, the scientific community has produced huge amounts of publications aboutthe most varied biomedical topics, making the search for relevant information a really difficulttask for every researcher. Some approaches have been followed to develop tools that canfacilitate this process. For instance, PubMed implemented in 2017 a Machine Learning model tosort documents by their relevance. Nevertheless, even the authors consider that their systemwould benefit from the implementation of a Deep Learning model, which for now needs morestudies.In this context, a package called BioTMPy1 was developed in this work, to perform documentclassification of biomedical literature using the Python programming language. The packageis divided into different modules to provide to the user functions to read documents in differentformats, perform preprocessing and data analysis and to train, optimize and evaluate Machineand Deep learning models. Our package also provides intuitive pipelines that can be easilyadapted for the user needs, illustrating how to implement complex deep learning models.The developed package was applied to a dataset from a challenge of the BioCreative forum,from 2019, about protein-protein interactions altered by mutations, an important topic for theadvances related to precision medicine. Using this dataset, it was possible to observe a slightlybetter performance of BioWordVec pre-trained embeddings over GloVe, ”pubmed pmc” and”pubmed ncbi” embeddings. Also, with the evaluation of the developed models on the test set,we managed to overcome the challenge’s best submission, by using a model with BioBERT anda bidirectional LSTM on top, resulting in a difference of 7.25% for average precision, 3.22% forprecision, 2.99% for recall and 3.15% for the f1-score.Also, a web server was developed to provide access to the best Deep Learning modeltrained in this work. The overall pipeline here developed can be applied to other case studies indifferent topics, provided there is a set of documents annotated as relevant and non-relevant,allowing to train the models.",
    "text2": "One of the challenging problems in bioinformatics is to computationally characterize sequences, structures and functions of proteins. Sequence-derived structural and physico-chemical properties of proteins have been used in the development of machine learning models in protein related problems. However, tools and platforms to calculate features and perform Machine learning (ML) with proteins are scarce and have their limitations in terms of effectiveness, user-friendliness and capacity. Here, a generic modular automated platform for the classification of proteins based on their physicochemical properties using different ML algorithms is proposed. The tool developed, as a Python package, facilitates the major tasks of ML and includes modules to read and alter sequences, calculate protein features, preprocess datasets, execute feature reduction and selection, perform clustering, train and optimize ML models and make predictions. As it is modular, the user retains the power to alter the code to fit specific needs. This platform was tested to predict membrane active anticancer and antimicrobial peptides and further used to explore viral fusion peptides. Membrane-interacting peptides play a crucial role in several biological processes. Fusion peptides are a subclass found in enveloped viruses, that are particularly relevant for membrane fusion. Determining what are the properties that characterize fusion peptides and distinguishing them from other proteins is a very relevant scientific question with important technological implications. Using three different datasets composed by well annotated sequences, different feature extraction techniques and feature selection methods (resulting in a total of over 20 datasets), seven ML models were trained and tested, using cross validation for error estimation and grid search for model selection. The different models, feature sets and feature selection techniques were compared. The best models obtained for distinct metric were then used to predict the location of a known fusion peptide in a protein sequence from the Dengue virus. Feature importances were also analysed. The models obtained will be useful in future research, also providing a biological insight of the distinctive physicochemical characteristics of fusion peptides. This work presents a freely available tool to perform ML-based protein classification and the first global analysis and prediction of viral fusion peptides using ML, reinforcing the usability and importance of ML in protein classification problems.",
    "similarity": 0.3179441576429111
  },
  {
    "text1": "In the last decades, the scientific community has produced huge amounts of publications aboutthe most varied biomedical topics, making the search for relevant information a really difficulttask for every researcher. Some approaches have been followed to develop tools that canfacilitate this process. For instance, PubMed implemented in 2017 a Machine Learning model tosort documents by their relevance. Nevertheless, even the authors consider that their systemwould benefit from the implementation of a Deep Learning model, which for now needs morestudies.In this context, a package called BioTMPy1 was developed in this work, to perform documentclassification of biomedical literature using the Python programming language. The packageis divided into different modules to provide to the user functions to read documents in differentformats, perform preprocessing and data analysis and to train, optimize and evaluate Machineand Deep learning models. Our package also provides intuitive pipelines that can be easilyadapted for the user needs, illustrating how to implement complex deep learning models.The developed package was applied to a dataset from a challenge of the BioCreative forum,from 2019, about protein-protein interactions altered by mutations, an important topic for theadvances related to precision medicine. Using this dataset, it was possible to observe a slightlybetter performance of BioWordVec pre-trained embeddings over GloVe, ”pubmed pmc” and”pubmed ncbi” embeddings. Also, with the evaluation of the developed models on the test set,we managed to overcome the challenge’s best submission, by using a model with BioBERT anda bidirectional LSTM on top, resulting in a difference of 7.25% for average precision, 3.22% forprecision, 2.99% for recall and 3.15% for the f1-score.Also, a web server was developed to provide access to the best Deep Learning modeltrained in this work. The overall pipeline here developed can be applied to other case studies indifferent topics, provided there is a set of documents annotated as relevant and non-relevant,allowing to train the models.",
    "text2": "Knowing what lies around us has been a goal for many decades now, and the new advances in sequencing technologies and in meta-omics approaches have permitted to start answering some of the main questions of microbiology - what is there, and what is it doing?The exponential growth of omics studies has been answered by the development ofsome bioinformatic tools capable of handling Metagenomics (MG) analysis, with a scarcefew integrating such analysis with Metatranscriptomics (MT) or Metaproteomics (MP) studies.Furthermore, the existing tools for meta-omics analysis are usually not user friendly,usually limited to command-line usage.Because of the variety in meta-omics approaches, a standard workflow is not possible,but some routines exist, which may be implemented in a single tool, thereby facilitatingthe work of laboratory professionals. In the framework of this master thesis, a pipeline forintegrative MG and MT data analysis was developed. This pipeline aims to retrieve comprehensivecomparative gene/transcript expression results obtained from different biologicalsamples. The user can access the data at the end of each step and summaries containing severalparameters of evaluation of the previous step, and final graphical representations, likeKrona plots and Differential Expression (DE) heatmaps. Several quality reports are alsogenerated. The pipeline was constructed with tools tested and validated for meta-omicsdata analysis. Selected tools include FastQC, Trimmomatic and SortMeRNA for preprocessing,MetaSPAdes and Megahit for assembly, MetaQUAST and Bowtie2 for reporting onthe quality of the assembly, FragGeneScan and DIAMOND for annotation and DeSEQ2 forDE analysis.Firstly, the tools were tested separately and then integrated in several python wrappers toconstruct the software Meta-Omics Software for Community Analysis (MOSCA). MOSCAperforms preprocessing of MG and MT reads, assembly of the reads, annotation of theassembled contigs, and a final data analysis.Real datasets were used to test the capabilities of the tool. Since different types of filescan be obtained along the workflow, it is possible to perform further analyses to obtainadditional information and/or additional data representations, such as metabolic pathwaymapping.",
    "similarity": 0.305858123569794
  },
  {
    "text1": "The previous few decades have seen an enormous volume of articles from the scientific commu nity on the most diverse biomedical topics, making it extremely challenging for researchers tofind relevant information. Methods like Machine Learning (ML) and Deep Learning (DL) havebeen used to create tools that can speed up this process. In that context, this work focuseson examining the performance of different ML and DL techniques when classifying biomedicaldocuments, mainly regarding their relevance to given topics. To evaluate the different techniques,the dataset from the BioCreative VI Track 4 challenge was used. The objective of the challengewas to identify documents related to protein-protein interactions altered by mutations, a topicextremely important in precision medicine. Protein-protein interactions play a crucial role in thecellular mechanisms of all living organisms, and mutations in these interaction sites could beindicative of diseases.To handle the data to be used in training, some text processing methods were implementedin the Omnia package from OmniumAI, the host company of this work. Several preprocessingand feature extraction methods were implemented, such as removing stopwords and TF-IDF,which may be used in other case studies. They can be used either with generic text or biomedicaltext. These methods, in conjunction with ML pipelines already developed by the Omnia team,allowed the training of several traditional ML models.We were able to achieve a small improvement on performance, compared to the challengebaseline, when applying these traditional ML models on the same dataset. Regarding DL, testingwith a CNN model, it was clear that the BioWordVec pre-trained embedding achieved the bestperformance of all pre-trained embeddings. Additionally, we explored the application of morecomplex DL models. These models achieved a better performance than the best challengesubmission. BioLinkBERT managed an improvement of 0.4 percent points on precision, 4.9percent points on recall, and 2.2 percent points on F1.",
    "text2": "Bacterial resistance to antibiotics is nowadays becoming a major concern. Several reports indicatethat bacteria are developing resistance mechanisms to various antibiotics. Moreover, the processes involvedin the development of new antibiotics are lengthy and expensive. Therefore, an alternative to antibioticsis needed. One promising alternative are bacteriophages, viruses that specifically infect bacteria,causing their lysis. Hence, it would be interesting to discover which bacteria a specific phage recognizes.The bacterial receptors determine phage specificity, using tail spikes/fibres as receptor binding proteinsto detect carbohydrates or proteins, in bacterial surface. Studying interactions between phage tail spikes/-fibres and bacterial receptors can allow the identification of interaction pairs. Machine learning algorithmscan be used to find patterns in these interactions and build models to make predictions.In this work, PhageHost, a tool that predicts hosts at a strain level, for three species, E. coli, K.pneumoniae and A. baumannii was developed. Several data was extracted from GenBank, retrievinggeneral, protein and coding information, for both phages and bacteria. The protein data was used tobuild an important phage protein function database, that allowed the classification of protein functions,namely, phage tail spikes/fibres. In the end, several machine learning models with relevant protein featureswere created to predict phage-host strain interactions. Compared with previously performed works, thesemodels show better predictive power and the ability to perform strain-level predictions. For the best model,a Matthews correlation coefficient (MCC) of 96.6% and an F-score of 98.3% were obtained. These bestpredictive models were implemented online, in a server under the name PhageHost (https://galaxy.bio.di.uminho.pt).",
    "similarity": 0.301904432132964
  },
  {
    "text1": "In the healthcare industry, the patient’s nutrition is a key factor in their treatment process,as every user has their own specific nutritional needs and requirements. For example, aftera major surgery, a patient should eat products with high fiber while avoiding processedfoods and dairy. An appropriate nutrition policy can therefore complement the patient’srecovery process, alleviating possible symptoms.Food recommender systems are platforms that offer personalised suggestions of recipesto users. These systems are often implemented in food recipe websites, offering similar sug gestions. They are also used for improving the user’s health and recommending healthierrecipes while keeping their preferences in consideration. However, there is an absence ofusage of recipe recommendation systems in the healthcare sector. Multiple challenges inrepresenting the domain of food, coupled with the patient’s needs, make it complicated toimplement these systems in healthcare services and continuous care.In the context of this master’s dissertation, the aim was to design, develop, and explorea new generation platform for the provision, planning, and reservation of food plans, com prised of web and mobile tools. A key feature of this platform is the suggestion of mealplans to each department, taking into account the patient’s nutritional requirements.Data regarding the user’s nutritional requirements were collected and analysed, as wellas feedback from health professionals and users from the social cafeteria. The collectedinformation supported the development of a food recommendation system. These toolswill help nutrition professionals at the Santa Casa da Misericórdia of Vila Verde in their work,namely with the making of meal plans for multiple departments, each with their specificnutritional requirements.",
    "text2": "A healthcare institution produces huge amounts of data on a daily basis. These data come from n sourcesand therefore have m different formats. As it is evident, this heterogeneity of information sources can be a hugeobstacle, since increases the need for this information to be available and shared among the various informationsystems. The exchange of clinical information between Health Information System (HIS) is crucial for the effectiveprovision of care, significantly improving the performance of the institutions.In the healthcare industry, the ability of different information and software systems to communicate and sharedata, as well as use the data exchanged, is called interoperability. This knowledge can be exchanged aroundthe healthcare ecosystem thanks to the use of standards and data sharing models, regardless of the applicationbeing used. However, the lack of interoperability remains a concern. The Agency for the Integration, Diffusionand Archive (AIDA) proposes to achieve levels of interoperability never before implemented. For this purpose,web services are used for the processing, dissemination, and archiving of clinical information.In the context of this master’s dissertation, the aim is to develop and explore new information technologyartefacts to help the administrative and accounting teams of the Hospital da Santa Casa da Misericórdia deVila Verde. This solution aims to fill the existing gaps between the hospital and the Assistência na Doençaaos Servidores do Estado (ADSE). The first gap occurs in the dentistry speciality, where it is not possible toverify the patient’s ADSE status to perform some dental medicine act under co-payment. The second gapoccurs in the invoicing process through ADSE in real-time, in order to perform some medical appointmentsand/or acts resulting from them since the hospital’s accounting team cannot verify if a patient complies with theADSE requirements. The gaps identified can make ADSE refuse to reimburse the hospital for the medical actsperformed, which makes the administrative and accounting work unpleasant. In this situation, the hospital willhave to find a solution that suits the patient and the ADSE. Very often, the hospital has to bear the costs.In order to overpass these problems with the validation and invoicing process of medical acts through ADSE,this project consists of two web applications that enable the hospital’s information systems to interoperate withthe ADSE web service.",
    "similarity": 0.30393005540166207
  },
  {
    "text1": "In the healthcare industry, the patient’s nutrition is a key factor in their treatment process,as every user has their own specific nutritional needs and requirements. For example, aftera major surgery, a patient should eat products with high fiber while avoiding processedfoods and dairy. An appropriate nutrition policy can therefore complement the patient’srecovery process, alleviating possible symptoms.Food recommender systems are platforms that offer personalised suggestions of recipesto users. These systems are often implemented in food recipe websites, offering similar sug gestions. They are also used for improving the user’s health and recommending healthierrecipes while keeping their preferences in consideration. However, there is an absence ofusage of recipe recommendation systems in the healthcare sector. Multiple challenges inrepresenting the domain of food, coupled with the patient’s needs, make it complicated toimplement these systems in healthcare services and continuous care.In the context of this master’s dissertation, the aim was to design, develop, and explorea new generation platform for the provision, planning, and reservation of food plans, com prised of web and mobile tools. A key feature of this platform is the suggestion of mealplans to each department, taking into account the patient’s nutritional requirements.Data regarding the user’s nutritional requirements were collected and analysed, as wellas feedback from health professionals and users from the social cafeteria. The collectedinformation supported the development of a food recommendation system. These toolswill help nutrition professionals at the Santa Casa da Misericórdia of Vila Verde in their work,namely with the making of meal plans for multiple departments, each with their specificnutritional requirements.",
    "text2": "Nutrition is fundamental to human well-being and health, especially when applied topatients who need special health care. In these cases, it is crucial that each patient hasadequate nutrition to meet their needs, in order to accelerate their recovery process.Recommender systems make it possible to offer suggestions to users, adapted to theirpreferences and to previously obtained information about them. Food recommender systemsare recommender systems applied to nutrition and diet. They are usually implementedfeeding plans recommendation platforms based on food and the person using it.In this sense, the existing gap in the use of these recommendation systems applied tonutrition in health care is notorious. This is mainly due to the difficulty in associating thenutritional value of each food with the needs of patients.The main objective of this project is to fill the existing void, through the development andimplementation of a platform that will allow the planning of meals taking into account thenutritional plan of the food and the specific needs associated with the users of the Vila VerdeSocial Canteen.The use of machine learning algorithms will allow us to identify how the connectionbetween food and patient requirements can be made, making this task possible, which iscomplex due to the wide domain associated with it.This platform will be used for the generation of kitchen meal plans, which shall beproduced using the algorithms developed after a bibliographic study and an investigation ofthe existing work, in order to understand how they can be implemented and which are themost adequate to the nutritional recommendations system.",
    "similarity": 0.3497119743137749
  },
  {
    "text1": "The development of Cyber-physical Systems (CPSs) models is a complex process which requires deep multi-disciplinary knowledge of the intended topic to model. Added to this complexity is the difficulty of combining multiple models, sometimes without access to their source code, and make them communicate in a harmonious and integrated way in order to represent the vicissitudes of the environment where the physical system is inserted into. Functional Mockup Interface is a set of C headers that define a protocol that allows the interoperability of different models, independently of the programming languages and tools that generated them. A model that implements this interface is called Functional Mockup Unit (FMU). This dissertation explores the usage of Machine Learning to generate automatically a FMU from parsing a dataset containing the inputs and outputs obtained during the observation of a physical system. A Command-line Interface (CLI) tool named AutoFMU is also presented here, and it accepts as parameters a set of CSV tables and the names of the column that correspond to the inputs and outputs, using several supervised learning algorithms to infer the relationships between these variables. Its invocation results in a file containing a valid FMU ready to be used. In order to assess its feasibility in a real context, the tool AutoFMU was used to generate approximations of a controller of a line follower robot. The generated models were then simulated in the INTO-CPS program and the robot movements under the purview of the new controller were observed. The values generated by the new models were also compared with the datasets of the original physical unit.",
    "text2": "This document presents a Master Thesis in the Integrated Master’s in Informatics Engi neering focused on the automatic identification of vulnerabilities, that was accomplished atUniversidade do Minho in Braga, Portugal.This thesis work aims at developing a machine learning based tool for automatic iden tification of vulnerabilities on programs (source, high level code), that uses an abstractsyntax11tree representation. It is based on FastScan, using code2seq approach. Fastscanis a recently developed system aimed capable of detecting vulnerabilities in source codeusing machine learning techniques. Nevertheless, FastScan is not able of identifying thevulnerability type. In the presented work the main goal is to go further and develop amethod to identify specific types of vulnerabilities. As will be shown, the goal will beachieved by changing the method of receiving and processing in a different way the inputdata and developing an architecture that brings together multiple models to predict differentspecific vulnerabilities. The best f1 metric obtained is 93% resulting in a precision of 90% andaccuracy of 85%, according to the performed tests and regarding a trained model to predictvulnerabilities of the injection type. These results were obtained with the contribution givenby the optimization of the model’s hyperparameters and also the use of the Search Clusterfrom University of Minho that greatly diminished the necessary time to perform trainingand testing. It is important to refer that overfitting was detected in the late stages of the tests,so this results do not represent the true value in real context. Also an interface is presented,it allows to better interact with the models and analyse the scan results.",
    "similarity": 0.30141828254847647
  },
  {
    "text1": "The exponential growth of digital information that has been witnessed in recent years requires a continuousevolution and optimization of data management systems, such as databases and storage solutions.In order to provide efficient processing and storage capabilities for large amounts of data, data man agement systems must adopt different optimizations (e.g., caching, replication, data reduction) that in crease their complexity. As a result, developing, configuring and maintaining a data management systembecomes increasingly difficult and costly.Tracing and analyzing the interactions and exchanges between components of these systems is funda mental to uncover performance, correctness and dependability issues almost unavoidable in any complexsolution. On the other hand, this presents several challenges, such as minimizing the impact on applica tions’ performance and storage space, improving tracing accuracy and achieving real-time analysis, thatmust be explored.With this thesis, we present a tracing and analysis pipeline capable of capturing and analyzing the I/Opatterns of these data-centric systems in order to better understand their behavior, using LTTng as tracingtool.In particular, the proposed solution includes a tracing component that efficiently collects disk andnetwork I/O metrics originated by the target application. This component is the major focus of this thesisand allows for the capture of system calls that the application executes, as well as their arguments, in anon-intrusive and almost real-time way. The rest of the pipeline facilitates the analysis and visualizationof captured events through search queries and diagrams, allowing the user to find potential performanceand optimization problems.In the end, we demonstrate that the proposed solution allows for the identification of inefficient andredundant I/O patterns in production applications without causing significant impacts on the runtimeperformance of the application and allowing for near real-time analysis.",
    "text2": "In recent years more and more complex structures have been built. Buildings and locations whichusers must navigate efficiently so they can reach their appointments in a timely fashion, such as hospitals,universities and airports. Unfortunately technologies such as GPS are not well adapted to indoor locationsand therefore do not provide a solution to this problem. Indoor mapping has been subject to increasedamounts of research in the past few years and a plethora of different solutions have started to arisealthough none completely fulfill every requirement this problem presents. This thesis is done in conjunctionwith others with the final objective of creating the prototype of a mobile application and system that will beable to precisely locate where a user is inside of an indoor location through showing them their location ona floorplan. It will more specifically focus on the modeling aspect of the space geometry in an efficient waythat can be used by this application. The purpose of this dissertation is to document the research doneto choose the most appropriate data format, the development of a conversion method of the availabledata to the chosen format, and the development of web services and mobile application components thatwill provide this information to the end user. Additionally the development of a web application that, withthe results obtained throughout this investigation process, helps keep track of the progress of the radiomapping will also be documented.",
    "similarity": 0.30102618987660545
  },
  {
    "text1": "Bacterial resistance to antibiotics is nowadays becoming a major concern. Several reports indicatethat bacteria are developing resistance mechanisms to various antibiotics. Moreover, the processes involvedin the development of new antibiotics are lengthy and expensive. Therefore, an alternative to antibioticsis needed. One promising alternative are bacteriophages, viruses that specifically infect bacteria,causing their lysis. Hence, it would be interesting to discover which bacteria a specific phage recognizes.The bacterial receptors determine phage specificity, using tail spikes/fibres as receptor binding proteinsto detect carbohydrates or proteins, in bacterial surface. Studying interactions between phage tail spikes/-fibres and bacterial receptors can allow the identification of interaction pairs. Machine learning algorithmscan be used to find patterns in these interactions and build models to make predictions.In this work, PhageHost, a tool that predicts hosts at a strain level, for three species, E. coli, K.pneumoniae and A. baumannii was developed. Several data was extracted from GenBank, retrievinggeneral, protein and coding information, for both phages and bacteria. The protein data was used tobuild an important phage protein function database, that allowed the classification of protein functions,namely, phage tail spikes/fibres. In the end, several machine learning models with relevant protein featureswere created to predict phage-host strain interactions. Compared with previously performed works, thesemodels show better predictive power and the ability to perform strain-level predictions. For the best model,a Matthews correlation coefficient (MCC) of 96.6% and an F-score of 98.3% were obtained. These bestpredictive models were implemented online, in a server under the name PhageHost (https://galaxy.bio.di.uminho.pt).",
    "text2": "Proteins are one of the more important biological structures in living organisms, since theyperform multiple biological functions. Each protein has different characteristics and properties,which can be employed in many industries, such as industrial biotechnology, clinical applications,among others, demonstrating a positive impact.Modern high-throughput methods allow protein sequencing, which provides the proteinsequence data. Machine learning methodologies are applied to characterize proteins usinginformation of the protein sequence. However, a major problem associated with this methodis how to properly encode the protein sequences without losing the biological relationshipbetween the amino acid residues. The transformation of the protein sequence into a numericrepresentation is done by encoder methods. In this sense, the main objective of this project is tostudy different encoders and identify the methods which yield the best biological representationof the protein sequences, when used in machine learning (ML) models to predict different labelsrelated to their function.The methods were analyzed in two study cases. The first is related to enzymes, sincethey are a well-established case in the literature. The second used transporter sequences, alesser studied case in the literature. In both cases, the data was collected from the curateddatabase Swiss-Prot. The encoders that were tested include: calculated protein descriptors;matrix substitution methods; position-specific scoring matrices; and encoding by pre-trainedtransformer methods. The use of state-of-the-art pretrained transformers to encode proteinsequences proved to be a good biological representation for subsequent application in state-of-the-art ML methods. Namely, the ESM-1b transformer achieved a Mathews correlation coefficientabove 0.9 for any multiclassification task of the transporter classification system.",
    "similarity": 0.3086628053387056
  },
  {
    "text1": "Ontologies are very powerful tools when it comes to handling knowledge. They offer a goodsolution to exchange, store, search and infer large volumes of information. Throughout theyears various solutions for knowledge-based systems use ontologies at their core.OntoDL has been developed as a Domain Specific Language using ANTLR4, to allow forthe specification of ontologies. This language has already been used by experts of variousfields has a way to use computer-based solutions to solve their problems.In this thesis, included on the second year of the Master degree in Informatics Engineering,OntoDL+ was created as an expansion of the original OntoDL. Both the language andits compiler have been improved. The language was extended to improve usability andproductivity for its users, while ensuring an easy to learn and understand language. Thecompiler was expanded to translate the language specifications to a vaster array of languages,increasing the potential uses of the DSL with the features provided by the languages.The compiler and some examples of the DSL can be downloaded at the website https://epl.di.uminho.pt/∼gepl/GEPL DS/OntoDL/ created for the application and presented inthe final chapters of the thesis.",
    "text2": "Encryption has been essential to protect modern systems and services. It became the security foundation ofdatabases, payment systems, cloud services, and others. Cryptography enabled the creation and validation ofdigital signatures, where the protection of the private key is very important to prevent false signatures. Cryptocur rencies rely on this mechanism.Crypto wallets hold private keys used to sign transactions and prove ownership of a digital asset. These haveto keep the private key secure, but accessible to its owner, as it may be needed frequently. With the increasingnumber of decentralized web applications that interact with a blockchain, this subject has become more prevalent,as they usually require frequent signatures from the user.The mass adoption of cryptocurrencies by non-technical users urged the creation of crypto wallets that aresecure but prioritize usability. Some of these are hosted services that store the private keys in their serversand others are non-hosted, where the user is responsible for storing it. When implemented as a browser plugin,these wallets allow the user to seamlessly interact with a web application. The rise of cloud technology broughtforth multi-signature on the cloud, by combining different cloud services owned by the user. These give the usercontrol of his private key and are less vulnerable to cyber attacks.In this work, it is presented a comprehensive analysis of existing crypto wallet approaches in usability andsecurity to understand the existing problems. The next step was to propose multiple possible solutions to thoseproblems and produce their implementations. These take advantage of previously studied multi-cloud technologyand are used to attempt to improve usability and security. To evaluate the proposed solutions and to comparethem to the existing ones, we have developed a framework that consisted of various objective tests based onprevious work, which have the goal of evaluating security and usability.Finally, the proposed and existing solutions were compared using the proposed framework.",
    "similarity": 0.30060327840763057
  },
  {
    "text1": "Com a constante evolução da economia e da sociedade, surge a crescente preocupação emestabelecer e manter modelos de negócios que não sejam apenas lucrativos, mas tambémsustentáveis a longo prazo. Entre esses modelos, destaca-se o sistema de franchising, que,como qualquer empreendimento, enfrenta desafios complexos e singulares no quotidiano dasua gestão.Ora, na presente dissertação, apresenta-se o desenvolvimento de uma plataforma de gestãode franchisings, criada em colaboração com a empresa Wintouch. Este sistema representaráum valioso complemento à oferta de produtos já disponibilizados pela referida empresasobre o mercado de software de gestão comercial.Dessa forma, foi concebida uma aplicação web, e todos os componentes associados, quevisam abordar os diversos domínios que envolvem a gestão de franchisings. Essa solução foiprojetada para atender às necessidades de dois tipos distintos de utilizadores intervenientesnum negócio de franchising, nomeadamente, os franchisadores e os franchisados. Ainda, aplataforma desenvolvida abrange uma ampla gama de funcionalidades, desde a manutençãoda rede de franchising até a disponibilização de sistemas para controlar as encomendas e demonitorização do desempenho dos franchisados.Por fim, considerando a ambição e complexidade inerentes a este projeto de desenvol vimento de software, foram adotados um planeamento e estratégia bem definidos, quecompreenderam três fases distintas: uma investigação inicial sobre o tema em questão, amodelação cuidadosa e robusta da solução a ser desenvolvida e, por fim, o desenvolvimentoefetivo da plataforma. Todas essas fases estão minuciosamente documentadas ao longodeste relatório.",
    "text2": "O desenvolvimento de todo o código necessário para uma loja online é um trabalho demorado e complexo. Todas as lojas online têm diferentes exigências e condições, no entanto, existem pontos comuns entre vários tipos de loja. Supondo a possibilidade de extrair esses aspetos comuns, seria possível a criação de um esqueleto de código com todos os componentes básicos, sobre os quais um programador poderia acrescentar e moldar a loja online, reduzindo assim o tempo necessário para a desenvolver. A elaboração desta dissertação começou pela criação de uma loja online que suportasse um negócio fictício de venda de bicicletas e produtos relacionados. Este passo serviu para identificar e avaliar quais seriam os parâmetros necessários especificar, e em que sentido fariam diferença na construção de um website de vendas bem como, distinguir os componentes comuns e as suas relações.A presente dissertação tem como propósito principal o desenvolvimento de uma ferramenta para a criação de lojas online. Esta ferramenta pretende ser usada por programadores para produzir o código padrão que é comum a qualquer implementação de uma solução de loja online. Através da recolha de parâmetros sobre a loja online a ser criada, são construídos os ficheiros necessários para a implementação do site.A aplicação concebida focou-se na utilização de apenas alguns dos componentes básicos, nomeadamente, “Utilizadores” e “Categorias” no back-end, “Registo e Login” e “Perfil” no front-end, mostrando assim ser possível usar a framework desenvolvida para uma implementação parcial de uma loja online. A abordagem modular permite expandir a aplicação, criando e adicionando outros componentes à estrutura parcial existente.",
    "similarity": 0.3031099650094766
  },
  {
    "text1": "Os exames endoscópicos são prescritos em grandes quantidades, pois são eficazes no diagnóstico,baratos quando comparados com outros exames e estarem generalizados há muito tempo, pois podemser realizados em quase todos os hospitais. O resultado deste exame é normalmente um relatório queinclui anotações médicas complementadas com algumas imagens retiradas durante o exame.Alguns dos exames realizados são apenas feitos para confirmar informação já recolhida, o que leva a umaduplicação de esforços desnecessária e desperdício de recursos. Os profissionais de saúde podemdescartar informação relevante ao não conseguirem anotar em pormenor uma região de interesse paraposterior análise mais cuidada.O objetivo deste trabalho consiste na criação de um sistema que consiga resolver o problema apresentadoanteriormente, usando tecnologia de reconhecimento de voz. Este sistema deve reconhecer um pequenovocabulário, independentemente do falante, usado para anotar regiões de interesse nos exames.O sistema MyEndoscopy atua como uma cloud privada, que contém vários dispositivos que usam eprovidenciam serviços entre si. O dispositivo central deste sistema é a MIVbox, que se liga ao endoscópioe permite a captura digital do sinal de vídeo que este gera. A principal funcionalidade providenciada poreste sistema é a capacidade de armazenar indefinidamente os vídeos completos que são produzidosdurante exames endoscópicos, bem como disponibilizar estes vídeos e outros dados para outrosprofissionais de saúde que os necessitem de consultar.Nesta dissertação apresenta-se um módulo de reconhecimento de voz para línguas portuguesa e inglesa,denominado MIVcontrol, totalmente integrado no sistema MyEndoscopy. Este módulo reconhece umpequeno vocabulário, que consiste em comandos usado para controlar os outros módulos. O MIVcontrol éapresentado como uma alternativa a sistemas similares baseados na cloud, que resolve certos problemasrelacionados com proteção de dados e segurança.Foi realizado um estudo sobre o módulo desenvolvido para determinar a sua eficácia em comparação aoestado da arte. Na sequência desse estudo conclui-se que o sistema tinha uma taxa de erro comparável asistemas similares para outras línguas, e que como resultado é passível de ser usado em ambientes reais.",
    "text2": "A displasia congénita da anca é uma doença esquelética congénita comum em recém nascidos. O seudiagnóstico é importante para evitar complicações tardias no crescimento e locomoção. Por ser um exametão complexo e de grande responsabilidade, os diagnósticos feitos pelos profissionais são muitas vezesassociados a um grau elevado de incerteza na decisão, provocando receio na realização de exames dogénero. Os atos complementares de diagnóstico, neste caso a construção de ferramentas de apoio, sãosem dúvida o maior passo para reduzir ou eliminar este problema. Desta forma, com profissionais maisinstruídos, consegue-se um diagnóstico mais seguro e fiável.São apresentadas recomendações para a realização do exame, englobando parâmetros como a realizaçãodo exame clínico, do exame de ecografia e da leitura de imagens de ecografia. As imagens de ecografiatêm imenso ruído e para permitir um melhor processamento foram experimentadas operações básicas deprocessamento de imagem. É também proposto um relatório normalizado para este exame. O benefício daimplementação do relatório é a sua ligação ao sistema de machine learning em que informaçõescolocadas nos campos de preenchimento do relatório seriam transformadas em metainformação dasimagens de ecografia guardadas também no relatório, funcionando como a alimentação do sistema. Estesistema permitiria avaliar e classificar imagens de ecografia de um exame às articulações coxo-femorais.Para além destas ferramentas descritas, é proposto uma para otimizar em termos práticos o exame - umsistema de comandos por voz com ligação ao ecógrafo para que o profissional não tenha de desviar aatenção para carregar num simples botão do ecógrafo para assinalar frames essenciais para o diagnóstico.A adoção de ferramentas de apoio ao diagnóstico da displasia congénita da anca que permitam melhorara prestação dos cuidados de saúde é uma necessidade. As ferramentas apresentadas são um contributo erepresentam o início de novas abordagens ao despiste desta anomalia.",
    "similarity": 0.4101756161659209
  },
  {
    "text1": "Sleep represents a fundamental role to our well-being and today, as sleep disorders become more and more common, there is a growing necessity to monitor our sleep quality daily. Unobtrusive automatic sleep stage classification has made a tremendous breakthrough in this subject allowing regular users to monitor their sleep with day-to-day wearables, such as Fitbit Charge 2 tracker, contrary to the traditional manual sleep scoring based on polysomnography (PSG). Usingcardiorespiratory signals to sleep stage has attracted increased attention as these signals can be obtained through unobtrusive techniques and have potential for continuous daily application. Therefore, in this thesis, deep learning frameworks based on Long-short-memory networks (LSTMs) and Convolutional Neural Networks (CNNs) are used to sleep stage classify, either just using respiratory effort signals, for example obtained from respiratory inductance plethysmography (RIP), or using the combination of respiratory and cardiac features, often based on heart rate variability (HRV) calculated from electrocardiogram (ECG). The dataset used was the SIESTA dataset that contains a total of 294 subjects (588 PSG recordings) of which 197 are healthy subjects, 51 suffer from obstructive sleep apnea syndrome (OSA), and the remaining from a variety of sleep or sleep related disorders. The classification problem was divided in a three-class and four-class sleep stage classification problem. As for the results, it was obtained with respiratory data for three stages classification (Wake, rapid eye-movement (REM) and non-REM stages) a Cohen’s kappa (𝜅) of 0.46 for the overall pool of subjects (All), 0.50 for healthy subjects and 0.34 for OSA subjects. For four stages classification (Wake, REM, light sleep (N1/N2) and deep sleep (N3/N4) stages) it was obtained a Cohen’s Kappa (𝜅) of 0.40 for the subject pool containing all subjects (All), 0.44 for healthy subjects and 0.31 for OSA. With cardiorespiratory data, for four stages classification, it was obtained a 𝜅 of 0.40 for the overall subject pool (All), 0.44 for healthy subjects and 0.30 for OSA subjects. With three stages, a 𝜅 of 0.46 for All subjects, 0.51 for healthy and 0.32 for OSA subjects. These results demonstrate that, with the developed frameworks, it is possible to achieve fairly good results as they are similar, in some cases moderately higher, to the current state-of-the-art but fail to generalize well, as significant differences can be found between subject types (All, Healthy and OSA).",
    "text2": "The brain functional connectivity extracted from rs-fMRI has been used as a powerful tool to study the different networks in the brain. This neuronal network, found in normal condition, can be associated to different cognitive processes. The applicability of these networks in the future is promising, since is a greater technique to study the effects of several diseases or even treatments on normal brain functional connectivity. Firstly, this question should be addressed: are these networks possible to be described and to be used as features to classify a group or a particular subject?.In order to answer this question, it was settled the use of a Machine Learning method, which has been developed great advances in the recent years, due the good performances in the Deep Learning (DL) method. Therefore, it was created a workflow since the beginning, started with data acquisition until the application of DL methods and the process of creation and fine-tune of these models. In the end, several studies using the functional connectivity were done, namely the assessment of the brain functional connectivity to be used as a “fingerprint”. Additionally, it were performed some tests regarding the groups’ classification.After settled the correct approach and validate the DL framework, the “fingerprint” study showed a great improvement on impairment classification, even for simple models. We proved that rs-fMRI can be use in research field to identify singular brain patterns as well as the differences between the subjects, which could be applied as group differentiator in a population.",
    "similarity": 0.3100788408267633
  },
  {
    "text1": "Os Sistemas de Informação (SI) das Unidades de Saúde recorrem, cadavez mais, a ferramentas informáticas para gerir a grande quantidade de informação, e assim garantir a qualidade e a segurança da mesma.A interoperabilidade semântica é uma urgência nos Sistemas de Informação de Saúde (SIS), pois, através de normas, permite a uniformização dostermos médicos, assegurando registos clínicos com informação fiável, semredundância e ambiguidade, conferindo qualidade e segurança à informação.Sem terminologias médicas a prestação de cuidados de saúde pode tornaruma tarefa complexa e conduzir a erros médicos, pelo que a utilizaçãodas mesmas é fulcral para o registo de diagnósticos, procedimentos e peçasanatómicas no Registo Clínico Eletrónico (RCE) de cada utente.Como tal, o desenvolvimento de uma plataforma de interoperabilidadesemântica vai permitir uniformizar termos médicos e conduzir à diminuiçãode erros. Recorrendo às tecnologias mais avançadas de eHealth e mHealth,pretende-se implementar o Systematized Nomenclature of Medicine ClinicalTerms (SNOMED CT) em contexto hospitalar real, num serviço de AnatomiaPatológica.A solução consiste numa aplicação independente da plataforma de registode relatórios médicos, utilizando Web Services, que proporcionam a interação humana com diferentes interfaces para diferentes tipos de dispositivoseletrónicos.",
    "text2": "Nos dias de hoje, os Sistemas de Informação Hospitalar assumem-se como uma ferramenta indispensável para a prestação de cuidados de saúde, uma vez que permitem o aumento da qualidade e da eficiência quer na prática clínica, quer na gestão hospitalar. A interoperabilidade emerge, assim, como uma necessidade, uma vez que a enorme diversidade de sistemas torna difícil a troca e a partilha de informação clínica. Além disso, a elevada quantidade de sistemas não articulados faz com que seja muito mais provável a existência de dados repetidos e contraditórios, razão pela qual se torna ainda mais imperativa a utilização de normas e terminologias que conduzam à uniformização do registo clínico. Neste contexto, a presente dissertação descreve a criação de um modelo relacional de dados, que serve de base a uma aplicação de classificação de termos médicos segundo o Systematized Nomenclature of Medicine Clinical Terms (SNOMED CT), no âmbito da Anatomia Patológica. A base de dados construída assenta na estrutura original do SNOMED, e foi obtida através da criação de subsets que contêm os conceitos de interesse para o referido setor.",
    "similarity": 0.32882484551459623
  },
  {
    "text1": "Os Sistemas de Informação (SI) das Unidades de Saúde recorrem, cadavez mais, a ferramentas informáticas para gerir a grande quantidade de informação, e assim garantir a qualidade e a segurança da mesma.A interoperabilidade semântica é uma urgência nos Sistemas de Informação de Saúde (SIS), pois, através de normas, permite a uniformização dostermos médicos, assegurando registos clínicos com informação fiável, semredundância e ambiguidade, conferindo qualidade e segurança à informação.Sem terminologias médicas a prestação de cuidados de saúde pode tornaruma tarefa complexa e conduzir a erros médicos, pelo que a utilizaçãodas mesmas é fulcral para o registo de diagnósticos, procedimentos e peçasanatómicas no Registo Clínico Eletrónico (RCE) de cada utente.Como tal, o desenvolvimento de uma plataforma de interoperabilidadesemântica vai permitir uniformizar termos médicos e conduzir à diminuiçãode erros. Recorrendo às tecnologias mais avançadas de eHealth e mHealth,pretende-se implementar o Systematized Nomenclature of Medicine ClinicalTerms (SNOMED CT) em contexto hospitalar real, num serviço de AnatomiaPatológica.A solução consiste numa aplicação independente da plataforma de registode relatórios médicos, utilizando Web Services, que proporcionam a interação humana com diferentes interfaces para diferentes tipos de dispositivoseletrónicos.",
    "text2": "O controlo e a prevenção de infeções nosocomiais são essenciais para aredução de custos, bem como para a melhoria dos cuidados prestados numainstituição de saúde. Por outro lado, o tratamento de dados que permitamcompreender, caracterizar e monitorizar as infeções possibilita um controloe uma prevenção mais eficaz das mesmas. Sendo um método automatizadoe eficiente para o tratamento de dados, a tecnologia de Business Intelligencepermite a extração de informação importante para gerar conhecimento quepode auxiliar o processo de tomada de decisão dos profissionais de saúde.O principal objetivo deste trabalho é o desenvolvimento e implementaçãode uma plataforma de Business Intelligence que permita o estudo da incidênciade infeção nosocomial nas Unidades de Medicina do Centro Hospitalardo Porto. Este estudo é feito através da apresentação de um conjunto deindicadores clínicos (informações importantes extraídas dos dados referentesa infeções nosocomiais) que ajudam a analisar e caracterizar estas infeções.Por conseguinte, depois de identificados os indicadores relevantes, torna-sepertinente desenvolver um sistema que permita tratar os dados, extrair osindicadores destes e apresentá-los, de forma atrativa, na plataforma. Porsua vez, a plataforma facilita a análise das informações que disponibiliza,apoiando a tomada de decisões, nomeadamente através da identificação dosprincipais fatores de risco. Assim, o sistema atua como um Sistema de Apoioà Decisão Clínica, podendo auxiliar no controlo e prevenção destas infeções.Pretende-se ainda estudar a aplicabilidade da tecnologia de Data Miningna criação de modelos de classificação capazes de prever a ocorrência deinfeções nosocomiais, na presença de determinados fatores de risco.O conhecimento obtido com a análise dos indicadores e as previsões efetuadaspode possibilitar a diminuição da incidência de infeção nosocomiale, consequentemente, a redução dos custos associados à sua ocorrência, bemcomo o aumento da segurança e do bem-estar dos doentes, ao permitir a tomadade decisões mais fundamentadas. A aplicação de Business Intelligencena área da saúde contribui para melhorar não só o fluxo de trabalho diárionas unidades de saúde, como também a qualidade dos cuidados prestados.",
    "similarity": 0.3627529820792583
  },
  {
    "text1": "As necessidades e expectativas dos clientes acompanham o avanço tecnológico que ocorre de forma exponencial, o que gera um ambiente muito competitivo entre as instituições que precisam de manter os clientes habituais e chamar novos. Deste modo, para que as instituições consigam permanecer e evoluir têm de conseguir um elevado grau de qualidade que só é possível caso se mantenham atentos às constantes mudanças sociais e tecnológicas. Na área da saúde este facto não é exceção e, adicionalmente, o fator qualidade é ainda mais importante, já que se lida com a vida dos pacientes. A saúde do utente não está dependente apenas do topo das tecnologias relacionadas com os cuidados de saúde diretos, portanto todas as tecnologias que permitem uma melhor organização dos dados do paciente, bem como um aumento na eficiência de todos os processos envolventes devem ser consideradas.Diversas instituições de saúde encontraram nos sistemas self-service a solução para tornar o processo de atendimento ao utente mais eficiente. No entanto, nas horas de maior afluência estes sistemas não são suficientes e as filas de espera persistem, causando interferências no bem-estar dos pacientes e no desenrolar de outros processos. Tirando proveito das oportunidades que esta quarta revolução industrial revela, problemas deste tipo podem ser minimizados, a experiência do paciente pode tornar-se mais rica e a instituição de saúde pode tomar um lugar de notoriedade. É neste conceito que surge esta dissertação, onde se conceptualiza uma solução para integrar um sistema de quiosques self-service, já existente em algumas unidades de saúde, não só para otimizar o atendimento dos utentes, mas também para modernizar a instituição. É desenvolvido também um possível protótipo desta solução. Para o seu desenvolvimento foi imperativo a utilização de conceitos de tecnologias promissoras, destacando-se a tecnologia mobile, realidade aumentada e WiFi, de modo a que a solução final agregue todas as funcionalidades dos quiosques com todas as vantagens das tecnologias utilizadas.",
    "text2": "Cada vez mais as necessidades e os requisitos do paciente acompanham os desenvolvimentos tecnológicos na área da cirurgia médica. Tal acontece para que estes obtenham uma intervenção o mais eficiente e seguro possível por parte dos serviços de saúde e dos seus profissionais. No entanto, hoje em dia ainda é difícil implementar e operar diferentes tipos de tecnologias em ambientes médicos devido às desvantagens que estes podem trazer para os seus utilizadores e por todo o processo de aprendizagem que estas requerem. Numa primeira abordagem, este trabalho tem como objetivo esclarecer conceitos e reunir algumas soluções existentes para a resolução destes problemas, assim como as respetivas tecnologias utilizadas pelas mesmas. Posteriormente é elaborado e apresentado um conceito e protótipo de uma aplicação móvel de planeamento cirúrgico ortopédico que implementa tecnologias de Realidade Aumentada. A solução proposta pretende ajudar o cirurgião desde a fase de planeamento até a própria fase de intervenção cirúrgica. Para além de alguns exemplos e da apresentação do trabalho realizado para a solução, é também descrito o processo de implementação e a arquitetura do sistema. Tendo em conta o protótipo desenvolvido, são discutidas as vantagens da sua utilização num contexto cirúrgico e levantados alguns pontos de interesse futuro a serem estudados e implementados para a sua melhoria.",
    "similarity": 0.3121533505555729
  },
  {
    "text1": "Nowadays, cybernetic attacks are a real threat that can compromise any individual,organization or company’s integrity. Every day new cases are reported, that show thereal damage cyber criminals can cause. Sensitive data exposure, identity theft, servicemalfunctioning or shutdown are just a few of the most common threats, which in manycases might impact companies either with financial loss or by damaging their reputation.Population, in general, is becoming each time more aware of the risks of using electronicdevices connected to the web and so are companies. With the rise of this awareness, over thelast years, cyber security has become a major concern for Software companies.This threat also led to the birth of the Software vulnerability detection market. Companiesstarted commercializing Software and advisory to other companies, in order to keep themless exposed to cybernetic risks. There are many mechanisms and technologies used bythese companies to identify vulnerabilities in applications. The most popular technologyused to detect vulnerabilities is SAST (Static Application Security Testing) as it focus onthe detection of vulnerabilities at the early stages of Software development. However, thisrequires the analysis of the source code, which in many cases, is huge and thus such analysisis too time consuming.Being that the context and motivation for this dissertation, the goal is to investigate thepossibility of performing source code analysis in a faster way, relying on machine learningapproaches. Code embeddings, classification algorithms and clustering algorithms were themain approaches explored in this work.Along the project, it was realized that some approaches performed better than others, in thetask of detecting software vulnerabilities. Clustering algorithms, according to the performedexperiments, are not suitable for the problem. Classification algorithms produced results thatcan be considered worthy of further investigation, but did not meet the established goals.After some failed attempts, this project demonstrated that it is possible to train a predictionmodel, based on code2seq approach, capable of detecting vulnerabilities in source code,with better performance and accuracy than classic SAST solutions (according to a specific setof experiments). Moreover, the used approach allows to easily extend the developed work tofind vulnerabilities in any programming language.",
    "text2": "Tools that detect security problems are very important nowadays and for the people doingcode reviews it is even more important to have tools that identify vulnerabilities in the code.In this way companies that provide applications can be more confident that the code theydeploy is almost vulnerabilities free.A subset of these tools, known as Static Application Security Testing (SAST) tools, rely onthe analysis of the source code aiming at looking for patterns that correspond to vulnerabili ties. These analyzers use mainly language processors to help them extract from the sourcecode the information they need. Languages exist for many years but they never ceased toexist because they are in constant development.The description of languages is supported bygrammars. Grammars also evolve to sustain the referred languages evolution. They wereprimarily used for compilers to analyse the structure of the language and parse it; nowadaysthey help many other tools like SAST for example.Having a tool that can detect vulnerabilities is very useful like was said, but to identifythose vulnerabilities it is necessary to find patterns in languages. By finding these abstractpatterns the work is simplified since all concrete languages will present similar vulnerabilities.For example, SQl Injection is a vulnerability that is shared across almost all languages; so,it is possible to define one general pattern to capture that common vulnerability in eachlanguage.Those patterns are defined over Abstract Syntax Trees (AST). To build an AST whileparsing a program, Checkmarx uses a set of functions called Visitors that are associated to theproductions of the programming language Grammar. In that context, the Language Factorytool developed by Checkmarx generates automatically some visitors and let programmers togenerate the others by dragging and dropping rules. The main objective of Language Factorytool is to aid programmers understanding how to create visitors and, at the same time, togenerate as many visitors as possible to be used directly. When Checkmarx is working ona new Language to to include support for that language in the CxSAST tool, the use ofLanguage Factory will help creating the appropriate Visitors making this process simplerand faster.The Master’s project reported in this dissertation appears in that framework aiming at theimprovement of the Checkmarx Language Factory making it capable of infer more Visitorsfrom the new language’s Grammar.",
    "similarity": 0.32243043783850833
  },
  {
    "text1": "Nowadays, cybernetic attacks are a real threat that can compromise any individual,organization or company’s integrity. Every day new cases are reported, that show thereal damage cyber criminals can cause. Sensitive data exposure, identity theft, servicemalfunctioning or shutdown are just a few of the most common threats, which in manycases might impact companies either with financial loss or by damaging their reputation.Population, in general, is becoming each time more aware of the risks of using electronicdevices connected to the web and so are companies. With the rise of this awareness, over thelast years, cyber security has become a major concern for Software companies.This threat also led to the birth of the Software vulnerability detection market. Companiesstarted commercializing Software and advisory to other companies, in order to keep themless exposed to cybernetic risks. There are many mechanisms and technologies used bythese companies to identify vulnerabilities in applications. The most popular technologyused to detect vulnerabilities is SAST (Static Application Security Testing) as it focus onthe detection of vulnerabilities at the early stages of Software development. However, thisrequires the analysis of the source code, which in many cases, is huge and thus such analysisis too time consuming.Being that the context and motivation for this dissertation, the goal is to investigate thepossibility of performing source code analysis in a faster way, relying on machine learningapproaches. Code embeddings, classification algorithms and clustering algorithms were themain approaches explored in this work.Along the project, it was realized that some approaches performed better than others, in thetask of detecting software vulnerabilities. Clustering algorithms, according to the performedexperiments, are not suitable for the problem. Classification algorithms produced results thatcan be considered worthy of further investigation, but did not meet the established goals.After some failed attempts, this project demonstrated that it is possible to train a predictionmodel, based on code2seq approach, capable of detecting vulnerabilities in source code,with better performance and accuracy than classic SAST solutions (according to a specific setof experiments). Moreover, the used approach allows to easily extend the developed work tofind vulnerabilities in any programming language.",
    "text2": "Personalized medicine is a constantly growing area. Important goals of this field are early diagnosis and the discovery of new personalized treatments. Gene expression data play a key role at this level, as variations in these data can often offer explanations for some phenotypes. To this end, Machine Learning (ML) models capable of predicting biologically relevant information, have been widely used. Deep Learning (DL) is a branch of ML that has become popular over the past few years. The increasing amounts of data that have been generated, and the growing use of this type of models in biomedical areas, have been accelerating the analysis of biological processes associated with cancer and other complex diseases.In this work, we focused on developing a framework that allows to create and evaluate distinct work-flows for the application of a variety of machine and deep learning models, working over gene expression data, including different options regarding data preprocessing pipelines, distinct ML and DL models, including traditional ML models, Dense Neural Networks, Convolutional Neural Networks and Variational Autoencoders. The framework has been validated using different case studies, where the data sources were two of the main repositories of gene expression data (TCGA and GTEx). The goal of each case study was to predict important variables for clinical application. A variety of models were developed and evaluated for each case study, generally with competitive performance. For the first case study, the task was to predict the type of cancer from TCGA data, and the best performing DL model was a dense neural network, being outperformed by a logistic regression model. In the second case, where the task was to predict the hypoxia score, the best DL model was a two dimensional convolutional neural network (2D CNN), being outperformed by the LightGBM model. As for the third case study, where the objective was to predict the aneuploidy score, the best model was an one dimensional convolutional neural network (1D CNN). For the fourth case, where the task was to predict body mass index, the best model was again a 1D CNN. Finally, in the fifth case study, where the main goal was to predict gene expression for a set of genes based on landmark genes, the best DL model was found by an 1D CNN, still slightly outperformed by linear regression. Some of the DL models developed in this work show promising results. However, these need to be improved in the future as they are not clinically applicable at this time. This framework can be reused for new problems and can be easily expanded.",
    "similarity": 0.3008595404920971
  },
  {
    "text1": "Nowadays, cybernetic attacks are a real threat that can compromise any individual,organization or company’s integrity. Every day new cases are reported, that show thereal damage cyber criminals can cause. Sensitive data exposure, identity theft, servicemalfunctioning or shutdown are just a few of the most common threats, which in manycases might impact companies either with financial loss or by damaging their reputation.Population, in general, is becoming each time more aware of the risks of using electronicdevices connected to the web and so are companies. With the rise of this awareness, over thelast years, cyber security has become a major concern for Software companies.This threat also led to the birth of the Software vulnerability detection market. Companiesstarted commercializing Software and advisory to other companies, in order to keep themless exposed to cybernetic risks. There are many mechanisms and technologies used bythese companies to identify vulnerabilities in applications. The most popular technologyused to detect vulnerabilities is SAST (Static Application Security Testing) as it focus onthe detection of vulnerabilities at the early stages of Software development. However, thisrequires the analysis of the source code, which in many cases, is huge and thus such analysisis too time consuming.Being that the context and motivation for this dissertation, the goal is to investigate thepossibility of performing source code analysis in a faster way, relying on machine learningapproaches. Code embeddings, classification algorithms and clustering algorithms were themain approaches explored in this work.Along the project, it was realized that some approaches performed better than others, in thetask of detecting software vulnerabilities. Clustering algorithms, according to the performedexperiments, are not suitable for the problem. Classification algorithms produced results thatcan be considered worthy of further investigation, but did not meet the established goals.After some failed attempts, this project demonstrated that it is possible to train a predictionmodel, based on code2seq approach, capable of detecting vulnerabilities in source code,with better performance and accuracy than classic SAST solutions (according to a specific setof experiments). Moreover, the used approach allows to easily extend the developed work tofind vulnerabilities in any programming language.",
    "text2": "There always have been a huge interest in working with public data from online socialmedia users, with the exponential growth of social media usage, this interest and re searches on the area keep increasing.This thesis aims to address prediction and classification tasks on online social net work data. The goal is to predict psycho-demographic - personality and demographic -traits by doing text emotion analysis on social networks as Twitter and Facebook. Ourmain motivation was to raise awareness to what can be done with users’ social mediaor network information or usual behaviours on the web, such as from text analysiswe can trace their personality, know their tastes, how they behave and so on, and tospread the emotion-text relation on social networks subject, because it only started tobe studied recently and there’s so much data and information to do it.To perform these tasks mentioned above we carried an extensive review of literatureof previous works to define the state-of-art of the project and to learn and identify workstrategies. Almost all of the past researches, based their results on a vast sample ofusers and data, but because some frameworks and APIs were shutdown in recent years,such as MyPersonality from Facebook adding to some frameworks being paid for,resulted in a small sample of users’ data to analyze in our thesis which can prejudicethe results.We start by gathering data from Twitter and Facebook with users consent. On Twit ter we focused on tweets and retweets, on Facebook we focused on all of what theuser typed by using the DataSelfie plugin that stored all that data on a server thatcan be retrieved later. Our next step was to find emotions on their text data with thehelp of a lexicon that categorized words by eight different emotions, two of them wereput away because we focused only on the six major emotions - this is explained later- and we had to remove stopwords and apply stemming to all of the text and do aword-matching of every word of our data with every word from the lexicon. Afterthis, we asked our participants to fulfill a \"Big-Five\" personality questionnaire and toprovide us their age, so we added the Big-Five traits and age to each users individualdataset. We got their final versions, ready to apply machine-learning algorithms tofind correlations between emotions and personality or demographic attributes. Wefocused on practical and methodological aspects of the user attribute prediction task.We used many techniques and algorithms that we thought it were best fit for the datawe had and for the goal that we had to achieve.We gathered data in two datasets that we tested, one of them we called \"Mixed Lan guage Dataset\", contains all text entries from each user, and the other \"User Dataset\",contains one entry per user after we analyze every text entry for all users in order tohave a more general view on each one. For the first mentioned dataset we achievebest results with the decision trees algorithms, from 58% on the agreeableness trait,to 68% on the neuroticism trait. This dataset had a problem with the way data wasspread, so it was impossible to predict age and gender with efficiency. As for the lat ter, regarding demographic characteristics all of the classifiers had a good classifyingpercentage, from K-nearest’s 73% to Naive Bayes’ 95%. The most solid classifier forpersonality traits was the one using the CART decision tree algorithm, it ranged from50% on the openness trait to 76% on the agreeableness one. There were classifiers withterrible results, there were others that were a bit dull, and there were some that stoodout as we stated above. We had a small sample, and that was a problem as it wasn’tconsistent or solid in terms of data value and that can change our results, we believethat our results would be way better if we applied the same mechanisms to a muchbigger sample.Concluding, we demonstrate how we can predict personality or demographic traits- BigFive traits, age or gender - from studying emotions in text. As stated above, wehope this thesis will alert people for what can be done with their online information,we only focus on psycho-demographic profiling, but there are many other things thatcan be done.",
    "similarity": 0.30150867562836703
  },
  {
    "text1": "Over the last few years, there has been a development of Information Technologies (IT)and its applicability has had repercussions in the most varied domains. The healthsector has been no exception, with significant repercussions in terms of improving thequality and effectiveness of healthcare provided by the various organizations, the security of data maintenance and transmission, and the increased interoperability betweenthe various Hospital Information Systems (HIS).The present dissertation project comes in the context of the need for maintenanceand updating of University Hospital Center of Porto computer services. In this sense,the objective was to develop a new web application, called Portal Pedidos, throughwhich will be managed the whole process of requesting Complementary Diagnosticand Therapeutic Means. With reference to users’ perceptions of the current state ofthe platform and the needs identified by them, the developments to be implementedshould ensure the optimization of the existing essential functionality and the introduction of gains that enable earnings in terms of usability, adaptation to devices andincreased data structuring performance. The application developed also allows theavailability of information, previously monolithic and exclusive of the application inuse, with other services within the hospital unit through the implementation orientedto a web service.For the purpose of application development, the prior exploration and selection ofthe technologies to be adopted was crucial in order to guarantee an appropriate optionto achieve the established objectives. The strategy adopted was the use of innovativeweb technologies, specifically using the ReactJs for frontend and Node.js for backend.The adoption of these technologies enabled the implementation of the pre-establishedrequirements and the incorporation of the contributions that emerged throughout theprocess.",
    "text2": "A healthcare institution produces huge amounts of data on a daily basis. These data come from n sourcesand therefore have m different formats. As it is evident, this heterogeneity of information sources can be a hugeobstacle, since increases the need for this information to be available and shared among the various informationsystems. The exchange of clinical information between Health Information System (HIS) is crucial for the effectiveprovision of care, significantly improving the performance of the institutions.In the healthcare industry, the ability of different information and software systems to communicate and sharedata, as well as use the data exchanged, is called interoperability. This knowledge can be exchanged aroundthe healthcare ecosystem thanks to the use of standards and data sharing models, regardless of the applicationbeing used. However, the lack of interoperability remains a concern. The Agency for the Integration, Diffusionand Archive (AIDA) proposes to achieve levels of interoperability never before implemented. For this purpose,web services are used for the processing, dissemination, and archiving of clinical information.In the context of this master’s dissertation, the aim is to develop and explore new information technologyartefacts to help the administrative and accounting teams of the Hospital da Santa Casa da Misericórdia deVila Verde. This solution aims to fill the existing gaps between the hospital and the Assistência na Doençaaos Servidores do Estado (ADSE). The first gap occurs in the dentistry speciality, where it is not possible toverify the patient’s ADSE status to perform some dental medicine act under co-payment. The second gapoccurs in the invoicing process through ADSE in real-time, in order to perform some medical appointmentsand/or acts resulting from them since the hospital’s accounting team cannot verify if a patient complies with theADSE requirements. The gaps identified can make ADSE refuse to reimburse the hospital for the medical actsperformed, which makes the administrative and accounting work unpleasant. In this situation, the hospital willhave to find a solution that suits the patient and the ADSE. Very often, the hospital has to bear the costs.In order to overpass these problems with the validation and invoicing process of medical acts through ADSE,this project consists of two web applications that enable the hospital’s information systems to interoperate withthe ADSE web service.",
    "similarity": 0.3094563711911358
  },
  {
    "text1": "A eficiência e desempenho das operações de Entrada/Saída(E/S) são aspetos fundamentais na implementação de sistemas de armazenamento. A maioria das soluções atuais são implementadas emkernel, obrigando a trocas de contexto entre espaço de utilizador e kernel por parte das aplicações. Estas trocas de contexto são custosas e, por isso, limitam o desempenho do sistema de armazenamento.A plataforma Storage Performance Development Kit (SPDK) disponibiliza uma forma de construir estessistemas evitando o acesso a kernel, realizando todas as operações de E/S necessárias diretamente doespaço de utilizador para o disco físico.Contudo, os dados continuam a ter que ser guardados com garantias de persistência. Assim sendo,os sistemas construídos com SPDK devem se tolerantes a faltas para garantir resiliência em cenários defalta. A inexistência de uma ferramenta capaz de testar essa resiliência em sistemas de armazenamentoconstruídos com SPDK é um problema para os programadores que querem testar a resiliência dos seussistemas.De forma a resolver este problema, esta dissertação propõe o Fault Injector in SPDK (FISPDK), umaferramenta que estende o SPDK e fornece injeção de faltas determinística ao nível do block device. Parainjetar faltas deterministicamente, FISPDK utiliza diferenciação de pedidos E/S de forma a identificar quaispedidos devem (ou não) ser injetados com uma falta. Para isso, o FISPDK implementa mecanismos depropagação de contexto, que permitem passar informação da aplicação para os níveis mais baixos daspilhas de E/S, e é baseado numa extensão da block device Application Programming Interface (API)original do SPDK. Para providenciar injeção de faltas, o FISPDK apresenta um block device virtual queinterceta pedidos E/S e injeta corrupção de dados ou atraso neles. O block device virtual pode serconfigurado pelos utilizadores para apontar os tipos de faltas e quais os pedidos que devem ser injetadoscom essas faltas.Uma avaliação compreensiva do FISPDK demonstra que a nossa solução consegue injetar faltas deforma determinística e avaliar a tolerância a faltas de sistemas de armazenamento que usam SPDK, semadicionar uma sobrecarga significativa à pilha de armazenamento.",
    "text2": "A era digital trouxe a incorporação dos computadores em vários setores do nosso quotidiano. Tem-severificado, ao longo dos anos, uma crescente dependência na tecnologia, o que se traduz na necessidadede sistemas cada vez mais resilientes, rápidos, seguros e disponíveis.Consequentemente, a complexidade dos sistemas tem vindo a crescer, o que leva à implementaçãode mecanismos de persistência e atualização de dados mais difíceis de testar. Para elevar o nível dedificuldade, os diversos sistemas de ficheiros possuem particularidades que afetam de forma significativaestes mecanismos e a consistência das aplicações após a ocorrência de falhas de energia e dos sistemasoperativos.Evitar a perda total ou parcial dos dados deve ser um ponto fulcral para sistemas de armazenamentocom fortes garantias de durabilidade e coerência. Na literatura, os sistemas capazes de voltar a um estadocoerente após uma falha de energia são chamados de crash-consistent. Muito do trabalho relacionadofoca-se na crash consistency dos sistemas de ficheiros e, quando se foca nas aplicações, verifica-se afalta de ferramentas para reprodução de bugs. Quando um utilizador reporta problemas encontradosnuma dada aplicação, é útil para as equipas de desenvolvimento terem uma ferramenta que rapidamentereproduz o bug e ajude na sua correção.Esta dissertação propõe o LazyFS+, um sistema de ficheiros que simula a perda total e parcial dedados através da injeção de faltas baseada em software. A nossa solução possui uma cache interna, oque permite uma gestão determinística dos dados das aplicações e a injeção de faltas reprodutível. Umdos seus pontos fortes é o facto de imitar comportamentos que alguns sistemas de ficheiros apresentam,como a reordenação de escritas, sem se prender a uma implementação específica. Para além disso,facilita a análise das operações executadas pela aplicação e permite obter informação sobre os dadosnão sincronizados.O LazyFS+ provou-se útil através da reprodução de bugs já conhecidos e da identificação dessesmesmos bugs em versões antigas das aplicações, nunca antes reportados. Para além disso, foi possívelencontrar novos bugs, quer em versões antigas, quer em versões mais recentes das aplicações. Estesúltimos foram reportados com todos os passos de reprodução realizados com o LazyFS+. Como resultado,atualmente este está a ser integrado nos testes do sistema de armazenamento chave-valor etcd.",
    "similarity": 0.30180581366808096
  },
  {
    "text1": "A eficiência e desempenho das operações de Entrada/Saída(E/S) são aspetos fundamentais na implementação de sistemas de armazenamento. A maioria das soluções atuais são implementadas emkernel, obrigando a trocas de contexto entre espaço de utilizador e kernel por parte das aplicações. Estas trocas de contexto são custosas e, por isso, limitam o desempenho do sistema de armazenamento.A plataforma Storage Performance Development Kit (SPDK) disponibiliza uma forma de construir estessistemas evitando o acesso a kernel, realizando todas as operações de E/S necessárias diretamente doespaço de utilizador para o disco físico.Contudo, os dados continuam a ter que ser guardados com garantias de persistência. Assim sendo,os sistemas construídos com SPDK devem se tolerantes a faltas para garantir resiliência em cenários defalta. A inexistência de uma ferramenta capaz de testar essa resiliência em sistemas de armazenamentoconstruídos com SPDK é um problema para os programadores que querem testar a resiliência dos seussistemas.De forma a resolver este problema, esta dissertação propõe o Fault Injector in SPDK (FISPDK), umaferramenta que estende o SPDK e fornece injeção de faltas determinística ao nível do block device. Parainjetar faltas deterministicamente, FISPDK utiliza diferenciação de pedidos E/S de forma a identificar quaispedidos devem (ou não) ser injetados com uma falta. Para isso, o FISPDK implementa mecanismos depropagação de contexto, que permitem passar informação da aplicação para os níveis mais baixos daspilhas de E/S, e é baseado numa extensão da block device Application Programming Interface (API)original do SPDK. Para providenciar injeção de faltas, o FISPDK apresenta um block device virtual queinterceta pedidos E/S e injeta corrupção de dados ou atraso neles. O block device virtual pode serconfigurado pelos utilizadores para apontar os tipos de faltas e quais os pedidos que devem ser injetadoscom essas faltas.Uma avaliação compreensiva do FISPDK demonstra que a nossa solução consegue injetar faltas deforma determinística e avaliar a tolerância a faltas de sistemas de armazenamento que usam SPDK, semadicionar uma sobrecarga significativa à pilha de armazenamento.",
    "text2": "A atual era digital depende de dados numa perspetiva de grande escala e as organizações requeremsistemas de armazenamento que funcionem corretamente sob falhas. Por exemplo, falhas de energiapodem levar à perda de dados em aplicações cujos ficheiros ainda estão armazenados em memória,isto é, num meio volátil. Evitar estes cenários de perda de dados constitui um grande desafio, umavez que exige que os programadores apliquem primitivas de sincronização (fsync()) que garantem adurabilidade dos dados, a custo de uma potencial diminuição do desempenho das aplicações.As ferramentas de injeção de faltas permitem ajudar os programadores com testes automáticos econsequente validação das suas políticas de durabilidade de dados. No entanto, as abordagens atuaispara sistemas de ficheiros focam-se: (1) na manipulação direta de hardware; ou (2) em erros internosde implementação do sistema de ficheiros, e não na interação da aplicação com o mesmo. Além disso,estas ferramentas são limitadas quanto à informação disponibilizada ao programador, de forma a estecompreender a causa efetiva que levou à perda de dados reportada.Para resolver estes desafios, esta dissertação propõe o LazyFS, um sistema de ficheiros que simulaa perda de dados utilizando uma abordagem de injeção de faltas em software reprodutível e automática.Este sistema tem uma cache dedicada que gere os dados das aplicações e a sua sincronização parauma camada persistente. A pedido, o LazyFS pode limpar todos os dados que não foram previamentesincronizados, fornecendo também aos programadores informações relevantes sobre os dados em riscode serem perdidos com potenciais falhas de energia.O desempenho e validação da correção do protótipo demonstra que a nossa solução consegue avaliara durabilidade dos dados de aplicações, sem adicionar uma sobrecarga significativa à sua execuçãonormal. Foram também reproduzidas quatro anomalias em diferentes bases de dados e o protótipo já seencontra integrado na ferramenta de injeção de faltas Jepsen. Atualmente, o LazyFS está a ser usado,juntamente com o Jepsen, para avaliar sistemas de bases de dados em produção, como o PerconaMySQL Server, MongoDB e o etcd. Adicionalmente, foi descoberta uma possível violação de coerênciano etcd, que está a ser estudada pela sua equipa de desenvolvimento.",
    "similarity": 0.3084639551381664
  },
  {
    "text1": "Com a evolução tecnológica, as aplicações WEB têm um papel crucial na comunidade. Nesse sentidoé essencial que estas acompanhem o desenvolvimento tecnológico e sejam cada vez mais plataformasconfiáveis e disponíveis. Um dos componentes imprescindíveis para o sucesso de um sistema interativoé a interface gráfica com o utilizador (GUI, em inglês Graphical User Interface), que, neste caso, sãoacedidas através de web browsers. Com o aumento das capacidades dos browsers, cada vez maisaplicações fazem uso dessas capacidades, existindo uma componente lógica que é executada no própriobrowser. Desse modo, é fundamental analisar o impacto, a nível computacional, resultante da execuçãoda componente lógica no próprio browser. Uma forma de o fazer é através de testes de carga quesão executados a partir da interface com o utilizador, permitindo identificar possíveis falhas, tais comoproblemas de implementação, tempos de resposta elevados ou gargalos de desempenho.No entanto, é indiscutível que as aplicações são cada vez mais complexas e, por sua vez, o processode testes torna-se mais difícil e demorado, existindo uma necessidade crescente da automatização domesmo. Os testes baseados em modelos (MBT, em inglês Model-Based Testing) suportam a geração eexecução automática de testes a partir de um modelo do sistema. O MBT aplicado às interfaces gráficaspermite uma avaliação mais exaustiva da aplicação, dado que permitem uma simulação da interação doutilizador com o sistema.Esta dissertação tem como objetivo desenvolver uma solução que, tendo como componentes principais o processo de testes baseados em modelos, testes a interfaces gráficas e testes de carga, permitacom o menor esforço possível gerar e executar testes de carga a partir da interface gráfica.",
    "text2": "Na área de Engenharia de Software, a modelação de sistemas com recurso a diagramas,permite representar um sistema de forma padronizada, com o intuito de facilitar a compreensão da especificação, estrutura lógica, e documentação dos mesmos.Hoje em dia, no mundo empresarial, a utilização de diagramas através de ferramentaspróprias para o efeito tem como objetivo a comunicação entre equipas, inserindo-se na fasede modelação dos projetos. No entanto, a construção de aplicações com recurso a técnicasde low code, ou mesmo zero code, é uma realidade cada vez mais atual.A evolução natural deste conceito resultará na geração automática de código através deuma linguagem visual, como os diagramas, facilitando, assim, a produção de código, e aomesmo tempo, conseguir-se-á uma poupança de tempo aproveitando o trabalho realizadonuma fase mais precoce do projeto. Posto isto, a utilização de modelos, mais ou menosstandard, como forma de especificar e prototipar aplicações é e será, cada vez mais, umarealidade bem fundada e com sucesso assinalável, permitindo também gerir de forma maiseficaz questões de multi-plataforma, visto que a geração de código não é exclusiva a nenhumparadigma nem linguagem de programação específica.Com esta dissertação pretende-se, então, utilizar modelos UML como mecanismo únicode especificação de aplicações, automatizando o processo de construção do respetivo códigoe os aspetos tecnológicos relativos ao seu deployment e instalação, disponibilizando umaferramenta que possibilite o processo de criação de aplicações web e android a partir dediagramas UML.Assim, foi criada uma aplicação que, através da interação do utilizador, recebe diagramasde classe exportados em formato XML interpretando-os e gerando aplicações android eaplicações web. Estas aplicações realizam as operações CRUD para cada entidade representadano diagrama de classe.",
    "similarity": 0.30360192276356524
  },
  {
    "text1": "O desenvolvimento de processos ETL é uma tarefa dispendiosa e complexa. Não admira, pois, ocuidado que os seus implementadores têm, em particular, durante as suas fases de planeamento eanálise. Muito trabalho tem sido desenvolvido em prol do estabelecimento de novos e melhoresmétodos e técnicas de modelação conceptual e lógica destes processos. Todavia, ainda ocorreminúmeros problemas durante as primeiras fases de execução dos processos de ETL, muitos delesprovocados por erros de análise, de desenvolvimento, ou de simples esquecimento. Como tal, é vitalque antes da entrada destes processos em produção, eles sejam submetidos a algum tipo demecanismo que permita validá-los e comprovar a sua correção, relativamente àquilo que se esperaque eles realizem. A utilização da linguagem Alloy na especificação e validação de processos ETLoferece esse tipo de validação. Neste trabalho de dissertação, suportado por um caso de estudoespecífico, Alloy é estudada, utilizada e avaliada quanto à sua aplicação na especificação formal evalidação de processos ETL.",
    "text2": "O protocolo de máquinas de estado replicadas (MER) é uma peça fundamental dos sistemas distribuídos. Nocentro deste protocolo estão os algoritmos de consenso, como o Paxos, usados para manter a consistência dasMER. Todavia, os sistemas modernos não podem depender estritamente das técnicas de MER, estes devemtambém implementar estratégias de reconfiguração. Estas estratégias consistem em alterar a configuração dosistema, adicionando, removendo ou substituindo os processos que o compõem. Dada a sua complexidade, aimplementação de protocolos de reconfiguração é muito suscetível a erros, daí que seja aconselhável a especificação,validação e verificação dos mesmos.No presente trabalho apresentamos uma especificação em linguagem Alloy do protocolo de reconfiguraçãoVertical Paxos e do protocolo de consenso Paxos. Além destes, modelamos o protocolo Multi-Paxos, o qualimplementa uma MER. Estes protocolos estão intrinsecamente relacionados e a compreensão do primeiro éfacilitada com o conhecimento dos demais. Atualmente, o Alloy é uma das linguagens de especificação maispopulares, mas pouco explorada na modelação de algoritmos distribuídos e, tanto quanto sabemos, não existeainda nenhuma especificação dos referidos protocolos em Alloy.O presente trabalho visa modelar e validar os referidos protocolos, bem como verificar as suas propriedadesde safety, de modo a obtermos confiança nas especificações. Ademais, realizamos uma avaliação de desempenhode diferentes solvers e estratégias de decomposição nativas do Alloy, bem como uma breve análisecomparativa com o TLA+.",
    "similarity": 0.3048108994290237
  },
  {
    "text1": "Most event data analysis tasks in the ATLAS project require both intensive data access and processing, where some tasks are typically I/O bound while others are compute bound. This dissertation work mainly focus improving the code efficiency of the compute bound stages of the ATLAS detector data analysis, complementing a parallel dissertation work that addresses the I/O bound issues.The main goal of the work was to design, implement, validate and evaluate an improved and more robust data analysis task, originally developed by the LIP research group at the University of Minho. This involved tuning the performance of both Top Quark and Higgs Boson reconstruction of events, within the ATLAS framework, to run on homogeneous systems with multiple CPUs and on heterogeneous computing platforms. The latter are based on multicore CPU devices coupled to PCI-E boards with many-core devices, such as the Intel Xeon Phi or the NVidia Fermi GPU devices.Once the critical areas of the event analysis were identified and restructured, two parallelization approaches for homogeneous systems and two for heterogeneous systems were developed and evaluated to identify their limitations and the restrictions imposed by the LipMiniAnalysis library, an integral part of every application developed at LIP. To efficiently use multiple CPU resources, an application scheduler was also developed to extract parallelism from simultaneously execution of both sequential and parallel applications when processing large sets of input data files.A key achieved outcome of this work is a set of guidelines for LIP researchers to efficiently use the available computing resources in current and future complex parallel environments, taking advantage of the acquired expertise during this dissertation work. Further improvements on LIP libraries can be achieved by developing a tool to automatically extract parallelism of LIP applications, complemented by the application scheduler and additional suggested approaches.",
    "text2": "Ad-hoc networks can be useful in many contexts because they can be spontaneously created and do not require any sort of infrastructure. They can be useful for small groups when no other network is accessible. They can also be used in wider areas as a low cost replacement for wireless infrastructure networks with multiple dedicated access points. Despite this, ad-hoc networks are not a very popular option for most users.Unfortunately, ad-hoc networks are not as user friendly as infrastructure networks. The latter ones usually provide standardized mechanisms that perform the essential configurations for the correct functioning of the network. Ad-hoc networks do not have standardized mechanisms adapted to them. Each wireless network manager supports a different set of configuration mechanisms. There is usually no problem when every machine uses the same operating system but when different ones are used, users may need to manually perform the required configurations. Another cause for this low popularity is the lack of useful and easy to use applications. These applications are usually hosted on the Internet, as it provides a larger variety of business models.To tackle these problems, new forms of automatically configuring machines and providing services should be explored. These services must be easy to develop, in order to attract the developers that would develop them. The designed solutions must also be adapted to ad-hoc environments. Another important aspect that must be addressed is security. In some contexts, such as public and corporate environments, security can be essential to provide authentication and even to allow the correct functioning of thenetwork.",
    "similarity": 0.3199770794008776
  },
  {
    "text1": "Most event data analysis tasks in the ATLAS project require both intensive data access and processing, where some tasks are typically I/O bound while others are compute bound. This dissertation work mainly focus improving the code efficiency of the compute bound stages of the ATLAS detector data analysis, complementing a parallel dissertation work that addresses the I/O bound issues.The main goal of the work was to design, implement, validate and evaluate an improved and more robust data analysis task, originally developed by the LIP research group at the University of Minho. This involved tuning the performance of both Top Quark and Higgs Boson reconstruction of events, within the ATLAS framework, to run on homogeneous systems with multiple CPUs and on heterogeneous computing platforms. The latter are based on multicore CPU devices coupled to PCI-E boards with many-core devices, such as the Intel Xeon Phi or the NVidia Fermi GPU devices.Once the critical areas of the event analysis were identified and restructured, two parallelization approaches for homogeneous systems and two for heterogeneous systems were developed and evaluated to identify their limitations and the restrictions imposed by the LipMiniAnalysis library, an integral part of every application developed at LIP. To efficiently use multiple CPU resources, an application scheduler was also developed to extract parallelism from simultaneously execution of both sequential and parallel applications when processing large sets of input data files.A key achieved outcome of this work is a set of guidelines for LIP researchers to efficiently use the available computing resources in current and future complex parallel environments, taking advantage of the acquired expertise during this dissertation work. Further improvements on LIP libraries can be achieved by developing a tool to automatically extract parallelism of LIP applications, complemented by the application scheduler and additional suggested approaches.",
    "text2": "Recent evolution of high performance computing moved towards heterogeneous platforms:multiple devices with different architectures, characteristics and programming models, shareapplication workloads. To aid the programmer to efficiently explore these heterogeneousplatforms several frameworks have been under development. These dynamically manage theavailable computing resources through workload scheduling and data distribution, dealingwith the inherent difficulties of different programming models and memory accesses. Amongother frameworks, these include GAMA and StarPU.The GAMA framework aims to unify the multiple execution and memory models ofeach different device in a computer system, into a single, hardware agnostic model. It wasdesigned to efficiently manage resources with both regular and irregular applications, andcurrently only supports conventional CPU devices and CUDA-enabled accelerators. StarPUhas similar goals and features with a wider user based community, but it lacks a singleprogramming model.The main goal of this dissertation was an in-depth evaluation of a heterogeneous frameworkusing a complex application as a case study. GAMA provided the starting vehiclefor training, while StarPU was the selected framework for a thorough evaluation. The progressivephoton mapping irregular algorithm was the selected case study. The evaluationgoal was to assert the StarPU effectiveness with a robust irregular application, and make ahigh-level comparison with the still under development GAMA, to provide some guidelinesfor GAMA improvement.Results show that two main factors contribute to the performance of applications writtenwith StarPU: the consideration of data transfers in the performance model, and chosenscheduler. The study also allowed some caveats to be found within the StarPU API. Althoughthis have no effect on performance, they present a challenge for new coming developers.Both these analysis resulted in a better understanding of the framework, and a comparativeanalysis with GAMA could be made, pointing out the aspects where GAMA could be furtherimproved upon.",
    "similarity": 0.3597614786850685
  },
  {
    "text1": "Most event data analysis tasks in the ATLAS project require both intensive data access and processing, where some tasks are typically I/O bound while others are compute bound. This dissertation work mainly focus improving the code efficiency of the compute bound stages of the ATLAS detector data analysis, complementing a parallel dissertation work that addresses the I/O bound issues.The main goal of the work was to design, implement, validate and evaluate an improved and more robust data analysis task, originally developed by the LIP research group at the University of Minho. This involved tuning the performance of both Top Quark and Higgs Boson reconstruction of events, within the ATLAS framework, to run on homogeneous systems with multiple CPUs and on heterogeneous computing platforms. The latter are based on multicore CPU devices coupled to PCI-E boards with many-core devices, such as the Intel Xeon Phi or the NVidia Fermi GPU devices.Once the critical areas of the event analysis were identified and restructured, two parallelization approaches for homogeneous systems and two for heterogeneous systems were developed and evaluated to identify their limitations and the restrictions imposed by the LipMiniAnalysis library, an integral part of every application developed at LIP. To efficiently use multiple CPU resources, an application scheduler was also developed to extract parallelism from simultaneously execution of both sequential and parallel applications when processing large sets of input data files.A key achieved outcome of this work is a set of guidelines for LIP researchers to efficiently use the available computing resources in current and future complex parallel environments, taking advantage of the acquired expertise during this dissertation work. Further improvements on LIP libraries can be achieved by developing a tool to automatically extract parallelism of LIP applications, complemented by the application scheduler and additional suggested approaches.",
    "text2": "In the last years, the widespread of Cloud computing as the main paradigm to deliver a largeplethora of virtualized services significantly increased the complexity of Datacenters managementand raised new performance issues for the intra-Datacenter network. Providing heterogeneousservices and satisfying users’ experience is really challenging for Cloud service providers,since system (IT resources) and network administration functions are definitely separated.As the Software Defined Networking (SDN) approach seems to be a promising way to addressinnovation in Datacenters, the thesis presents a new framework that allows to develop andtest new OpenFlow–based controllers for Cloud Datacenters. More specifically, the frameworkenhances both Mininet (a well–known SDN emulator) and POX (a Openflow controller writtenin python), with all the extensions necessary to experiment novel control and managementstrategies of IT and network resources.Further more, the framework was validated by implementing and testing well known policies.Hybrid allocation policies (considering both network and servers) were also implemented andscalability tests were performed.This work was developed under the ERASMUS student mobility program, in the TelecommunicationNetworks Research Group, Dept. of Information Engineering, University of Pisa,and resulted in the paper Datacenter in a box: test your SDN cloud-datacenter controller athome that was accepted into EWSDN2013.",
    "similarity": 0.3112016767582674
  },
  {
    "text1": "Most event data analysis tasks in the ATLAS project require both intensive data access and processing, where some tasks are typically I/O bound while others are compute bound. This dissertation work mainly focus improving the code efficiency of the compute bound stages of the ATLAS detector data analysis, complementing a parallel dissertation work that addresses the I/O bound issues.The main goal of the work was to design, implement, validate and evaluate an improved and more robust data analysis task, originally developed by the LIP research group at the University of Minho. This involved tuning the performance of both Top Quark and Higgs Boson reconstruction of events, within the ATLAS framework, to run on homogeneous systems with multiple CPUs and on heterogeneous computing platforms. The latter are based on multicore CPU devices coupled to PCI-E boards with many-core devices, such as the Intel Xeon Phi or the NVidia Fermi GPU devices.Once the critical areas of the event analysis were identified and restructured, two parallelization approaches for homogeneous systems and two for heterogeneous systems were developed and evaluated to identify their limitations and the restrictions imposed by the LipMiniAnalysis library, an integral part of every application developed at LIP. To efficiently use multiple CPU resources, an application scheduler was also developed to extract parallelism from simultaneously execution of both sequential and parallel applications when processing large sets of input data files.A key achieved outcome of this work is a set of guidelines for LIP researchers to efficiently use the available computing resources in current and future complex parallel environments, taking advantage of the acquired expertise during this dissertation work. Further improvements on LIP libraries can be achieved by developing a tool to automatically extract parallelism of LIP applications, complemented by the application scheduler and additional suggested approaches.",
    "text2": "Every program starts from a model, an abstraction, which is iteratively re ned until we reach the nal result, the implementation. However, at the end, one must ask: does the nal program resemblein anyway the original model? Was the original idea correct to begin with? Formal methodsguarantee that those questions are answered positively, resorting to mathematical techniques. Inparticular, in this thesis we are interested on the second factor: veri cation of formal models.A trend of formal methods defends that they should be lightweight, resulting in a reducedcomplexity of the speci cation, and automated analysis. Alloy was proposed as a solution for thisproblem. In Alloy, the structures are described using a simple mathematical notation: relationallogic. A tool for model checking, automatic veri cation within a given scope, is also provided.However, sometimes model checking is not enough and the need arises to perform unboundedveri cations. The only way to do this is to mathematically prove that the speci cations are correct.As such, there is the need to nd a mathematical logic expressive enough to be able to representthe speci cations, while still being su ciently understandable.We see the point-free style, a style where there are no variables or quanti cations, as a kindof Laplace transform, where complex problems are made simple. Being Alloy completely relational,we believe that a point-free relational logic is the natural framework to reason about Alloyspeci cations.Our goal is to present a translation from Alloy speci cations to a point-free relational calculus,which can then be mathematically proven, either resorting to proof assistants or to manual proving.Since our motivation for the use of point-free is simplicity, we will focus on obtaining expressionsthat are simple enough for manipulation and proofs about them.",
    "similarity": 0.3139870811168583
  },
  {
    "text1": "Real-time monitoring has become one of the most important and clinically relevant tasksin medical settings, yet one of the most repetitive and tiresome tasks is the analysis of24-hour ECG records. One way to automate this long task is to convert this process intoa real-time process with the automatic classification of the heart rate and with this, theclassification of arrhythmias.Thus, this master thesis focuses on the study of Deep Learning models for the classificationof arrhythmias and data processing tools for the streaming and processing of data inreal time. Consequently, this master’s thesis comprises several phases. In the first place,a more theoretical part is presented which is the ground truth of the use of the tools laterused for the development of the system. The development of the system includes amore practical part of data streaming composed by an IoT middleware, Apache Kafka asan intermediate agent between this middleware and Apache Spark, and ElasticSearch forreal-time data storage for visualization. On the other hand, in the main scope of this thesis,two models of Deep Learning were created, one for the classification of arrhythmias andanother one for their forecast.The results obtained are promising with the arrhythmia classification yielding 98% accuracyin the classification of each beat in one of the four classes used. When the modelwas tested in data obtained directly from the Hospital of Braga, it was not possible to obtainsuch good results, however, the model after new training was able to obtain accuracyvalues of 81% for the testing dataset. This deep learning model was also tested with theintegration of Apache Spark, in order to create data parallelism and increase the speed ofthe deep learning process, which tends to be very time consuming, without neglecting itsperformance.The development of the model for the prediction of arrhythmias was done based on Long-Short Term Memory layers, in order to create a neural network with memory, the resultsobtained in the records with 30 minutes were not high. Despite the less good results in thefirst dataset, when the model was tested in the 24-hour records, the results obtained werequite high which demonstrated that the model can predict if it is based on a longer record.Nevertheless, these results were obtained individually because the Electrocardiograms canbe an object of human identification.Based on the results obtained it was possible to conclude that more tests should be doneincreasing the spectrum of arrhythmias to be classified so that this process becomes fully automatic, without neglecting the precision of the results since human lives may dependon it.",
    "text2": "Throughout the years, Deep Learning has proven to be an excellent technology to solve problems that would otherwise be too complex. Furthermore, it has shown great success in the area of medical imaging, especially when applied to segmentation of brain tissues. As such, this dissertation explores a possible new approach, using Deep Artificial Neural Networks to perform spatial normalization on brain MRI studies as well as classify using Brain MRI studies regarding their state of brain atrophy. Spatial normalization of Magnetic Resonance images by tools like the FSL, or SPM turned out to be inefficient for researches as they need too many resources to achieve good results. Theseresources include, for example, wasted human and computer time when executing the commands to normalize and waiting for the process to finish, this can take up to several hours just for one study. Therefore, a new approach was needed, a faster and easier way to normalize the MRI studies. To do so, Deep Artificial Neural Networks were used by creating a python program to deal with said studiesin much less time. This program should free the researchers’ time for other more relevant tasks and help reach conclusions faster in their studies when trying to find patterns between the analysed brains. Several architectures were tried, having better results with U-Net based architecture as well as GAN architecture.At the end, the model couldn’t learn correctly all the brain features to be changed in any of the approaches but showed great potential. Even though the final model did achieve the correct shape it could not yet achieve the final normalization.With some more time invested in perfecting the models, these could, in the future, learn to correctly perform the final normalization and allow the researchers to perform it in less than 10 seconds per exam instead of hours.Regarding the Brain Atrophy models, the models showed some potential too as the predictions were partially correct. With more data, and less unbalanced, the model could probably learn correctly and output the expected results for all classes.",
    "similarity": 0.3123930889459531
  },
  {
    "text1": "Real-time monitoring has become one of the most important and clinically relevant tasksin medical settings, yet one of the most repetitive and tiresome tasks is the analysis of24-hour ECG records. One way to automate this long task is to convert this process intoa real-time process with the automatic classification of the heart rate and with this, theclassification of arrhythmias.Thus, this master thesis focuses on the study of Deep Learning models for the classificationof arrhythmias and data processing tools for the streaming and processing of data inreal time. Consequently, this master’s thesis comprises several phases. In the first place,a more theoretical part is presented which is the ground truth of the use of the tools laterused for the development of the system. The development of the system includes amore practical part of data streaming composed by an IoT middleware, Apache Kafka asan intermediate agent between this middleware and Apache Spark, and ElasticSearch forreal-time data storage for visualization. On the other hand, in the main scope of this thesis,two models of Deep Learning were created, one for the classification of arrhythmias andanother one for their forecast.The results obtained are promising with the arrhythmia classification yielding 98% accuracyin the classification of each beat in one of the four classes used. When the modelwas tested in data obtained directly from the Hospital of Braga, it was not possible to obtainsuch good results, however, the model after new training was able to obtain accuracyvalues of 81% for the testing dataset. This deep learning model was also tested with theintegration of Apache Spark, in order to create data parallelism and increase the speed ofthe deep learning process, which tends to be very time consuming, without neglecting itsperformance.The development of the model for the prediction of arrhythmias was done based on Long-Short Term Memory layers, in order to create a neural network with memory, the resultsobtained in the records with 30 minutes were not high. Despite the less good results in thefirst dataset, when the model was tested in the 24-hour records, the results obtained werequite high which demonstrated that the model can predict if it is based on a longer record.Nevertheless, these results were obtained individually because the Electrocardiograms canbe an object of human identification.Based on the results obtained it was possible to conclude that more tests should be doneincreasing the spectrum of arrhythmias to be classified so that this process becomes fully automatic, without neglecting the precision of the results since human lives may dependon it.",
    "text2": "A huge amount of medical data is being generated each day, leaving the doctors unableto analyze such volume and make a good diagnosis for the patient. The emergence of BigData frameworks for data analysis leverages the automatic analysis of healthcare data in afaster and accurate manner, by scanning which information is relevant, and, consequently,detecting diseases in earlier stages.Nowadays, it is estimated that about 9% to 38% of the world’s population has sleep ap nea. Unawareness of the disease’s presence can lead to the development of cardiovasculardiseases, and consequently, death. The detection of sleep apnea syndrome through the tra ditional method, Polysomnography (PSG), becomes not only expensive but also inconvenientfor the patient. Therefore, systems based on Electrocardiogram (ECG) can improve the qua lity of a patient’s health by overcoming these inconveniences. This master thesis relies ondeep learning (DL) networks, such as convolutional and recurrent neural networks for sleepapnea detection. The computational complexity of these models depends on its size, typesof layers and data. This complexity also increases the computation time of the training taskleading to several hours spent training on a single machine. For this work, we proposea sleep apnea detection system based on ECGs, alongside with a distributed version of it,which parallelizes the training computation, reducing the overall learning time, while notcompromising the model performance.The results obtained for sleep apnea detection encourage the use of electrocardiogramsfor the detection of this disease. Our model achieved a value of 93% of sensitivity onthe Physionet database, being the highest value compared to other studies described inthe literature. Besides this, on the distributed environment it was accomplished similaroutput quality, reducing the training time by approximately 50%, from the centralized todistributed learning.The model was trained with the Sleep Heart Health Study (SHHS) data, achieving the highestresults compared to the work described in the literature that used the same dataset. Incomparison with the previous dataset, the model trained and tested with the SHHS wasnot able to attain a similar quality output. However, this corroborates the large diversity ofthe SHHS data. Moreover, when it was tested if this model could classify the Physionet data,it achieved promising results of 73,7%, 73,8%, 68,3% and 63,5% of accuracy, sensitivity, F1-score, and precision, respectively, which lead us to conclude that the SHHS trained modelcould be able to generalize to new data. In addition to this, on the distributed environment it was achieved equal output perfor mance for SHHS, reducing the training time by approximately 90%.",
    "similarity": 0.3437353505220542
  },
  {
    "text1": "Real-time monitoring has become one of the most important and clinically relevant tasksin medical settings, yet one of the most repetitive and tiresome tasks is the analysis of24-hour ECG records. One way to automate this long task is to convert this process intoa real-time process with the automatic classification of the heart rate and with this, theclassification of arrhythmias.Thus, this master thesis focuses on the study of Deep Learning models for the classificationof arrhythmias and data processing tools for the streaming and processing of data inreal time. Consequently, this master’s thesis comprises several phases. In the first place,a more theoretical part is presented which is the ground truth of the use of the tools laterused for the development of the system. The development of the system includes amore practical part of data streaming composed by an IoT middleware, Apache Kafka asan intermediate agent between this middleware and Apache Spark, and ElasticSearch forreal-time data storage for visualization. On the other hand, in the main scope of this thesis,two models of Deep Learning were created, one for the classification of arrhythmias andanother one for their forecast.The results obtained are promising with the arrhythmia classification yielding 98% accuracyin the classification of each beat in one of the four classes used. When the modelwas tested in data obtained directly from the Hospital of Braga, it was not possible to obtainsuch good results, however, the model after new training was able to obtain accuracyvalues of 81% for the testing dataset. This deep learning model was also tested with theintegration of Apache Spark, in order to create data parallelism and increase the speed ofthe deep learning process, which tends to be very time consuming, without neglecting itsperformance.The development of the model for the prediction of arrhythmias was done based on Long-Short Term Memory layers, in order to create a neural network with memory, the resultsobtained in the records with 30 minutes were not high. Despite the less good results in thefirst dataset, when the model was tested in the 24-hour records, the results obtained werequite high which demonstrated that the model can predict if it is based on a longer record.Nevertheless, these results were obtained individually because the Electrocardiograms canbe an object of human identification.Based on the results obtained it was possible to conclude that more tests should be doneincreasing the spectrum of arrhythmias to be classified so that this process becomes fully automatic, without neglecting the precision of the results since human lives may dependon it.",
    "text2": "Methods for the study of the functional connectivity in the brain have seen severaldevelopments over the last years, however not yet in a fully realized manner. Machine learning andcomplex network analysis are two promising techniques that together can help the process of betterexploring functional connectivity for future clinical applications.Machine learning and pattern recognition algorithms are helpful for mining vast amountsof neural data with increasing precision of measures and also for detecting signals from anoverwhelming noise component (Lemm, Blankertz, Dickhaus, & Müller, 2011). Complex networkanalysis, a subset of graph theory, is an approach that allows the quantitative assessment ofnetwork properties such as functional segregation, integration, resilience, and centrality (Rubinov& Sporns, 2010). These properties can be fed into classification algorithms as features. This is anew and complex approach that has no standard procedures defined, so the aim of this work is toexplore the use of fMRI-derived complex network measures combined with machine learningalgorithms in a clinical dataset.In order to do so, a set of classifiers is implemented on a feature dataset built with brainregional volumes and topological network measures that, in turn, were constructed based onfunctional connectivity data extracted from a resting-state functional MRI study. The set of classifiersincludes the nearest neighbor, support vector machine, linear discriminant analysis and decisiontree methods. A set of feature selection methods was also implemented before the classificationtasks. Every possible combination of feature selection methods and classifiers was implementedand the performance was evaluated by a cross-validation procedure.Although the results achieved weren’t exceptionally good, the present work generatedknowledge on how to implement this recent approach and allowed the conclusion that, for mostcases, feature selection improves the performance of the classifier. The results also showed thatthe decision tree algorithm produces relatively good results without being associated with a featureselection method and that the SVM classifier, together with RFE feature selection method, producedresults on the same level as other work done with a similar approach.",
    "similarity": 0.30558963197467354
  },
  {
    "text1": "Real-time monitoring has become one of the most important and clinically relevant tasksin medical settings, yet one of the most repetitive and tiresome tasks is the analysis of24-hour ECG records. One way to automate this long task is to convert this process intoa real-time process with the automatic classification of the heart rate and with this, theclassification of arrhythmias.Thus, this master thesis focuses on the study of Deep Learning models for the classificationof arrhythmias and data processing tools for the streaming and processing of data inreal time. Consequently, this master’s thesis comprises several phases. In the first place,a more theoretical part is presented which is the ground truth of the use of the tools laterused for the development of the system. The development of the system includes amore practical part of data streaming composed by an IoT middleware, Apache Kafka asan intermediate agent between this middleware and Apache Spark, and ElasticSearch forreal-time data storage for visualization. On the other hand, in the main scope of this thesis,two models of Deep Learning were created, one for the classification of arrhythmias andanother one for their forecast.The results obtained are promising with the arrhythmia classification yielding 98% accuracyin the classification of each beat in one of the four classes used. When the modelwas tested in data obtained directly from the Hospital of Braga, it was not possible to obtainsuch good results, however, the model after new training was able to obtain accuracyvalues of 81% for the testing dataset. This deep learning model was also tested with theintegration of Apache Spark, in order to create data parallelism and increase the speed ofthe deep learning process, which tends to be very time consuming, without neglecting itsperformance.The development of the model for the prediction of arrhythmias was done based on Long-Short Term Memory layers, in order to create a neural network with memory, the resultsobtained in the records with 30 minutes were not high. Despite the less good results in thefirst dataset, when the model was tested in the 24-hour records, the results obtained werequite high which demonstrated that the model can predict if it is based on a longer record.Nevertheless, these results were obtained individually because the Electrocardiograms canbe an object of human identification.Based on the results obtained it was possible to conclude that more tests should be doneincreasing the spectrum of arrhythmias to be classified so that this process becomes fully automatic, without neglecting the precision of the results since human lives may dependon it.",
    "text2": "Prognosis and patient stratification for brain tumors is an important and clinically relevant task and a precise treatment outcome prediction would allow to choose an adequate therapy strategy and schedule the most appropriate follow-up examinations. Magnetic Resonance Imaging (MRI) is an already know imaging technique to assess these tumors. Next to medical imaging, other clinical information is important for patient management, e.g. genetic markers like O6-Methyl-Guanine-Methyl-Transferase (MGMT) methylation is a well-known prognostic marker in Glioblastoma (GBM) tumors.Therefore, the main goal of this thesis was to study Deep Learning (DL) approaches to combine MRI with non-image clinical data in two different classification scenarios: brain tumor segmentation and patient outcome prediction. There are studies that combine these two types of data, however, in two steps: extracting MRI features and then combining them with relevant non-image data. Here, end-to-end DL architectures with two input layers are presented, as well as an infrastructure that allows the easy development of future Machine Learning (ML) /DL models that consumes these two types of data in a clinical context. In this way, the classification in both scenarios is done in a single step, where Convolution Layers perform the feature extraction in MRI input.In brain tumor segmentation, the model with combined data achieved a slightly better Dice Similarity Coefficient (DSC) (0.894 ± 0.025) over image only model (0.882 ± 0.025). As for patient outcome prediction, when trying to predict the Progression-Free Survival (PFS) class (“bad”,” medium” and “good” outcomes), the combined model didn't improve when compared with the model where only MRI was used. Both models, however, outperformed models where only non-image data was used.The segmentation results point to a positive influence when adding the clinical information to MRI. Nevertheless, there is a lot more to investigate in this field, not only in the model architecture, but also in selecting relevant clinical information. In same way, more tests should be run for patient outcome prediction, especially using Overall Survival (OS) information.",
    "similarity": 0.31731796596755046
  },
  {
    "text1": "A era digital trouxe a incorporação dos computadores em vários setores do nosso quotidiano. Tem-severificado, ao longo dos anos, uma crescente dependência na tecnologia, o que se traduz na necessidadede sistemas cada vez mais resilientes, rápidos, seguros e disponíveis.Consequentemente, a complexidade dos sistemas tem vindo a crescer, o que leva à implementaçãode mecanismos de persistência e atualização de dados mais difíceis de testar. Para elevar o nível dedificuldade, os diversos sistemas de ficheiros possuem particularidades que afetam de forma significativaestes mecanismos e a consistência das aplicações após a ocorrência de falhas de energia e dos sistemasoperativos.Evitar a perda total ou parcial dos dados deve ser um ponto fulcral para sistemas de armazenamentocom fortes garantias de durabilidade e coerência. Na literatura, os sistemas capazes de voltar a um estadocoerente após uma falha de energia são chamados de crash-consistent. Muito do trabalho relacionadofoca-se na crash consistency dos sistemas de ficheiros e, quando se foca nas aplicações, verifica-se afalta de ferramentas para reprodução de bugs. Quando um utilizador reporta problemas encontradosnuma dada aplicação, é útil para as equipas de desenvolvimento terem uma ferramenta que rapidamentereproduz o bug e ajude na sua correção.Esta dissertação propõe o LazyFS+, um sistema de ficheiros que simula a perda total e parcial dedados através da injeção de faltas baseada em software. A nossa solução possui uma cache interna, oque permite uma gestão determinística dos dados das aplicações e a injeção de faltas reprodutível. Umdos seus pontos fortes é o facto de imitar comportamentos que alguns sistemas de ficheiros apresentam,como a reordenação de escritas, sem se prender a uma implementação específica. Para além disso,facilita a análise das operações executadas pela aplicação e permite obter informação sobre os dadosnão sincronizados.O LazyFS+ provou-se útil através da reprodução de bugs já conhecidos e da identificação dessesmesmos bugs em versões antigas das aplicações, nunca antes reportados. Para além disso, foi possívelencontrar novos bugs, quer em versões antigas, quer em versões mais recentes das aplicações. Estesúltimos foram reportados com todos os passos de reprodução realizados com o LazyFS+. Como resultado,atualmente este está a ser integrado nos testes do sistema de armazenamento chave-valor etcd.",
    "text2": "A atual era digital depende de dados numa perspetiva de grande escala e as organizações requeremsistemas de armazenamento que funcionem corretamente sob falhas. Por exemplo, falhas de energiapodem levar à perda de dados em aplicações cujos ficheiros ainda estão armazenados em memória,isto é, num meio volátil. Evitar estes cenários de perda de dados constitui um grande desafio, umavez que exige que os programadores apliquem primitivas de sincronização (fsync()) que garantem adurabilidade dos dados, a custo de uma potencial diminuição do desempenho das aplicações.As ferramentas de injeção de faltas permitem ajudar os programadores com testes automáticos econsequente validação das suas políticas de durabilidade de dados. No entanto, as abordagens atuaispara sistemas de ficheiros focam-se: (1) na manipulação direta de hardware; ou (2) em erros internosde implementação do sistema de ficheiros, e não na interação da aplicação com o mesmo. Além disso,estas ferramentas são limitadas quanto à informação disponibilizada ao programador, de forma a estecompreender a causa efetiva que levou à perda de dados reportada.Para resolver estes desafios, esta dissertação propõe o LazyFS, um sistema de ficheiros que simulaa perda de dados utilizando uma abordagem de injeção de faltas em software reprodutível e automática.Este sistema tem uma cache dedicada que gere os dados das aplicações e a sua sincronização parauma camada persistente. A pedido, o LazyFS pode limpar todos os dados que não foram previamentesincronizados, fornecendo também aos programadores informações relevantes sobre os dados em riscode serem perdidos com potenciais falhas de energia.O desempenho e validação da correção do protótipo demonstra que a nossa solução consegue avaliara durabilidade dos dados de aplicações, sem adicionar uma sobrecarga significativa à sua execuçãonormal. Foram também reproduzidas quatro anomalias em diferentes bases de dados e o protótipo já seencontra integrado na ferramenta de injeção de faltas Jepsen. Atualmente, o LazyFS está a ser usado,juntamente com o Jepsen, para avaliar sistemas de bases de dados em produção, como o PerconaMySQL Server, MongoDB e o etcd. Adicionalmente, foi descoberta uma possível violação de coerênciano etcd, que está a ser estudada pela sua equipa de desenvolvimento.",
    "similarity": 0.33762836970474974
  },
  {
    "text1": "O aumento exponencial do volume de dados gerados no mundo tecnológico atual é incontestável. A necessidade de armazenar e processar esses grandes volumes de dados levou aindústria a optar por soluções de armazenamento e processamento na nuvem. Além disto,os desenvolvedores optam cada vez mais por sistemas de base de dados que permitemmelhor desempenho e também tirar partido da variedade estrutural dos dados face aossistemas relacionais tradicionais. Estes sistemas que estão a surgir apresentam modelosde dados baseados em estruturas como, p.e., grafos ou índices chave-valor, e oferecem interfacesque podem ser apenas duas operações (PUT/GET) ou, à semelhança dos sistemasrelacionais com o SQL, ter linguagens de interrogação específica.Contudo, a migração de praticamente todos os componentes das infraestruturas dasaplicações para a nuvem implica que os dados sejam processados e armazenados em infraestruturasde terceiros, ficando muitas vezes a privacidade destes comprometida. Poroutro lado, um dado problema pode ter dados com estruturas diferentes ou partes diferentesde uma aplicação podem ter necessidades diferentes quanto aos dados e, por isso, adiversidade entre sistemas de armazenamento leva uma grande complexidade em desenvolversistemas que usem várias fontes de dados diferentes e heterogéneas eficientemente.Assim, esta dissertação pretende dar uma resposta à problemática da gestão de dados deforma privada nas aplicações web, potencializando a utilização de múltiplos sistemas defontes de dados heterogéneas. Em específico, esta dissertação apresenta uma nova arquitetura,à qual se chamou Polyglot, que permite a manutenção da privacidade dos dados, enquantoao mesmo tempo possibilita a utilização de múltiplas fontes de dados heterogénease tira partido da nuvem para grande parte do processamento. Esta arquitetura é tambémimplementada sob a forma de um protótipo direcionado a um sistema de monitorização,que consiste no caso de estudo desta dissertação. Este protótipo permite comprovar a validadeda arquitetura, sendo que a implementação feita demonstra todas as funcionalidadesessenciais ao funcionamento do sistema. Mais ainda, este protótipo é também avaliado anível de desempenho e utilização de recursos, permitindo demonstrar a viabilidade destesistema para uma utilização em cenários reais. Por último exploram-se algumas das funcionalidadesmais relevantes que se poderiam adicionar ao sistema e os ganhos que estastrariam face à implementação atual, demonstrando o potencial do protótipo.",
    "text2": "O desenvolvimento de aplicações e serviços baseados em web está a crescer todos os diascada vez mais. As facilidades que nos oferecem, entre elas a alta-disponibilidade e acessibilidade,levou a que as grandes empresas de tecnologia investissem neste tipo de tecnologias,surgindo assim aplicações como o Evernote, o Google Photos, o Dropbox, o Slack, entre outras.Associadas à utilização constante destas aplicações e serviços pelos seus clientes estãoas enormes quantidade de dados criados, bem como os dados gerados a partir destes. Coma necessidade de armazenar e processar esses de forma rápida e eficiente, estes serviçostem vindo a optar pela utilização de serviços de computação em nuvem de terceiros.Existem vantagens claras associadas à migração de dados para estas plataformas, desdea redução de custos associados armazenamento, manutenção e compra de infraestruturas,até às conveniências oferecidas pela disponibilização ferramentas de monitorização econfiguração avançadas, entre muitas outras. Associado também à utilização desta plataformasde cloud computing estão também os problemas com a privacidade dos dados por elasarmazenadas. Apesar dos esforços, por parte dos fornecedores destes serviços, em negaro acesso a entidades não autorizadas, existem ameaças fora do seu controlo e temos vistomuitas vezes que o acesso a dados sensíveis por terceiros tem um risco elevado associado.Com vista a combater este aspeto existem hoje em dia soluções capazes de garantir a confidencialidadedos dados em bases de dados relacionais e não relacionais, através de técnicascriptográficas. Estas soluções estão usualmente associadas a arquiteturas específicas deforma a precaverem sempre esta questão de segurança dos dados em todos os momentos.Estas arquiteturas implicam um maior esforço computacional do lado do cliente, pois édesse lado que se encontra toda a lóogica da aplicacional e mecanismos de segurança.Esta dissertação oferece uma nova arquitetura web onde maior parte do trabalho aplicacionalé delegado para as infraestruturas de nuvem maximizando assim o desempenhoda aplicação, tirando para isso partido da arquitetura browser servidor característica destessistemas.",
    "similarity": 0.3286898582685637
  },
  {
    "text1": "Understanding the evolutionary relationships between organisms is a complex issue that has gained importance not only in evolution but also in clinical and biological inferences, only possible with technological advances that require new analytical tools. In this work, the main focus is to study the genome of Mycobacterium tuberculosis, the causal agent of tuberculosis, establishing a detailed evolutionary framework.The secondary objective, regardless of the focus on the evolution of Mtb, is that the pipeline created can be applied to any other organism. This dissertation presents some basic facts about tuberculosis, an infectious bacterial disease caused by the Mycobacterium tuberculosis complex, its constitution, evolution, pathology, drug resistance and genetic variation. Our objectives were contextualized considering the most up-to-date tools of alignment and phylogenetics, an area in constant progress due to the growing needs of bioinformatics tools in the area of genomics and evolution. Taxonomic and genetic data were compiled from all organisms with complete genomes in NCBI. This database was subsequently cured by eliminating redundant genomes, i.e., containing only one representative element of each species with the complete proteome. A search of each Mycobacterium tuberculosis protein in this local database using BLAST allowed the detection of probable homologs in a large number of taxonomically informative organisms. The search results were limited to two hundred homologues, which were aligned using MUSCLE. Phylogenetic trees, based on maximum likelihood were constructed for the approximately four thousand Mycobacterium tuberculosis proteins. The phylogenetic relationship and monophyly of Mycobacterium tuberculosis with the remaining bacteria of the same genus(Mycobacterium) and the same family (Corynebacteriaceae) were studied to understand possible processes of acquisition of genes by horizontal transference. Finally, positive selection processes were studied by searching for excess or deficit of non-synonymous mutations in relation to the synonymous (Ka / Ks) using the CODEML software, in order to identify branches with an accelerated evolution in the establishment of the pathogenic species Mycobacterium tuberculosis. These genes may form the basis of the physiological and biochemical characteristics that make this bacterium pathogenic to humans.",
    "text2": "Atrial fibrillation affects millions of individuals worldwide, posing a major threat topublic health due to the variety of comorbidities that constitute by-products of the disease.In light of this epidemic, new means of diagnosis, prognosis and therapy are pressing.Biomarkers, particularly protein markers, are important tools in this process but lackvalidation, which is essential before clinical translation. Several appraisal benchmarkshave been developed to determine the relative potential of biomarkers, but these presentmultiple limitations.We developed a bioinformatic-oriented scoring function aimed at weighing theimportance of proteins and mitigating the limitations of the currently known scores. Aftertaking an extensive literature search and mining a massive volume of reports, data wasorganized into several subsets, according to the sample major characteristic and atrialfibrillation type. A mathematical scoring function was proposed, based on the consensusof studies supporting the protein-disease association (incoherence), median of thereported fold-changes and importance of each study according to the number of diseasedindividuals, and applied to each subset in the form of an algorithm implemented in Python3.5.The developed ranking method performed well regarding both the degree of alterationand the inconsistency parameters. Our results portray a set of proteins with the highestbiomarker potential (highest scores) for atrial fibrillation. We also selected the top fivepotential biomarkers for atrial fibrillation in general and for each type of disease. Themain biological functions in which they are involved were retrieved for comparison withthe state of the art. Alterations in the expression levels of proteins involved in either ofthese functions seem to agree with AF’s pathophysiology and clinical presentation,showing the effectiveness of the developed algorithm.Overall, the developed pipeline seems to improve the processes of biomarker rankingand selection for a target disease, allowing a leap towards clinical translation.",
    "similarity": 0.3113437491909804
  },
  {
    "text1": "Ad-hoc networks can be useful in many contexts because they can be spontaneously created and do not require any sort of infrastructure. They can be useful for small groups when no other network is accessible. They can also be used in wider areas as a low cost replacement for wireless infrastructure networks with multiple dedicated access points. Despite this, ad-hoc networks are not a very popular option for most users.Unfortunately, ad-hoc networks are not as user friendly as infrastructure networks. The latter ones usually provide standardized mechanisms that perform the essential configurations for the correct functioning of the network. Ad-hoc networks do not have standardized mechanisms adapted to them. Each wireless network manager supports a different set of configuration mechanisms. There is usually no problem when every machine uses the same operating system but when different ones are used, users may need to manually perform the required configurations. Another cause for this low popularity is the lack of useful and easy to use applications. These applications are usually hosted on the Internet, as it provides a larger variety of business models.To tackle these problems, new forms of automatically configuring machines and providing services should be explored. These services must be easy to develop, in order to attract the developers that would develop them. The designed solutions must also be adapted to ad-hoc environments. Another important aspect that must be addressed is security. In some contexts, such as public and corporate environments, security can be essential to provide authentication and even to allow the correct functioning of thenetwork.",
    "text2": "Recent evolution of high performance computing moved towards heterogeneous platforms:multiple devices with different architectures, characteristics and programming models, shareapplication workloads. To aid the programmer to efficiently explore these heterogeneousplatforms several frameworks have been under development. These dynamically manage theavailable computing resources through workload scheduling and data distribution, dealingwith the inherent difficulties of different programming models and memory accesses. Amongother frameworks, these include GAMA and StarPU.The GAMA framework aims to unify the multiple execution and memory models ofeach different device in a computer system, into a single, hardware agnostic model. It wasdesigned to efficiently manage resources with both regular and irregular applications, andcurrently only supports conventional CPU devices and CUDA-enabled accelerators. StarPUhas similar goals and features with a wider user based community, but it lacks a singleprogramming model.The main goal of this dissertation was an in-depth evaluation of a heterogeneous frameworkusing a complex application as a case study. GAMA provided the starting vehiclefor training, while StarPU was the selected framework for a thorough evaluation. The progressivephoton mapping irregular algorithm was the selected case study. The evaluationgoal was to assert the StarPU effectiveness with a robust irregular application, and make ahigh-level comparison with the still under development GAMA, to provide some guidelinesfor GAMA improvement.Results show that two main factors contribute to the performance of applications writtenwith StarPU: the consideration of data transfers in the performance model, and chosenscheduler. The study also allowed some caveats to be found within the StarPU API. Althoughthis have no effect on performance, they present a challenge for new coming developers.Both these analysis resulted in a better understanding of the framework, and a comparativeanalysis with GAMA could be made, pointing out the aspects where GAMA could be furtherimproved upon.",
    "similarity": 0.3054097002374357
  },
  {
    "text1": "Ad-hoc networks can be useful in many contexts because they can be spontaneously created and do not require any sort of infrastructure. They can be useful for small groups when no other network is accessible. They can also be used in wider areas as a low cost replacement for wireless infrastructure networks with multiple dedicated access points. Despite this, ad-hoc networks are not a very popular option for most users.Unfortunately, ad-hoc networks are not as user friendly as infrastructure networks. The latter ones usually provide standardized mechanisms that perform the essential configurations for the correct functioning of the network. Ad-hoc networks do not have standardized mechanisms adapted to them. Each wireless network manager supports a different set of configuration mechanisms. There is usually no problem when every machine uses the same operating system but when different ones are used, users may need to manually perform the required configurations. Another cause for this low popularity is the lack of useful and easy to use applications. These applications are usually hosted on the Internet, as it provides a larger variety of business models.To tackle these problems, new forms of automatically configuring machines and providing services should be explored. These services must be easy to develop, in order to attract the developers that would develop them. The designed solutions must also be adapted to ad-hoc environments. Another important aspect that must be addressed is security. In some contexts, such as public and corporate environments, security can be essential to provide authentication and even to allow the correct functioning of thenetwork.",
    "text2": "On a business context, it is responsibility of the Software Product Support Team analyze and solve, if necessary, problems that may arise on software products. Sometimes, the reported problems are not a real defect, i.e., sometimes the client does not have a full understanding about all features of the software product. The team must evaluate and analyze all the Problem Reports that arrive every day. As products are spread across different customers, it is normal to have Problem Reports that are very similar to others that have already been solved for other clients and/or by another member of the Support Team. This dissertation proposes the development of a system that is able to analyze a Problem Report and then provide past problems that are similar to the one being analyzed. An artificial intelligence technique, named Case-Based Reasoning, will be used to achieve such goals. Existent Case-Based Reasoning systems are neither complete nor adaptable to specific domains since the effort to adapt either the reasoning process or the knowledge representation mechanism, to a new domain, is too high. To address such drawbacks, a generic reasoning component will be designed and developed. This dissertation introduces a new approach to the typical Case-Based Reasoning cycle where is possible to handle default, unknown and incomplete data.",
    "similarity": 0.3252979145978153
  },
  {
    "text1": "Ad-hoc networks can be useful in many contexts because they can be spontaneously created and do not require any sort of infrastructure. They can be useful for small groups when no other network is accessible. They can also be used in wider areas as a low cost replacement for wireless infrastructure networks with multiple dedicated access points. Despite this, ad-hoc networks are not a very popular option for most users.Unfortunately, ad-hoc networks are not as user friendly as infrastructure networks. The latter ones usually provide standardized mechanisms that perform the essential configurations for the correct functioning of the network. Ad-hoc networks do not have standardized mechanisms adapted to them. Each wireless network manager supports a different set of configuration mechanisms. There is usually no problem when every machine uses the same operating system but when different ones are used, users may need to manually perform the required configurations. Another cause for this low popularity is the lack of useful and easy to use applications. These applications are usually hosted on the Internet, as it provides a larger variety of business models.To tackle these problems, new forms of automatically configuring machines and providing services should be explored. These services must be easy to develop, in order to attract the developers that would develop them. The designed solutions must also be adapted to ad-hoc environments. Another important aspect that must be addressed is security. In some contexts, such as public and corporate environments, security can be essential to provide authentication and even to allow the correct functioning of thenetwork.",
    "text2": "Every program starts from a model, an abstraction, which is iteratively re ned until we reach the nal result, the implementation. However, at the end, one must ask: does the nal program resemblein anyway the original model? Was the original idea correct to begin with? Formal methodsguarantee that those questions are answered positively, resorting to mathematical techniques. Inparticular, in this thesis we are interested on the second factor: veri cation of formal models.A trend of formal methods defends that they should be lightweight, resulting in a reducedcomplexity of the speci cation, and automated analysis. Alloy was proposed as a solution for thisproblem. In Alloy, the structures are described using a simple mathematical notation: relationallogic. A tool for model checking, automatic veri cation within a given scope, is also provided.However, sometimes model checking is not enough and the need arises to perform unboundedveri cations. The only way to do this is to mathematically prove that the speci cations are correct.As such, there is the need to nd a mathematical logic expressive enough to be able to representthe speci cations, while still being su ciently understandable.We see the point-free style, a style where there are no variables or quanti cations, as a kindof Laplace transform, where complex problems are made simple. Being Alloy completely relational,we believe that a point-free relational logic is the natural framework to reason about Alloyspeci cations.Our goal is to present a translation from Alloy speci cations to a point-free relational calculus,which can then be mathematically proven, either resorting to proof assistants or to manual proving.Since our motivation for the use of point-free is simplicity, we will focus on obtaining expressionsthat are simple enough for manipulation and proofs about them.",
    "similarity": 0.31614292060837296
  },
  {
    "text1": "Since the dawn of times, curiosity and necessity to improve the quality of theirlife, led humans to find means to understand everything surrounding them, aimingat improving it. Whereas the creating abilities of some was growing, the capacityto comprehend of others follow their steps. Disassembling physical objects to comprehendthe connections between the pieces in order to understand how they worktogether is a common human behavior. With the computers arrival, humans feltthe necessity of applying the same techniques (disassemble to comprehend) to theirprograms.Traditionally, these programs are written resorting to general-purpose programminglanguages. Hence, techniques and artifacts, used to aid on program comprehension,were built to facilitate the work of software programmers on maintainingand improving programs that were developed by others. Generally, these genericlanguages deal with concepts at a level that the human brain can hardly understand.So understanding programs written in this languages is an hard task, because thedistance between the concepts at the program level and the concepts at the problemlevel is too big.Thus, as in politics, justice, medicine, etc. groups of words are regularly usedfacilitating the comprehension between people, also in programming, languages thataddress a specific domain were created. These programming languages raise theabstraction of the program domain, shortening the gap to the concepts of the problemdomain.Tools and techniques for program comprehension commonly address the programdomain and they took little advantage of the problem domain. In this master’s thesis,the hypothesis that it is easier to comprehend a program when the underlying problemand program domains are known and a bridge between them is established, isassumed. Then, a program comprehension technique for domain specific languages,is conceived, proposed and discussed. The main objective is to take advantage fromthe large knowledge about the problem domain inherent to the domain specific language,and to improve traditional program comprehension tools that only dealt, untilthen, with the program domain. This will create connections between both programand problem domains. The final result will show, visually, what happens internallyat the program domain level, synchronized with what happens externally, at problemlevel.",
    "text2": "Tools that detect security problems are very important nowadays and for the people doingcode reviews it is even more important to have tools that identify vulnerabilities in the code.In this way companies that provide applications can be more confident that the code theydeploy is almost vulnerabilities free.A subset of these tools, known as Static Application Security Testing (SAST) tools, rely onthe analysis of the source code aiming at looking for patterns that correspond to vulnerabili ties. These analyzers use mainly language processors to help them extract from the sourcecode the information they need. Languages exist for many years but they never ceased toexist because they are in constant development.The description of languages is supported bygrammars. Grammars also evolve to sustain the referred languages evolution. They wereprimarily used for compilers to analyse the structure of the language and parse it; nowadaysthey help many other tools like SAST for example.Having a tool that can detect vulnerabilities is very useful like was said, but to identifythose vulnerabilities it is necessary to find patterns in languages. By finding these abstractpatterns the work is simplified since all concrete languages will present similar vulnerabilities.For example, SQl Injection is a vulnerability that is shared across almost all languages; so,it is possible to define one general pattern to capture that common vulnerability in eachlanguage.Those patterns are defined over Abstract Syntax Trees (AST). To build an AST whileparsing a program, Checkmarx uses a set of functions called Visitors that are associated to theproductions of the programming language Grammar. In that context, the Language Factorytool developed by Checkmarx generates automatically some visitors and let programmers togenerate the others by dragging and dropping rules. The main objective of Language Factorytool is to aid programmers understanding how to create visitors and, at the same time, togenerate as many visitors as possible to be used directly. When Checkmarx is working ona new Language to to include support for that language in the CxSAST tool, the use ofLanguage Factory will help creating the appropriate Visitors making this process simplerand faster.The Master’s project reported in this dissertation appears in that framework aiming at theimprovement of the Checkmarx Language Factory making it capable of infer more Visitorsfrom the new language’s Grammar.",
    "similarity": 0.3110989122356597
  },
  {
    "text1": "Since the dawn of times, curiosity and necessity to improve the quality of theirlife, led humans to find means to understand everything surrounding them, aimingat improving it. Whereas the creating abilities of some was growing, the capacityto comprehend of others follow their steps. Disassembling physical objects to comprehendthe connections between the pieces in order to understand how they worktogether is a common human behavior. With the computers arrival, humans feltthe necessity of applying the same techniques (disassemble to comprehend) to theirprograms.Traditionally, these programs are written resorting to general-purpose programminglanguages. Hence, techniques and artifacts, used to aid on program comprehension,were built to facilitate the work of software programmers on maintainingand improving programs that were developed by others. Generally, these genericlanguages deal with concepts at a level that the human brain can hardly understand.So understanding programs written in this languages is an hard task, because thedistance between the concepts at the program level and the concepts at the problemlevel is too big.Thus, as in politics, justice, medicine, etc. groups of words are regularly usedfacilitating the comprehension between people, also in programming, languages thataddress a specific domain were created. These programming languages raise theabstraction of the program domain, shortening the gap to the concepts of the problemdomain.Tools and techniques for program comprehension commonly address the programdomain and they took little advantage of the problem domain. In this master’s thesis,the hypothesis that it is easier to comprehend a program when the underlying problemand program domains are known and a bridge between them is established, isassumed. Then, a program comprehension technique for domain specific languages,is conceived, proposed and discussed. The main objective is to take advantage fromthe large knowledge about the problem domain inherent to the domain specific language,and to improve traditional program comprehension tools that only dealt, untilthen, with the program domain. This will create connections between both programand problem domains. The final result will show, visually, what happens internallyat the program domain level, synchronized with what happens externally, at problemlevel.",
    "text2": "Risk assessment is an important topic for financial institution nowadays, especially in the context of loan applications or loan requests and credit scoring. Some of these institutions have already implemented their own custom credit scoring systems to evaluate their clients’ risk supporting the loan application decision with this indicator. In fact, the information gathered by financial institutions constitutes a valuable source of data for the creation of information assets from which credit scoring mechanisms may be developed.Historically, most financial institutions support their decision mechanisms on regression algorithms, however, these algorithms are no longer considered the state of the art on decision algorithms. This fact has led to the interest on the research of new types of learning algorithms from machine learning able to deal with the credit scoring problem.The work presented in this dissertation has as an objective the evaluation of state of the art algorithms for credit decision proposing new optimization to improve their performance. In parallel, a suggestion system on credit scoring is also proposed in order to allow the perception of how algorithm produce decisions on clients’ loan applications, provide clients with a source of research on how to improve their chances of being granted with a loan and also develop client profiles that suit specific credit conditions and credit purposes.At last, all the components studied and developed are combined on a platform able to deal with the problem of credit scoring through an experts system implemented upon a multi-agent system. The use of multi-agent systems to solve complex problems in today’s world is not a new approach. Nevertheless, there has been a growing interest in using its properties in conjunction with machine learning and data mining techniques in order to build efficient systems. The work presented aims to demonstrate the viability and utility of this type of systems for the credit scoring problem.",
    "similarity": 0.3176219438757076
  },
  {
    "text1": "Since the dawn of times, curiosity and necessity to improve the quality of theirlife, led humans to find means to understand everything surrounding them, aimingat improving it. Whereas the creating abilities of some was growing, the capacityto comprehend of others follow their steps. Disassembling physical objects to comprehendthe connections between the pieces in order to understand how they worktogether is a common human behavior. With the computers arrival, humans feltthe necessity of applying the same techniques (disassemble to comprehend) to theirprograms.Traditionally, these programs are written resorting to general-purpose programminglanguages. Hence, techniques and artifacts, used to aid on program comprehension,were built to facilitate the work of software programmers on maintainingand improving programs that were developed by others. Generally, these genericlanguages deal with concepts at a level that the human brain can hardly understand.So understanding programs written in this languages is an hard task, because thedistance between the concepts at the program level and the concepts at the problemlevel is too big.Thus, as in politics, justice, medicine, etc. groups of words are regularly usedfacilitating the comprehension between people, also in programming, languages thataddress a specific domain were created. These programming languages raise theabstraction of the program domain, shortening the gap to the concepts of the problemdomain.Tools and techniques for program comprehension commonly address the programdomain and they took little advantage of the problem domain. In this master’s thesis,the hypothesis that it is easier to comprehend a program when the underlying problemand program domains are known and a bridge between them is established, isassumed. Then, a program comprehension technique for domain specific languages,is conceived, proposed and discussed. The main objective is to take advantage fromthe large knowledge about the problem domain inherent to the domain specific language,and to improve traditional program comprehension tools that only dealt, untilthen, with the program domain. This will create connections between both programand problem domains. The final result will show, visually, what happens internallyat the program domain level, synchronized with what happens externally, at problemlevel.",
    "text2": "We are facing a period where software projects have a huge dimension involvingsmall resources, high risk and a wide range of available approaches. In thisscenario the Software Development Methodologies (SDMs) can prove to be auseful ally, but very dangerous and even fatal if misused. The big issue aroundthis matter is how to choose the appropriated SDM that ts a speci c project.In the given scope, this dissertation describes a framework for comparing SDMsdelivering a set of procedures that should be followed when the choice of anSDM is made. The dissertation approaches the framework by applying it to agroup of SDMs that were selected by their popularity and signi cance. Thisexercise is done to prove the concept of the framework and to provide a basecomparison, with each chosen SDM, that can, and should, be extended by thosewho choose to use the framework.The classi cation is achieved by de ning a scale that goes from total satisfactionto no satisfaction, with an intermediate level of partial satisfaction, that is appliedto a set of keys. These keys are based in SWEBOK (Software EngineeringBody Of Knowledge) that describes and explains the di erent Knowledge Areas(KA) stating their common issues and best practices. To explain the framework,the dissertation analyzes each KA and evaluates the selected SDMs byassessing how their approach complies with SWEBOK's knowledge areas, usingthe previous stated scale.The framework delivered can be enriched by its user who should provide weightsto each KA regarding the project in which the SDM will be used and previousexperiences",
    "similarity": 0.30597982159648274
  },
  {
    "text1": "Since the dawn of times, curiosity and necessity to improve the quality of theirlife, led humans to find means to understand everything surrounding them, aimingat improving it. Whereas the creating abilities of some was growing, the capacityto comprehend of others follow their steps. Disassembling physical objects to comprehendthe connections between the pieces in order to understand how they worktogether is a common human behavior. With the computers arrival, humans feltthe necessity of applying the same techniques (disassemble to comprehend) to theirprograms.Traditionally, these programs are written resorting to general-purpose programminglanguages. Hence, techniques and artifacts, used to aid on program comprehension,were built to facilitate the work of software programmers on maintainingand improving programs that were developed by others. Generally, these genericlanguages deal with concepts at a level that the human brain can hardly understand.So understanding programs written in this languages is an hard task, because thedistance between the concepts at the program level and the concepts at the problemlevel is too big.Thus, as in politics, justice, medicine, etc. groups of words are regularly usedfacilitating the comprehension between people, also in programming, languages thataddress a specific domain were created. These programming languages raise theabstraction of the program domain, shortening the gap to the concepts of the problemdomain.Tools and techniques for program comprehension commonly address the programdomain and they took little advantage of the problem domain. In this master’s thesis,the hypothesis that it is easier to comprehend a program when the underlying problemand program domains are known and a bridge between them is established, isassumed. Then, a program comprehension technique for domain specific languages,is conceived, proposed and discussed. The main objective is to take advantage fromthe large knowledge about the problem domain inherent to the domain specific language,and to improve traditional program comprehension tools that only dealt, untilthen, with the program domain. This will create connections between both programand problem domains. The final result will show, visually, what happens internallyat the program domain level, synchronized with what happens externally, at problemlevel.",
    "text2": "Software applications evolve over the years at a cost: their architecture modularity tends to be degraded. This happens mainly because software application maintenance often leads to architectural degradation. In this context, software architects need to elaborate strategies for detecting architectural degradation symptoms and thus maintaining the software architectural quality. The elaborations of these strategies often rely on tools with domain-specific languages (DSLs), which help them to specify software architecture rules. These tools also enforce the adherence of these rules in the evolving program. However, their adoption in mainstream software development is largely dependent on the usability of the language. Unfortunately, it is also often hard to identify their usability strengths and weaknesses early, as there is no guidance on how to objectively reveal them. Usability is a multi-faceted quality characteristic, which is challenging to quantify before a DSL is actually used by its stakeholders. There is even less support and experience on how to quantitatively evaluate the usability of DSLs used in software maintenance tasks. To this end in this dissertation, a usability measurement framework was developed based on the Cognitive Dimensions of Notations (CDN). The framework was evaluated both qualitatively and quantitatively using two textual DSLs for architecture rules in the context of two evolving object-oriented systems. The results suggested that the proposed metrics were useful: (1) to early identify the DSL usability limitations to be addressed, (2) to reveal specific features of the DSLs favoring software maintenance tasks, and (3) to successfully analyze eight usability dimensions that are critical in many DSLs. However, along with these results this evaluation also revealed that this kind of tools lack support for communication among the stakeholders, creating a gap in the software development. To solve this problem we proposed heuristics for tools that use DSLs for detecting architecture degradation symptoms. These heuristics will permit the exchange of information between the stakeholders, thereby, also increasing the tool usability. Finally, we chose TamDera as the tool to implement these heuristics in our study domain. Therefore, we implemented in the new version of TamDera the communication support for the stakeholders by using a new architecture and a new environment with the developed heuristics.",
    "similarity": 0.5537685721480735
  },
  {
    "text1": "Since the dawn of times, curiosity and necessity to improve the quality of theirlife, led humans to find means to understand everything surrounding them, aimingat improving it. Whereas the creating abilities of some was growing, the capacityto comprehend of others follow their steps. Disassembling physical objects to comprehendthe connections between the pieces in order to understand how they worktogether is a common human behavior. With the computers arrival, humans feltthe necessity of applying the same techniques (disassemble to comprehend) to theirprograms.Traditionally, these programs are written resorting to general-purpose programminglanguages. Hence, techniques and artifacts, used to aid on program comprehension,were built to facilitate the work of software programmers on maintainingand improving programs that were developed by others. Generally, these genericlanguages deal with concepts at a level that the human brain can hardly understand.So understanding programs written in this languages is an hard task, because thedistance between the concepts at the program level and the concepts at the problemlevel is too big.Thus, as in politics, justice, medicine, etc. groups of words are regularly usedfacilitating the comprehension between people, also in programming, languages thataddress a specific domain were created. These programming languages raise theabstraction of the program domain, shortening the gap to the concepts of the problemdomain.Tools and techniques for program comprehension commonly address the programdomain and they took little advantage of the problem domain. In this master’s thesis,the hypothesis that it is easier to comprehend a program when the underlying problemand program domains are known and a bridge between them is established, isassumed. Then, a program comprehension technique for domain specific languages,is conceived, proposed and discussed. The main objective is to take advantage fromthe large knowledge about the problem domain inherent to the domain specific language,and to improve traditional program comprehension tools that only dealt, untilthen, with the program domain. This will create connections between both programand problem domains. The final result will show, visually, what happens internallyat the program domain level, synchronized with what happens externally, at problemlevel.",
    "text2": "O recurso a ferramentas de geração automática de código permite economizar tempo quando se desenvolvem soluções de software, factor importante em questões de produtividade.Existe um conjunto de padrões de conceção [Gamma et al., 1995] que representam soluções genéricas para problemas relativos ao desenvolvimento de aplicações de software, numa perspetiva orientada aos objetos. Para cada um deles pode ser vista a sua estrutura de classes, métodos e relacionamentos, bem como as situações mais adequadas para a sua utilização. Bastará consultar o catálogo de padrões de conceção [Gamma et al., 1995] e utilizar aquele que mais se adequar à resolução de determinado problema que surja no desenvolvimento de um novo programa.A existência de uma aplicação de software capaz de fazer a geração automática do código associado aos padrões de conceção, agiliza o desenvolvimento de novas aplicações, porque fornece de imediato o respetivo código.O que se propõe com o desenvolvimento desta dissertação é uma solução de software, capaz de efetuar a geração automática de código para os padrões de conceção catalogados em [Gamma et al., 1995]. Juntamente com o programa desenvolvido, é também apresentado um levantamento do estado da arte sobre os padrões de conceção, considerando também situações atuaisda sua aplicabilidade. Em seguida, é descrita a especificação da aplicação elaborada, bem como o seu processo de desenvolvimento, acompanhado de um exemplo de utilização. Por fim, encontram-se dois casos de estudo, servindo para provar que o programa elaborado pode ser utilizado em contextos reais.",
    "similarity": 0.4573648631477293
  },
  {
    "text1": "Diabetic Retinopathy (DR) and diabetic macular edema (DME) are the damages caused to the retina and are complications that can affect the diabetic population. Diabetic retinopathy (DR), is the most common disease due to the presence of exudates and has three levels of severity, such as mild, moderate and severe, depending on the exudates distribution in the retina. For screening of diabetic retinopathy or a population-based clinical study, a large number of digital fundus images are captured and to be possible to recognize the signs of DR and DME, it is necessary that the images have quality, because low-quality images may force the patient to return for a second examination, wasting time and possibly delaying treatment.These images are evaluated by trained human experts, which can be a time-consuming and expensive task due to the number of images that need to be examined. Therefore, this is a field that would be hugely benefited with the development of an automated eye fundus quality assessment and analysis systems. It can potentially facilitate health care in remote regions and in developing countries where reading skills are scarce. Deep Learning is a kind of Machine Learning method that involves learning multi-level representations that begin with raw data entry and gradually moves to more abstract levels through non-linear transformations. With enough training data and sufficiently deep architectures, neural networks, such as Convolutional Neural Networks (CNN), can learn very complex functions and discover complex structures in the data. Thus, Deep Learning emerges as a powerful tool for medical image analysis and evaluation of retinal image quality using computer-aided diagnosis.Therefore, the aim of this study is to automatically assess all the three quality parameters alone (focus, illumination and color), and then an overall quality of fundus images assessment, classifying the images into the classes “accept” or “reject with a Deep Learning approach using convolutional neural networks (CNN). For the overall classification, the following results were obtained: test accuracy=97.89%, SN=97.9%, AUC=0.98 and 𝐹1-score=97.91%.",
    "text2": "A huge amount of medical data is being generated each day, leaving the doctors unableto analyze such volume and make a good diagnosis for the patient. The emergence of BigData frameworks for data analysis leverages the automatic analysis of healthcare data in afaster and accurate manner, by scanning which information is relevant, and, consequently,detecting diseases in earlier stages.Nowadays, it is estimated that about 9% to 38% of the world’s population has sleep ap nea. Unawareness of the disease’s presence can lead to the development of cardiovasculardiseases, and consequently, death. The detection of sleep apnea syndrome through the tra ditional method, Polysomnography (PSG), becomes not only expensive but also inconvenientfor the patient. Therefore, systems based on Electrocardiogram (ECG) can improve the qua lity of a patient’s health by overcoming these inconveniences. This master thesis relies ondeep learning (DL) networks, such as convolutional and recurrent neural networks for sleepapnea detection. The computational complexity of these models depends on its size, typesof layers and data. This complexity also increases the computation time of the training taskleading to several hours spent training on a single machine. For this work, we proposea sleep apnea detection system based on ECGs, alongside with a distributed version of it,which parallelizes the training computation, reducing the overall learning time, while notcompromising the model performance.The results obtained for sleep apnea detection encourage the use of electrocardiogramsfor the detection of this disease. Our model achieved a value of 93% of sensitivity onthe Physionet database, being the highest value compared to other studies described inthe literature. Besides this, on the distributed environment it was accomplished similaroutput quality, reducing the training time by approximately 50%, from the centralized todistributed learning.The model was trained with the Sleep Heart Health Study (SHHS) data, achieving the highestresults compared to the work described in the literature that used the same dataset. Incomparison with the previous dataset, the model trained and tested with the SHHS wasnot able to attain a similar quality output. However, this corroborates the large diversity ofthe SHHS data. Moreover, when it was tested if this model could classify the Physionet data,it achieved promising results of 73,7%, 73,8%, 68,3% and 63,5% of accuracy, sensitivity, F1-score, and precision, respectively, which lead us to conclude that the SHHS trained modelcould be able to generalize to new data. In addition to this, on the distributed environment it was achieved equal output perfor mance for SHHS, reducing the training time by approximately 90%.",
    "similarity": 0.30466599190283405
  },
  {
    "text1": "Deep Learning (DL) is a widely used technique often applied to many domains, from computer vision to natural language processing. To avoid overfitting, DL applications have to access large amounts of data, which affects the training performance. Although significant hardware advances have already been made, current storage systems cannot keep up with the needs required by DL techniques. Considering this, multiple storage solutions have already been developed to improve the Input/Output (I/O) performance of DL training. Nevertheless, they are either specific to certain DL frameworks or present drawbacks, such as loss of accuracy. Most DL frameworks also contain internal I/O optimizations, however they cannot be easily decoupled and applied to other frameworks. Furthermore, most of these optimizations have to be manually configured or comprise greedy provisioning algorithms that waste computational resources. To address these issues, we propose PRISMA, a novel storage middleware that employs data prefetching and parallel I/O to improve DL training performance. PRISMA provides an autotuning mechanism to automatically select the optimal configuration. This mechanism was designed to achieve a good trade-off between performance and resource usage. PRISMA is framework-agnostic, meaning that it can be applied to any DL framework, and does not impact the accuracy of the training model. In addition to PRISMA, we provide a thorough study and evaluation of the TensorFlow Dataset Application Programming Interface (API), demonstrating that local DL can benefit from I/O optimization. PRISMA was integrated and evaluated with two popular DL frameworks, namely Tensor Flow and PyTorch, proving that it is successful under different I/O workloads. Experimental results demonstrate that PRISMA is the most efficient solution for the majority of the scenar ios that were studied, while for the other scenarios exhibits similar performance to built-in optimizations of TensorFlow and PyTorch.",
    "text2": "Deep Learning (DL) has become fundamental to the advancement of several areas, such as computervision, natural language processing and expert systems. Utilizing DL techniques demands vast amountsof data and processing power, which raises challenges to the training performance of DL models. High Performance Computing (HPC) systems are becoming increasingly popular to support DL training, byoffering extensive computing capabilities, however, due to convenience and usability, many DL jobs runningon these infrastructures resort to the shared Parallel File System (PFS) for storing and accessing trainingdata. Under such scenario, where multiple Input/Output (I/O)-intensive applications operate concurrently,the PFS can quickly get saturated with simultaneous storage requests and become a critical performancebottleneck, leading to throughput variability and performance loss.To solve these issues, this dissertation presents a storage middleware agnostic to any DL solution,Monarch, that deploys storage tiering to accelerate DL models’ training performance and decrease the I/Opressure imposed over the PFS. It leverages from existing storage tiers of supercomputers (e.g., computenode’s local storage, shared PFS), as well as the I/O patterns of DL solutions to improve data placementacross storage tiers. Furthermore, this middleware is non-intrusive and easily installed in HPC centers,thus enabling its wide adoption and applicability.The performance and applicability of Monarch are validated with the TensorFlow and PyTorch DLframeworks. Results show that, when the training dataset can only be partially stored at the local storagetier, Monarch decreases TensorFlow’s and PyTorch’s training time by up to 28% and 37% for I/O-intensivemodels, respectively. Furthermore, Monarch can reduce the number of I/O operations submitted to thePFS by up to 56%.",
    "similarity": 0.3139401284311257
  },
  {
    "text1": "A necessidade das empresas evoluírem as suas aplicações por forma a disponibilizarem mais recursos aos seusutilizadores é uma realidade da atualidade. A disponibilização de informação em tempo real é cada vez mais necessária,mesmo que isso implique a interação entre sistemas distintos, o que exige que essa comunicação seja completamenteagnóstica de tecnologias.Sendo uma das premissas da Q-Better - empresa que permitiu o desenvolvimento desta dissertação em contextoempresarial - proporcionar aos seus clientes uma melhor experiência de utilização aliado ao acompanhamento daevolução tecnológica, tornou-se imperativo a conceção de uma arquitetura que fornecesse suporte ao desenvolvimentode novas aplicações e também às já desenvolvidas, ainda que para tal seja necessária uma reformulação das mesmas.Inicialmente foi feito um estudo sobre a temática das arquiteturas orientadas a serviços, incluindo os vários tiposde web services existentes, e também uma passagem pela temática da sincronização de dados para proporcionar asincronização entre as várias aplicações da Q-Better.A viabilidade da solução final - uma arquitetura orientada a serviços composta por um conjunto de web servicesREST - foi testada com a criação da aplicação Bloom Appointments cujo objetivo passa pela gestão de agendamentosa partir de qualquer dispositivo que tenha ligação à internet ou à rede onde o sistema esteja instalado.Foi possível concluir que a escolha deste tipo de arquitetura se revelou acertada, uma vez que além de permitir ainteroperabilidade entre os vários sistemas existentes na Q-Better, permite uma maior expansão não só da aplicaçãousada como case study, mas também de todo o legacy software e de futuras aplicações.",
    "text2": "Apesar da evolução observada nas últimas décadas na utilização de Sistemas de Informação(SI) na gestão de matérias primas (MPs) e informação ao longo dos vários elos de umacadeia de abastecimento, a rastreabilidade de MPs em tempo real é ainda muito limitadadevido à falta de integração dos SI com tecnologias de identificação automática.A fábrica Bosch Car Multimedia de Braga (Bosch BrgP) não é indiferente a este problemae recorre com grande frequência a fornecedores que utilizam rotas dispendiosas em termosde tempo, custo e esforço de operacionalização, o que levanta diversos desafios relativamenteaos processos logísticos (planeamento, receção, gestão e abastecimento de MPs), ouseja, de todo o fluxo de MP desde os fornecedores até às linhas de produção.Atualmente, a Bosch BrgP enfrenta problemas que decorrem da dificuldade em localizar,em tempo real e com elevado grau de precisão, todas as MPs (envolvidas) nos diferentes fluxosda logística interna (na cadeia de abastecimento interna), o que dificulta o planeamentodas necessidades de cliente. Deste modo, a Bosch BrgP tem a necessidade permanente deter acesso a informação relativa à localização da MP.É então pretendido otimizar a logística interna da Bosch BrgP, tornando-a mais competitivano mercado e diminuir os desvios de stock originados pela dificuldade em localizaras MPs. De forma a resolver os problemas de visibilidade e rastreabilidade de MPs desdea sua receção até ao seu consumo, esta dissertação analisa e concebe uma solução pararastrear o fluxo das MPs em todo o processo interno responsável pela gestão da cadeia deabastecimento interna, que recorre a tecnologia Radio-Frequency IDentification (RFID).Os objetivos são alcançados através do desenvolvimento de um sistema de identificaçãoe localização de MPs, que garante uma maior visibilidade dos fluxos de MPs, contribuindopara a redução do tempo de abastecimento às linhas de produção. Para além disso, osistema deve garantir que toda a movimentação/localização da MP em curso na cadeia deabastecimento interna é rastreável e efetuada de modo automático, em tempo real e comelevado grau de precisão, contribuindo para a disponibilização dessa informação sempreque solicitada.Esta dissertação contribui para esse esforço de desenvolvimento com atividades de análisee conceção que se concretizam através do levantamento de requisitos (funcionais e nãofuncionais), da conceção da arquitetura de hardware e software, da definição dos pontos deinteroperabilidade com os sistemas legados e da caracterização do novo fluxo de rastreabilidade.Estas atividades são documentadas através de diversos esquemas e diagramas (deuse-cases e de atividades) que seguem a notação Unified Modeling Language (UML).",
    "similarity": 0.30425064476072217
  },
  {
    "text1": "A necessidade das empresas evoluírem as suas aplicações por forma a disponibilizarem mais recursos aos seusutilizadores é uma realidade da atualidade. A disponibilização de informação em tempo real é cada vez mais necessária,mesmo que isso implique a interação entre sistemas distintos, o que exige que essa comunicação seja completamenteagnóstica de tecnologias.Sendo uma das premissas da Q-Better - empresa que permitiu o desenvolvimento desta dissertação em contextoempresarial - proporcionar aos seus clientes uma melhor experiência de utilização aliado ao acompanhamento daevolução tecnológica, tornou-se imperativo a conceção de uma arquitetura que fornecesse suporte ao desenvolvimentode novas aplicações e também às já desenvolvidas, ainda que para tal seja necessária uma reformulação das mesmas.Inicialmente foi feito um estudo sobre a temática das arquiteturas orientadas a serviços, incluindo os vários tiposde web services existentes, e também uma passagem pela temática da sincronização de dados para proporcionar asincronização entre as várias aplicações da Q-Better.A viabilidade da solução final - uma arquitetura orientada a serviços composta por um conjunto de web servicesREST - foi testada com a criação da aplicação Bloom Appointments cujo objetivo passa pela gestão de agendamentosa partir de qualquer dispositivo que tenha ligação à internet ou à rede onde o sistema esteja instalado.Foi possível concluir que a escolha deste tipo de arquitetura se revelou acertada, uma vez que além de permitir ainteroperabilidade entre os vários sistemas existentes na Q-Better, permite uma maior expansão não só da aplicaçãousada como case study, mas também de todo o legacy software e de futuras aplicações.",
    "text2": "A PRIMAVERA BSS é uma empresa tecnológica portuguesa ao serviço da gestão empresarial. Empresapioneira, em Portugal, a desenvolver soluções de gestão para Windows. A nível tecnológico, a PRIMAVERABSS disponibiliza um vasto leque de serviços, nomeadamente softwares de gestão.O desenvolvimento dos micro-serviços na empresa assenta numa framework proprietária — a frameworkLithium. Esta assegura uma arquitetura comum e padrões de desenho aplicando práticas deModel-driven Development (MDD).Os micro-serviços são cada vez mais uma arquitetura muito utilizada na indústria. Grandes empresas,adotaram esta arquitetura e muitas outras seguem a tendência, ao migrar as suas aplicações para estaarquitetura. Contudo, existe ainda uma dificuldade em construir um sistema neste estilo muito devidoà falta de informação ou conhecimento acerca dos padrões disponíveis, e por isso mesmo, este estiloarquitetural necessita de ser amplamente estudado.Posto isto, um dos objetivos desta dissertação é suprir esta lacuna, através do estudo de elementosimportantes, que devem ser considerados durante o desenvolvimento de aplicações/sistemas baseadosna arquitetura de micro-serviços. Outro objetivo passa por estudar a framework acima referida bem comorespetivas alternativas.Em suma, para além de se ter procedido à pesquisa e estudo de arquiteturas concorrentes, bem comode frameworks alternativas à Lithium, também foi desenvolvida uma aplicação baseada na arquitetura dosmicro-serviços.",
    "similarity": 0.30511464139104894
  },
  {
    "text1": "A implementação da interoperabilidade nos Sistemas de Informação Hospitalar(SIH) é cada vez mais um requisito e não uma opção. A Agênciapara a Integração, Difusão e Arquivo de Informação Médica e Clínica (AIDA)consiste numa plataforma de interoperabilidade hospitalar desenvolvida porinvestigadores da Universidade do Minho e que se encontra instalada no CentroHospitalar do Porto (CHP). A AIDA assegura a interoperabilidade entreos SIH e para alémdisto, assegura também a confidencialidade, integridade edisponibilidade dos dados. A AIDA deve possuir um elevado nível de disponibilidadee um funcionamento eficiente 24 horas por dia. Um pequeno períodode paragem poderá trazer graves consequências para a qualidade dos serviçosprestados. Esta plataforma possui mecanismos de recuperação e tolerânciade falhas, contudo devido à sua elevada importância, é preciso agir antes daocorrência das falhas, evitando sérios danos. Os processos de monitorizaçãoe prevenção de falhas devem ser implementados nos “órgãos vitais” da AIDA,que são as base de dados, máquinas e agentes inteligentes.Uma vez que a prevenção de falhas em base de dados da AIDA já tersido alvo de estudo, esta dissertação aborda a monitorização e prevenção defalhas nas máquinas e agentes. Para prever as falhas, foram criados modelosbaseados no Modified Early Warning Score (MEWS). Este modelo através darecolha frequente dos valores dos sinais vitais, calcula um conjunto de scorespara determinar o nível de risco a que o paciente está submetido.Foram desenvolvidos sistemas de monitorização de prevenção para as máquinase agentes que permitem não só prevenir falhas, mas também observare avaliar o comportamento destes componentes através de dashboards de monitorização.A prevenção de falhas nos agentes foi baseada na frequência comque estes registam as suas atividades nos seus ficheiros log, enquanto que paraas máquinas a prevenção foi baseada em indicadores de desempenho como amemória e o CPU. Apurou-se que os componentes, em geral, encontram-secom os seus principais recursos bem balanceados e que os sistemas de prevençãodesenvolvidos detetaram situações críticas com sucesso, contribuindopara um aumento da integridade e disponibilidade da AIDA do CHP.",
    "text2": "A crescente utilização dos Sistemas de Informação (SI) nas unidades desaúde tem um papel muito importante para garantir a qualidade das mesmas.Com as Tecnologias da Informação e da Comunicação (TIC), os dadosarmazenados estão estruturados e organizados de forma a possibilitar umautilização rápida e e caz. O aumento de informações em formato eletrónicono processo de Registo Clínico (RC) apesar de diminuir em grande escalaerros que resultavam da utilização de dados mal entendidos, trouxe um desa o aos técnicos de informática médica. Esse desa o passa por melhorar aqualidade da prestação de cuidados de saúde utilizando a informação armazenada.É neste âmbito que surgem as normas e sistemas de nomenclatura quepossibilitam uma uniformização do RC de forma a evitar dados ambíguose permitir a comunicação entre diferentes pro ssionais de saúde e serviçoshospitalares. Estas normas são divididas conforme a sua nalidade, havendonormas de comunicação, imagem e representação.Pretende-se, neste contexto, implementar o Systematized Nomenclatureof Medicine (SNOMED) na Agência de Interoperação, Difusão e Arquivo(AIDA) no Centro Hospitalar do Alto Ave (CHAA) de forma a utilizar as suaspotencialidades no processo de uniformização do Registo Clínico Eletrónico(RCE).",
    "similarity": 0.30731734764542934
  },
  {
    "text1": "A implementação da interoperabilidade nos Sistemas de Informação Hospitalar(SIH) é cada vez mais um requisito e não uma opção. A Agênciapara a Integração, Difusão e Arquivo de Informação Médica e Clínica (AIDA)consiste numa plataforma de interoperabilidade hospitalar desenvolvida porinvestigadores da Universidade do Minho e que se encontra instalada no CentroHospitalar do Porto (CHP). A AIDA assegura a interoperabilidade entreos SIH e para alémdisto, assegura também a confidencialidade, integridade edisponibilidade dos dados. A AIDA deve possuir um elevado nível de disponibilidadee um funcionamento eficiente 24 horas por dia. Um pequeno períodode paragem poderá trazer graves consequências para a qualidade dos serviçosprestados. Esta plataforma possui mecanismos de recuperação e tolerânciade falhas, contudo devido à sua elevada importância, é preciso agir antes daocorrência das falhas, evitando sérios danos. Os processos de monitorizaçãoe prevenção de falhas devem ser implementados nos “órgãos vitais” da AIDA,que são as base de dados, máquinas e agentes inteligentes.Uma vez que a prevenção de falhas em base de dados da AIDA já tersido alvo de estudo, esta dissertação aborda a monitorização e prevenção defalhas nas máquinas e agentes. Para prever as falhas, foram criados modelosbaseados no Modified Early Warning Score (MEWS). Este modelo através darecolha frequente dos valores dos sinais vitais, calcula um conjunto de scorespara determinar o nível de risco a que o paciente está submetido.Foram desenvolvidos sistemas de monitorização de prevenção para as máquinase agentes que permitem não só prevenir falhas, mas também observare avaliar o comportamento destes componentes através de dashboards de monitorização.A prevenção de falhas nos agentes foi baseada na frequência comque estes registam as suas atividades nos seus ficheiros log, enquanto que paraas máquinas a prevenção foi baseada em indicadores de desempenho como amemória e o CPU. Apurou-se que os componentes, em geral, encontram-secom os seus principais recursos bem balanceados e que os sistemas de prevençãodesenvolvidos detetaram situações críticas com sucesso, contribuindopara um aumento da integridade e disponibilidade da AIDA do CHP.",
    "text2": "Cada vez mais a relação entre as tecnologias da informação e a saúde seestreitam. Concretamente, na neuroimagiologia, essa ligação tem vindo a tornar-se cada vezmais importante principalmente após o surgimento da imagem de Ressonância Magnética(MRI – Magnetic Ressonance Imaging).Com o desenvolvimento da tecnologia, para além das aquisições MRI convencionais, surgiramoutras técnicas como a aquisição de imagens de tensor de difusão (DTI – Diffusion TensorImaging) e da MRI funcional (fMRI). Estas técnicas permitem a obtenção de uma imageminterior do corpo. Um dos órgãos mais estudados com estas imagens é o cérebro, que é alvode vários estudos mas que devido à sua complexidade ainda é bastante desconhecido.Enquanto que com a MRI estrutural pode-se efetuar uma análise volumétrica às diferentesestruturas do cérebro, com a DTI é possível verificar a integridade da substância brancaatravés das fibras virtualmente criadas que representam o movimento das moléculas de água.Vários estudos referem os benefícios de uma análise multimodal com estas duas técnicas.Para tratamento e análise destas imagens é necessário uma gestão de várias aplicaçõesinformáticas que processam os dados e corregistam as imagens de forma automática. Um dosgrandes desafios consta, não só na utilização individual de cada ferramenta na qual é exigidoalgum conhecimento técnico, como na combinação das várias aplicações que apresentam osdados resultantes em diferentes formatos.Uma solução passa pela pesquisa e definição de fluxos de trabalho para que exista umaabordagem simples dos procedimentos a ter com as várias ferramentas e da sua combinaçãocom outras. No entanto, esta solução não impedirá o gasto de recursos de tempo e o trabalhomoroso de um estudo que contenha vários sujeitos.Assim, neste trabalho, para além de serem apresentados os vários fluxos de trabalho possíveispara análise multimodal, será exposto um módulo automatizado que será inserido numaaplicação de multimodalidade já existente: BrainCat.A presente dissertação apresenta um meio de facilitar as análises multimodais para que aqualidade quer a nível de investigação científica quer a nível dos diagnósticos clínicos aumente.",
    "similarity": 0.3093592608914631
  },
  {
    "text1": "A implementação da interoperabilidade nos Sistemas de Informação Hospitalar(SIH) é cada vez mais um requisito e não uma opção. A Agênciapara a Integração, Difusão e Arquivo de Informação Médica e Clínica (AIDA)consiste numa plataforma de interoperabilidade hospitalar desenvolvida porinvestigadores da Universidade do Minho e que se encontra instalada no CentroHospitalar do Porto (CHP). A AIDA assegura a interoperabilidade entreos SIH e para alémdisto, assegura também a confidencialidade, integridade edisponibilidade dos dados. A AIDA deve possuir um elevado nível de disponibilidadee um funcionamento eficiente 24 horas por dia. Um pequeno períodode paragem poderá trazer graves consequências para a qualidade dos serviçosprestados. Esta plataforma possui mecanismos de recuperação e tolerânciade falhas, contudo devido à sua elevada importância, é preciso agir antes daocorrência das falhas, evitando sérios danos. Os processos de monitorizaçãoe prevenção de falhas devem ser implementados nos “órgãos vitais” da AIDA,que são as base de dados, máquinas e agentes inteligentes.Uma vez que a prevenção de falhas em base de dados da AIDA já tersido alvo de estudo, esta dissertação aborda a monitorização e prevenção defalhas nas máquinas e agentes. Para prever as falhas, foram criados modelosbaseados no Modified Early Warning Score (MEWS). Este modelo através darecolha frequente dos valores dos sinais vitais, calcula um conjunto de scorespara determinar o nível de risco a que o paciente está submetido.Foram desenvolvidos sistemas de monitorização de prevenção para as máquinase agentes que permitem não só prevenir falhas, mas também observare avaliar o comportamento destes componentes através de dashboards de monitorização.A prevenção de falhas nos agentes foi baseada na frequência comque estes registam as suas atividades nos seus ficheiros log, enquanto que paraas máquinas a prevenção foi baseada em indicadores de desempenho como amemória e o CPU. Apurou-se que os componentes, em geral, encontram-secom os seus principais recursos bem balanceados e que os sistemas de prevençãodesenvolvidos detetaram situações críticas com sucesso, contribuindopara um aumento da integridade e disponibilidade da AIDA do CHP.",
    "text2": "Os avanços tecnológicos verificados nos dia de hoje assim como a quantidadede informação e comunicação que lhes estão associados, atribuem umpapel de grande importância aos sistemas de monitorização. É no seio destaevolução, que a competição existente entre os vários setores de mercado nãoestão acessíveis a erros e falhas, principalmente ao nível dos equipamentostecnológicos. Assim, neste contexto de intolerância, assiste-se a uma proliferaçãoe a uma utilização cada vez maior de sistemas de monitorização eprevenção.Mais importante que monitorizar é prevenir. Ter a capacidade de evitaruma falha, e permitir a resolução de algum problema atempadamente é umamais valia para o desempenho, atribuindo fiabilidade e qualidade ao serviço.A gestão e a verificação de equipamentos, bem como de processos associadosaos mesmos permitem um maior controlo e domínio dum sistema.Assim esta dissertação tem como objetivo principal a implementação dumsistema para monitorizar a atividade de um ou mais sistemas multi-agente,com capacidade para intervir e avisar o administrador do sistema quandoocorre um problema.O sistema construído, que assenta numa estrutura formada por três unidadesdistintas, unidade de análise, unidade de processamento e unidade deinterface com o utilizador, permitem a implementação de processos para trocae integração de informação, exercendo assim uma comunicação fundamentalentre sistemas e utilizadores . É um sistema direcionado principalmenteà gestão e monitorização do desempenho de diferentes equipamentos assimcomo dos processos em execução nos mesmos. Este trabalho foi desenvolvido em colaboração com um Hospital no Norte do País e o ambiente escolhidopara a implementação da plataforma foi unicamente laboratorial.A concretização deste projeto esteve dividida em quatro fases: Início,Pesquisas, Construção da Aplicação e Escrita da Dissertação. Na primeirafase, o Início, foi feito o levantamento dos principais requisitos para o sistema,definição dos objetivos, e elaboração de um plano de trabalho. Na segundafase, Pesquisas, procedeu-se ao levantamento de informação sobre os conceitosteóricos relacionados com o tema em causa, como artigos científicos quedão suporte ao tema, entre outros trabalhos já publicados na mesma área.No final desta etapa já se encontravam definidas as ideias base da aplicaçãoa construir de acordo com as necessidades. Na terceira fase deste projeto, aConstrução englobou a modelação e implementação da plataforma de monitorização,de acordo com as especificações definidas anteriormente. A quartaetapa englobou a escrita da dissertação, o que incluiu um enquadramentodos conceitos teóricos em função da aplicação desenvolvida.",
    "similarity": 0.3372518467220683
  },
  {
    "text1": "O paradigma do controlo de acessos, em especial o controlo de acesso à informação, tem vindo a mudar nos últimos anos. Controlo este que inicialmente era efetuado pelas próprias aplicações de forma isolada e autónoma, sem a possibilidade de consultarem ou se integrarem com qualquer sistema centralizado. Todavia, com o crescente uso das tecnologias de informação nas organizações, novas soluções (tais como os serviços de diretoria LDAP) têm vindo a ser adotadas com o intuito de dar resposta à necessidade de uma política de acessos unificada e coesa, transversal aos diversos serviços e aplicações. Estas soluções representam uma mais-valia no desempenho das tarefas organizacionais.Tendo em conta esta necessidade, este trabalho propõe uma nova solução para o controlo de acessos físicos e lógicos através da apresentação e implementação de um novo modelo de controlo de acessos baseado no par Cargo-Organização. É ainda apresentada e implementada neste projeto uma nova abordagem no controlo de acessos lógicos, sendo esta assim capaz de interagir e configurar aplicações que carecem do suporte de protocolos e mecanismos padrão para o controlo de acessos.",
    "text2": "massificação dos sistemas de informação tem contribuído significativamente para aforma como os utilizadores interagem com as empresas e seus sistemas. Esta nova relaçãoentre cliente e fornecedor tem aumentado significativamente o volume de dados geradospelas organizações, criando novas necessidades de como manter e gerir toda estainformação. Assim, as empresas têm investido cada vez mais em soluções que permitammanter toda a informação tratada e consolidada num repositório único de dados. Estessistemas são vulgarmente designados por sistemas de data warehousing. Tradicionalmente,estes sistemas são refrescados em modo offline, em períodos de tempo que podem serdiários ou semanais. Contudo, o aumento da competitividade no mundo empresarial tornaeste tipo de refrescamentos desadequados, originando uma reação atrasada à ação quedespoletou essa informação. Na realidade, períodos longos de refrescamento tornam ainformação desatualizada, diminuído consequentemente a sua importância e valor para aorganização em causa. Assim sendo, é cada vez mais necessário que a informaçãoarmazenada num sistema de data warehousing, seja a mais recente possível, evitandointerrupções na disponibilização da informação. A necessidade de obter a informação emtempo real, coloca alguns desafios, tais como manter os dados acessíveis 24 horas por dia,7 dias por semana, 365 dias por ano, reduzir o período de latência dos dados ou evitarestrangulamentos operacionais nos sistemas transacionais. Assim, é imperativo a utilização de técnicas de coleta de dados não intrusivas, que atuem no momento em que determinadoevento ocorreu num sistema operacional e reflitam a sua informação de forma imediata (ouquase imediata) num sistema de data warehousing. Neste trabalho de dissertação pretendeseestudar a problemática relacionada com a captura de dados em tempo real e conceberum componente que capaz de suportar um sistema de extração de dados em tempo realuniversal, que capture as mudanças ocorridas nos sistemas transacionais, de forma nãointrusiva, e as comunique na altura certa ao seu sistema de data warehousing.",
    "similarity": 0.3448101678344468
  },
  {
    "text1": "O paradigma do controlo de acessos, em especial o controlo de acesso à informação, tem vindo a mudar nos últimos anos. Controlo este que inicialmente era efetuado pelas próprias aplicações de forma isolada e autónoma, sem a possibilidade de consultarem ou se integrarem com qualquer sistema centralizado. Todavia, com o crescente uso das tecnologias de informação nas organizações, novas soluções (tais como os serviços de diretoria LDAP) têm vindo a ser adotadas com o intuito de dar resposta à necessidade de uma política de acessos unificada e coesa, transversal aos diversos serviços e aplicações. Estas soluções representam uma mais-valia no desempenho das tarefas organizacionais.Tendo em conta esta necessidade, este trabalho propõe uma nova solução para o controlo de acessos físicos e lógicos através da apresentação e implementação de um novo modelo de controlo de acessos baseado no par Cargo-Organização. É ainda apresentada e implementada neste projeto uma nova abordagem no controlo de acessos lógicos, sendo esta assim capaz de interagir e configurar aplicações que carecem do suporte de protocolos e mecanismos padrão para o controlo de acessos.",
    "text2": "Nos últimos anos os sistemas distribuídos têm sofrido um crescimento exponencial. Estes sistemas, normalmente implementados na plataforma Java, são compostos por um vasto conjunto de componentes de middleware, os quais desempenham várias tarefas de comunicação e de coordenação. Esta tendência influencia a modelação e a arquitetura de novas aplicações cada vez mais complexas obrigando a um enorme esforço e a um custo elevado na avaliação do seu desempenho. A concorrência e a sua distribuição, bem como o facto de muitos problemas só se manifestarem pela grande escala em si, não permite que a sua avaliação seja feita com recurso a simples ferramentas que não tenham em conta estas características. Avaliação realista e controlada de aplicações distribuídas é ainda hoje muito difícil de alcançar, especialmente em cenários de larga escala. Modelos de simulação pura podem ser uma solução para este problema, mas criar modelos abstratos a partir de implementações reais nem sempre é possível ou mesmo desejável, sobretudo na fase de desenvolvimento na qual ainda podem não existir todos os componentes ou a sua funcionalidade estar incompleta. Para colmatar esta falha, nesta dissertação é apresentada o Minha, uma plataforma que permite uma avaliação realista das aplicações através da combinação de modelos abstratos de simulação e implementações reais num ambiente centralizado. Esta plataforma combina a execução de código real sob análise, com modelos de simulação do ambiente envolvente, isto é, da rede e da aplicação. Este sistema permite reproduzir as condições de um sistema em grande escala e através da manipulação de bytecode Java, suporta componentes de middleware inalterados. A utilidade deste sistema é demonstrada aplicando-o ao WS4D, uma pilha que cumpre a especificação Device Profile for Web Services.",
    "similarity": 0.31427285318559556
  },
  {
    "text1": "O processo de tomada de decisão revela-se um fator cada vez mais diferenciador nas empresas atuais. Sejam elas empresas diretamente relacionadas com as Tecnologias de Informação, sejam empresas de outros sectores. Nesse aspeto, a recolha e tratamento de informação crítica a cada atividade, pode ser bastante útil para ser usado no processo de tomada de decisão, sendo sempre necessário avaliar até que ponto pode a informação ser válida e qual a sua qualidade e importância no processo em que é necessária.Recorrendo a um sistema de Case-based reasoning tentar-se-á criar-se um sistema que de forma autónoma aprenda a melhor maneira de atribuir tarefas dentro de uma equipa multifacetada, aprendendo a discernir quais os colabores que melhor se adaptam a cada tarefa e cujos resultados podem ser melhores para a empresa. Esse mesmo sistema também estará apto para lidar com equipas dinâmicas aproveitando os melhores recursos que tem em cada altura.",
    "text2": "massificação dos sistemas de informação tem contribuído significativamente para aforma como os utilizadores interagem com as empresas e seus sistemas. Esta nova relaçãoentre cliente e fornecedor tem aumentado significativamente o volume de dados geradospelas organizações, criando novas necessidades de como manter e gerir toda estainformação. Assim, as empresas têm investido cada vez mais em soluções que permitammanter toda a informação tratada e consolidada num repositório único de dados. Estessistemas são vulgarmente designados por sistemas de data warehousing. Tradicionalmente,estes sistemas são refrescados em modo offline, em períodos de tempo que podem serdiários ou semanais. Contudo, o aumento da competitividade no mundo empresarial tornaeste tipo de refrescamentos desadequados, originando uma reação atrasada à ação quedespoletou essa informação. Na realidade, períodos longos de refrescamento tornam ainformação desatualizada, diminuído consequentemente a sua importância e valor para aorganização em causa. Assim sendo, é cada vez mais necessário que a informaçãoarmazenada num sistema de data warehousing, seja a mais recente possível, evitandointerrupções na disponibilização da informação. A necessidade de obter a informação emtempo real, coloca alguns desafios, tais como manter os dados acessíveis 24 horas por dia,7 dias por semana, 365 dias por ano, reduzir o período de latência dos dados ou evitarestrangulamentos operacionais nos sistemas transacionais. Assim, é imperativo a utilização de técnicas de coleta de dados não intrusivas, que atuem no momento em que determinadoevento ocorreu num sistema operacional e reflitam a sua informação de forma imediata (ouquase imediata) num sistema de data warehousing. Neste trabalho de dissertação pretendeseestudar a problemática relacionada com a captura de dados em tempo real e conceberum componente que capaz de suportar um sistema de extração de dados em tempo realuniversal, que capture as mudanças ocorridas nos sistemas transacionais, de forma nãointrusiva, e as comunique na altura certa ao seu sistema de data warehousing.",
    "similarity": 0.3142883330617566
  },
  {
    "text1": "Automation developments are enabling industrial restructuring through the incorporationof more efficient and accurate processes with less associated cost. Consequently, robots arebeing increasingly used in the most various scenarios, including in Safety Critical domains.In such cases, the use of suitable methods to attest both the system’s quality and their safetyis absolutely essential.Following the current increase of complexity of cyber-physical systems, safety guardswhich used to be fully hardware dependent, are constantly migrating to software. Here upon, middleware software to abstract systems hardware are constantly evolving and arebeing increasingly adopted. The common feature of these systems is usually associated withits modular architectures based on message-passing communication patterns. A notoriouscase is the ROS middleware, where highly configurable robots are usually built by composingthird-party modules. The verification of such systems is usually very hard, and its implemen tation in real industrial environments is, in most cases, impracticable. To promote adoption,this work advocates the use of lightweight formal methods associated with semi-automatictechniques that require minimal user input and provide valuable intuitive feedback.This work explores and proposes a technique to automatically verify system-wide safetyproperties of ROS-based applications in continuous integration environments. It is basedon the formalization of ROS architectural models and nodes behaviours in Electrum, aspecification language of first-order temporal logic supported by a model-finder over which,system-wide properties are subsequently model-checked. In order to automate the analysis,the technique is deployed as an HAROS plug-in, a framework for quality assessment of ROSsoftware, specially aimed to its community.The technique proposal and its implementation under the HAROS framework are eval uated with positive results on a real agricultural robot, AgRobV16, whose dimension andcomplexity are industrially representative.",
    "text2": "Industrial manufacturing is becoming highly reliant on automation developments, as they bring moreefficient and accurate processes, with lower associated costs. Consequently, robots are increasingly beingdeployed in a wide range of scenarios, especially where safety is demanded. In such cases, it is criticalto employ appropriate procedures to verify both the system’s quality and safety.Following the current growth of cyber-physical systems, as well as their usage in various technologydomains, the development of software applications is becoming more demanding due to the complexitybehind the integration of complementing services, beyond those provided by the operating system.One of the most popular open-source software platforms for building robotic systems is the Robot Operating System (ROS) [53] middleware, where highly configurable robots are usually built by composingthird-party modules. Robot Operating System 2 (ROS2) is implemented using the Data DistributionService (DDS) [49] communication protocol. ROS2 implicitly makes use of the DDS-Security artefactsthrough the Secure Robot Operating System 2 (SROS2) security toolset.The present study focus on detecting security problems in ROS2 networks, in which it is intended toverify, through formal techniques, security properties. However, security is a very broad subject, so thisstudy focuses on a particular security property to show the viability of the proposed technique, namelyObservational Determinism (OD).This dissertation introduces a software tool, named Security Verification in ROS (svROS), thatprovides multiple functionalities to support this type of security analysis using Alloy [32], a formal specification language and analysis tool.",
    "similarity": 0.3704325395816921
  },
  {
    "text1": "In the last decades, the emergence and evolution of the Next Generation Sequence technologies have revolutionised genomic research, leading to an exponential increase in the number of sequenced genomes. Many of the sequenced genomes belong to bacteriophages (phages), mostly due to their therapeutic potential against bacterial infections. This abundance of genomic data demands the creation of user-friendly bioinformatics tools for performing genome annotation. The most challenging step in phage genome annotation is the identification of regulatory elements, primarily promoters, to understand phage transcription regulation mechanisms.Thus, in this work, PhagePromoter, a tool for promoter prediction in phage genomes, was developed, using machine learning methods. Several models were created using different datasets and machine learning algorithms, such as support vector machines (SVM), artificial neural networks (ANN) and Random Forests (RF). All models were tested using a 5-fold cross-validation process. The datasets were composed by known phage promoter sequences, mainly retrieved from the phiSITE database, and by a different number of negative cases. After optimization, the performance was similar for all models and two were selected to be integrated in the tool: the ANN model created with the dataset containing 1600 negative examples and the SVM model created with the dataset containing 2400 negatives. The ANN model presented 92% of accuracy, 89% of precision and 87% of recall, whereas the SVM model presented 93% of accuracy, 91% of precision and 80% of recall. Hence, the first model will predict more sequences as promoters and may lead to more false positives. The SVM model will return few positive results, but most of them will be correct classified while some real promoters may not be identified by the model.PhagePromoter was integrated in the widely used Galaxy framework, available at https://galaxy.bio.di.uminho.pt/?tool_id=get_proms&version=0.1.0&__identifer=4u05obc3o5w, which provides a graphical user interface. This tool returns better results when compared to other tools, such as BPROM, PromoterHunter and CNNpromoter_e.",
    "text2": "Nowadays, the ability to predict protein functions directly from amino-acid sequences alone remains a major biological challenge. The understanding of protein properties and functions is extremely important and can have a wide range of biotechnological and medical applications.Technological advances have led to an exponential growth of biological data challenging conventionalanalysis strategies. High-level representations from the field of deep learning canprovide new alternatives to address these problems, particularly NLP methods, such as wordembeddings, have shown particular success when applied for protein sequence analysis.Here, a module that eases the implementation of word embedding models toward proteinrepresentation and classification is presented. Furthermore, this module was integrated in theProPythia framework, allowing to straightforwardly integrate WE representations with the trainingand testing of ML and DL models.This module was validated using two protein classification problems namely, identification ofplant ubiquitylation sites and lysine crotonylation site prediction. This module was further usedto explore enzyme functional annotation. Several WE were tested and fed to different ML andDL networks. Overall, WE achieved good results being even competitive with state-of-the-artmodels, reinforcing the idea that language based methods can be applied with success to awide range of protein classification problems.This work presents a freely available tool to perform word embedding techniques for proteinclassification. The case studies presented reinforce the usability and importance of using NLPand ML in protein classification problems.",
    "similarity": 0.30771309204849917
  },
  {
    "text1": "In the last decades, the emergence and evolution of the Next Generation Sequence technologies have revolutionised genomic research, leading to an exponential increase in the number of sequenced genomes. Many of the sequenced genomes belong to bacteriophages (phages), mostly due to their therapeutic potential against bacterial infections. This abundance of genomic data demands the creation of user-friendly bioinformatics tools for performing genome annotation. The most challenging step in phage genome annotation is the identification of regulatory elements, primarily promoters, to understand phage transcription regulation mechanisms.Thus, in this work, PhagePromoter, a tool for promoter prediction in phage genomes, was developed, using machine learning methods. Several models were created using different datasets and machine learning algorithms, such as support vector machines (SVM), artificial neural networks (ANN) and Random Forests (RF). All models were tested using a 5-fold cross-validation process. The datasets were composed by known phage promoter sequences, mainly retrieved from the phiSITE database, and by a different number of negative cases. After optimization, the performance was similar for all models and two were selected to be integrated in the tool: the ANN model created with the dataset containing 1600 negative examples and the SVM model created with the dataset containing 2400 negatives. The ANN model presented 92% of accuracy, 89% of precision and 87% of recall, whereas the SVM model presented 93% of accuracy, 91% of precision and 80% of recall. Hence, the first model will predict more sequences as promoters and may lead to more false positives. The SVM model will return few positive results, but most of them will be correct classified while some real promoters may not be identified by the model.PhagePromoter was integrated in the widely used Galaxy framework, available at https://galaxy.bio.di.uminho.pt/?tool_id=get_proms&version=0.1.0&__identifer=4u05obc3o5w, which provides a graphical user interface. This tool returns better results when compared to other tools, such as BPROM, PromoterHunter and CNNpromoter_e.",
    "text2": "One of the challenging problems in bioinformatics is to computationally characterize sequences, structures and functions of proteins. Sequence-derived structural and physico-chemical properties of proteins have been used in the development of machine learning models in protein related problems. However, tools and platforms to calculate features and perform Machine learning (ML) with proteins are scarce and have their limitations in terms of effectiveness, user-friendliness and capacity. Here, a generic modular automated platform for the classification of proteins based on their physicochemical properties using different ML algorithms is proposed. The tool developed, as a Python package, facilitates the major tasks of ML and includes modules to read and alter sequences, calculate protein features, preprocess datasets, execute feature reduction and selection, perform clustering, train and optimize ML models and make predictions. As it is modular, the user retains the power to alter the code to fit specific needs. This platform was tested to predict membrane active anticancer and antimicrobial peptides and further used to explore viral fusion peptides. Membrane-interacting peptides play a crucial role in several biological processes. Fusion peptides are a subclass found in enveloped viruses, that are particularly relevant for membrane fusion. Determining what are the properties that characterize fusion peptides and distinguishing them from other proteins is a very relevant scientific question with important technological implications. Using three different datasets composed by well annotated sequences, different feature extraction techniques and feature selection methods (resulting in a total of over 20 datasets), seven ML models were trained and tested, using cross validation for error estimation and grid search for model selection. The different models, feature sets and feature selection techniques were compared. The best models obtained for distinct metric were then used to predict the location of a known fusion peptide in a protein sequence from the Dengue virus. Feature importances were also analysed. The models obtained will be useful in future research, also providing a biological insight of the distinctive physicochemical characteristics of fusion peptides. This work presents a freely available tool to perform ML-based protein classification and the first global analysis and prediction of viral fusion peptides using ML, reinforcing the usability and importance of ML in protein classification problems.",
    "similarity": 0.3212068748426089
  },
  {
    "text1": "In the last decades, the emergence and evolution of the Next Generation Sequence technologies have revolutionised genomic research, leading to an exponential increase in the number of sequenced genomes. Many of the sequenced genomes belong to bacteriophages (phages), mostly due to their therapeutic potential against bacterial infections. This abundance of genomic data demands the creation of user-friendly bioinformatics tools for performing genome annotation. The most challenging step in phage genome annotation is the identification of regulatory elements, primarily promoters, to understand phage transcription regulation mechanisms.Thus, in this work, PhagePromoter, a tool for promoter prediction in phage genomes, was developed, using machine learning methods. Several models were created using different datasets and machine learning algorithms, such as support vector machines (SVM), artificial neural networks (ANN) and Random Forests (RF). All models were tested using a 5-fold cross-validation process. The datasets were composed by known phage promoter sequences, mainly retrieved from the phiSITE database, and by a different number of negative cases. After optimization, the performance was similar for all models and two were selected to be integrated in the tool: the ANN model created with the dataset containing 1600 negative examples and the SVM model created with the dataset containing 2400 negatives. The ANN model presented 92% of accuracy, 89% of precision and 87% of recall, whereas the SVM model presented 93% of accuracy, 91% of precision and 80% of recall. Hence, the first model will predict more sequences as promoters and may lead to more false positives. The SVM model will return few positive results, but most of them will be correct classified while some real promoters may not be identified by the model.PhagePromoter was integrated in the widely used Galaxy framework, available at https://galaxy.bio.di.uminho.pt/?tool_id=get_proms&version=0.1.0&__identifer=4u05obc3o5w, which provides a graphical user interface. This tool returns better results when compared to other tools, such as BPROM, PromoterHunter and CNNpromoter_e.",
    "text2": "Interstitial lung diseases (ILD) are defined as a set of more than 200 pulmonary disorders. Among these, the ones broadly termed as pneumonia represent a major cause of morbidity and mortality in the world. The chest radiograph (CXR) was the first x-ray based lung imaging technique to emerge and is still widely used as a diagnostic method for pneumonia and other lung diseases. However, correct interpretation of CXR requires analysis by experts and stays vulnerable to errors and observer-related variation. To counteract these problems, artificial intelligence (Al) methods have been applied for the automated analysis of CXR and other medical images. The deep learning (DL) branch of AI and in the particular the methods based on convolutional neural networks (CNN), recently obtained impressive results in these tasks. This dissertation presents a DL approach to classify pneumonia from medical CXR image datasets. Two different models based on the development of CNN were trained from a preprocessed dataset of CXR images obtained from 8562 individuals classified as normal (n=7214) or with pneumonia (n=1348) (Dataset XP1’). Model 1 applied a normal cross entropy loss function, and model 2 an alternative loss function aiming at counteracting the unbalance in normal/pneumonia class frequency. For performance enhancing both models underwent a hyper optimization procedure. The optimized model 1 and 2 were tested on a test set from PI'. To better understand the predictability and generalization potential we then tested both models on an unrelated test set of 624 images (Dataset XP2). Interestingly, model 1 obtained better performance when tested on XP2 than in XP1', scoring an accuracy of 85%, recall of 93% and precision of 85% for the detection of the pneumonia class. The higher homogeneity present on dataset XP2 compared with dataset XP1' could be a plausible justification. As for model 2, it correctly predicted more pneumonia cases an test set XP1' than model 1. However, on test set XP2 the results were poor, predicting most cases as pneumonia and scoring a recall value of only 26% for the pneumonia class. Testing the DL models on unseen data is a relevant but not always performed validation. Overall, the higher accuracy, recall and precision levels of model 1 in XP2 suggests it has a higher potential to be applied for real-word application although its performance should be further improved and evaluated. This work opened promising new lines of research for the future development of a high-performance CNN-based automated method to classify CXR and assist in the diagnostic of pneumonia.",
    "similarity": 0.32673602367161925
  },
  {
    "text1": "In the last decades, the emergence and evolution of the Next Generation Sequence technologies have revolutionised genomic research, leading to an exponential increase in the number of sequenced genomes. Many of the sequenced genomes belong to bacteriophages (phages), mostly due to their therapeutic potential against bacterial infections. This abundance of genomic data demands the creation of user-friendly bioinformatics tools for performing genome annotation. The most challenging step in phage genome annotation is the identification of regulatory elements, primarily promoters, to understand phage transcription regulation mechanisms.Thus, in this work, PhagePromoter, a tool for promoter prediction in phage genomes, was developed, using machine learning methods. Several models were created using different datasets and machine learning algorithms, such as support vector machines (SVM), artificial neural networks (ANN) and Random Forests (RF). All models were tested using a 5-fold cross-validation process. The datasets were composed by known phage promoter sequences, mainly retrieved from the phiSITE database, and by a different number of negative cases. After optimization, the performance was similar for all models and two were selected to be integrated in the tool: the ANN model created with the dataset containing 1600 negative examples and the SVM model created with the dataset containing 2400 negatives. The ANN model presented 92% of accuracy, 89% of precision and 87% of recall, whereas the SVM model presented 93% of accuracy, 91% of precision and 80% of recall. Hence, the first model will predict more sequences as promoters and may lead to more false positives. The SVM model will return few positive results, but most of them will be correct classified while some real promoters may not be identified by the model.PhagePromoter was integrated in the widely used Galaxy framework, available at https://galaxy.bio.di.uminho.pt/?tool_id=get_proms&version=0.1.0&__identifer=4u05obc3o5w, which provides a graphical user interface. This tool returns better results when compared to other tools, such as BPROM, PromoterHunter and CNNpromoter_e.",
    "text2": "Knowing what lies around us has been a goal for many decades now, and the new advances in sequencing technologies and in meta-omics approaches have permitted to start answering some of the main questions of microbiology - what is there, and what is it doing?The exponential growth of omics studies has been answered by the development ofsome bioinformatic tools capable of handling Metagenomics (MG) analysis, with a scarcefew integrating such analysis with Metatranscriptomics (MT) or Metaproteomics (MP) studies.Furthermore, the existing tools for meta-omics analysis are usually not user friendly,usually limited to command-line usage.Because of the variety in meta-omics approaches, a standard workflow is not possible,but some routines exist, which may be implemented in a single tool, thereby facilitatingthe work of laboratory professionals. In the framework of this master thesis, a pipeline forintegrative MG and MT data analysis was developed. This pipeline aims to retrieve comprehensivecomparative gene/transcript expression results obtained from different biologicalsamples. The user can access the data at the end of each step and summaries containing severalparameters of evaluation of the previous step, and final graphical representations, likeKrona plots and Differential Expression (DE) heatmaps. Several quality reports are alsogenerated. The pipeline was constructed with tools tested and validated for meta-omicsdata analysis. Selected tools include FastQC, Trimmomatic and SortMeRNA for preprocessing,MetaSPAdes and Megahit for assembly, MetaQUAST and Bowtie2 for reporting onthe quality of the assembly, FragGeneScan and DIAMOND for annotation and DeSEQ2 forDE analysis.Firstly, the tools were tested separately and then integrated in several python wrappers toconstruct the software Meta-Omics Software for Community Analysis (MOSCA). MOSCAperforms preprocessing of MG and MT reads, assembly of the reads, annotation of theassembled contigs, and a final data analysis.Real datasets were used to test the capabilities of the tool. Since different types of filescan be obtained along the workflow, it is possible to perform further analyses to obtainadditional information and/or additional data representations, such as metabolic pathwaymapping.",
    "similarity": 0.3099609463693747
  },
  {
    "text1": "This dissertation aims to evaluate and improve the performance of deep learning (DL)algorithms to autonomously drive a vehicle, using a Remo Car (an RC vehicle) as testbed.The RC vehicle was built with a 1:10 scaled remote controlled car and fitted with anembedded system and a video camera to capture and process real-time image data. Twodifferent embedded systems were comparatively evaluated: an homogeneous system, aRaspberry Pi 4, and an heterogeneous system, a NVidia Jetson Nano. The Raspberry Pi 4 withan advanced 4-core ARM device supports multiprocessing, while the Jetson Nano, also witha 4-core ARM device, has an integrated accelerator, a 128 CUDA-core NVidia GPU.The captured video is processed with convolutional neural networks (CNNs), whichinterpret image data of the vehicle’s surroundings and predict critical data, such as lane viewand steering angle, to provide mechanisms to drive on its own, following a predefined path.To improve the driving performance of the RC vehicle, this work analysed the programmedDL algorithms, namely different computer vision approaches for object detection and imageclassification, aiming to explore DL techniques and improve their performance at the inferencephase.The work also analysed the computational efficiency of the control software, while runningintense and complex deep learning tasks in the embedded devices, and fully explored theadvanced characteristics and instructions provided by the two embedded systems in thevehicle.Different machine learning (ML) libraries and frameworks were analysed and evaluated:TensorFlow, TensorFlow Lite, Arm NN, PyArmNN and TensorRT. They play a key role todeploy the relevant algorithms and to fully engage the hardware capabilities.The original algorithm was successfully optimized and both embedded systems couldperfectly handle this workload. To understand the computational limits of both devices, anadditional and heavy DL algorithm was developed that aimed to detect traffic signs.The homogeneous system, the Raspberry Pi 4, could not deliver feasible low-latency values,hence the detection of traffic signs was not possible in real-time. However, a great performanceimprovement was achieved using the heterogeneous system, Jetson Nano, enabling theirCUDA-cores to process the additional workload.",
    "text2": "Machine Learning (ML) gives a computer system the ability to perform a certain task without being explicitly programmed to do it. Although ML is not a new topic in the fieldof computer science, these techniques have been gaining increasing popularity due to advances in hardware (especially GPUs). More powerful hardware supports more efficienttraining and a more responsive end-system, once deployed. These algorithms have provento be particularly effective in image processing and feature detection, namely with deepneural networks.In the context of a vehicle, autonomous or not, perceiving its external and internal environment enables the ability to detect and identify left behind objects, its misuse or otherpotentially dangerous situations. This captured data is relevant to trigger vehicle intelligentresponses. Bosch is currently developing a system that has these capabilities and plans toleverage deep learning approaches to implement it.This work aimed to test and evaluate the suitability of a given embedded device forthe project. It also determined the best strategy to implement deep learning solutions inthe device. The supplied test bed was a NVidia Software Development Kit (SDK) systemfor the embedded NVidia Jetson TX2 device with the System-on-Chip (SOC) Parker, anheterogeneous computing chip with 2 Denver-cores (a NVidia implementation of ARM-64architecture), 4 CortexA57-cores (also ARM-64), 256 Pascal GPU-cores and support for up to6 video cameras. The SDK includes several software library packages, including for imageprocessing and ML.With the goal of fully exploiting the embedded device compute capabilities, this workstudied several inference frameworks, going as far as implementing an inference enginefrom scratch (named Deeploy) that produces inferences based on two libraries providedby NVidia: cuDNN and TensorRT. Deeploy was evaluated against well known and established frameworks, namely Tensorflow, PyTorch and Darknet, in terms of efficiency, resourcemanagement and overall ease of use, maintainability and flexibility. This work also exploited key performance related features available on the device, such as power modes,half-precision floating point computation and the implemented shared memory architecture between the GPU-cores and the CPU-cores.",
    "similarity": 0.33089656104317283
  },
  {
    "text1": "This dissertation aims to evaluate and improve the performance of deep learning (DL)algorithms to autonomously drive a vehicle, using a Remo Car (an RC vehicle) as testbed.The RC vehicle was built with a 1:10 scaled remote controlled car and fitted with anembedded system and a video camera to capture and process real-time image data. Twodifferent embedded systems were comparatively evaluated: an homogeneous system, aRaspberry Pi 4, and an heterogeneous system, a NVidia Jetson Nano. The Raspberry Pi 4 withan advanced 4-core ARM device supports multiprocessing, while the Jetson Nano, also witha 4-core ARM device, has an integrated accelerator, a 128 CUDA-core NVidia GPU.The captured video is processed with convolutional neural networks (CNNs), whichinterpret image data of the vehicle’s surroundings and predict critical data, such as lane viewand steering angle, to provide mechanisms to drive on its own, following a predefined path.To improve the driving performance of the RC vehicle, this work analysed the programmedDL algorithms, namely different computer vision approaches for object detection and imageclassification, aiming to explore DL techniques and improve their performance at the inferencephase.The work also analysed the computational efficiency of the control software, while runningintense and complex deep learning tasks in the embedded devices, and fully explored theadvanced characteristics and instructions provided by the two embedded systems in thevehicle.Different machine learning (ML) libraries and frameworks were analysed and evaluated:TensorFlow, TensorFlow Lite, Arm NN, PyArmNN and TensorRT. They play a key role todeploy the relevant algorithms and to fully engage the hardware capabilities.The original algorithm was successfully optimized and both embedded systems couldperfectly handle this workload. To understand the computational limits of both devices, anadditional and heavy DL algorithm was developed that aimed to detect traffic signs.The homogeneous system, the Raspberry Pi 4, could not deliver feasible low-latency values,hence the detection of traffic signs was not possible in real-time. However, a great performanceimprovement was achieved using the heterogeneous system, Jetson Nano, enabling theirCUDA-cores to process the additional workload.",
    "text2": "Parkinson’s Disease (PD) is a neurodegenerative disorder of the central nervous system. Resting tremor, akinesia, and bradykinesia (slow movements), rigidity, shuffling walking, and postural instabilityare some of the symptoms that not only negatively impacts patients’ life, but also the life of people aroundthem.Current approaches for monitoring patients’ motor autonomy are limited to the observer and self reported methods. The observer-based examinations, patients perform a set of standard PD examinations.The self-reported method relies on patients’ daily activities diaries. These approaches are commonly used,but are limited to a few sessions per year, they do not address common motor daily tasks, and their results are object of subjective interpretation by the clinical expert.By combining kinematic-driven data from wearable sensor with AI, the main goal of this dissertation is to develop an automatic software for recognition of human activities (e.g., walking, standing, turning, sitting, and lying) in PD to assist the clinical experts with objective and concrete data.A data collection protocol was developed and captured, resulting in a database comprised of data collected from eighteen PD patients who performed three trials of six different daily activities: walk; 180º turning; sit on chair; get up from chair; lay on bed and get up from bed.A Deep Learning (DL) framework based on Convolutional Neural Network capable of recognizing daily activities was developed and attained a performance of F1 Score equal to 0.90892.As a complementary goal an automatic software for human walk initial contact (IC) and final contact (FC) recognition using kinematic data was also developed. IC and FC are tremendously important to provide patient on-demand motor assistance and estimation of walking-associated metrics.A Deep Learning framework based on Bidirectional Long Short-Term Memory Neural Networkcapable of walking IC/FC events detection was developed and attained a performance of MCC Score equal to 0.538386.Promising results were attained for both DL frameworks, however, this dissertation suggests that there is still room for further improvements. Enriching the dataset with more data from different patient, data balancing and feature extraction techniques, experimenting new models’ architectures should be considered in future works.",
    "similarity": 0.3002564198547578
  },
  {
    "text1": "The growth of concepts such as Intelligent Environments and Internet of things allows us to understand the habits of users and consequently act to improve people’s daily lives. Through information gathering, it is thus possible to gather patterns about different kinds of human behavior and consequently build a learning model with predictive capabilities. In addition, there are increasing concerns from large companies about the influence, positive or negative, that aspects such as comfort and well-being have on the behavior and health of the population. In fact, as human beings, we are greatly influenced by the environment in which we are inserted. There are therefore conditions in a place that give us certain levels of comfort that will eventually interfere with our well-being. However, it is difficult to identify which of these factors are relevant and how they intervene in our daily lives. Also, the habits we adopt as a result of the routines we follow can contribute to improving or worsening any of these indicators With the help of the various types of sensors present, for example, in the smart devices (smartphones, smartwatches, wristbands), it is increasingly possible to collect information on these factors, easily and comprehensively. In this sense, firstly the main objective of this dissertation is thus to collect data on factors that may influence the user in order to create a user profile. These factors can be inferred through its interests, the visited locations, and its main activities. This objective involves a large-scale analysis, where there are no geographical restrictions. Furthermore, the study will be independent of the type of space (open or closed) that is explored. In that way, the perspective that will be used is from the user. Then there is an exploration of the data so that some intelligence can be inferred, and in this sense, build a mobile application capable of providing smart notifications based on user needs.",
    "text2": "File systems are widely used for storing digital information, as they offer abstractions thatallow data to be intuitively separated and organized through files and directories, accordingto the requirements of applications and users. The continuous growth of data volume andcomplexity leads to the constant evolution of these systems. However, the complexity ofintegration of new features and lack of continuous support, leads to many file systems notbeing adopted in practice.In this sense, stackable file systems have emerged, which allow the development of complexfile systems, providing existing systems with new functionalities through independentprocessing layers. Despite this, the development of these systems presents some challenges,namely in terms of speed of implementation, portability, and resilience, since they aredeveloped in kernel. In this way, later solutions emerged that allowed the development offile systems in user space, thus mitigating some of the problems identified in the developmentof this type of file systems. However, these solutions have not been properly explored in thedevelopment of remote file systems.Therefore, this dissertation presents RSafeFS, a platform that extends the SafeFS system toallow developing modular, flexible and extensible remote file systems in user space. Theproposed solution enables extensible remote file system implementations that adjust to therequirements of different types of applications and storage workloads. It was then necessaryto develop a layer that would allow an RSafeFS instance to operate as a system server, anda communication layer, based on remote procedure calls (RPCs), to allow interoperabilitybetween client and server instances. To demonstrate the ease of integration of new features,taking advantage of the modularity and flexibility of RSafeFS, the developed prototype wasequipped with two layers of caching, namely data and metadata, which aim to improvesystem peformance. The results obtained with this prototype reveal that the file systemsdeveloped through RSafeFS obtain performances comparable to remote storage solutionsbased on FUSE. Furthermore, with the processing layers developed it is possible to adjustthe system to different types of workloads, allowing, for example, to improve systemperformance by 1.5× in certain workloads.",
    "similarity": 0.30137490710087156
  },
  {
    "text1": "The growth of concepts such as Intelligent Environments and Internet of things allows us to understand the habits of users and consequently act to improve people’s daily lives. Through information gathering, it is thus possible to gather patterns about different kinds of human behavior and consequently build a learning model with predictive capabilities. In addition, there are increasing concerns from large companies about the influence, positive or negative, that aspects such as comfort and well-being have on the behavior and health of the population. In fact, as human beings, we are greatly influenced by the environment in which we are inserted. There are therefore conditions in a place that give us certain levels of comfort that will eventually interfere with our well-being. However, it is difficult to identify which of these factors are relevant and how they intervene in our daily lives. Also, the habits we adopt as a result of the routines we follow can contribute to improving or worsening any of these indicators With the help of the various types of sensors present, for example, in the smart devices (smartphones, smartwatches, wristbands), it is increasingly possible to collect information on these factors, easily and comprehensively. In this sense, firstly the main objective of this dissertation is thus to collect data on factors that may influence the user in order to create a user profile. These factors can be inferred through its interests, the visited locations, and its main activities. This objective involves a large-scale analysis, where there are no geographical restrictions. Furthermore, the study will be independent of the type of space (open or closed) that is explored. In that way, the perspective that will be used is from the user. Then there is an exploration of the data so that some intelligence can be inferred, and in this sense, build a mobile application capable of providing smart notifications based on user needs.",
    "text2": "Improving customer experience is crucial in any industry, especially in telecommunications, wherecompetition is a constant factor. Today, all telecommunications companies rely on the massiveamount of data generated daily to get to know the customer, study their behavior, and create neweffective strategies for their business. The information collected may include network information,representing the status of hardware and software components in the network, and the client’s details and calls to support and customer assistance data, which describes problems, consumercomplaints, and all other problem-solving interactions. By combining these mountains of raw datawith data mining and machine learning techniques, companies can find solid patterns or systematicrelationships that represent valuable information, that is, generate knowledge.Within the most varied user experiences, the process of installing new services can be an eventthat raises doubts about their operation, degrade the user experience, or, in extreme cases, lead tomaintenance interventions. Therefore, the use of advanced predictive models that can predict suchoccurrences become vital. With this, the company can anticipate the cases that will be problematicand reduce the number of negative experiences.The main objective of this work is to create a predictive model that, through all the available datahistory, can predict which customers will contact the customer service with problems derived fromthe installation process and have a following maintenance intervention.After analyzing an imbalanced dataset with approximately 560K entries from a Portuguese telecommunications company, and resorting to the CRISP-DM methodology for modeling, the best resultswere found with LightGBM, which obtained an AUPRC of 0.11 and AUROC of 0.62. The best tradeoff between precision and recall was found with a threshold model of 0.43 in order to maximizerecall while still avoiding a large number of false negatives. The strategies explored in this work andthe challenges found may help the company understand which details should improve in its serviceprovision, and which data still need to be investigated in the future.",
    "similarity": 0.30811431660022975
  },
  {
    "text1": "The growth of concepts such as Intelligent Environments and Internet of things allows us to understand the habits of users and consequently act to improve people’s daily lives. Through information gathering, it is thus possible to gather patterns about different kinds of human behavior and consequently build a learning model with predictive capabilities. In addition, there are increasing concerns from large companies about the influence, positive or negative, that aspects such as comfort and well-being have on the behavior and health of the population. In fact, as human beings, we are greatly influenced by the environment in which we are inserted. There are therefore conditions in a place that give us certain levels of comfort that will eventually interfere with our well-being. However, it is difficult to identify which of these factors are relevant and how they intervene in our daily lives. Also, the habits we adopt as a result of the routines we follow can contribute to improving or worsening any of these indicators With the help of the various types of sensors present, for example, in the smart devices (smartphones, smartwatches, wristbands), it is increasingly possible to collect information on these factors, easily and comprehensively. In this sense, firstly the main objective of this dissertation is thus to collect data on factors that may influence the user in order to create a user profile. These factors can be inferred through its interests, the visited locations, and its main activities. This objective involves a large-scale analysis, where there are no geographical restrictions. Furthermore, the study will be independent of the type of space (open or closed) that is explored. In that way, the perspective that will be used is from the user. Then there is an exploration of the data so that some intelligence can be inferred, and in this sense, build a mobile application capable of providing smart notifications based on user needs.",
    "text2": "Domotics represent a field of consumer electronics related primarily to home automation.Although smart environments have existed for decades and even for longer in the imaginaryof people and sci-fi, the new age of Internet of Things (IoT) and the low-cost Do ItYourself (DIY) electronics/maker market has brought smart homes and the understandingof domotics closer to everyone.In recent years, the interest in the fields of domotics and IoT has increased. This recent academicand industrial interest has contributed to the evolution of the Smart Home concept,being more and more appealing to our civilization. This has prompted new commercial solutionson the market, which are discovering ways to expand and increase their own valueby integrating new features, especially from the IoT market.The proliferation of IoT devices leads to new sources of information. In addition, the relationbetween the environment occupant and the environment is responsible for addingvalue to this data. Afterwards, the data can then be used in a meaningful way, by machinelearning algorithms to learn usage patterns. Furthermore, this data may or may beunrelated to the data incoming from sensors.This Masters Project will focus on learning strategies to allow Smart Homes to becomeintelligent, in a sense that they anticipate needs and actions, thus enabling extended featuresto the home automation system. The user should be able to give feedback on his ”feeling”regarding the decision making and suggestions, possible by our system implementation.",
    "similarity": 0.30378690629011557
  },
  {
    "text1": "The growth of concepts such as Intelligent Environments and Internet of things allows us to understand the habits of users and consequently act to improve people’s daily lives. Through information gathering, it is thus possible to gather patterns about different kinds of human behavior and consequently build a learning model with predictive capabilities. In addition, there are increasing concerns from large companies about the influence, positive or negative, that aspects such as comfort and well-being have on the behavior and health of the population. In fact, as human beings, we are greatly influenced by the environment in which we are inserted. There are therefore conditions in a place that give us certain levels of comfort that will eventually interfere with our well-being. However, it is difficult to identify which of these factors are relevant and how they intervene in our daily lives. Also, the habits we adopt as a result of the routines we follow can contribute to improving or worsening any of these indicators With the help of the various types of sensors present, for example, in the smart devices (smartphones, smartwatches, wristbands), it is increasingly possible to collect information on these factors, easily and comprehensively. In this sense, firstly the main objective of this dissertation is thus to collect data on factors that may influence the user in order to create a user profile. These factors can be inferred through its interests, the visited locations, and its main activities. This objective involves a large-scale analysis, where there are no geographical restrictions. Furthermore, the study will be independent of the type of space (open or closed) that is explored. In that way, the perspective that will be used is from the user. Then there is an exploration of the data so that some intelligence can be inferred, and in this sense, build a mobile application capable of providing smart notifications based on user needs.",
    "text2": "Neurodegenerative diseases impair the functioning of the brain and are characterized by alterations in the morphology of specific brain regions. Some of the main disorders include Alzheimer's, Parkinson's, and Huntington's diseases, and the number of cases increases exponentially since ageing is one of the main risk factors. Trying to identify the areas in which this type of disease appears is something that can have a very positive impact in this area of Medicine and can guarantee a more appropriate treatment or allow the improvement of the quality of life of patients. With the current technological advances, computer tools are capable of performing a structural or functional analysis of neuroimaging data from Magnetic Resonance Images(MRI). Therefore, Medical Informatics uses these techniques to create and manage medical neuroimaging data to improve the diagnosis and management of these patients. MRI is the image type used in the analysis of the brain area and points to a promising and reliable diagnostic tool since it allows high-quality images in various planes or strategies and MRI methods are fundamental diagnostic tools in clinical practice, allowing the diagnosis of pathologic processes such as stroke or brain tumours. However, structural MRI has limitations for the diagnosis of neurodegenerative disorders since it mainly identifies atrophy of brain regions.Currently, there is increased interest in informatics applications capable of monitoring and quantifying human brain imaging alterations, with potential for neurodegenerative disorders diagnosis and monitoring. One of these applications is Radiomics, which corresponds to a methodolog ythat allows the extraction of features from images of a given region of the brain. Specific quantitative metrics from MRI are acquired by this tool, and they correspond to a set of features, including texture, shape, among others. To standardize Radiomics application, specific libraries have been proposed to be used by the bioinformatics and biomedical communities, such as PyRadiomics, which corresponds to an open source Python package for extracting Radiomics of MRIs.Therefore, this dissertation was developed based on magnetic resonance images and the study of DeepLearning (DL) techniques to assist researchers and neuroradiologists in the diagnosis and prediction of neurodegenerative disease development. Two different main tasks were made: first, a segmentation, using FreeSurfer, of different regions of the brain and then, a model was build from radiomic features extracted from each part of the brain and interpreted for knowledge extraction.",
    "similarity": 0.30397588398240183
  },
  {
    "text1": "Recent evolution of high performance computing moved towards heterogeneous platforms:multiple devices with different architectures, characteristics and programming models, shareapplication workloads. To aid the programmer to efficiently explore these heterogeneousplatforms several frameworks have been under development. These dynamically manage theavailable computing resources through workload scheduling and data distribution, dealingwith the inherent difficulties of different programming models and memory accesses. Amongother frameworks, these include GAMA and StarPU.The GAMA framework aims to unify the multiple execution and memory models ofeach different device in a computer system, into a single, hardware agnostic model. It wasdesigned to efficiently manage resources with both regular and irregular applications, andcurrently only supports conventional CPU devices and CUDA-enabled accelerators. StarPUhas similar goals and features with a wider user based community, but it lacks a singleprogramming model.The main goal of this dissertation was an in-depth evaluation of a heterogeneous frameworkusing a complex application as a case study. GAMA provided the starting vehiclefor training, while StarPU was the selected framework for a thorough evaluation. The progressivephoton mapping irregular algorithm was the selected case study. The evaluationgoal was to assert the StarPU effectiveness with a robust irregular application, and make ahigh-level comparison with the still under development GAMA, to provide some guidelinesfor GAMA improvement.Results show that two main factors contribute to the performance of applications writtenwith StarPU: the consideration of data transfers in the performance model, and chosenscheduler. The study also allowed some caveats to be found within the StarPU API. Althoughthis have no effect on performance, they present a challenge for new coming developers.Both these analysis resulted in a better understanding of the framework, and a comparativeanalysis with GAMA could be made, pointing out the aspects where GAMA could be furtherimproved upon.",
    "text2": "In the last years, the widespread of Cloud computing as the main paradigm to deliver a largeplethora of virtualized services significantly increased the complexity of Datacenters managementand raised new performance issues for the intra-Datacenter network. Providing heterogeneousservices and satisfying users’ experience is really challenging for Cloud service providers,since system (IT resources) and network administration functions are definitely separated.As the Software Defined Networking (SDN) approach seems to be a promising way to addressinnovation in Datacenters, the thesis presents a new framework that allows to develop andtest new OpenFlow–based controllers for Cloud Datacenters. More specifically, the frameworkenhances both Mininet (a well–known SDN emulator) and POX (a Openflow controller writtenin python), with all the extensions necessary to experiment novel control and managementstrategies of IT and network resources.Further more, the framework was validated by implementing and testing well known policies.Hybrid allocation policies (considering both network and servers) were also implemented andscalability tests were performed.This work was developed under the ERASMUS student mobility program, in the TelecommunicationNetworks Research Group, Dept. of Information Engineering, University of Pisa,and resulted in the paper Datacenter in a box: test your SDN cloud-datacenter controller athome that was accepted into EWSDN2013.",
    "similarity": 0.3029945340324495
  },
  {
    "text1": "Recent evolution of high performance computing moved towards heterogeneous platforms:multiple devices with different architectures, characteristics and programming models, shareapplication workloads. To aid the programmer to efficiently explore these heterogeneousplatforms several frameworks have been under development. These dynamically manage theavailable computing resources through workload scheduling and data distribution, dealingwith the inherent difficulties of different programming models and memory accesses. Amongother frameworks, these include GAMA and StarPU.The GAMA framework aims to unify the multiple execution and memory models ofeach different device in a computer system, into a single, hardware agnostic model. It wasdesigned to efficiently manage resources with both regular and irregular applications, andcurrently only supports conventional CPU devices and CUDA-enabled accelerators. StarPUhas similar goals and features with a wider user based community, but it lacks a singleprogramming model.The main goal of this dissertation was an in-depth evaluation of a heterogeneous frameworkusing a complex application as a case study. GAMA provided the starting vehiclefor training, while StarPU was the selected framework for a thorough evaluation. The progressivephoton mapping irregular algorithm was the selected case study. The evaluationgoal was to assert the StarPU effectiveness with a robust irregular application, and make ahigh-level comparison with the still under development GAMA, to provide some guidelinesfor GAMA improvement.Results show that two main factors contribute to the performance of applications writtenwith StarPU: the consideration of data transfers in the performance model, and chosenscheduler. The study also allowed some caveats to be found within the StarPU API. Althoughthis have no effect on performance, they present a challenge for new coming developers.Both these analysis resulted in a better understanding of the framework, and a comparativeanalysis with GAMA could be made, pointing out the aspects where GAMA could be furtherimproved upon.",
    "text2": "On a business context, it is responsibility of the Software Product Support Team analyze and solve, if necessary, problems that may arise on software products. Sometimes, the reported problems are not a real defect, i.e., sometimes the client does not have a full understanding about all features of the software product. The team must evaluate and analyze all the Problem Reports that arrive every day. As products are spread across different customers, it is normal to have Problem Reports that are very similar to others that have already been solved for other clients and/or by another member of the Support Team. This dissertation proposes the development of a system that is able to analyze a Problem Report and then provide past problems that are similar to the one being analyzed. An artificial intelligence technique, named Case-Based Reasoning, will be used to achieve such goals. Existent Case-Based Reasoning systems are neither complete nor adaptable to specific domains since the effort to adapt either the reasoning process or the knowledge representation mechanism, to a new domain, is too high. To address such drawbacks, a generic reasoning component will be designed and developed. This dissertation introduces a new approach to the typical Case-Based Reasoning cycle where is possible to handle default, unknown and incomplete data.",
    "similarity": 0.30714594875346257
  },
  {
    "text1": "Recent evolution of high performance computing moved towards heterogeneous platforms:multiple devices with different architectures, characteristics and programming models, shareapplication workloads. To aid the programmer to efficiently explore these heterogeneousplatforms several frameworks have been under development. These dynamically manage theavailable computing resources through workload scheduling and data distribution, dealingwith the inherent difficulties of different programming models and memory accesses. Amongother frameworks, these include GAMA and StarPU.The GAMA framework aims to unify the multiple execution and memory models ofeach different device in a computer system, into a single, hardware agnostic model. It wasdesigned to efficiently manage resources with both regular and irregular applications, andcurrently only supports conventional CPU devices and CUDA-enabled accelerators. StarPUhas similar goals and features with a wider user based community, but it lacks a singleprogramming model.The main goal of this dissertation was an in-depth evaluation of a heterogeneous frameworkusing a complex application as a case study. GAMA provided the starting vehiclefor training, while StarPU was the selected framework for a thorough evaluation. The progressivephoton mapping irregular algorithm was the selected case study. The evaluationgoal was to assert the StarPU effectiveness with a robust irregular application, and make ahigh-level comparison with the still under development GAMA, to provide some guidelinesfor GAMA improvement.Results show that two main factors contribute to the performance of applications writtenwith StarPU: the consideration of data transfers in the performance model, and chosenscheduler. The study also allowed some caveats to be found within the StarPU API. Althoughthis have no effect on performance, they present a challenge for new coming developers.Both these analysis resulted in a better understanding of the framework, and a comparativeanalysis with GAMA could be made, pointing out the aspects where GAMA could be furtherimproved upon.",
    "text2": "Every program starts from a model, an abstraction, which is iteratively re ned until we reach the nal result, the implementation. However, at the end, one must ask: does the nal program resemblein anyway the original model? Was the original idea correct to begin with? Formal methodsguarantee that those questions are answered positively, resorting to mathematical techniques. Inparticular, in this thesis we are interested on the second factor: veri cation of formal models.A trend of formal methods defends that they should be lightweight, resulting in a reducedcomplexity of the speci cation, and automated analysis. Alloy was proposed as a solution for thisproblem. In Alloy, the structures are described using a simple mathematical notation: relationallogic. A tool for model checking, automatic veri cation within a given scope, is also provided.However, sometimes model checking is not enough and the need arises to perform unboundedveri cations. The only way to do this is to mathematically prove that the speci cations are correct.As such, there is the need to nd a mathematical logic expressive enough to be able to representthe speci cations, while still being su ciently understandable.We see the point-free style, a style where there are no variables or quanti cations, as a kindof Laplace transform, where complex problems are made simple. Being Alloy completely relational,we believe that a point-free relational logic is the natural framework to reason about Alloyspeci cations.Our goal is to present a translation from Alloy speci cations to a point-free relational calculus,which can then be mathematically proven, either resorting to proof assistants or to manual proving.Since our motivation for the use of point-free is simplicity, we will focus on obtaining expressionsthat are simple enough for manipulation and proofs about them.",
    "similarity": 0.3107464384645825
  },
  {
    "text1": "Nowadays, companies live in a scenario of strong competitiveness. The telecommunicationsmarket is not an exception and it is possible to offer a differentiation from competition throughbetter service quality, differentiated support and even better value proposals. With the evolution oftechnologies, companies have more data about their customers and the usage profile of each oneof them. With this information it is possible to establish a better relationship with the customerthrough a more efficient support service.The evolution of artificial intelligence and computational power, combined with existing data, al lows for several comparisons between different machine learning algorithms. In this dissertation,a prediction model capable of predicting recurrences of contacts with the customer service is pro posed. The aim is to predict whether a particular problem reported by the customer will repeat andrequire a new contact, so that it is possible to correct those problems in advance, making the userexperience more pleasant and fluid. In order to achieve the best possible model, different classicalmachine learning approaches were tested, along with several deep neural network architectures.In recent years, deep neural networks have shown interesting results in several non-tabular appli cations, therefore being interesting to test them in tabular applications like the one present in thiswork. TabNet, developed by Google, is a deep neural network adjusted to perform the better in tabu lar datasets, and was also tested, as it has shown better performance than several neural networksor decision-tree bases algorithms.The used data were collected by various internal systems, the most important of which being theone related to customer support calls. The customer service, due to its size and complexity, has asystem that monitors all calls and their motivations, as well as the parties involved (both operatorand customer) and other additional data such as time spent and the call outcome. Data from othersystems is related to billing, service usage and customer profile, and is added to help to understandthe context of the call.The model that shown the best results was CatBoost, a decision trees based algorithm, showingan AUC_ROC of 79%, with a Recall of 61% and a Precision of 62%, allowing the identification of about8,6% of the 3.9 million calls made to the support service as recurrences even before they occur,about 340k cases. In an ideal scenario, all these calls would be avoided, allowing a substantial costreduction for the company, as well as a consequent increase in customer satisfaction in relation tothe service.The CatBoost model showed better training times and less memory needs, while achieving a better performance than the different architectures of deep neural networks proposed. Only TabNetwas able to achieve a similar performance, while maintaining a higher training time. However, infutures uses, where the CatBoost model achieves a plateau and is not benefiting for the increasingdata, it could be useful to use TabNet as the model in production. TabNet has the advantage of beinga neural network and, for that reason, being more capable of breaking the plateau that classicalmodels often achieve.",
    "text2": "The introduction of Machine Learning (ML) on the orbit of the resolution of problemstypically associated within the human behaviour has brought great expectations tothe future. In fact, the possible development of machines capable of learning, in asimilar way as of the humans, could bring grand perspectives to diverse areas likehealthcare, the banking sector, retail, and any other area in which we could avoid theconstant attention of a person dedicated to the solving of a problem; furthermore, thereare those problems that are still not at the hands of humans to solve - these are nowat the disposal of intelligent machines, bringing new possibilities to the humankinddevelopment.ML algorithms, specifically Deep Learning (DL) methods, lack a bigger acceptance bypart of the community, even though they are present in various systems in our dailybasis. This lack of confidence, mandatory to let systems make big, important decisionswith great impact in the everyday life is due to the difficulty on understanding thelearning mechanisms and previsions that result by the same - some algorithms representthemselves as ”black boxes”, translating an input into an output, while not being totallytransparent to the outside. Another complication rises, when it is taken into accountthat the same algorithms are trained to a specific task and in accordance to the trainingcases found on their development, being more susceptible to error in a real environment- one can argue that they do not constitute a true Artificial Intelligence (AI).Following this line of thought, this dissertation aims at studying a new theory,Hierarchical Temporal Memory (HTM), that can be placed in the area of MachineIntelligence (MI), an area that studies the capacity of how the software systems canlearn, in an identical way to the learning of a human being. The HTM is still a freshtheory, that lays on the present perception of the functioning of the human neocortexand assumes itself as under constant development; at the moment, the theory dictatesthat the neocortex zones are organized in an hierarchical structure, being a memorysystem, capable of recognizing spatial and temporal patterns. In the course of thisproject, an analysis was made to the functioning of the theory and its applicabilityto the various tasks typically solved with ML algorithms, like image classification, sound recognition and time series forecasting. At the end of this dissertation, after theevaluation of the different results obtained in various approaches, it was possible toconclude that even though these results were positive, the theory still needs to mature,not only in its theoretical basis but also in the development of libraries and frameworksof software, to capture the attention of the AI community.",
    "similarity": 0.3115094479620103
  },
  {
    "text1": "Nowadays, companies live in a scenario of strong competitiveness. The telecommunicationsmarket is not an exception and it is possible to offer a differentiation from competition throughbetter service quality, differentiated support and even better value proposals. With the evolution oftechnologies, companies have more data about their customers and the usage profile of each oneof them. With this information it is possible to establish a better relationship with the customerthrough a more efficient support service.The evolution of artificial intelligence and computational power, combined with existing data, al lows for several comparisons between different machine learning algorithms. In this dissertation,a prediction model capable of predicting recurrences of contacts with the customer service is pro posed. The aim is to predict whether a particular problem reported by the customer will repeat andrequire a new contact, so that it is possible to correct those problems in advance, making the userexperience more pleasant and fluid. In order to achieve the best possible model, different classicalmachine learning approaches were tested, along with several deep neural network architectures.In recent years, deep neural networks have shown interesting results in several non-tabular appli cations, therefore being interesting to test them in tabular applications like the one present in thiswork. TabNet, developed by Google, is a deep neural network adjusted to perform the better in tabu lar datasets, and was also tested, as it has shown better performance than several neural networksor decision-tree bases algorithms.The used data were collected by various internal systems, the most important of which being theone related to customer support calls. The customer service, due to its size and complexity, has asystem that monitors all calls and their motivations, as well as the parties involved (both operatorand customer) and other additional data such as time spent and the call outcome. Data from othersystems is related to billing, service usage and customer profile, and is added to help to understandthe context of the call.The model that shown the best results was CatBoost, a decision trees based algorithm, showingan AUC_ROC of 79%, with a Recall of 61% and a Precision of 62%, allowing the identification of about8,6% of the 3.9 million calls made to the support service as recurrences even before they occur,about 340k cases. In an ideal scenario, all these calls would be avoided, allowing a substantial costreduction for the company, as well as a consequent increase in customer satisfaction in relation tothe service.The CatBoost model showed better training times and less memory needs, while achieving a better performance than the different architectures of deep neural networks proposed. Only TabNetwas able to achieve a similar performance, while maintaining a higher training time. However, infutures uses, where the CatBoost model achieves a plateau and is not benefiting for the increasingdata, it could be useful to use TabNet as the model in production. TabNet has the advantage of beinga neural network and, for that reason, being more capable of breaking the plateau that classicalmodels often achieve.",
    "text2": "Achieving great and undeniable success in a great variety of industries and businesses has made the term Big Data very popular among the scientific community. Big Data (BD) refers to the ever fast-growing research area in Computer Science (CS) that comprises many work areas across the world. The healthcare sector is widely known to be highly proficient inthe production of big quantities of data. It can go from health information, such as thepatient’s blood pressure and cholesterol levels, to more private and sensitive data, such asthe medical procedures history or the report of ongoing diseases.The application of sophisticated techniques enables a profound and rigorous analysis ofdata, something a human cannot do in real-time. However, a machine is capable of rapidlycollect, group, storage and examine vast amounts of data and extract unknown and possi bly interesting knowledge from it. The algorithms used can discover hidden relationshipsbetween attributes that prove to be very useful for a corporation’s work. Buried structureswithin the produced data can also be detected by these techniques. Machine Learning (ML)methods can be adjusted and modelled to different input representations - this adaptabilityis one of the factors that contributes to its blooming prosperity.The main goal is to make predictions on data, by building utterly efficient models that canaccurately take in the data and thus predict a certain outcome. This is especially importantto the healthcare industry since it can considerably improve the lives of many patients.Everything from detecting a type of disease, predicting the chance of morbidity after ahospital stay, to aid in the decision making of treatment strategies are vital to patients aswell as to clinicians.Any improvement over established methods that have been previously studied, testedand published are an asset that will improve the patient’s satisfaction about the healthcareperformance in medical institutions. This can be achieved by refining those algorithms orimplementing new approaches that will make better predictions on the given data.The main objective of this dissertation is to propose ML approaches having acknowledged and evaluated the existent methods used in clinical data. In order to fulfill this goal,an analysis of the state of the art of medical knowledge repositories and scientific paperspublished related to the selected keywords selected was performed. In this line of work,it is crucial to understand, compare and discuss the results obtained to those previouslypublished. Thus, one of the goals is to suggest new ways of solving those problems andmeasuring them up against the existent ones.",
    "similarity": 0.3073877127028097
  },
  {
    "text1": "Nowadays, companies live in a scenario of strong competitiveness. The telecommunicationsmarket is not an exception and it is possible to offer a differentiation from competition throughbetter service quality, differentiated support and even better value proposals. With the evolution oftechnologies, companies have more data about their customers and the usage profile of each oneof them. With this information it is possible to establish a better relationship with the customerthrough a more efficient support service.The evolution of artificial intelligence and computational power, combined with existing data, al lows for several comparisons between different machine learning algorithms. In this dissertation,a prediction model capable of predicting recurrences of contacts with the customer service is pro posed. The aim is to predict whether a particular problem reported by the customer will repeat andrequire a new contact, so that it is possible to correct those problems in advance, making the userexperience more pleasant and fluid. In order to achieve the best possible model, different classicalmachine learning approaches were tested, along with several deep neural network architectures.In recent years, deep neural networks have shown interesting results in several non-tabular appli cations, therefore being interesting to test them in tabular applications like the one present in thiswork. TabNet, developed by Google, is a deep neural network adjusted to perform the better in tabu lar datasets, and was also tested, as it has shown better performance than several neural networksor decision-tree bases algorithms.The used data were collected by various internal systems, the most important of which being theone related to customer support calls. The customer service, due to its size and complexity, has asystem that monitors all calls and their motivations, as well as the parties involved (both operatorand customer) and other additional data such as time spent and the call outcome. Data from othersystems is related to billing, service usage and customer profile, and is added to help to understandthe context of the call.The model that shown the best results was CatBoost, a decision trees based algorithm, showingan AUC_ROC of 79%, with a Recall of 61% and a Precision of 62%, allowing the identification of about8,6% of the 3.9 million calls made to the support service as recurrences even before they occur,about 340k cases. In an ideal scenario, all these calls would be avoided, allowing a substantial costreduction for the company, as well as a consequent increase in customer satisfaction in relation tothe service.The CatBoost model showed better training times and less memory needs, while achieving a better performance than the different architectures of deep neural networks proposed. Only TabNetwas able to achieve a similar performance, while maintaining a higher training time. However, infutures uses, where the CatBoost model achieves a plateau and is not benefiting for the increasingdata, it could be useful to use TabNet as the model in production. TabNet has the advantage of beinga neural network and, for that reason, being more capable of breaking the plateau that classicalmodels often achieve.",
    "text2": "There always have been a huge interest in working with public data from online socialmedia users, with the exponential growth of social media usage, this interest and re searches on the area keep increasing.This thesis aims to address prediction and classification tasks on online social net work data. The goal is to predict psycho-demographic - personality and demographic -traits by doing text emotion analysis on social networks as Twitter and Facebook. Ourmain motivation was to raise awareness to what can be done with users’ social mediaor network information or usual behaviours on the web, such as from text analysiswe can trace their personality, know their tastes, how they behave and so on, and tospread the emotion-text relation on social networks subject, because it only started tobe studied recently and there’s so much data and information to do it.To perform these tasks mentioned above we carried an extensive review of literatureof previous works to define the state-of-art of the project and to learn and identify workstrategies. Almost all of the past researches, based their results on a vast sample ofusers and data, but because some frameworks and APIs were shutdown in recent years,such as MyPersonality from Facebook adding to some frameworks being paid for,resulted in a small sample of users’ data to analyze in our thesis which can prejudicethe results.We start by gathering data from Twitter and Facebook with users consent. On Twit ter we focused on tweets and retweets, on Facebook we focused on all of what theuser typed by using the DataSelfie plugin that stored all that data on a server thatcan be retrieved later. Our next step was to find emotions on their text data with thehelp of a lexicon that categorized words by eight different emotions, two of them wereput away because we focused only on the six major emotions - this is explained later- and we had to remove stopwords and apply stemming to all of the text and do aword-matching of every word of our data with every word from the lexicon. Afterthis, we asked our participants to fulfill a \"Big-Five\" personality questionnaire and toprovide us their age, so we added the Big-Five traits and age to each users individualdataset. We got their final versions, ready to apply machine-learning algorithms tofind correlations between emotions and personality or demographic attributes. Wefocused on practical and methodological aspects of the user attribute prediction task.We used many techniques and algorithms that we thought it were best fit for the datawe had and for the goal that we had to achieve.We gathered data in two datasets that we tested, one of them we called \"Mixed Lan guage Dataset\", contains all text entries from each user, and the other \"User Dataset\",contains one entry per user after we analyze every text entry for all users in order tohave a more general view on each one. For the first mentioned dataset we achievebest results with the decision trees algorithms, from 58% on the agreeableness trait,to 68% on the neuroticism trait. This dataset had a problem with the way data wasspread, so it was impossible to predict age and gender with efficiency. As for the lat ter, regarding demographic characteristics all of the classifiers had a good classifyingpercentage, from K-nearest’s 73% to Naive Bayes’ 95%. The most solid classifier forpersonality traits was the one using the CART decision tree algorithm, it ranged from50% on the openness trait to 76% on the agreeableness one. There were classifiers withterrible results, there were others that were a bit dull, and there were some that stoodout as we stated above. We had a small sample, and that was a problem as it wasn’tconsistent or solid in terms of data value and that can change our results, we believethat our results would be way better if we applied the same mechanisms to a muchbigger sample.Concluding, we demonstrate how we can predict personality or demographic traits- BigFive traits, age or gender - from studying emotions in text. As stated above, wehope this thesis will alert people for what can be done with their online information,we only focus on psycho-demographic profiling, but there are many other things thatcan be done.",
    "similarity": 0.31050034626038786
  },
  {
    "text1": "Nowadays, companies live in a scenario of strong competitiveness. The telecommunicationsmarket is not an exception and it is possible to offer a differentiation from competition throughbetter service quality, differentiated support and even better value proposals. With the evolution oftechnologies, companies have more data about their customers and the usage profile of each oneof them. With this information it is possible to establish a better relationship with the customerthrough a more efficient support service.The evolution of artificial intelligence and computational power, combined with existing data, al lows for several comparisons between different machine learning algorithms. In this dissertation,a prediction model capable of predicting recurrences of contacts with the customer service is pro posed. The aim is to predict whether a particular problem reported by the customer will repeat andrequire a new contact, so that it is possible to correct those problems in advance, making the userexperience more pleasant and fluid. In order to achieve the best possible model, different classicalmachine learning approaches were tested, along with several deep neural network architectures.In recent years, deep neural networks have shown interesting results in several non-tabular appli cations, therefore being interesting to test them in tabular applications like the one present in thiswork. TabNet, developed by Google, is a deep neural network adjusted to perform the better in tabu lar datasets, and was also tested, as it has shown better performance than several neural networksor decision-tree bases algorithms.The used data were collected by various internal systems, the most important of which being theone related to customer support calls. The customer service, due to its size and complexity, has asystem that monitors all calls and their motivations, as well as the parties involved (both operatorand customer) and other additional data such as time spent and the call outcome. Data from othersystems is related to billing, service usage and customer profile, and is added to help to understandthe context of the call.The model that shown the best results was CatBoost, a decision trees based algorithm, showingan AUC_ROC of 79%, with a Recall of 61% and a Precision of 62%, allowing the identification of about8,6% of the 3.9 million calls made to the support service as recurrences even before they occur,about 340k cases. In an ideal scenario, all these calls would be avoided, allowing a substantial costreduction for the company, as well as a consequent increase in customer satisfaction in relation tothe service.The CatBoost model showed better training times and less memory needs, while achieving a better performance than the different architectures of deep neural networks proposed. Only TabNetwas able to achieve a similar performance, while maintaining a higher training time. However, infutures uses, where the CatBoost model achieves a plateau and is not benefiting for the increasingdata, it could be useful to use TabNet as the model in production. TabNet has the advantage of beinga neural network and, for that reason, being more capable of breaking the plateau that classicalmodels often achieve.",
    "text2": "In traffic environments, road signs have a key role to control, warn, and command or prohibitthe driver of certain actions. Traffic sign maintenance is essential to prevent negativeevents. In order for these traffic signs to play the role they were designed for, periodic onsiteinspections are essential and followed out to determine if signs are in good conditionand visible, both during the day and night. However, periodic inspections are time and costconsuming.Another issue is related to the drivers’ awareness to the traffic signs on the road. Manyfactors, both internal and external to the driver, may potentially contribute to him missing asign. Given the purpose of this dissertation, we will focus primarily on the external factorssuch as the sign being damaged or occluded, or distractions caused by the many gadgetsinside the vehicle. Due to all these extraneous influences, a traffic sign recognition systemmay help the driver to respect these signs and increase significantly their safety, as well asthe others around them.Some high-end vehicles already have such a warning system, at least for danger signs.However, drivers with these vehicles represent a small fraction of the total driving force.This dissertation aims at bringing such a system to a much broader audience.Smartphones are one of the most used devices by society today, mostly due to the manyfunctionalities they provide in day to day life and their relative accessible monetary value.The increased computational power and cameras’ quality improvement of these devicesover the years make them good candidates to support the access to this kind of technologyto all. In other words, smartphones of this day and age have the necessary resources to beused as instruments for sign recognition.Hence, we propose a dual purpose community based approach. On the one hand, eachdriver can use his mobile device to detect, recognize and geolocate traffic signs, contributingto the traffic sign central repository. Detection is performed using Cascade Classifiers,while a Convolutional Neural Network supports the recognition phase. The repository,based on the information received from the clients, can be used to provide sign statusreports and to enable more direct and timely inspection instead of relying on prescheduledglobal inspections. On the other hand, drivers would have access to the database of trafficsigns, therefore being able to receive real-time notifications regarding traffic signs such asspeed limit signs, school proximity, or road construction signs. Hence, allowing the systemto perform its function even if the recognition phase is not active when used in a lowcomputational power device.",
    "similarity": 0.30694252077562323
  },
  {
    "text1": "Nowadays, companies live in a scenario of strong competitiveness. The telecommunicationsmarket is not an exception and it is possible to offer a differentiation from competition throughbetter service quality, differentiated support and even better value proposals. With the evolution oftechnologies, companies have more data about their customers and the usage profile of each oneof them. With this information it is possible to establish a better relationship with the customerthrough a more efficient support service.The evolution of artificial intelligence and computational power, combined with existing data, al lows for several comparisons between different machine learning algorithms. In this dissertation,a prediction model capable of predicting recurrences of contacts with the customer service is pro posed. The aim is to predict whether a particular problem reported by the customer will repeat andrequire a new contact, so that it is possible to correct those problems in advance, making the userexperience more pleasant and fluid. In order to achieve the best possible model, different classicalmachine learning approaches were tested, along with several deep neural network architectures.In recent years, deep neural networks have shown interesting results in several non-tabular appli cations, therefore being interesting to test them in tabular applications like the one present in thiswork. TabNet, developed by Google, is a deep neural network adjusted to perform the better in tabu lar datasets, and was also tested, as it has shown better performance than several neural networksor decision-tree bases algorithms.The used data were collected by various internal systems, the most important of which being theone related to customer support calls. The customer service, due to its size and complexity, has asystem that monitors all calls and their motivations, as well as the parties involved (both operatorand customer) and other additional data such as time spent and the call outcome. Data from othersystems is related to billing, service usage and customer profile, and is added to help to understandthe context of the call.The model that shown the best results was CatBoost, a decision trees based algorithm, showingan AUC_ROC of 79%, with a Recall of 61% and a Precision of 62%, allowing the identification of about8,6% of the 3.9 million calls made to the support service as recurrences even before they occur,about 340k cases. In an ideal scenario, all these calls would be avoided, allowing a substantial costreduction for the company, as well as a consequent increase in customer satisfaction in relation tothe service.The CatBoost model showed better training times and less memory needs, while achieving a better performance than the different architectures of deep neural networks proposed. Only TabNetwas able to achieve a similar performance, while maintaining a higher training time. However, infutures uses, where the CatBoost model achieves a plateau and is not benefiting for the increasingdata, it could be useful to use TabNet as the model in production. TabNet has the advantage of beinga neural network and, for that reason, being more capable of breaking the plateau that classicalmodels often achieve.",
    "text2": "Nowadays the success of a business is dependent on the ability to effectively integrate in an intricatenetwork of entities that are connected by material and information flows, inventory management beingone of the main concerns. These flows are characterized by decision-making processes that will varydepending on the environment, entities and business models in the network. So, these networks needa decision-making system capable of providing solutions that dictate the optimal way the network and itsentities provide and collect inventory in order to reduce costs and maximize profit. In the context of thisdissertation, the problem arises when there is a stock disruption in the network and outside entities can nolonger answer the stores’ supply requests and these stores become the entities responsible for requesting and delivering products to each other. This problem is modeled as an Inventory Routing problem,since it encompasses inventory management and routing decisions. The main goal of the system can bedescribed as maximizing the collection of products per travel distance, without causing stock-outs at anysupplier, for the entire network. The problem at hand is an optimization problem.In order to solve this optimization problem, first, the structural characteristics and key aspects were identified and studied, followed by the mathematical conceptualization, which involved the definition of theobjective function and the corresponding set of constraints. The mathematical formulation allows theproblem to be translated into a specific and precise mathematical language, making it possible to evaluatesolutions, by means of a fitness function, and apply optimization algorithms to solve the problem. Theseoptimization algorithms can be approximate or exact methods and their suitability to the problem dependson many factors such as the size, structure and complexity of the problem. So, the choice of the optimization algorithms must be preceded by a careful analysis of the problem at hand and its characteristics.After this, in the implementation phase, two adaptations of the genetic algorithm, two adaptions of thesimulated annealing algorithm, two adaptations of the tabu search algorithm were developed. Additionaly,another algorithm responsible for generating reference solutions was also developed (Dynamic2). In order to test and compare the developed optimization algorithms, three different sized scenarios were generated.Each of these scenarios has a different amount of data associated with it, whether it be in the number ofstores, types of products or number of requests. As to compare the results of the different instances ofthe algorithms fairly in each scenario, these were made to generate roughly the same number of solutions.In scenarios 1 and 3, all the optimization algorithms developed were successful in finding solutions withhigher fitness values than the baseline Dynamic2 solution. In scenario 2, due to time constraints andcomputational complexities, only the Genetic algorithm and the Genetic algorithm with Elitism using aninitial population consisting of solutions generated by the Dynamic2 algorithm, managed to find solutionswith higher fitness value than the baseline solution. In this scenario, the developed optimization algorithmswere also tested using feasible solutions generated through random mechanisms as initial solutions. Theseinstances also achieve solutions with improved fitness values when compared to their respective initial solutions or populations.Furthermore, in scenarios 1 and 3, the Genetic algorithm with an initial population consisting of feasiblesolutions generated through random mechanisms was the optimization algorithm that found the best solutions, with these solutions having fitness values 56.14% and 92.07% greater than the baseline Dynamic2solution’s, respectively. In scenario 2, the Genetic algorithm with Elitism, utilizing an initial population consisting of solutions generated by the mentioned Dynamic2 algorithm, found the solution with the highestfitness value, being approximately 1.00% higher than the baseline solution.",
    "similarity": 0.30916848041155526
  },
  {
    "text1": "Nowadays, companies live in a scenario of strong competitiveness. The telecommunicationsmarket is not an exception and it is possible to offer a differentiation from competition throughbetter service quality, differentiated support and even better value proposals. With the evolution oftechnologies, companies have more data about their customers and the usage profile of each oneof them. With this information it is possible to establish a better relationship with the customerthrough a more efficient support service.The evolution of artificial intelligence and computational power, combined with existing data, al lows for several comparisons between different machine learning algorithms. In this dissertation,a prediction model capable of predicting recurrences of contacts with the customer service is pro posed. The aim is to predict whether a particular problem reported by the customer will repeat andrequire a new contact, so that it is possible to correct those problems in advance, making the userexperience more pleasant and fluid. In order to achieve the best possible model, different classicalmachine learning approaches were tested, along with several deep neural network architectures.In recent years, deep neural networks have shown interesting results in several non-tabular appli cations, therefore being interesting to test them in tabular applications like the one present in thiswork. TabNet, developed by Google, is a deep neural network adjusted to perform the better in tabu lar datasets, and was also tested, as it has shown better performance than several neural networksor decision-tree bases algorithms.The used data were collected by various internal systems, the most important of which being theone related to customer support calls. The customer service, due to its size and complexity, has asystem that monitors all calls and their motivations, as well as the parties involved (both operatorand customer) and other additional data such as time spent and the call outcome. Data from othersystems is related to billing, service usage and customer profile, and is added to help to understandthe context of the call.The model that shown the best results was CatBoost, a decision trees based algorithm, showingan AUC_ROC of 79%, with a Recall of 61% and a Precision of 62%, allowing the identification of about8,6% of the 3.9 million calls made to the support service as recurrences even before they occur,about 340k cases. In an ideal scenario, all these calls would be avoided, allowing a substantial costreduction for the company, as well as a consequent increase in customer satisfaction in relation tothe service.The CatBoost model showed better training times and less memory needs, while achieving a better performance than the different architectures of deep neural networks proposed. Only TabNetwas able to achieve a similar performance, while maintaining a higher training time. However, infutures uses, where the CatBoost model achieves a plateau and is not benefiting for the increasingdata, it could be useful to use TabNet as the model in production. TabNet has the advantage of beinga neural network and, for that reason, being more capable of breaking the plateau that classicalmodels often achieve.",
    "text2": "The process of Automatic Speech Recognition (ASR) opens doors to a vast amount of possibleimprovements in customer experience. The use of this type of technology has increasedsignificantly in recent years, this change being the result of the recent evolution in ASRsystems. The opportunities to use ASR are vast, covering several areas, such as medical,industrial, business, among others. We must emphasize the use of these voice recognitionsystems in telecommunications companies, namely, in the automation of consumer assistanceoperators, allowing the service to be routed to specialized operators automatically throughthe detection of matters to be dealt with through recognition of the spoken utterances. Inrecent years, we have seen big technological breakthrough in ASR, achieving unprecedentedaccuracy results that are comparable to humans. We are also seeing a move from whatis known as the Traditional approach of ASR systems, based on Hidden Markov Models(HMM), to the newer End-to-End ASR systems that obtain benefits from the use of deepneural networks (DNNs), large amounts of data and process parallelization.The literature review showed us that the focus of this previous work was almost exclusivelyfor the English and Chinese languages, with little effort being made in the development ofother languages, as it is the case with Portuguese. In the research carried out, we did notfind a model for the European Portuguese (EP) dialect that is freely available for generaluse. Focused on this problem, this work describes the development of a End-to-End ASRsystem for EP. To achieve this goal, a set of procedures was followed that allowed us topresent the concepts, characteristics and all the steps inherent to the construction of thesetypes of systems. Furthermore, since the transcribed speech needed to accomplish our goalis very limited for EP, we also describe the process of collecting and formatting data from avariety of different sources, most of them freely available to the public. To further try andimprove our results, a variety of different data augmentation techniques were implementedand tested. The obtained models are based on a PyTorch implementation of the Deep Speech2 model.Our best model achieved an Word Error Rate (WER) of 40.5%, in our main test corpus,achieving slightly better results to those obtained by commercial systems on the same data.Around 150 hours of transcribed EP was collected, so that it can be used to train other ASRsystems or models in different areas of investigation. We gathered a series of interestingresults on the use of different batch size values as well as the improvements provided bythe use of a large variety of data augmentation techniques. Nevertheless, the ASR theme is vast and there is still a variety of different methods and interesting concepts that we couldresearch in order to seek an improvement of the achieved results.",
    "similarity": 0.3092092896715473
  },
  {
    "text1": "Mathematical models are fundamental tools for explaining biological behaviors. Dynamical andconstraint-based models are two different formulations that attempt to capture the phenotypiccapabilities of organisms.Dynamic models are formulated as ordinary differential equations (ODEs) that simulate metabolicconcentration over time. These models, however, only depict changes in metabolic concentration andrely on mechanistic details and kinetic parameters that are not always available. Constraint-basedmodels, on the other hand, have a better cellular perspective. By performing constraint-basedoptimizations, they simulate cell behavior under different genetic and environmental conditions.Metabolic models also have some drawbacks. In addition to providing no mechanical knowledge of anychemical reactions (beyond their stoichiometry) and no information regarding metabolic concentrationsor reaction flux dynamics, they are based on a steady-state assumption that production andconsumption of metabolites are balanced within the cell. Constraint-based optimizations, Flux BalanceAnalysis (FBA) methods, generally return an infinite set of solutions, requiring the imposition of additionalassumptions to identify unique flux distributions.While individually, both modeling approaches have several advantages, one lacks the benefitsprovided by the other. With this in mind, we implemented a tool in MEWpy capable of hybridizing kineticand constraint-based models. With it, we were able to reduce the constraint-based model solution spaceby overlapping the kinetic solution space and sampling the kinetic model, analyze the impact of differentstandard deviation values on the sampling, perform hybridization of enzymatic constrained models, andfurther compare distinct hybridization approaches. To demonstrate the potential of our tool and itsapplicability in strain optimization, we performed hybrid optimization of succinate production, where wediscovered a set of genetic mutations that boosted its production.",
    "text2": "Microbial communities participate in many biological processes, directly affecting itssurrounding environment. Thus, the study of a community’s behaviour and interactionsamong its members can be very useful in the biotechnology, environmental and humanhealth fields. Nevertheless, decoding the metabolic exchanges between microorganismsand community dynamics remains a challenge.Computational modelling methods have gained interest as a way to unravel the interactionsand behaviour. GSM models allow the prediction of an organism’s response tochanges in genetic and environmental conditions. Thus, the extension of such method to acommunity level can help decode a community’s phenotype.In this work, different GSM models and current bioinformatics tools were used to modelthe metabolism of different microbial communities. The different tools’ performances werecompared to assess which is currently the best method to perform an analysis on a communitylevel. Distinct case studies regarding microbial communities for which its interactionswere already known, were selected. To assess the tools’ performances, each tools outputwas compared to what was expected in theory.COBRA Toolbox's methods proved to be useful to build a community structure fromindividual GSM models, while pFBA and SteadyCom’s simulation methods can predictexchange between the organisms and the environment. Additionally, Dynamic Flux BalanceAnalysis (dFBA) approaches, such as DFBAlab and DyMMM, can successfully simulatemetabolite and biomass variation over time. Nevertheless, these methods are more limitedas they require specific organism information, which is not always available.Several GSM models are available for use. Nonetheless, their quality control has to gainattention as the simulations’ results are directly affected by the individual models accuracyto represent an organism’s metabolism. Thus, community model builders should carefullychose a GSM model, or combination of models before performing simulations.",
    "similarity": 0.3126388469871918
  },
  {
    "text1": "The procedural generation of geometry within the space of computer graphics has been a topic of study for quitesome time, benefiting from a more unpredictable brand of randomness. Similarly, the exploration of lighting as aphenomenon within virtual space has been a field of study of comparable age.Despite its age and early adoption, there is a surprising lack of research in emulating the phenomenon oflighting past its interactions with the world. Most implementations of procedurally generated lightning within videogames are based on randomized data trees. When part of the skybox, 2D meshes or textures are randomlyselected from a pre-made pool. There are, however, methods based entirely on the dielectric breakdown model,using approximations to solve a Laplacian equation.This dissertation aims to present an alternative approach to the randomized and procedural generation oflightning bolts based on the Space Colonization algorithm. While the algorithm was first conceived for use inbotanical applications, modeling the growth of biological structures, the similarities between the results producedby the dielectric breakdown model and botanic modeling algorithms coupled with the visual likeness of a lightningbolt and certain trees, made for solid groundwork upon which to establish this unique approach.As such, this work largely aims to be a first step into this particular realm, showing Space Colonizationas a suitable algorithm for this specific purpose. That being said, a large portion of time was spent iterating,modifying and experimenting with ideas that were either discarded or adapted, an effort primarily dedicatedtowards controlling and stifling the possible growth of branches in ways beyond the reduction of attractors.The original algorithm was altered, focus put especially on the creation of a singular channel at a time, mixingdiscoveries from previous research with the work done on manipulating Space Colonization. Instead of thevenation patterns observed with the original work, the stifling of any growth means that each node has a chance,when created, of sprouting a branch and each branch is, in turn, a different, modified instance of the sameunderlying concept providing an additional level of control. Effort was equally placed on showcasing differentproperties inherent to a lightning strike, such as its iterative construction when descending from its origin.In the rendering section, along with recreating the bloom and glow effect seen in previous works, effort was putinto recreating the strobing observed in capturing slow-motion footage of lightning bolts with special detail givento this. In addition, parameters were joined with a waypoint system to allow for a great degree of freedom whengenerating new bolts.",
    "text2": "Procedural generation of content has been studied for quite some time and it is increasinglyrelevant in scientific areas and in video-game and film industries. Procedural road layoutgeneration has been traditionally approached using L-Systems, with some works exploringalternative avenues. Although originally conceived for biological systems modelling, theadequacy of L-Systems as a base for road generation has been demonstrated in severalworks.In this context, this work presents an alternative approach for procedural road layoutgeneration that is also inspired by plant generation algorithms: space colonisation.In particular, this work uses the concept of attraction points introduced in space colonisationas its base to produce road layouts, both in urban and inter-city environments. As willbe shown, the usage of attraction points provides an intuitive way to parameterise a roadlayout. The original Space Colonization Algorithm (SCA) generates a tree like structure,but in this work, the extensions made aim to fully generate a inter-connected road network.As most previous methods the method has two phases. A first phase generates whatis mostly a tree structure growing from user defined road segments. The second phaseperforms the inter connectivity among the roads created in the first phase.The original SCA parameters such as the killradius help to control the capillarity of theroad layout, the number of attraction points used by each segment will dictate its relevanceestablishing a road hierarchy naturally dependent on the distribution of the attractionpoints on the terrain. An angle control allows the creation of grid like or more organicroad layouts.The distribution of the attraction points in the terrain can be conditioned by boundarymaps, containing parks, sea, rivers, and other forbidden areas. Population density maps canbe used to supply an explicit probabilistic distribution to the attraction points. Flow-fieldscan be used to dictate the flow of the road layout. Elevation maps provide an additionalrestriction regarding the steepness of the roads.The tests were executed within a graphic toolbox developed simultaneously. The resultsare exported to a geographical information file format, GeoJSON, and then maps are renderedusing a geospatial visualisation and processing framework called Mapnik.For the most part, parameter settings were intuitively reflected on the road layout andthis method can be seen as a first step towards fully exploring the usage of attraction pointsin the context of road layout.",
    "similarity": 0.32226883542043455
  },
  {
    "text1": "Na área de Engenharia de Software, a modelação de sistemas com recurso a diagramas,permite representar um sistema de forma padronizada, com o intuito de facilitar a compreensão da especificação, estrutura lógica, e documentação dos mesmos.Hoje em dia, no mundo empresarial, a utilização de diagramas através de ferramentaspróprias para o efeito tem como objetivo a comunicação entre equipas, inserindo-se na fasede modelação dos projetos. No entanto, a construção de aplicações com recurso a técnicasde low code, ou mesmo zero code, é uma realidade cada vez mais atual.A evolução natural deste conceito resultará na geração automática de código através deuma linguagem visual, como os diagramas, facilitando, assim, a produção de código, e aomesmo tempo, conseguir-se-á uma poupança de tempo aproveitando o trabalho realizadonuma fase mais precoce do projeto. Posto isto, a utilização de modelos, mais ou menosstandard, como forma de especificar e prototipar aplicações é e será, cada vez mais, umarealidade bem fundada e com sucesso assinalável, permitindo também gerir de forma maiseficaz questões de multi-plataforma, visto que a geração de código não é exclusiva a nenhumparadigma nem linguagem de programação específica.Com esta dissertação pretende-se, então, utilizar modelos UML como mecanismo únicode especificação de aplicações, automatizando o processo de construção do respetivo códigoe os aspetos tecnológicos relativos ao seu deployment e instalação, disponibilizando umaferramenta que possibilite o processo de criação de aplicações web e android a partir dediagramas UML.Assim, foi criada uma aplicação que, através da interação do utilizador, recebe diagramasde classe exportados em formato XML interpretando-os e gerando aplicações android eaplicações web. Estas aplicações realizam as operações CRUD para cada entidade representadano diagrama de classe.",
    "text2": "O Desenvolvimento Orientado pelo Comportamento (Behaviour-Driven-Development, BDD) é um paradigma de desenvolvimento de software que permite especificar as necessidades dos utilizadores e os seus critérios de aceitação. A especificação de um sistema é feita através da descrição de cenários de utilização que serão depois implementados. Rocha Silva (2022) propôs uma linguagem de especificação de cenários de utilização, para interfaces web, que utiliza os widgets da própria interface na especificação, permitindo não só especificar os requisitos do sistema, mas também referir como estes deverão ser implementados. No processo de BDD podem surgir na especificação cenários contraditórios que, passando despercebidos, podem levar a que a especificação tenha de ser revista na fase de implementação. Todo este processo acarreta custos, pelo que surgiu a necessidade de criar um método de determinar se uma interface está especificada sem quaisquer contradições (isto é, se a especificação é ou não consistentena descrição do sistema). O objetivo deste trabalho é então definir um método que permite, para uma interface web especificada na linguagem proposta por Rocha Silva (2022), determinar se a especificação apresenta ou não contradições (ou seja, é inconsistente) nos seus cenários. Para cumprir este objetivo será utilizada a ferramenta IVY workbench que permite analisar, de forma automática, modelos escritos em MAL interactors do comportamento de sistemas interativos (permitindo verificar propriedades sobre estes). O primeiro passo do projeto será, então, desenvolver uma ferramenta (o modelador) capaz de traduzir uma interface webespecificada na linguagem proposta por Rocha Silva (2022) para MAL interactors, de modo a que esta possa ser analisada na ferramenta IVY Workbench. Depois, serão ainda apresentadas as propriedades CTL que serão verificadas na ferramenta IVY Workbench para determinar se uma determinada especificação é consistente. Por fim, será apresentado um método de, utilizando a ferramenta IVY Workbench e o modelo em MAL interactors gerado pelo modelador com as devidas propriedades CTL, determinar não só se a especificação é inconsistente mas, caso o seja, os cenários que dão origem a essa inconsistência.",
    "similarity": 0.3045123195801137
  },
  {
    "text1": "Na área de Engenharia de Software, a modelação de sistemas com recurso a diagramas,permite representar um sistema de forma padronizada, com o intuito de facilitar a compreensão da especificação, estrutura lógica, e documentação dos mesmos.Hoje em dia, no mundo empresarial, a utilização de diagramas através de ferramentaspróprias para o efeito tem como objetivo a comunicação entre equipas, inserindo-se na fasede modelação dos projetos. No entanto, a construção de aplicações com recurso a técnicasde low code, ou mesmo zero code, é uma realidade cada vez mais atual.A evolução natural deste conceito resultará na geração automática de código através deuma linguagem visual, como os diagramas, facilitando, assim, a produção de código, e aomesmo tempo, conseguir-se-á uma poupança de tempo aproveitando o trabalho realizadonuma fase mais precoce do projeto. Posto isto, a utilização de modelos, mais ou menosstandard, como forma de especificar e prototipar aplicações é e será, cada vez mais, umarealidade bem fundada e com sucesso assinalável, permitindo também gerir de forma maiseficaz questões de multi-plataforma, visto que a geração de código não é exclusiva a nenhumparadigma nem linguagem de programação específica.Com esta dissertação pretende-se, então, utilizar modelos UML como mecanismo únicode especificação de aplicações, automatizando o processo de construção do respetivo códigoe os aspetos tecnológicos relativos ao seu deployment e instalação, disponibilizando umaferramenta que possibilite o processo de criação de aplicações web e android a partir dediagramas UML.Assim, foi criada uma aplicação que, através da interação do utilizador, recebe diagramasde classe exportados em formato XML interpretando-os e gerando aplicações android eaplicações web. Estas aplicações realizam as operações CRUD para cada entidade representadano diagrama de classe.",
    "text2": "O recurso a ferramentas de geração automática de código permite economizar tempo quando se desenvolvem soluções de software, factor importante em questões de produtividade.Existe um conjunto de padrões de conceção [Gamma et al., 1995] que representam soluções genéricas para problemas relativos ao desenvolvimento de aplicações de software, numa perspetiva orientada aos objetos. Para cada um deles pode ser vista a sua estrutura de classes, métodos e relacionamentos, bem como as situações mais adequadas para a sua utilização. Bastará consultar o catálogo de padrões de conceção [Gamma et al., 1995] e utilizar aquele que mais se adequar à resolução de determinado problema que surja no desenvolvimento de um novo programa.A existência de uma aplicação de software capaz de fazer a geração automática do código associado aos padrões de conceção, agiliza o desenvolvimento de novas aplicações, porque fornece de imediato o respetivo código.O que se propõe com o desenvolvimento desta dissertação é uma solução de software, capaz de efetuar a geração automática de código para os padrões de conceção catalogados em [Gamma et al., 1995]. Juntamente com o programa desenvolvido, é também apresentado um levantamento do estado da arte sobre os padrões de conceção, considerando também situações atuaisda sua aplicabilidade. Em seguida, é descrita a especificação da aplicação elaborada, bem como o seu processo de desenvolvimento, acompanhado de um exemplo de utilização. Por fim, encontram-se dois casos de estudo, servindo para provar que o programa elaborado pode ser utilizado em contextos reais.",
    "similarity": 0.3021422583466978
  },
  {
    "text1": "Cancer is one of the major causes of death in developed countries. It is not a single disease,but a group of different types of diseases with specific symptoms, treatments and prognosis.Early diagnosis and prognostic assessment are essential to select the best treatment for eachcase.Deep learning is a branch of machine learning that became popular in recent years. Deeplearning methods have been employed in a broad range of areas including self-driving cars,natural language processing, computer vision, health, among others.The main goal of the thesis is to develop deep learning methods to predict cancer and itsoutcome from transcriptomics data. Reviewing literature, exploring datasets, developingpipelines and validating the methods using a case study are some of the tasks needed toachieve the goals of the thesis.The developed methods are implemented as a pipeline for creating models from geneexpression data. The framework is capable of reading and pre-processing these data, andtraining, optimizing and evaluating traditional machine learning and deep learning models.The framework was showcased by using the METABRIC dataset as a case study, whichcontains samples from breast cancer patients. The gene expression microarray data from thedataset was used to generate traditional, deep learning and multi-task models. The modelswere used to predict the expression of Estrogen Receptor (ER), the subtype of breast cancerregarding ER, Human Epidermal Growth Factor (HER-2) and Progesterone Receptor (PR) andthe prognosis of breast cancer patients with Nottingham Prognostic Index (NPI), respectively.Another dataset allowed the use of single-cell RNAseq data and confirmed the main trendsof the results.Overall, the results were promising with classification tasks obtaining good results whileregression models had a poorer performance. While the best results were obtained withtraditional machine learning models, deep learning models were near and could providebetter results if the dataset contained a larger number of samples.",
    "text2": "Nowadays, the ability to predict protein functions directly from amino-acid sequences alone remains a major biological challenge. The understanding of protein properties and functions is extremely important and can have a wide range of biotechnological and medical applications.Technological advances have led to an exponential growth of biological data challenging conventionalanalysis strategies. High-level representations from the field of deep learning canprovide new alternatives to address these problems, particularly NLP methods, such as wordembeddings, have shown particular success when applied for protein sequence analysis.Here, a module that eases the implementation of word embedding models toward proteinrepresentation and classification is presented. Furthermore, this module was integrated in theProPythia framework, allowing to straightforwardly integrate WE representations with the trainingand testing of ML and DL models.This module was validated using two protein classification problems namely, identification ofplant ubiquitylation sites and lysine crotonylation site prediction. This module was further usedto explore enzyme functional annotation. Several WE were tested and fed to different ML andDL networks. Overall, WE achieved good results being even competitive with state-of-the-artmodels, reinforcing the idea that language based methods can be applied with success to awide range of protein classification problems.This work presents a freely available tool to perform word embedding techniques for proteinclassification. The case studies presented reinforce the usability and importance of using NLPand ML in protein classification problems.",
    "similarity": 0.3007950138504155
  },
  {
    "text1": "Cancer is one of the major causes of death in developed countries. It is not a single disease,but a group of different types of diseases with specific symptoms, treatments and prognosis.Early diagnosis and prognostic assessment are essential to select the best treatment for eachcase.Deep learning is a branch of machine learning that became popular in recent years. Deeplearning methods have been employed in a broad range of areas including self-driving cars,natural language processing, computer vision, health, among others.The main goal of the thesis is to develop deep learning methods to predict cancer and itsoutcome from transcriptomics data. Reviewing literature, exploring datasets, developingpipelines and validating the methods using a case study are some of the tasks needed toachieve the goals of the thesis.The developed methods are implemented as a pipeline for creating models from geneexpression data. The framework is capable of reading and pre-processing these data, andtraining, optimizing and evaluating traditional machine learning and deep learning models.The framework was showcased by using the METABRIC dataset as a case study, whichcontains samples from breast cancer patients. The gene expression microarray data from thedataset was used to generate traditional, deep learning and multi-task models. The modelswere used to predict the expression of Estrogen Receptor (ER), the subtype of breast cancerregarding ER, Human Epidermal Growth Factor (HER-2) and Progesterone Receptor (PR) andthe prognosis of breast cancer patients with Nottingham Prognostic Index (NPI), respectively.Another dataset allowed the use of single-cell RNAseq data and confirmed the main trendsof the results.Overall, the results were promising with classification tasks obtaining good results whileregression models had a poorer performance. While the best results were obtained withtraditional machine learning models, deep learning models were near and could providebetter results if the dataset contained a larger number of samples.",
    "text2": "Knowing what lies around us has been a goal for many decades now, and the new advances in sequencing technologies and in meta-omics approaches have permitted to start answering some of the main questions of microbiology - what is there, and what is it doing?The exponential growth of omics studies has been answered by the development ofsome bioinformatic tools capable of handling Metagenomics (MG) analysis, with a scarcefew integrating such analysis with Metatranscriptomics (MT) or Metaproteomics (MP) studies.Furthermore, the existing tools for meta-omics analysis are usually not user friendly,usually limited to command-line usage.Because of the variety in meta-omics approaches, a standard workflow is not possible,but some routines exist, which may be implemented in a single tool, thereby facilitatingthe work of laboratory professionals. In the framework of this master thesis, a pipeline forintegrative MG and MT data analysis was developed. This pipeline aims to retrieve comprehensivecomparative gene/transcript expression results obtained from different biologicalsamples. The user can access the data at the end of each step and summaries containing severalparameters of evaluation of the previous step, and final graphical representations, likeKrona plots and Differential Expression (DE) heatmaps. Several quality reports are alsogenerated. The pipeline was constructed with tools tested and validated for meta-omicsdata analysis. Selected tools include FastQC, Trimmomatic and SortMeRNA for preprocessing,MetaSPAdes and Megahit for assembly, MetaQUAST and Bowtie2 for reporting onthe quality of the assembly, FragGeneScan and DIAMOND for annotation and DeSEQ2 forDE analysis.Firstly, the tools were tested separately and then integrated in several python wrappers toconstruct the software Meta-Omics Software for Community Analysis (MOSCA). MOSCAperforms preprocessing of MG and MT reads, assembly of the reads, annotation of theassembled contigs, and a final data analysis.Real datasets were used to test the capabilities of the tool. Since different types of filescan be obtained along the workflow, it is possible to perform further analyses to obtainadditional information and/or additional data representations, such as metabolic pathwaymapping.",
    "similarity": 0.3079859301719646
  },
  {
    "text1": "Web-based videotelephony services currently occupy a prominent place in the wide rangeof services and generated network traffic. With the growing use of such services comes also anincreasing need for the evaluation of user experience. Depending on network conditions, thereare relevant QoS parameters (bandwidth, delay, loss ratio, jitter, etc.) that have an impact on thequality of experience of the service.The objective of this thesis is to find out which network parameters affect videocalls qualityof experience, which are the threshold values for which the quality of experience levels areaffected, in what way is the quality of experience impacted and what is their relation.The quality of experience was evaluated using objective methods for all video and audiosamples collected during the experimentation phase. Conclusions were made based on the resultswhich are presented in this dissertation.",
    "text2": "The constant development of the Internet and underlying transmission technologies,together with the increasing popularity of provided services, such as multimediaapplications and applications using P2P technologies, are contributing to the continuousgrowth of the network traffic in volume and diversity.To be able to handle such amount of data while assuring the quality and operationof provided services, traffic-measuring tools are required to implement mechanismsthat scale and have a minimum interference on the normal network behaviour.One of the most common solutions for this purpose involves the implementationof measurement techniques based on traffic sampling. These techniques aim toprovide accurate estimations of traffic behaviour and characteristics by processingfractions of the original network traffic.Another fundamental area of traffic monitoring concerns the traffic classificationand characterization, as it supports important tasks such as resource allocation,planning and management, security and quality of service. Attending to this, addedup to the mentioned growth in traffic volumes, it is likely that traffic classificationand characterization will be increasingly supported by traffic sampling mechanisms.This work aims to study the impact of traffic sampling mechanisms on the accuracyof traffic flows characterization. This was carried out through the applicationof classical and adaptive traffic sampling techniques to real traffic traces, which werecaptured in different real scenarios and opened to public access. The resulting sampleddata is then organized under the form of flow records, which are then classifiedaccording to their transport and application protocols.The performance of the distinct traffic sampling techniques in enabling a correctcharacterization of traffic flows was then assessed taking into account multiple metricsapplied to the flow records of sampled traffic, compared to the metrics of thefull original traffic.",
    "similarity": 0.3062313019390582
  },
  {
    "text1": "Transcription factors (TFs) are proteins that mediate the cellular response to the changes of thesurrounding environment. Studying their functional domains and protein structure is fundamentalin order to gain insight of the way they are triggered and how they shape genetic transcription.The current work aimed for classifying both TFs and functional domains, understanding whichfeatures can be related to the different functions of the TFs.By using UniProtJAPI, a JAVA library that allows remote access to UniProt, the informationof 200 Escherichia coli’s (E. coli) TFs has been retrieved. This data was manually curated, inorder to remove domain duplicates and other excess information, and to add missing domains.The obtained functional domains were classified according to their molecular function, whilethe TFs were classified according to their regulatory function. TFs that exclusively induce geneexpression were classified as activators, while TFs that only perform gene repression were classifiedas repressors. On the other hand, TFs that perform both the activation and repression oftranscription were classified as duals. The information was then analysed altogether in orderto understand what relationships between the TFs’ function and functional domains could exist.Several analysis were performed, which include statistical tests and clustering methods. Alongwith the analysis of the full list of TFs, TFs that are part of two-component signal transductionsystems and global TFs were given special focus, due to their important role in cellular function.The results showed that there is a relationship between the functional domains and the regulatoryfunction of the different TFs. This may be related to the evolutionary relationships betweenrepressors and activators. It is also understandable that dual regulators are closely related to activatorsand repressors than what activators and repressors are to each other. Moreover, TFs oftwo-component signal transduction systems are similar to each other, given that they performsimilar functions. Their domain architectures are also predictable and do not vary from whatwas expected of these TFs. However, in global TFs the results are opposite of the ones obtainedfor two-component system TFs: their structures are very different from each other and each TFis specific. The amount of different domains is high when comparing to the full sample of TFs,since the number of domains exceeds the number of TFs. Domains of all classification types arepresent in their structure and the domain architectures are varied, which reflects their differentactivities within the cell.",
    "text2": "Microbial communities participate in many biological processes, directly affecting itssurrounding environment. Thus, the study of a community’s behaviour and interactionsamong its members can be very useful in the biotechnology, environmental and humanhealth fields. Nevertheless, decoding the metabolic exchanges between microorganismsand community dynamics remains a challenge.Computational modelling methods have gained interest as a way to unravel the interactionsand behaviour. GSM models allow the prediction of an organism’s response tochanges in genetic and environmental conditions. Thus, the extension of such method to acommunity level can help decode a community’s phenotype.In this work, different GSM models and current bioinformatics tools were used to modelthe metabolism of different microbial communities. The different tools’ performances werecompared to assess which is currently the best method to perform an analysis on a communitylevel. Distinct case studies regarding microbial communities for which its interactionswere already known, were selected. To assess the tools’ performances, each tools outputwas compared to what was expected in theory.COBRA Toolbox's methods proved to be useful to build a community structure fromindividual GSM models, while pFBA and SteadyCom’s simulation methods can predictexchange between the organisms and the environment. Additionally, Dynamic Flux BalanceAnalysis (dFBA) approaches, such as DFBAlab and DyMMM, can successfully simulatemetabolite and biomass variation over time. Nevertheless, these methods are more limitedas they require specific organism information, which is not always available.Several GSM models are available for use. Nonetheless, their quality control has to gainattention as the simulations’ results are directly affected by the individual models accuracyto represent an organism’s metabolism. Thus, community model builders should carefullychose a GSM model, or combination of models before performing simulations.",
    "similarity": 0.3034846664868973
  },
  {
    "text1": "Transcription factors (TFs) are proteins that mediate the cellular response to the changes of thesurrounding environment. Studying their functional domains and protein structure is fundamentalin order to gain insight of the way they are triggered and how they shape genetic transcription.The current work aimed for classifying both TFs and functional domains, understanding whichfeatures can be related to the different functions of the TFs.By using UniProtJAPI, a JAVA library that allows remote access to UniProt, the informationof 200 Escherichia coli’s (E. coli) TFs has been retrieved. This data was manually curated, inorder to remove domain duplicates and other excess information, and to add missing domains.The obtained functional domains were classified according to their molecular function, whilethe TFs were classified according to their regulatory function. TFs that exclusively induce geneexpression were classified as activators, while TFs that only perform gene repression were classifiedas repressors. On the other hand, TFs that perform both the activation and repression oftranscription were classified as duals. The information was then analysed altogether in orderto understand what relationships between the TFs’ function and functional domains could exist.Several analysis were performed, which include statistical tests and clustering methods. Alongwith the analysis of the full list of TFs, TFs that are part of two-component signal transductionsystems and global TFs were given special focus, due to their important role in cellular function.The results showed that there is a relationship between the functional domains and the regulatoryfunction of the different TFs. This may be related to the evolutionary relationships betweenrepressors and activators. It is also understandable that dual regulators are closely related to activatorsand repressors than what activators and repressors are to each other. Moreover, TFs oftwo-component signal transduction systems are similar to each other, given that they performsimilar functions. Their domain architectures are also predictable and do not vary from whatwas expected of these TFs. However, in global TFs the results are opposite of the ones obtainedfor two-component system TFs: their structures are very different from each other and each TFis specific. The amount of different domains is high when comparing to the full sample of TFs,since the number of domains exceeds the number of TFs. Domains of all classification types arepresent in their structure and the domain architectures are varied, which reflects their differentactivities within the cell.",
    "text2": "Technological evolution is impacting several industries, e.g., by allowing them to deliver higher levelsof functionality. The automotive industry is an example of how technology is supporting the developmentof new solutions in vehicle safety and comfort.Advanced Driver Assistance Systems (ADAS) are cases of solutions that evolved significantly inrecent years. This is possible not only due to the progress of electronic solutions but also becauseof higher quality in software. The smartphone is an example of this evolution with a broad rangeof applicability since these devices have been used to develop ADAS, making them an interestingcost-effective platform to develop such systems.Previous research has shown smartphones’ ability to output sensors data with the necessary qualityfor a broad number of applications with special focus in inertial sensors. However, such studiestend to be difficult to reproduce or lack the desired detail levels of their experimental methods. Concernsabout how good are smartphone sensors and their use to develop ADAS emerge when readingexisting literature, particularly, how the context of collecting data is controlled and which variablesimpact the collection process.In order to assess the feasibility of using smartphones as sensing devices, questions arise on howdifferent parts of the collection setup affect the quality of data collected. Motivated by those questions,a study considering four different hypotheses is proposed to assess the impact of a controlled set ofvariables, namely: brands of inertial sensors, car mounts, sensor sampling rates, and vehicles. A setof controlled experiments is performed to assess the impact of each variable in the collection processof inertial sensors, more precisely the vertical acceleration.To perform the experiments, three special-purpose tools were developed. Smartphones used inthe experiments feature an application to collect and export their sensors data. A researcher of anexperiment operates another smartphone application to annotate road anomalies found while driving.A desktop application automates the computation and statistical validation of the vertical accelerationcorrelation from different setups.Dynamic Time Warping was used to compute the correlation coefficient of vertical accelerationas measured by different devices. Results show a baseline correlation coefficient of 0.892 with astandard configuration of software and hardware. When one of the independent variables is changed,the resulting coefficients range from 0.827 to 0.848.Randomization tests were executed to statistically validate experiments results, making use of aRandom Shuffle algorithm on surrogate data. Such tests rejected all four proposed null hypothesesregarding dissimilarities on vertical acceleration sensed by different setups.From the controlled experiment a deeper understanding of the variables influencing data collectionwith smartphones was obtained. Results showed that varying the inertial sensors, car mounts, ratesof sampling, or vehicles had a low impact on vertical acceleration sensed by smartphones. This isa good indicator that smartphones can be used to develop ADAS without the need to standardizeevery part of the collection setup. Thus, it possible to foresee the deployment of a system to a wideraudience by taking advantage of existing equipment.",
    "similarity": 0.30122687874184617
  },
  {
    "text1": "Transcription factors (TFs) are proteins that mediate the cellular response to the changes of thesurrounding environment. Studying their functional domains and protein structure is fundamentalin order to gain insight of the way they are triggered and how they shape genetic transcription.The current work aimed for classifying both TFs and functional domains, understanding whichfeatures can be related to the different functions of the TFs.By using UniProtJAPI, a JAVA library that allows remote access to UniProt, the informationof 200 Escherichia coli’s (E. coli) TFs has been retrieved. This data was manually curated, inorder to remove domain duplicates and other excess information, and to add missing domains.The obtained functional domains were classified according to their molecular function, whilethe TFs were classified according to their regulatory function. TFs that exclusively induce geneexpression were classified as activators, while TFs that only perform gene repression were classifiedas repressors. On the other hand, TFs that perform both the activation and repression oftranscription were classified as duals. The information was then analysed altogether in orderto understand what relationships between the TFs’ function and functional domains could exist.Several analysis were performed, which include statistical tests and clustering methods. Alongwith the analysis of the full list of TFs, TFs that are part of two-component signal transductionsystems and global TFs were given special focus, due to their important role in cellular function.The results showed that there is a relationship between the functional domains and the regulatoryfunction of the different TFs. This may be related to the evolutionary relationships betweenrepressors and activators. It is also understandable that dual regulators are closely related to activatorsand repressors than what activators and repressors are to each other. Moreover, TFs oftwo-component signal transduction systems are similar to each other, given that they performsimilar functions. Their domain architectures are also predictable and do not vary from whatwas expected of these TFs. However, in global TFs the results are opposite of the ones obtainedfor two-component system TFs: their structures are very different from each other and each TFis specific. The amount of different domains is high when comparing to the full sample of TFs,since the number of domains exceeds the number of TFs. Domains of all classification types arepresent in their structure and the domain architectures are varied, which reflects their differentactivities within the cell.",
    "text2": "The increasing pervasiveness and lower cost of electronic devices equipped with sensorsis leading to a greater and cheaper availability of localized information. The advent ofthe internet has brought phenomena such as crowd-sourced maps and related data. Thecombination of the availability of mobile information, community built maps, with theadded convenience of retrieving information over the internet creates the opportunity tocontextualize data in new ways.This work takes that opportunity and attempts to generalize the detection of drivingevents which are deemed problematic as a function of contextual factors, such as neighbouringbuildings, areas, amenities, the weather, and the time of day, week or month.In order to research the problem at hand, the issue is first contextualized properly, providingan overview of important factors, namely Smart Cities, Data Fusion, and MachineLearning.That is followed by a chapter concerning the state of the art, that showcases relatedprojects and how the various facets of road traffic expression are being approached.The focus is then turned to creating a solution. At first this consists in aggregating dataso as to create a richer context than would be present otherwise, this includes the retrievalfrom different services, as well as the composition of a unique view of the same drivingsituation with new dimensions added to it. And then Models were created using differentMachine Learning methods, and a comparison of results according to selected and justifiedevaluation metrics was made. The compared Methods are Decision Tree, Naive Bayes, andSupport Vector Machine.The different types of information were evaluated on their own as potential classifiers andthen were evaluated together, leading to the conclusion that the various types combinedallow for the creation of better models capable of finding problems with more confidencein such results.According to the tests performed the chosen approach can improve the performanceover a baseline approach and point out problematic situations with a precision of over 90%.As expected by not using factors concerning the driver state or acceleration the scope ofproblems which are detected is limited in domain.",
    "similarity": 0.3043215624199819
  },
  {
    "text1": "Transcription factors (TFs) are proteins that mediate the cellular response to the changes of thesurrounding environment. Studying their functional domains and protein structure is fundamentalin order to gain insight of the way they are triggered and how they shape genetic transcription.The current work aimed for classifying both TFs and functional domains, understanding whichfeatures can be related to the different functions of the TFs.By using UniProtJAPI, a JAVA library that allows remote access to UniProt, the informationof 200 Escherichia coli’s (E. coli) TFs has been retrieved. This data was manually curated, inorder to remove domain duplicates and other excess information, and to add missing domains.The obtained functional domains were classified according to their molecular function, whilethe TFs were classified according to their regulatory function. TFs that exclusively induce geneexpression were classified as activators, while TFs that only perform gene repression were classifiedas repressors. On the other hand, TFs that perform both the activation and repression oftranscription were classified as duals. The information was then analysed altogether in orderto understand what relationships between the TFs’ function and functional domains could exist.Several analysis were performed, which include statistical tests and clustering methods. Alongwith the analysis of the full list of TFs, TFs that are part of two-component signal transductionsystems and global TFs were given special focus, due to their important role in cellular function.The results showed that there is a relationship between the functional domains and the regulatoryfunction of the different TFs. This may be related to the evolutionary relationships betweenrepressors and activators. It is also understandable that dual regulators are closely related to activatorsand repressors than what activators and repressors are to each other. Moreover, TFs oftwo-component signal transduction systems are similar to each other, given that they performsimilar functions. Their domain architectures are also predictable and do not vary from whatwas expected of these TFs. However, in global TFs the results are opposite of the ones obtainedfor two-component system TFs: their structures are very different from each other and each TFis specific. The amount of different domains is high when comparing to the full sample of TFs,since the number of domains exceeds the number of TFs. Domains of all classification types arepresent in their structure and the domain architectures are varied, which reflects their differentactivities within the cell.",
    "text2": "In the past 30 years, accumulated evidence has been supporting viral infection as one factorresponsible for 15-20% of human malignancies worldwide (W. S. Liang et al. 2014;McLaughlin-Drubin and Munger 2008). Studies on oncogenic viruses have proved their importanceon cellular malfunction along the carcinogenic process, and showed that their associationwith cancer can amount from 15% to 100% (McLaughlin-Drubin and Munger 2008),depending on the type of tumour. With the large amount of genomic and metagenomic informationavailable on public international consortia, such as TCGA database, it is nowadayspossible to indirectly infer viral infections from the human centred omics studies, as a portionof the reads will align in viruses and bacteria.Taking as starting point the research made by Tang et al. 2013, we focused on cervical(CESC), hepatocellular (LIHC) and head and neck squamous cell (HNSC) carcinomas, whichare known to show a high proportion of viral-positive cases (Tang et al. 2013). We downloadedRNAseq data from 309, 424 and 566 samples, respectively, and run the unmapped reads againsta reference database of viruses (downloaded from NCBI) by using the tools Batch,SAMTOOLS, Bowtie and PRINTSEQ. Quantification of each virus was performed using partsper million reads (ppm) and only viruses with ppm above 10 were considered as positivelyinfecting the sample. We confirmed that around 94% of CESC samples were infected, mostlyby HPV (Human papillomavirus) and specifically by the HPV16 strain. Nearly 32% of LIHCwere infected by HBV (hepatitis B virus). Almost 17% of HNSC samples were infected, andthe HPV16 was the most common present virus.The evaluation of differential enrichment of metabolic pathways between infected and noninfectedgroups, for each cancer type, was performed in GSEA. Signs of enrichment for infectionand immune related pathways were evident in CESC infected group, while in LIHC andHNSC infected groups the enrichment was mostly related with DNA replication and repair.This seems to indicate that infection is especially active in CESC, contradicting previous claimsthat tumorigenesis in cervix was not directly linked with infection. For the three cancer types,the viruses integrate their genome in the host genome, affecting DNA replication, maintenanceand repair. In our investigation of integration of HPV16 genome in one HNSC tumor sample,we confirmed integration in the human RAD51B gene that codes a protein involved in DNArepair by homologous recombination. We thus confirmed that HPV16 can act both as indirectand direct carcinogen. The infection, most probably through the integration of the viral genome in the host genome,increased the amount of somatic mutations in the infected group in LIHC, but not in HNSCwhere tobacco consumption is also an important carcinogen. The low number of non-infectedsamples in CESC did not allow a reliable evaluation of changes in the amount of somatic mutations.Even so, in both LIHC and HNSC infected groups, some somatic mutations occurredin the context of immune-related pathways, showing that they can contribute to render theseindividuals susceptible to infection.Also, when checking expression of HPV16 genes in five samples each from CESC andHNSC, we confirmed that E6 and E7 genes are amongst the ones more expressed in manysamples, while E2 is not expressed. E6 and E7 have been said to be preferentially integrated inthe host genome, while E2, which controls their expression, is not integrated or it is disrupted.It is believed that the overexpression of E6 and E7 initiates carcinogenesis.The viral infection rates inferred here from mining the omics databases are very similar tothe ones evaluated by standard methods (Tang et al. 2013), showing that public internationalconsortia can indirectly provide interesting insights into the involvement of viral infection intumorigenesis. The high number of samples per tumor, the wide geographic origin of the samples,and the high-throughput characterisation for different omics platforms allows multilayercomparisons and evaluations, in a scale not affordable before.",
    "similarity": 0.31036124919364017
  },
  {
    "text1": "O absentismo é um problema que tem vindo a crescer ao longo dos últimos anos e que afeta gravementea economia das empresas. Para além disso, esta questão está intrinsecamente relacionada com a saúdedos trabalhadores, dado que doenças e acidentes de trabalho são duas das maiores causas de absentismopor todo o mundo.De modo a perceber melhor a razão por detrás da crescente taxa de absentismo, assim como arelação entre o absentismo e a saúde e estilo de vida dos colaboradores de uma empresa portuguesa,tornou-se necessário recorrer às Tecnologias de Informação (TI), nomeadamente ao Business Intelligence(BI). Esta tecnologia permite uma rápida análise de dados e uma melhor compreensão da informaçãoexistente.Assim sendo, esta dissertação tem como objetivo desenvolver uma aplicação Web, recorrendo aferramentas de BI, que permita o estudo dos dados de absentismo através de indicadores clínicos deforma a identificar as principais causas, bem como a implicação que o trabalho e o estilo de vida possater na saúde dos colaboradores e, consequentemente, no absentismo. Por conseguinte, esta aplicaçãofornece apoio à tomada de decisão e prática clínica por parte dos profissionais de saúde e permitetambém, através da análise dos dados, que sejam encontradas soluções para a diminuição da taxa deabsentismo da empresa.Esta solução pretende ainda apresentar toda a informação relativa aos colaboradores e às suasausências de uma forma organizada e de fácil leitura, sendo, deste modo, menos suscetível a erros,assim como mais rápido e mais eficiente que o atual sistema utilizado para a análise do absentismo,facilitando assim o trabalho dos profissionais.",
    "text2": "Nos últimos anos, tem surgido um grande interesse na aplicabilidade dastecnologias de Business Intelligence (BI) na área da saúde. A grande satisfaçãoresultante da sua implementação em outras áreas fez com que os profissionaisde saúde juntamente com os profissionais de Tecnologias de Informação(TI) cooperassem para a conceção e o desenvolvimento de plataformas de BIem ambiente clínico.A grande motivação para a sua implementação adveio da possibilidadede conceber um Sistema de Apoio à Decisão (SAD) médica, que suportasseo processo de tomada de decisão e que permitisse que este fosse realizado deforma mais rápida e eficaz. Além disso, com a implementação do ProcessoClínico Eletrónico, surgiu a necessidade de dar usabilidade aos dados dosutentes armazenados nas bases de dados, tornando-se isso possível com aimplementação da plataforma de BI.Neste projeto, incidiu-se numa área médica específica dentro da especialidadede Ginecologia e Obstetrícia, relacionada com a Interrupção Voluntáriada Gravidez (IVG), por ser uma unidade relativamente recente, onde nãoexiste nenhuma tecnologia semelhante implementada e, ainda, por ser umfoco de interesse para os profissionais de saúde. O local de estudo foi o CentroMaterno Infantil do Norte (CMIN), pertencente ao Centro Hospitalardo Porto (CHP), onde se teve acesso às fontes de dados necessárias para odesenvolvimento da plataforma de BI.Além disso, foram também desenvolvidos modelos de Data Mining (DM),igualmente integrados na plataforma de BI, que permitem prever quais asutentes que recorrem à IVG que constituem um grupo de risco e quais asutentes que necessitam de acompanhamento da equipa de enfermagem durante o processo da IVG. Os resultados obtidos foram bastante satisfatórios,uma vez que foram registados valores de 93% para a métrica da sensibilidadena questão relacionada com a probabilidade das utentes pertenceremao grupo de risco, e valores de 91% e de 87% para a sensibilidade e acuidade,respetivamente, no problema relacionado com a previsão do local derealização de uma das etapas do processo de IVG.Na seleção da tecnologia a utilizar para o desenvolvimento da plataformade BI, optou-se pelo Pentaho BI Suite, depois de realizada uma pesquisaaprofundada sobre ferramentas open source.Após a implementação da plataforma de BI, pode-se afirmar que o resultadofoi satisfatório, uma vez que todos os indicadores de desempenhorequisitados foram apresentados. Nestes indicadores, estão incluídos a distribuiçãodas utentes por idades, por profissão, por localidade, pela presençana última consulta de avaliação, entre outros. Além disso, a informação representadaé credível, pois esta foi submetida a um processo de validação porparte dos profissionais de saúde.",
    "similarity": 0.3032219357669839
  },
  {
    "text1": "O absentismo é um problema que tem vindo a crescer ao longo dos últimos anos e que afeta gravementea economia das empresas. Para além disso, esta questão está intrinsecamente relacionada com a saúdedos trabalhadores, dado que doenças e acidentes de trabalho são duas das maiores causas de absentismopor todo o mundo.De modo a perceber melhor a razão por detrás da crescente taxa de absentismo, assim como arelação entre o absentismo e a saúde e estilo de vida dos colaboradores de uma empresa portuguesa,tornou-se necessário recorrer às Tecnologias de Informação (TI), nomeadamente ao Business Intelligence(BI). Esta tecnologia permite uma rápida análise de dados e uma melhor compreensão da informaçãoexistente.Assim sendo, esta dissertação tem como objetivo desenvolver uma aplicação Web, recorrendo aferramentas de BI, que permita o estudo dos dados de absentismo através de indicadores clínicos deforma a identificar as principais causas, bem como a implicação que o trabalho e o estilo de vida possater na saúde dos colaboradores e, consequentemente, no absentismo. Por conseguinte, esta aplicaçãofornece apoio à tomada de decisão e prática clínica por parte dos profissionais de saúde e permitetambém, através da análise dos dados, que sejam encontradas soluções para a diminuição da taxa deabsentismo da empresa.Esta solução pretende ainda apresentar toda a informação relativa aos colaboradores e às suasausências de uma forma organizada e de fácil leitura, sendo, deste modo, menos suscetível a erros,assim como mais rápido e mais eficiente que o atual sistema utilizado para a análise do absentismo,facilitando assim o trabalho dos profissionais.",
    "text2": "Há cerca de duas décadas atrás, grande parte dos hospitais portugueses começaram autilizar um sistema de notificação de pacientes, para os alertar dos seus eventos médicosnos hospitais, como consultas, cirurgias, exames, tratamentos, entre outros, através de mensagensde texto. Este sistema de notificação é ainda usado nos dias de hoje, mas enfrentaum grande problema: a quantidade de dinheiro avultada que é gasta com as empresasde telecomunicações. Ainda que cada mensagem custe uma fração de cêntimos, poderáfacilmente ser representada num gasto superior a 50,000 euros anuais para um hospital.Uma vez que a tecnologia e o uso de smartphones tem evoluído de forma tão rápida, é estimadoque na próxima década, quase toda a população portuguesa possuirá ou poderá teracesso indireto a um smartphone. Por essas razões, o objetivo principal deste projeto de dissertação,é desenhar e desenvolver uma aplicação móvel de forma a substituir o serviço denotificação atual, por uma aplicação móvel que notificará o paciente através de notificaçõespush, cuja informação poderá ser salva no calendário do próprio smartphone, traduzindo-senuma maior comodidade para o paciente, assim como a erradicação de custos no envio denotificações por parte do hospital. A principal motivação é, portanto, suprimir esses custospara o hospital, aproximar os pacientes do hospital, integrar outros sistemas na aplicação etornar o sistema de notificação mais eficiente. De forma a gerir os utilizadores da aplicaçãoconsiderou-se necessário o desenvolvimento de uma aplicação web.Neste contexto, a presente dissertação apresenta então uma aplicação web, desenvolvidaem AngularJS, orientada para a gestão de utilizadores da aplicação móvel e apresenta tambéma aplicação móvel com a funcionalidade principal de notificar o paciente dos seuseventos médicos, oferecendo também funcionalidades como a consulta do seu histórico deeventos médicos passados, consulta de eventos médicos futuros, bem como a verificaçãodos eventos médicos próximos da data.",
    "similarity": 0.31194920440636476
  },
  {
    "text1": "O absentismo é um problema que tem vindo a crescer ao longo dos últimos anos e que afeta gravementea economia das empresas. Para além disso, esta questão está intrinsecamente relacionada com a saúdedos trabalhadores, dado que doenças e acidentes de trabalho são duas das maiores causas de absentismopor todo o mundo.De modo a perceber melhor a razão por detrás da crescente taxa de absentismo, assim como arelação entre o absentismo e a saúde e estilo de vida dos colaboradores de uma empresa portuguesa,tornou-se necessário recorrer às Tecnologias de Informação (TI), nomeadamente ao Business Intelligence(BI). Esta tecnologia permite uma rápida análise de dados e uma melhor compreensão da informaçãoexistente.Assim sendo, esta dissertação tem como objetivo desenvolver uma aplicação Web, recorrendo aferramentas de BI, que permita o estudo dos dados de absentismo através de indicadores clínicos deforma a identificar as principais causas, bem como a implicação que o trabalho e o estilo de vida possater na saúde dos colaboradores e, consequentemente, no absentismo. Por conseguinte, esta aplicaçãofornece apoio à tomada de decisão e prática clínica por parte dos profissionais de saúde e permitetambém, através da análise dos dados, que sejam encontradas soluções para a diminuição da taxa deabsentismo da empresa.Esta solução pretende ainda apresentar toda a informação relativa aos colaboradores e às suasausências de uma forma organizada e de fácil leitura, sendo, deste modo, menos suscetível a erros,assim como mais rápido e mais eficiente que o atual sistema utilizado para a análise do absentismo,facilitando assim o trabalho dos profissionais.",
    "text2": "O controlo e a prevenção de infeções nosocomiais são essenciais para aredução de custos, bem como para a melhoria dos cuidados prestados numainstituição de saúde. Por outro lado, o tratamento de dados que permitamcompreender, caracterizar e monitorizar as infeções possibilita um controloe uma prevenção mais eficaz das mesmas. Sendo um método automatizadoe eficiente para o tratamento de dados, a tecnologia de Business Intelligencepermite a extração de informação importante para gerar conhecimento quepode auxiliar o processo de tomada de decisão dos profissionais de saúde.O principal objetivo deste trabalho é o desenvolvimento e implementaçãode uma plataforma de Business Intelligence que permita o estudo da incidênciade infeção nosocomial nas Unidades de Medicina do Centro Hospitalardo Porto. Este estudo é feito através da apresentação de um conjunto deindicadores clínicos (informações importantes extraídas dos dados referentesa infeções nosocomiais) que ajudam a analisar e caracterizar estas infeções.Por conseguinte, depois de identificados os indicadores relevantes, torna-sepertinente desenvolver um sistema que permita tratar os dados, extrair osindicadores destes e apresentá-los, de forma atrativa, na plataforma. Porsua vez, a plataforma facilita a análise das informações que disponibiliza,apoiando a tomada de decisões, nomeadamente através da identificação dosprincipais fatores de risco. Assim, o sistema atua como um Sistema de Apoioà Decisão Clínica, podendo auxiliar no controlo e prevenção destas infeções.Pretende-se ainda estudar a aplicabilidade da tecnologia de Data Miningna criação de modelos de classificação capazes de prever a ocorrência deinfeções nosocomiais, na presença de determinados fatores de risco.O conhecimento obtido com a análise dos indicadores e as previsões efetuadaspode possibilitar a diminuição da incidência de infeção nosocomiale, consequentemente, a redução dos custos associados à sua ocorrência, bemcomo o aumento da segurança e do bem-estar dos doentes, ao permitir a tomadade decisões mais fundamentadas. A aplicação de Business Intelligencena área da saúde contribui para melhorar não só o fluxo de trabalho diárionas unidades de saúde, como também a qualidade dos cuidados prestados.",
    "similarity": 0.3325336367233874
  },
  {
    "text1": "Cerebellar ataxia arises from damage or dysfunction that affects the cerebellum and its pathways. As aresult, the motor abilities of individuals with this condition become weakened. Robotics-assisted therapy is still anemerging area, but it has several advantages that could boost the rehabilitation of these individuals. Consideringthis problematic, WALKit Smart Walker is being developed. Its main purpose is to improve the treatment of ataxicpatients through intelligent and multidisciplinary rehabilitation sessions. Thus, it is equipped with several sensorsthat provide monitoring capabilities through a continuous evaluation of the end-user gait and posture.A vast amount of data is acquired during each session by the walker sensors. For health professionals toanalyse this data and have feedback on the patient’s status throughout therapy, tools are needed to control,manage, and monitor sessions in a clear, practical and intuitive way. Therefore, the main goal of this dissertationis centred on implementing an effective way to store the acquired data, along with the development of softwarethat satisfies these requirements.To address these goals, a polyglot persistence database system, composed of a relational and a non-relationaldatabase, was implemented to store the required data while maintaining efficiency. Furthermore, a web applicationwas developed to provide, not only to health professionals, but also to patients themselves, the managementof the rehabilitation sessions with the walker. The application provides an individual and temporal analysis ofthe sessions through interactive graphics adapted to each patient. Additionally, it allows the management of theseveral patients who are/were in treatment and the addition of clinical ratting scales, which are useful to assesstheir motor condition and adapt therapies as needed. In this way, professionals can have a better perception ofthe patient’s condition, and can show patients their evolution, possibly contributing to increase their motivation intherapy.Moreover, in the context of this dissertation, the embedded software of WALKit SmartW, which allows thetherapy configuration, was optimized. This software had no security mechanisms, thus the main goal was on theimplementation of techniques capable of making the software secure. Additionally, other functionalities such asfeedback alerts, were added to the existing application.Throughout the development of this project, it was possible to have continuous feedback from health professionalsof the Hospital of Braga. Usability tests and questionnaires were also applied, and the results were verypromising, enhancing the need for a system with these characteristics. Professionals claimed the system mayhelp in analysing the patient clinical status in an intuitive form while keeping them motivated during treatments.",
    "text2": "In the last few decades, an increasing growth of Internet usage was witnessed worldwide.However, infrastructures do not always allow the existence of Internet connectivity everywhere.Therefore, to address this issue, the concept of Delay Tolerant Networks (DTNs) wasdeveloped. DTNs purpose is to provide a different level of intermittent connectivity, dissimulatingconnection problems that arise in complex connectivity scenarios. Examples of suchscenarios are, for instance, cities, where cars exchange information about their location; inunderdeveloped countries, where Internet is inexistent; in freeways, where is not viable toprovide infrastructures for a continuous connectivity, but cars, tolls, and services need to beaware of each other. Thus, DTNs constitute a possible solution for all the aforementionedcommunication environments.However, DTNs still faces some obstacles in terms of delivering a service with quality as itlacks specific mechanisms, such as traffic differentiation. Traffic differentiation is essential toprovide different levels of service quality regarding delivering of messages. Current proposalsto improve service delivery through traffic differentiation on DTNs are still under developmentor lack the proper testing and simulation. The main focus of these proposals is on buffermanagement mechanisms at each DTN node, instead of message prioritisation mechanisms.Message prioritisation allows some messages to be prioritised over others, improving thedelivery rate and, therefore, increasing the probability of a message being correctly delivered.The present thesis implements traffic differentiation in DTNs based on prioritisation strategies,assuming a clear alternative to other buffer management proposals and message prioritisation.Using The One simulation tool, three popular DTNs routing protocols (Epidemic,Spray & Wait, and PRoPHET) are adapted to comply with traffic differentiation. The DTNstraffic prioritisation objective is achieved by designing, implementing and testing four distinctalgorithms that classify and order messages according to their priority levels. Thesealgorithms are based and extend some traditional traffic differentiation mechanisms, namelythe well-known Priority Queuing and Weighted Round Robin strategies.Results from the simulation tests corroborate that the delivery rate of the messages isaffected according to their priorities. Specifically, the simulation shows an increase in thedelivery rate of high priority messages, with low impact on the total number of messages delivered,comparatively to the same scenario without differentiation capabilities. To conclude,DTNs can effectively benefit from traffic differentiation based on message prioritisation techniques,being a promising approach to improve service quality levels in such scenarios.",
    "similarity": 0.3008715868618916
  },
  {
    "text1": "Nos últimos anos, tem surgido um grande interesse na aplicabilidade dastecnologias de Business Intelligence (BI) na área da saúde. A grande satisfaçãoresultante da sua implementação em outras áreas fez com que os profissionaisde saúde juntamente com os profissionais de Tecnologias de Informação(TI) cooperassem para a conceção e o desenvolvimento de plataformas de BIem ambiente clínico.A grande motivação para a sua implementação adveio da possibilidadede conceber um Sistema de Apoio à Decisão (SAD) médica, que suportasseo processo de tomada de decisão e que permitisse que este fosse realizado deforma mais rápida e eficaz. Além disso, com a implementação do ProcessoClínico Eletrónico, surgiu a necessidade de dar usabilidade aos dados dosutentes armazenados nas bases de dados, tornando-se isso possível com aimplementação da plataforma de BI.Neste projeto, incidiu-se numa área médica específica dentro da especialidadede Ginecologia e Obstetrícia, relacionada com a Interrupção Voluntáriada Gravidez (IVG), por ser uma unidade relativamente recente, onde nãoexiste nenhuma tecnologia semelhante implementada e, ainda, por ser umfoco de interesse para os profissionais de saúde. O local de estudo foi o CentroMaterno Infantil do Norte (CMIN), pertencente ao Centro Hospitalardo Porto (CHP), onde se teve acesso às fontes de dados necessárias para odesenvolvimento da plataforma de BI.Além disso, foram também desenvolvidos modelos de Data Mining (DM),igualmente integrados na plataforma de BI, que permitem prever quais asutentes que recorrem à IVG que constituem um grupo de risco e quais asutentes que necessitam de acompanhamento da equipa de enfermagem durante o processo da IVG. Os resultados obtidos foram bastante satisfatórios,uma vez que foram registados valores de 93% para a métrica da sensibilidadena questão relacionada com a probabilidade das utentes pertenceremao grupo de risco, e valores de 91% e de 87% para a sensibilidade e acuidade,respetivamente, no problema relacionado com a previsão do local derealização de uma das etapas do processo de IVG.Na seleção da tecnologia a utilizar para o desenvolvimento da plataformade BI, optou-se pelo Pentaho BI Suite, depois de realizada uma pesquisaaprofundada sobre ferramentas open source.Após a implementação da plataforma de BI, pode-se afirmar que o resultadofoi satisfatório, uma vez que todos os indicadores de desempenhorequisitados foram apresentados. Nestes indicadores, estão incluídos a distribuiçãodas utentes por idades, por profissão, por localidade, pela presençana última consulta de avaliação, entre outros. Além disso, a informação representadaé credível, pois esta foi submetida a um processo de validação porparte dos profissionais de saúde.",
    "text2": "O controlo e a prevenção de infeções nosocomiais são essenciais para aredução de custos, bem como para a melhoria dos cuidados prestados numainstituição de saúde. Por outro lado, o tratamento de dados que permitamcompreender, caracterizar e monitorizar as infeções possibilita um controloe uma prevenção mais eficaz das mesmas. Sendo um método automatizadoe eficiente para o tratamento de dados, a tecnologia de Business Intelligencepermite a extração de informação importante para gerar conhecimento quepode auxiliar o processo de tomada de decisão dos profissionais de saúde.O principal objetivo deste trabalho é o desenvolvimento e implementaçãode uma plataforma de Business Intelligence que permita o estudo da incidênciade infeção nosocomial nas Unidades de Medicina do Centro Hospitalardo Porto. Este estudo é feito através da apresentação de um conjunto deindicadores clínicos (informações importantes extraídas dos dados referentesa infeções nosocomiais) que ajudam a analisar e caracterizar estas infeções.Por conseguinte, depois de identificados os indicadores relevantes, torna-sepertinente desenvolver um sistema que permita tratar os dados, extrair osindicadores destes e apresentá-los, de forma atrativa, na plataforma. Porsua vez, a plataforma facilita a análise das informações que disponibiliza,apoiando a tomada de decisões, nomeadamente através da identificação dosprincipais fatores de risco. Assim, o sistema atua como um Sistema de Apoioà Decisão Clínica, podendo auxiliar no controlo e prevenção destas infeções.Pretende-se ainda estudar a aplicabilidade da tecnologia de Data Miningna criação de modelos de classificação capazes de prever a ocorrência deinfeções nosocomiais, na presença de determinados fatores de risco.O conhecimento obtido com a análise dos indicadores e as previsões efetuadaspode possibilitar a diminuição da incidência de infeção nosocomiale, consequentemente, a redução dos custos associados à sua ocorrência, bemcomo o aumento da segurança e do bem-estar dos doentes, ao permitir a tomadade decisões mais fundamentadas. A aplicação de Business Intelligencena área da saúde contribui para melhorar não só o fluxo de trabalho diárionas unidades de saúde, como também a qualidade dos cuidados prestados.",
    "similarity": 0.30941142590713366
  },
  {
    "text1": "The rapid adoption of microservices and cloud-native architectures has revolutionized the way modernapplications are developed and deployed. However, this shift has introduced new challenges in termsof ensuring the reliability and performance of these distributed systems. In response, observability isproposed as a new methodology to address these challenges.Observability refers to the collection of telemetry data (including traces, metrics, and logs) from asystem components in real time, allowing for a comprehensive understanding of its internal status andbehavior. This capability is essential for troubleshooting, performance optimization, and enhancing systemreliability by facilitating the detection of errors and anomalies.The main objective of this thesis is to implement an observability concept within a Python Flask based system. The system follows a cloud-native, microservices, and event-driven architecture. The mainmotivation for this study is the recent, but important development of observability and the culture ofDevelopment and Operations (DevOps).The chosen method for implementation is OpenTelemetry, a neutral and open-source approach toobservability. This decision aims to avoid vendor lock-in, which can be a concern with vendor-specificagents.Furthermore, a study is carried out to make a choice among the vendors considered which are compat ible with OpenTelemetry, e.g. Jaeger, Zipkin, Prometheus, Elastic Search, New Relic, Datadog, Dynatrace,Grafana, Splunk, and AppDynamics. Each vendor offers different approaches to observability and visual ization of the telemetry data. In addition, a weighted decision matrix is used to aid in the decision alongwith a decision criterion defined by the development team.The results of this study not only highlight the vendor selection process for telemetry data visualizationbut also emphasize that OpenTelemetry is a viable and standardized approach to observability, offering aneffective means to prevent vendor lock-in.",
    "text2": "Public lighting, despite being one of the most important services a city must provide, it is also one of the main sources of energy consumption and consequently running costs. One way to drastically improve the efficiency of these systems is by using object detection in order to make each of the public lighting poles aware of their surroundings, giving them the ability to adapt to the environment. This is one of the main goals of an industry leader company's project in the area of public lighting, where this study is inserted. In this project, each public lighting pole is upgraded with a set of sensors: radar, microphone and camera(what we refer to as fog computing). By developing a multimodal machine learning model, the goal is to leverage the data from the different sensors to improve the object detection capabilities of traditional unimodal machine learning model. Additionally, the developed model will be deployed into an edge device that is also installed in the public lighting pole, due to data privacy concerns and network latency problems that would otherwise occur with traditional server-side approaches. This constrain raises the main question that this study will try to answer, which is how to develop a complex multimodal machine learning model for low-power efficient edge devices. In this study, a multi-agent architecture will be proposed, that authors can adapt to their own multimodal machine learning problems with edge devices. To prove the efficient of the proposed system, a proof of concept implementation will be carried out that involves the aforementioned sensors, as well as the You Only Look Once (YOLO) object detection model, with a feature-level data fusion approach. Finally, the implemented system will be deployed to an edge device, where the hardware performance will be tested and compared to similar work in the literature.",
    "similarity": 0.30466073205497135
  },
  {
    "text1": "A violência tem sido parte integrante da humanidade. Existem diferentes tipos de violência, sendo a violênciade cariz físico mais recorrente no nosso quotidiano, afetando cada vez mais a vida de muitas pessoas.O reconhecimento da ação humana tem sido crescentemente estudada nos últimos anos. O áudio (microfones)e vídeo (câmaras) são as formas mais utilizadas na captação de violência. O reconhecimento da ação humanaatravés do vídeo representa uma importante área na visão por computador. No entanto, a captação de vídeo requeruma grande capacidade de processamento e de desempenho, tanto de hardware como software. O áudio surgeassim como um fator capaz de colmatar estes problemas. No entanto, a deteção de áudio é altamente suscetívela grandes flutuações de precisão, dependendo do ambiente acústico em que está inserido.Na presente dissertação, pretendeu-se comparar os diferentes algoritmos de Machine Learning com o intuitode averiguar qual o melhor algoritmo a utilizar para detetar violência em áudio.A revisão da literatura revelou que o áudio pode ser classificado usando algoritmos de Machine Learning, sendoa sua conversão em imagens (mel spectrogram) a metodologia habitualmente utilizada, tendo sido a abordagemtomada. Além disto, estudaram-se os algoritmos frequentemente utilizados na classificação de áudio, tendo estessido utilizados para posterior avaliação.Os resultados obtidos demonstram um bom desempenho das redes neuronais EfficientNet, sendo que as redesque obtiveram melhor precisão foram a EfficientNetB1 e EfficientNetB0, com 95.06% e 94.19%, respetivamente.Adicionalmente, verificou-se que a rede MobileNetV2 é a mais incapaz de classificar entradas de violência, comuma classificação de 92.44%.A rede neuronal EfficientNetB1 apresentou uma melhor capacidade na classificação de violência em áudio.",
    "text2": "No presente trabalho foi desenvolvida uma solução de apoio a pessoas idosas, doentesou com limitações físicas, baseada em técnicas de aprendizagem automática e visão porcomputador. Os modelos de aprendizagem profunda utilizados resolvem problemas declassificação de imagens. Para desenvolver a solução proposta foi utilizada a linguagemPython e as bibliotecas TensorFlow, MediaPipe e OpenCV. Antes de treinar os modelos deaprendizagem automática, foram aplicadas técnicas de pré processamento às imagens,para as preparar para os modelos classificadores. A solução final desenvolvida combinaduas tarefas de classificação diferentes: a estimação da pose humana e o reconhecimentode expressões faciais. Para estimar a pose humana, primeiro utilizou-se um algoritmoque identifica a posição das articulações do corpo, sendo estas posições posteriormenteclassificadas com uma rede neuronal convolucional em três classes, queda, sentado e empé/a andar. Para efetuar o reconhecimento de expressões faciais utilizaram-se dois tiposde dados, os atributos de cor dos pixeis das imagens e os pontos de referência das facespreviamente identificadas. Estes dados foram depois classificados por uma rede neuronalhíbrida, que inclui uma rede completamente ligada a uma rede convolucional. A soluçãofinal proposta combina estes dois modelos, o que permite a partir de uma imagem de umapessoa, gerar um aviso se o modelo de estimação da pose detetar uma queda ou quando omodelo de reconhecimento de expressões faciais identificar uma expressão de dor. O modelode estimação da pose identificou a classe queda com uma precisão de 97%, um recall de 98%e uma acurácia de 97%. A expressão de dor foi identificada pelo modelo de reconhecimentode expressões faciais com uma precisão de 82%, um recall de 86% e uma acurácia de 92%.O maior desafio no reconhecimento da expressão foi a deteção da face nas imagens.",
    "similarity": 0.31121504193071
  },
  {
    "text1": "Emergency departments have a higher number of visits compared to other hospital de partments. Technology has played a crucial role in promoting improvements in hospitalmanagement and clinical performance. The number of visits to emergency departments hasincreased considerably, giving rise to crowding situations that cause several adverse effects.This situation negatively affects the provision of emergency services, impairs the quality ofhealth care and increases the time patients wait for medical check-up. One of the leadingcauses contributing to the crowding is the high number of patients with low severity clinicalcondition. These are referred to as non-urgent or inappropriate patients, whose clinicalsituation should be taken care through self-care or primary health care.It is the responsibility of the institutions to analyse and quantify the possible causes ofcrowding to find the best solution to mitigate the adverse effects caused. It is believed thatnon-urgent patients can use the time spent in the waiting room more productively, namelyby using a self-service kiosk to which they can provide valuable information to facilitate andaccelerate the clinical processing.This work proposes a solution to be used in the waiting room of emergency departments,which aims to reduce the period of medical check-up. The solution uses a self-service kioskfor the patient to provide relevant clinical data that would otherwise have to be collectedby the physician during the clinical observation process. In particular, the kiosk will collectvital signs, past medical history, main complaint and usual medication. This data willbe processed and provided to the physician in a structured and uniform way before eachmedical check-up. The primary purpose of this solution is to reduce the period of patients’medical check-up and thus improve the response capacity of the emergency departmentswith the same resources.During the Master’s work period, an Android application was implemented for patientsto enter the clinical data mentioned above, and a Web application for physicians to access it.Additionally, a data warehouse was implemented to store the data in a consolidated wayto discover hidden relationships and patterns in the data. The first moment of evaluation,undertaken in a non-hospital facility, shows positive acceptability by participants, with alarge majority considering the system user-friendly. Due to the pandemic, it was impossibleto perform the second planned evaluation moment in a real emergency environment.",
    "text2": "A healthcare institution produces huge amounts of data on a daily basis. These data come from n sourcesand therefore have m different formats. As it is evident, this heterogeneity of information sources can be a hugeobstacle, since increases the need for this information to be available and shared among the various informationsystems. The exchange of clinical information between Health Information System (HIS) is crucial for the effectiveprovision of care, significantly improving the performance of the institutions.In the healthcare industry, the ability of different information and software systems to communicate and sharedata, as well as use the data exchanged, is called interoperability. This knowledge can be exchanged aroundthe healthcare ecosystem thanks to the use of standards and data sharing models, regardless of the applicationbeing used. However, the lack of interoperability remains a concern. The Agency for the Integration, Diffusionand Archive (AIDA) proposes to achieve levels of interoperability never before implemented. For this purpose,web services are used for the processing, dissemination, and archiving of clinical information.In the context of this master’s dissertation, the aim is to develop and explore new information technologyartefacts to help the administrative and accounting teams of the Hospital da Santa Casa da Misericórdia deVila Verde. This solution aims to fill the existing gaps between the hospital and the Assistência na Doençaaos Servidores do Estado (ADSE). The first gap occurs in the dentistry speciality, where it is not possible toverify the patient’s ADSE status to perform some dental medicine act under co-payment. The second gapoccurs in the invoicing process through ADSE in real-time, in order to perform some medical appointmentsand/or acts resulting from them since the hospital’s accounting team cannot verify if a patient complies with theADSE requirements. The gaps identified can make ADSE refuse to reimburse the hospital for the medical actsperformed, which makes the administrative and accounting work unpleasant. In this situation, the hospital willhave to find a solution that suits the patient and the ADSE. Very often, the hospital has to bear the costs.In order to overpass these problems with the validation and invoicing process of medical acts through ADSE,this project consists of two web applications that enable the hospital’s information systems to interoperate withthe ADSE web service.",
    "similarity": 0.3274220914127424
  },
  {
    "text1": "Emergency departments have a higher number of visits compared to other hospital de partments. Technology has played a crucial role in promoting improvements in hospitalmanagement and clinical performance. The number of visits to emergency departments hasincreased considerably, giving rise to crowding situations that cause several adverse effects.This situation negatively affects the provision of emergency services, impairs the quality ofhealth care and increases the time patients wait for medical check-up. One of the leadingcauses contributing to the crowding is the high number of patients with low severity clinicalcondition. These are referred to as non-urgent or inappropriate patients, whose clinicalsituation should be taken care through self-care or primary health care.It is the responsibility of the institutions to analyse and quantify the possible causes ofcrowding to find the best solution to mitigate the adverse effects caused. It is believed thatnon-urgent patients can use the time spent in the waiting room more productively, namelyby using a self-service kiosk to which they can provide valuable information to facilitate andaccelerate the clinical processing.This work proposes a solution to be used in the waiting room of emergency departments,which aims to reduce the period of medical check-up. The solution uses a self-service kioskfor the patient to provide relevant clinical data that would otherwise have to be collectedby the physician during the clinical observation process. In particular, the kiosk will collectvital signs, past medical history, main complaint and usual medication. This data willbe processed and provided to the physician in a structured and uniform way before eachmedical check-up. The primary purpose of this solution is to reduce the period of patients’medical check-up and thus improve the response capacity of the emergency departmentswith the same resources.During the Master’s work period, an Android application was implemented for patientsto enter the clinical data mentioned above, and a Web application for physicians to access it.Additionally, a data warehouse was implemented to store the data in a consolidated wayto discover hidden relationships and patterns in the data. The first moment of evaluation,undertaken in a non-hospital facility, shows positive acceptability by participants, with alarge majority considering the system user-friendly. Due to the pandemic, it was impossibleto perform the second planned evaluation moment in a real emergency environment.",
    "text2": "One of the reasons for the increased number of visits to emergency departments is theprimary health care inability to handle urgent needs and provide all the health servicesneeded to assess complex conditions. A significant amount of these visits are due to theabnormal flow of patients whose clinical condition is of low severity and could ideally beresolved with self-care and primary health care.The crowding in emergency departments causes operational and logistical problems andhas undesirable consequences for patients, health professionals and hospitals. Delays intreatment interventions and increased mortality, medical errors and waiting times are just aphew examples of critical consequences that can occur, resulting in a significant barrier tothe quality of health care delivery.With the advances in technology, several institutions have found in self-service an alternativefor the patient’s collection of health information autonomously. These devices can be usedby low clinical severity patients (with the blue, green or yellow bracelets from Manchestertriage) to reduce waiting time in the emergency departments.This dissertation proposes a technological solution to improve both the time and qualityof the anamnesis procedure performed by medical staff in the emergency department. Theintroduction of a self-service kiosk in the emergency department waiting room will make itpossible to quickly and intuitively collect the patient’s past medical history, usual medication,main complaint symptoms and vital signs. Subsequently, this data will be made availableto the physician before each clinical observation. The hypothesis considered is that byproviding a selective, structured and uniform anamnesis information’s presentation of eachpatient, medical staff observation can proceed much faster and accurately, focusing on theconfirmation of the most relevant aspects. The primary purpose of this solution is to reducethe period of clinical observation and thus improve the response capacity of the emergencydepartment with the same resources.",
    "similarity": 0.356380826207395
  },
  {
    "text1": "Many people believe that information technology has the potential to change the way the healthcare industry approaches its current challenges by improving healthcare quality, safety, and efficiency by bringing decision support to the point of care and enabling routine quality measurement. In the medical field, healthcare information technology refers to any information technology tool or software that is intended to increase hospital and administrative productivity, provide new information about medications and treatments, or improve overall quality of care. Infrastructures in hospitals must manage both information technology and specialized healthcare systems and protocols. It is important in this type of structure to ensure that all operations and information technology run smoothly and one of the ways to achieve this is by continuously and automatically monitor the hospital environment’s systems. The right monitoring and reporting tools can help keep medical staff efficient without worrying about failing systems, provide visibility into usage trends, equipment performance, downtime, and much more, saving time and resources. A monitoring application of this type is regarded as an important source of information. The main goal of this Dissertation within the scope of this project is to develop a monitoring web platform for healthcare information technology administrators that is based on a multi-site and multi-organization scheme. The proposed solution will monitor various hospital services and is expected to provide the current state of the system in a timely manner through a set of graphs and reports, allowing for appropriate operational decisions and ensuring that the system functions as expected. A web application for monitoring hospital services was developed, implemented, and evaluated during the dissertation work period. Using questionnaires, the platform was evaluated and validated in order to understand if this approach may improve information technology availability and, in the long run, alleviate some of the healthcare industry’s pains. A formal evaluation of the solution was also performed, which comprised a strengths, weaknesses, opportunities and threats analysis and a risk assessment report, both of which gave helpful insights into the system’s strengths and shortcomings, as well as potential improvement areas.",
    "text2": "Information systems are continuously evolving in nature and complexity. Infrastructure concerns such as availability, efficiency, and disaster recovery have been some of the most important drivers regarding how infrastructure is planned and executed. As these mechanisms evolved, so did the underlying foundation for their functioning — Information Technology (IT) infrastructure monitoring. Inside the healthcare environment, it is important to discuss IT infrastructure monitoring and disaster prevention and recovery since availability and communication are vital for the proper functioning of healthcare units, whether acting in isolation or on a network. When acting on a network, it is especially important to be able to easily monitor and observe each unit from a single point of access so that actions can be swiftly taken when there is a problem. Considering the wide range of available solutions and heterogeneous nature of IT infrastructure, even within the healthcare industry, the majority of the solutions either focus too much on a particular problem of some industry, healthcare or not, or are too generic and can’t fulfill the needs of an increasingly connected and interdependent healthcare industry. This Dissertation proposes a web and microservices-based IT infrastructure monitoring backend solution with a multi-site and multi-organization scheme at its core that is designed to be scalable, easily deployed and integrated with existing tools, and simple to further extend and improve. This solution has two main components, one server which is the central point of the solution, the guardian server, and the other one, which is the local client to be installed on each organization’s infrastructure. The produced backend solution was tested and validated in two healthcare organizations which provided useful feedback and a positive answer to the usefulness of a monitoring solution, such as the one developed in this Dissertation, in improving the efficiency and reliability of the organizations’ IT infrastructure and, therefore, their healthcare services. A formal evaluation of the solution was also carried out with a combination of a Strengths, Weaknesses, Opportunities and Threats (SWOT) analysis and a risk assessment report, both mechanisms providing useful insights on the strengths and limitations of the solution, as well as possible improvement points.",
    "similarity": 0.33127819548872184
  },
  {
    "text1": "Nowadays, the ability to predict protein functions directly from amino-acid sequences alone remains a major biological challenge. The understanding of protein properties and functions is extremely important and can have a wide range of biotechnological and medical applications.Technological advances have led to an exponential growth of biological data challenging conventionalanalysis strategies. High-level representations from the field of deep learning canprovide new alternatives to address these problems, particularly NLP methods, such as wordembeddings, have shown particular success when applied for protein sequence analysis.Here, a module that eases the implementation of word embedding models toward proteinrepresentation and classification is presented. Furthermore, this module was integrated in theProPythia framework, allowing to straightforwardly integrate WE representations with the trainingand testing of ML and DL models.This module was validated using two protein classification problems namely, identification ofplant ubiquitylation sites and lysine crotonylation site prediction. This module was further usedto explore enzyme functional annotation. Several WE were tested and fed to different ML andDL networks. Overall, WE achieved good results being even competitive with state-of-the-artmodels, reinforcing the idea that language based methods can be applied with success to awide range of protein classification problems.This work presents a freely available tool to perform word embedding techniques for proteinclassification. The case studies presented reinforce the usability and importance of using NLPand ML in protein classification problems.",
    "text2": "One of the challenging problems in bioinformatics is to computationally characterize sequences, structures and functions of proteins. Sequence-derived structural and physico-chemical properties of proteins have been used in the development of machine learning models in protein related problems. However, tools and platforms to calculate features and perform Machine learning (ML) with proteins are scarce and have their limitations in terms of effectiveness, user-friendliness and capacity. Here, a generic modular automated platform for the classification of proteins based on their physicochemical properties using different ML algorithms is proposed. The tool developed, as a Python package, facilitates the major tasks of ML and includes modules to read and alter sequences, calculate protein features, preprocess datasets, execute feature reduction and selection, perform clustering, train and optimize ML models and make predictions. As it is modular, the user retains the power to alter the code to fit specific needs. This platform was tested to predict membrane active anticancer and antimicrobial peptides and further used to explore viral fusion peptides. Membrane-interacting peptides play a crucial role in several biological processes. Fusion peptides are a subclass found in enveloped viruses, that are particularly relevant for membrane fusion. Determining what are the properties that characterize fusion peptides and distinguishing them from other proteins is a very relevant scientific question with important technological implications. Using three different datasets composed by well annotated sequences, different feature extraction techniques and feature selection methods (resulting in a total of over 20 datasets), seven ML models were trained and tested, using cross validation for error estimation and grid search for model selection. The different models, feature sets and feature selection techniques were compared. The best models obtained for distinct metric were then used to predict the location of a known fusion peptide in a protein sequence from the Dengue virus. Feature importances were also analysed. The models obtained will be useful in future research, also providing a biological insight of the distinctive physicochemical characteristics of fusion peptides. This work presents a freely available tool to perform ML-based protein classification and the first global analysis and prediction of viral fusion peptides using ML, reinforcing the usability and importance of ML in protein classification problems.",
    "similarity": 0.31979035507428866
  },
  {
    "text1": "Nowadays many mathematical applications allow the user to introduce its own equationsin the system and also observe through different possibilities the desired results. Regardingphysics, an extended range of virtual laboratories allow the user to accomplish virtualphysics experiments. These virtual laboratories consist in predefined scenarios where theuser can change the value of the physics variables and then visualise the changes accomplished.Other virtual laboratories uses a physics engine allowing the user to create itsown scenarios. However, the physical behaviour of the objects is hardcoded since it resultsstrictly on the physics equations used internally by the physics engine.This dissertation pretends to investigate how far and with what degree of scientific rigorit is possible to associate the idea of the user introducing its own equations with the idea ofaccomplishing virtual experiments of physics. As a proof of concept, this dissertation focuson a specific area of mechanics: the dynamic of rigid bodies. The result of this research isa virtual laboratory completely different relatively the others.Our system has no knowledge about physics. Even the most general laws of physicssuch as the Newton’s second law are not known by the system. To the system, any equationintroduced is considered just as one more equation without any particular meaningassociated to it. The same happens for any physics entity. For example, if the gravitationalacceleration is introduced by the user, to the system it is just another attribute of the world.Taking into account the dynamics of rigid bodies, an object can be identified as being, atany time, in one of three different states. These are: when a object is not in contact withany other, when an object collides with another object and they immediately separate, andwhen two objects remain in contact over time. The user must specify all the equations thatdrive each of these three states. Using its geometrical knowledge, the engine determines atany time in which state an object is. Also, the system provides all the relevant geometricalinformation. For instance, in a collision between two objects, the point and the two normalsvectors of the collision are provided.The graphical simulations reflects strictly on the equations introduced. Therefore, ifthe equations to solve a collision between two objects does not reflect the real underlyingphysics of the situation, it is possible that the objects simply ends-up penetrating eachother. All the relevant numerical information about an experience can be processed throughdifferent forms. In fact, the user can request plots of variables, the graphical application ofvectors on objects, and even the tracing of the variables at a specific event.",
    "text2": "Current identity management systems rely on centralized databases to store user’s personal data, which posesa great risks for data security, as these infrastructure create a critical point of failure for the whole system. Besidethat service providers have to bear huge maintenance costs and comply with strict data protection regulations.Self-sovereign identity (SSI) is a new identity management paradigm that tries to answer some of theseproblems by providing a decentralized user-centric identity management system that gives users full control oftheir personal data. Some of its underlying concepts include Decentralized Identifiers (DIDs), Verifiable Claimsand Credentials. This approach does not rely on any central authority to enforce trust as it often uses Blockchainor other Decentralized Ledger Technologies (DLT) as the trust anchor of the system, although other decentralizednetwork or databases could also be used for the same purpose.This thesis focuses on finding alternative solutions to DLT, in the context of SSI. Despite being the most usedsolution some DLTs are known to lack scalability and performance, and since a global identity managementsystem heavily relies on these two requirements it might not be the best solution to the problem.This document provides an overview of the state of the art and main standards of SSI, and then focuses ona non-DLT approach to SSI, referencing non-DLT implementations and alternative decentralized infrastructuresthat can be used to replace DLTs in SSI. It highlights some of the limitations associated with using DLTs foridentity management and presents a SSI framework based on decentralized names systems and networks. Thisframework couples all the main functionalities needed to create different SSI agents, which were showcased ina proof of concept application.",
    "similarity": 0.30570530577455785
  },
  {
    "text1": "Nowadays many mathematical applications allow the user to introduce its own equationsin the system and also observe through different possibilities the desired results. Regardingphysics, an extended range of virtual laboratories allow the user to accomplish virtualphysics experiments. These virtual laboratories consist in predefined scenarios where theuser can change the value of the physics variables and then visualise the changes accomplished.Other virtual laboratories uses a physics engine allowing the user to create itsown scenarios. However, the physical behaviour of the objects is hardcoded since it resultsstrictly on the physics equations used internally by the physics engine.This dissertation pretends to investigate how far and with what degree of scientific rigorit is possible to associate the idea of the user introducing its own equations with the idea ofaccomplishing virtual experiments of physics. As a proof of concept, this dissertation focuson a specific area of mechanics: the dynamic of rigid bodies. The result of this research isa virtual laboratory completely different relatively the others.Our system has no knowledge about physics. Even the most general laws of physicssuch as the Newton’s second law are not known by the system. To the system, any equationintroduced is considered just as one more equation without any particular meaningassociated to it. The same happens for any physics entity. For example, if the gravitationalacceleration is introduced by the user, to the system it is just another attribute of the world.Taking into account the dynamics of rigid bodies, an object can be identified as being, atany time, in one of three different states. These are: when a object is not in contact withany other, when an object collides with another object and they immediately separate, andwhen two objects remain in contact over time. The user must specify all the equations thatdrive each of these three states. Using its geometrical knowledge, the engine determines atany time in which state an object is. Also, the system provides all the relevant geometricalinformation. For instance, in a collision between two objects, the point and the two normalsvectors of the collision are provided.The graphical simulations reflects strictly on the equations introduced. Therefore, ifthe equations to solve a collision between two objects does not reflect the real underlyingphysics of the situation, it is possible that the objects simply ends-up penetrating eachother. All the relevant numerical information about an experience can be processed throughdifferent forms. In fact, the user can request plots of variables, the graphical application ofvectors on objects, and even the tracing of the variables at a specific event.",
    "text2": "Ataxia is a neurological sign indicative of dysfunction in the cerebellum, a part of the brain that coordinatesmovement. The typical symptoms include lack of balance when walking or standing, loss of limb coordination,change in speech, and difficulty with fine motor tasks, strongly affecting the person’s daily activities. Cerebellarataxia can be inherited or caused by other disorders such as stroke, multiple sclerosis, or cerebral palsy. Whilethere is no known cure for inherited ataxia, the symptoms can be managed through intensive and personalisedrehabilitation, including physical, speech, and occupational therapy.Physical therapy, also known as conventional therapy, is a standard practice in the rehabilitation of patients withataxia. It focuses on performing different physical exercises repeatedly, where a therapist monitors the session andregulates the intensity. Although effective, the repetitiveness of conventional therapy can become monotonous,besides being a very time-consuming process, which can be cumbersome for the therapist. Without any additionalstimulation and decreasing motivation, patients may experience stagnation or even drop out of therapy.Robot-assisted Gait Training (RAGT) is being introduced in the rehabilitation of persons with motor disabilities.This technology allows personalised and intensity-adapted training, which could benefit the patient’s recovery.However, this therapy can also become monotonous, so there is a need for more interactive and appealingstrategies. A possible solution to this problem is the development of exergames (serious games) and theirinclusion in robotic-assisted therapy. This can become advantageous since the robotic devices integrate severalsensors that read the patient’s movement and can be used as controllers in the game, allowing a more immersiveexperience.Considering this, this dissertation proposes two serious videogames, which were integrated into a roboticwalker, the WALKit Smart Walker, intended for gait ataxia rehabilitation. The first game is cognitive, whose goal isto react to a certain shape or sound as quickly as possible. With this game, it is intended to study the influenceof dual tasking on motor rehabilitation. The second game is a dynamic one whose goal is to incite the patient’sbalance control. This game uses an algorithm for torso orientation estimation to control an avatar holding twobuckets full of water. The main goal is to give patients biofeedback regarding their postural balance and to exercisetheir balance with specific events, or minigames, that encourage them to lean in a way that causes weight transfer.Both games were validated with healthy volunteers, in terms of functionality and usability. The results allowed toconclude that both were fun to play and showed potential to aid rehabilitation. Moreover, the results emphasisedthe relevance of customisation, replayability, and aesthetics in serious games. Future work includes the thoroughvalidation of both serious games with patients with cerebellar ataxia, to assess their effectiveness in rehabilitationalong with WALKit Smart Walker.",
    "similarity": 0.3011191135734072
  },
  {
    "text1": "The applications’ development paradigm has faced changes in recent years, with modern development being characterized by the need to continuously deliver new software iterations. With great affinity with those principles,microservices is a software architecture which features characteristics that potentially promote multiple qualityattributes often required by modern, large-scale applications. Its recent growth in popularity and acceptance inthe industry made this architectural style often described as a form of modernizing applications that allegedlysolves all the traditional monolithic applications’ inconveniences. However, there are multiple worth mentioning costs associated with its adoption, which seem to be very vaguely described in existing empirical research, being often summarized as \"the complexity of a distributed system\". The adoption of microservices provides theagility to achieve its promised benefits, but to actually reach them, several key implementation principles haveto be honored. Given that it is still a fairly recent approach to developing applications, the lack of establishedprinciples and knowledge from development teams results in the misjudgment of both costs and values of thisarchitectural style. The outcome is often implementations that conflict with its promised benefits. In order toimplement a microservices-based architecture that achieves its alleged benefits, there are multiple patterns andmethodologies involved that add a considerable amount of complexity. To evaluate its impact in a concrete andempirical way, one same e-commerce platform was developed from scratch following a monolithic architecturalstyle and two architectural patterns based on microservices, featuring distinct inter-service communication anddata management mechanisms. The effort involved in dealing with eventual consistency, maintaining a communication infrastructure, and managing data in a distributed way portrayed significant overheads not existent in thedevelopment of traditional applications. Nonetheless, migrating from a monolithic architecture to a microservicesbasedis currently accepted as the modern way of developing software and this ideology is not often contested, nor the involved technical challenges are appropriately emphasized. Sometimes considered over-engineering,other times necessary, this dissertation contributes with empirical data from insights that showcase the impact of the migration to microservices in several topics. From the trade-offs associated with the use of specific patterns, the development of the functionalities in a distributed way, and the processes to assure a variety of quality attributes, to performance benchmarks experiments and the use of observability techniques, the entire development process is described and constitutes the object of study of this dissertation.",
    "text2": "Software applications evolve over the years at a cost: their architecture modularity tends to be degraded. This happens mainly because software application maintenance often leads to architectural degradation. In this context, software architects need to elaborate strategies for detecting architectural degradation symptoms and thus maintaining the software architectural quality. The elaborations of these strategies often rely on tools with domain-specific languages (DSLs), which help them to specify software architecture rules. These tools also enforce the adherence of these rules in the evolving program. However, their adoption in mainstream software development is largely dependent on the usability of the language. Unfortunately, it is also often hard to identify their usability strengths and weaknesses early, as there is no guidance on how to objectively reveal them. Usability is a multi-faceted quality characteristic, which is challenging to quantify before a DSL is actually used by its stakeholders. There is even less support and experience on how to quantitatively evaluate the usability of DSLs used in software maintenance tasks. To this end in this dissertation, a usability measurement framework was developed based on the Cognitive Dimensions of Notations (CDN). The framework was evaluated both qualitatively and quantitatively using two textual DSLs for architecture rules in the context of two evolving object-oriented systems. The results suggested that the proposed metrics were useful: (1) to early identify the DSL usability limitations to be addressed, (2) to reveal specific features of the DSLs favoring software maintenance tasks, and (3) to successfully analyze eight usability dimensions that are critical in many DSLs. However, along with these results this evaluation also revealed that this kind of tools lack support for communication among the stakeholders, creating a gap in the software development. To solve this problem we proposed heuristics for tools that use DSLs for detecting architecture degradation symptoms. These heuristics will permit the exchange of information between the stakeholders, thereby, also increasing the tool usability. Finally, we chose TamDera as the tool to implement these heuristics in our study domain. Therefore, we implemented in the new version of TamDera the communication support for the stakeholders by using a new architecture and a new environment with the developed heuristics.",
    "similarity": 0.3054294764088824
  },
  {
    "text1": "A crescente utilização dos Sistemas de Informação (SI) nas unidades desaúde tem um papel muito importante para garantir a qualidade das mesmas.Com as Tecnologias da Informação e da Comunicação (TIC), os dadosarmazenados estão estruturados e organizados de forma a possibilitar umautilização rápida e e caz. O aumento de informações em formato eletrónicono processo de Registo Clínico (RC) apesar de diminuir em grande escalaerros que resultavam da utilização de dados mal entendidos, trouxe um desa o aos técnicos de informática médica. Esse desa o passa por melhorar aqualidade da prestação de cuidados de saúde utilizando a informação armazenada.É neste âmbito que surgem as normas e sistemas de nomenclatura quepossibilitam uma uniformização do RC de forma a evitar dados ambíguose permitir a comunicação entre diferentes pro ssionais de saúde e serviçoshospitalares. Estas normas são divididas conforme a sua nalidade, havendonormas de comunicação, imagem e representação.Pretende-se, neste contexto, implementar o Systematized Nomenclatureof Medicine (SNOMED) na Agência de Interoperação, Difusão e Arquivo(AIDA) no Centro Hospitalar do Alto Ave (CHAA) de forma a utilizar as suaspotencialidades no processo de uniformização do Registo Clínico Eletrónico(RCE).",
    "text2": "Cada vez mais a relação entre as tecnologias da informação e a saúde seestreitam. Concretamente, na neuroimagiologia, essa ligação tem vindo a tornar-se cada vezmais importante principalmente após o surgimento da imagem de Ressonância Magnética(MRI – Magnetic Ressonance Imaging).Com o desenvolvimento da tecnologia, para além das aquisições MRI convencionais, surgiramoutras técnicas como a aquisição de imagens de tensor de difusão (DTI – Diffusion TensorImaging) e da MRI funcional (fMRI). Estas técnicas permitem a obtenção de uma imageminterior do corpo. Um dos órgãos mais estudados com estas imagens é o cérebro, que é alvode vários estudos mas que devido à sua complexidade ainda é bastante desconhecido.Enquanto que com a MRI estrutural pode-se efetuar uma análise volumétrica às diferentesestruturas do cérebro, com a DTI é possível verificar a integridade da substância brancaatravés das fibras virtualmente criadas que representam o movimento das moléculas de água.Vários estudos referem os benefícios de uma análise multimodal com estas duas técnicas.Para tratamento e análise destas imagens é necessário uma gestão de várias aplicaçõesinformáticas que processam os dados e corregistam as imagens de forma automática. Um dosgrandes desafios consta, não só na utilização individual de cada ferramenta na qual é exigidoalgum conhecimento técnico, como na combinação das várias aplicações que apresentam osdados resultantes em diferentes formatos.Uma solução passa pela pesquisa e definição de fluxos de trabalho para que exista umaabordagem simples dos procedimentos a ter com as várias ferramentas e da sua combinaçãocom outras. No entanto, esta solução não impedirá o gasto de recursos de tempo e o trabalhomoroso de um estudo que contenha vários sujeitos.Assim, neste trabalho, para além de serem apresentados os vários fluxos de trabalho possíveispara análise multimodal, será exposto um módulo automatizado que será inserido numaaplicação de multimodalidade já existente: BrainCat.A presente dissertação apresenta um meio de facilitar as análises multimodais para que aqualidade quer a nível de investigação científica quer a nível dos diagnósticos clínicos aumente.",
    "similarity": 0.3147562012087635
  },
  {
    "text1": "As empresas do sector dos transportes públicos têm procurado introduzir novas tecnologiase aplicações com o objetivo de melhorar o serviço disponibilizado aos passageiros. Nestesentido, os operadores deste tipo de serviço têm investido no aumento da segurança econforto do passageiro, na diversificação das funcionalidades disponibilizadas, no acrescentode novos destinos ou paragens e na eficácia do cumprimento de horários planeados, entreoutros. Do lado das tecnologias de informação, uma das funcionalidades que mais temrecebido atenção é o sistema de informação e monitorização acessível aos utilizadores.Enquanto uma parte substancial da informação mantida por estes sistemas é atualizadapouco frequentemente, podendo ser, inclusive, denominada de informação de carácter fixo,os dados utilizados no sistema de monitorização devem ser atualizados o maisfrequentemente possível. Mas, o objetivo de aumentar a qualidade do serviço de informaçãoprestado melhorando a qualidade da monitorização do sistema, implica, em geral, custoselevados. No planeamento e construção de sistemas e aplicações de informação paramonitorização de serviços de transporte de passageiros numa escala urbana ou regional, aescolha do tipo de infra-estrutura que torna possível obter, processar e utilizar os dados emtempo real, ou com frequência funcionalmente útil, é, assim, fulcral. Uma má escolha dastecnologias associadas e dos sistemas que integram o serviço, podem tornar os custosinerentes à sua implementação no terreno insustentáveis e podem comprometer seriamente asustentabilidade das empresas do ramo.O presente trabalho começa com um estudo aprofundado das várias soluções e tecnologias jáexistentes no mercado, analisando-as criticamente. Desse estudo resultou o desafio deconceber uma proposta dum sistema aplicativo integrado de gestão de informação quedisponibiliza ferramentas para a gestão, optimização e administração do serviço detransportes públicos com base em tecnologias normalizadas, abertas e de sem custo deutilização.A solução desenhada, que se pretendeu modular e escalável, consiste num sistema integradobaseado inteiramente no protocolo Simple Network Management Protocol (SNMP) e que combina aplicações informáticas com a capacidade de obter dados em tempo real dosveículos e também disponibilizar informação diferenciada aos diversos intervenientes dosistema (passageiros, gestores, motoristas).Após a implementação e teste dum sistema completo de aplicações protótipo, fica provada aefetividade funcional da arquitetura proposta. Sendo esta solução modular e baseada numatecnologia normalizada e aberta e de utilização livre de direitos de autor, espera-se, emconsequência, que também seja eficaz no que concerne a eventuais custos de implementaçãoe adoção no mundo real.",
    "text2": "A população mundial está a envelhecer, sendo que, na Europa, 5% da população temmais de 80 anos e estima-se que este número venha a triplicar nos próximos 20 anos. Estaevolução traz consigo um novo conjunto de desafios sociais e económicos, nomeadamente noâmbito da prestação de cuidados médicos.Uma das vertentes mais importantes da prestação de cuidados médicos é amonitorização de pacientes. Os sensores biomédicos atuais são dispendiosos e funcionamcom sistemas computacionais protegidos pelos fabricantes, com tecnologias próprias nãopartilhadas. Assim, torna-se útil a definição dum novo paradigma capaz de diminuirrelevantemente os custos de aquisição, instalação e manutenção desses sistemas demonitorização.Nesta dissertação apresenta-se um modelo genérico de monitorização biomédicacapaz de ser implementado em unidades hospitalares, visando a recolha de dados sensoriaisbiomédicos, o seu pré-processamento e eventual integração numa base de dados global (numacloud local, por exemplo). A arquitetura permite a monitorização automática de pacientes devariados serviços de saúde com a menor intervenção humana possível, independentemente dotipo de sensor utilizado, com baixo custo de implementação e de aplicação universal.O sistema desenvolvido utiliza mecanismos normalizados para a representação dainformação a monitorizar assim como para a comunicação entre as entidades da arquitetura, eque são baseados nas tecnologias amplamente utilizadas para a gestão de redes Internet.Nomeadamente, foram criadas definições para novas bases de dados específicas paramonitorização e configuração de sensores biomédicos utilizando o paradigma dasManagement Information Bases. Além disso, o protocolo de comunicação entre as entidadesda arquitetura proposta é o Simple Network Management Protocol (SNMP).Como prova de conceito foi implementado, com sucesso, um protótipo que ilustra aarquitetura proposta, incluindo o hardware dum sensor biomédico básico de baixo custo e osoftware dum agente SNMP e duma simples aplicação biomédica capaz gerar alertas emsituações clinicamente pre-definidas por uma equipa médica.",
    "similarity": 0.3057546242516308
  },
  {
    "text1": "As empresas do sector dos transportes públicos têm procurado introduzir novas tecnologiase aplicações com o objetivo de melhorar o serviço disponibilizado aos passageiros. Nestesentido, os operadores deste tipo de serviço têm investido no aumento da segurança econforto do passageiro, na diversificação das funcionalidades disponibilizadas, no acrescentode novos destinos ou paragens e na eficácia do cumprimento de horários planeados, entreoutros. Do lado das tecnologias de informação, uma das funcionalidades que mais temrecebido atenção é o sistema de informação e monitorização acessível aos utilizadores.Enquanto uma parte substancial da informação mantida por estes sistemas é atualizadapouco frequentemente, podendo ser, inclusive, denominada de informação de carácter fixo,os dados utilizados no sistema de monitorização devem ser atualizados o maisfrequentemente possível. Mas, o objetivo de aumentar a qualidade do serviço de informaçãoprestado melhorando a qualidade da monitorização do sistema, implica, em geral, custoselevados. No planeamento e construção de sistemas e aplicações de informação paramonitorização de serviços de transporte de passageiros numa escala urbana ou regional, aescolha do tipo de infra-estrutura que torna possível obter, processar e utilizar os dados emtempo real, ou com frequência funcionalmente útil, é, assim, fulcral. Uma má escolha dastecnologias associadas e dos sistemas que integram o serviço, podem tornar os custosinerentes à sua implementação no terreno insustentáveis e podem comprometer seriamente asustentabilidade das empresas do ramo.O presente trabalho começa com um estudo aprofundado das várias soluções e tecnologias jáexistentes no mercado, analisando-as criticamente. Desse estudo resultou o desafio deconceber uma proposta dum sistema aplicativo integrado de gestão de informação quedisponibiliza ferramentas para a gestão, optimização e administração do serviço detransportes públicos com base em tecnologias normalizadas, abertas e de sem custo deutilização.A solução desenhada, que se pretendeu modular e escalável, consiste num sistema integradobaseado inteiramente no protocolo Simple Network Management Protocol (SNMP) e que combina aplicações informáticas com a capacidade de obter dados em tempo real dosveículos e também disponibilizar informação diferenciada aos diversos intervenientes dosistema (passageiros, gestores, motoristas).Após a implementação e teste dum sistema completo de aplicações protótipo, fica provada aefetividade funcional da arquitetura proposta. Sendo esta solução modular e baseada numatecnologia normalizada e aberta e de utilização livre de direitos de autor, espera-se, emconsequência, que também seja eficaz no que concerne a eventuais custos de implementaçãoe adoção no mundo real.",
    "text2": "Ao longo das últimas duas décadas a utilização de sistemas domóticos, num mundo cada vez maisconectado e tecnológico, tem vindo a revelar-se cada vez mais atrativo e com maior aceitação do públicoem geral. Novos produtos suportados por novos protocolos e tecnologias estão constantemente a serintroduzidos no mercado. No entanto, este desenvolvimento foi quase sempre efetuado sem grandepreocupação em definir regras e normas para que fosse possível a interoperacionalidade entre produtosde diferentes fabricantes, originando soluções pouco modulares, de elevado custo e forçando os clientes aescolher um ecossistema de um mesmo fabricante sem ser possível de forma rápida e facilitada integrartecnologias de vários fabricantes num mesmo sistema.O principal objetivo desta dissertação foi a definição de uma arquitetura integrada para sistemasdomóticos baseada no protocolo de gestão SNMP e que permitisse ultrapassar algumas das mais importantes limitações das soluções atuais para este tipo de sistema. Nesse sentido foi criada uma novaMIB domótica para implementação num agente SNMP integrador. Além disso, foi desenvolvido umnovo protocolo de gestão para dispositivos domóticos, mais simples que o SNMP e mais adequado paragestão de pequenos equipamentos sensores ou atuadores utilizados em sistemas domóticos. Este protocolo, designado por Light SNMP (L-SNMP), será utilizado na comunicação entre o agente SNMPe os dispositivos domóticos que implementam uma Light MIB (L-MIB) de domótica. No decorrer doprojeto foi criado um sistema protótipo com dispositivos domóticos implementando a L-MIB de domótica,um agente SNMPv2 implementando a MIB domótica e uma aplicação gestora SNMP que contém umsimples interface com o utilizador. As experiências realizadas com este protótipo permitiram confirmar acorreção funcional da solução e a sua viabilidade como alternativa tecnológica válida, potencialmente debaixo custo e com elevados níveis de interoperabilidade.",
    "similarity": 0.3057310120466405
  },
  {
    "text1": "Machine Learning (ML) gives a computer system the ability to perform a certain task without being explicitly programmed to do it. Although ML is not a new topic in the fieldof computer science, these techniques have been gaining increasing popularity due to advances in hardware (especially GPUs). More powerful hardware supports more efficienttraining and a more responsive end-system, once deployed. These algorithms have provento be particularly effective in image processing and feature detection, namely with deepneural networks.In the context of a vehicle, autonomous or not, perceiving its external and internal environment enables the ability to detect and identify left behind objects, its misuse or otherpotentially dangerous situations. This captured data is relevant to trigger vehicle intelligentresponses. Bosch is currently developing a system that has these capabilities and plans toleverage deep learning approaches to implement it.This work aimed to test and evaluate the suitability of a given embedded device forthe project. It also determined the best strategy to implement deep learning solutions inthe device. The supplied test bed was a NVidia Software Development Kit (SDK) systemfor the embedded NVidia Jetson TX2 device with the System-on-Chip (SOC) Parker, anheterogeneous computing chip with 2 Denver-cores (a NVidia implementation of ARM-64architecture), 4 CortexA57-cores (also ARM-64), 256 Pascal GPU-cores and support for up to6 video cameras. The SDK includes several software library packages, including for imageprocessing and ML.With the goal of fully exploiting the embedded device compute capabilities, this workstudied several inference frameworks, going as far as implementing an inference enginefrom scratch (named Deeploy) that produces inferences based on two libraries providedby NVidia: cuDNN and TensorRT. Deeploy was evaluated against well known and established frameworks, namely Tensorflow, PyTorch and Darknet, in terms of efficiency, resourcemanagement and overall ease of use, maintainability and flexibility. This work also exploited key performance related features available on the device, such as power modes,half-precision floating point computation and the implemented shared memory architecture between the GPU-cores and the CPU-cores.",
    "text2": "The 2D convection-diffusion is a well-known problem in scientific simulation that often usesa direct method to solve a system of N linear equations, which requires N3 operations.This problem can be solved using a more efficient computational method, known as thealternating direction implicit (ADI). It solves a system of N linear equations in 2N times withN operations each, implemented in two steps, one to solve row by row, the other column bycolumn. Each N operation is fully independent in each step, which opens an opportunity toan embarrassingly parallel solution. This method also explores the way matrices are stored incomputer memory, either in row-major or column-major, by splitting each iteration in two.The major bottleneck of this method is solving the system of linear equations. Thesesystems of linear equations can be described as tridiagonal matrices since the elements arealways stored on the three main diagonals of the matrices. Algorithms tailored for tridiagonalmatrices, can significantly improve the performance. These can be sequential (i.e. the Thomasalgorithm) or parallel (i.e. the cyclic reduction CR, and the parallel cyclic reduction PCR).Current vector extensions in conventional scalar processing units, such as x86-64 andARM devices, require the vector elements to be in contiguous memory locations to avoidperformance penalties. To overcome these limitations in dot products several approachesare proposed and evaluated in this work, both in general-purpose processing units and inspecific accelerators, namely NVidia GPUs.Profiling the code execution on a server based on x86-64 devices showed that the ADImethod needs a combination of CPU computation power and memory transfer speed. Thisis best showed on a server based on the Intel manycore device, KNL, where the algorithmscales until the memory bandwidth is no longer enough to feed all 64 computing cores. Adual-socket server based on 16-core Xeon Skylakes, with AVX-512 vector support, proved tobe a better choice: the algorithm executes in less time and scales better.The introduction of GPU computing to further improve the execution performance (andalso using other optimisation techniques, namely a different thread scheme and sharedmemory to speed up the process) showed better results for larger grid sizes (above 32Ki x32Ki). The CUDA development environment also showed a better performance than usingOpenCL, in most cases. The largest difference was using a hybrid CR-PCR, where the OpenCLcode displayed a major performance improvement when compared to CUDA. But even withthis speedup, the better average time for the ADI method on all tested configurations on aNVidia GPU was using CUDA on an available updated GPU (with a Pascal architecture) andthe CR as the auxiliary method.",
    "similarity": 0.3018171745152355
  },
  {
    "text1": "The amount of data in information systems is growing constantly and, as a consequence, thecomplexity of analytical processing is greater. There are several storage solutions to persistthis information, with different architectures targeting different use cases. For analyticalprocessing, storage solutions with a column-oriented format are particularly relevant dueto the convenient placement of the data in persistent storage and the closer mapping toin-memory processing.The access to the database is typically remote and has overhead associated, mainly whenit is necessary to obtain the same data multiple times. Thus, it is desirable to have a cacheon the processing side and there are solutions for this. The problem with the existing so lutions is the overhead introduced by network latency and memory-copy between logicallayers. Remote Direct Memory Access (RDMA) mechanisms have the potential to help min imize this overhead. Furthermore, this type of mechanism is indicated for large amounts ofdata because zero-copy has more impact as the data volume increases. One of the problemsassociated with RDMA mechanisms is the complexity of development. This complexity isinduced by its different development paradigm when compared to other network commu nication protocols, for example, TCP.Aiming to improve the efficiency of analytical processing, this dissertation presents a dis tributed cache that takes advantage of RDMA mechanisms to improve analytical processingperformance. The cache abstracts the intricacies of RDMA mechanisms and is developedas a middleware making it transparent to take advantage of this technology. Moreover, thistechnique could be used in other contexts where a distributed cache makes sense, such asa set of replicated web servers that access the same database.",
    "text2": "The trend of increasing size of datasets in storage-based applications has promoted the research of newmethods and technologies for efficiently storing, processing, and analyzing large amounts of data. As aresult, Log Structured Merge (LSM) Key-Value Stores (KVSs) have been highly adopted since theirdesign allows high write throughput and enforces sequential disk access patterns. Additionally, with theadvent of Non-Volatile Main Memory (NVMM), new storage technologies have emerged that offerfaster access times compared to traditional block-based storage devices, thus accelerating KVSs.However, while NVMM devices offer faster access to data, they are typically limited in capacity and areoften more expensive. To address this trade-off, contemporary storage solutions harness the capabilities ofheterogeneous storage devices in two fundamental manners: caching and tiering. In this dissertation, weshow that, on one hand, read-dominated workloads benefit from a caching approach, but their performancedegrades under tiering. On the other hand, for write-dominated workloads, the tiering approach presentsbetter performance, while storing the entire dataset on NVMM actually degrades performance.To overcome these challenges, this dissertation proposes KEIGO, a novel storage middleware that al lows LSM-based KVS to efficiently use storage hierarchies composed of NVMM and block-based devices.KEIGO is aware of the different I/O operations done by the KVS (e.g., foreground requests, and backgroundflushes and compactions) and the characteristics of the underlying devices (e.g., concurrency, read/writeasymmetry). This knowledge serves as a pivotal factor in optimizing KEIGO’s performance in the face ofdynamic and mixed production workloads such as those observed in Nutanix and Meta. Moreover, KEIGOrequires minimal code modifications to integrate into production-ready LSM KVSs.Conducted experiments show that KEIGO significantly enhances the throughput of LSM KVS solu tions, including RocksDB, Speedb, and LevelDB, by as much as 12.4×. Furthermore, it substantiallyreduces tail latency by up to 21.3× over both general-purpose storage solutions and LSM KVSs builtfrom the ground up for hierarchical storage.",
    "similarity": 0.30629847645429364
  },
  {
    "text1": "Throughout the years, Deep Learning has proven to be an excellent technology to solve problems that would otherwise be too complex. Furthermore, it has shown great success in the area of medical imaging, especially when applied to segmentation of brain tissues. As such, this dissertation explores a possible new approach, using Deep Artificial Neural Networks to perform spatial normalization on brain MRI studies as well as classify using Brain MRI studies regarding their state of brain atrophy. Spatial normalization of Magnetic Resonance images by tools like the FSL, or SPM turned out to be inefficient for researches as they need too many resources to achieve good results. Theseresources include, for example, wasted human and computer time when executing the commands to normalize and waiting for the process to finish, this can take up to several hours just for one study. Therefore, a new approach was needed, a faster and easier way to normalize the MRI studies. To do so, Deep Artificial Neural Networks were used by creating a python program to deal with said studiesin much less time. This program should free the researchers’ time for other more relevant tasks and help reach conclusions faster in their studies when trying to find patterns between the analysed brains. Several architectures were tried, having better results with U-Net based architecture as well as GAN architecture.At the end, the model couldn’t learn correctly all the brain features to be changed in any of the approaches but showed great potential. Even though the final model did achieve the correct shape it could not yet achieve the final normalization.With some more time invested in perfecting the models, these could, in the future, learn to correctly perform the final normalization and allow the researchers to perform it in less than 10 seconds per exam instead of hours.Regarding the Brain Atrophy models, the models showed some potential too as the predictions were partially correct. With more data, and less unbalanced, the model could probably learn correctly and output the expected results for all classes.",
    "text2": "The brain functional connectivity extracted from rs-fMRI has been used as a powerful tool to study the different networks in the brain. This neuronal network, found in normal condition, can be associated to different cognitive processes. The applicability of these networks in the future is promising, since is a greater technique to study the effects of several diseases or even treatments on normal brain functional connectivity. Firstly, this question should be addressed: are these networks possible to be described and to be used as features to classify a group or a particular subject?.In order to answer this question, it was settled the use of a Machine Learning method, which has been developed great advances in the recent years, due the good performances in the Deep Learning (DL) method. Therefore, it was created a workflow since the beginning, started with data acquisition until the application of DL methods and the process of creation and fine-tune of these models. In the end, several studies using the functional connectivity were done, namely the assessment of the brain functional connectivity to be used as a “fingerprint”. Additionally, it were performed some tests regarding the groups’ classification.After settled the correct approach and validate the DL framework, the “fingerprint” study showed a great improvement on impairment classification, even for simple models. We proved that rs-fMRI can be use in research field to identify singular brain patterns as well as the differences between the subjects, which could be applied as group differentiator in a population.",
    "similarity": 0.3187713569363285
  },
  {
    "text1": "Throughout the years, Deep Learning has proven to be an excellent technology to solve problems that would otherwise be too complex. Furthermore, it has shown great success in the area of medical imaging, especially when applied to segmentation of brain tissues. As such, this dissertation explores a possible new approach, using Deep Artificial Neural Networks to perform spatial normalization on brain MRI studies as well as classify using Brain MRI studies regarding their state of brain atrophy. Spatial normalization of Magnetic Resonance images by tools like the FSL, or SPM turned out to be inefficient for researches as they need too many resources to achieve good results. Theseresources include, for example, wasted human and computer time when executing the commands to normalize and waiting for the process to finish, this can take up to several hours just for one study. Therefore, a new approach was needed, a faster and easier way to normalize the MRI studies. To do so, Deep Artificial Neural Networks were used by creating a python program to deal with said studiesin much less time. This program should free the researchers’ time for other more relevant tasks and help reach conclusions faster in their studies when trying to find patterns between the analysed brains. Several architectures were tried, having better results with U-Net based architecture as well as GAN architecture.At the end, the model couldn’t learn correctly all the brain features to be changed in any of the approaches but showed great potential. Even though the final model did achieve the correct shape it could not yet achieve the final normalization.With some more time invested in perfecting the models, these could, in the future, learn to correctly perform the final normalization and allow the researchers to perform it in less than 10 seconds per exam instead of hours.Regarding the Brain Atrophy models, the models showed some potential too as the predictions were partially correct. With more data, and less unbalanced, the model could probably learn correctly and output the expected results for all classes.",
    "text2": "Prognosis and patient stratification for brain tumors is an important and clinically relevant task and a precise treatment outcome prediction would allow to choose an adequate therapy strategy and schedule the most appropriate follow-up examinations. Magnetic Resonance Imaging (MRI) is an already know imaging technique to assess these tumors. Next to medical imaging, other clinical information is important for patient management, e.g. genetic markers like O6-Methyl-Guanine-Methyl-Transferase (MGMT) methylation is a well-known prognostic marker in Glioblastoma (GBM) tumors.Therefore, the main goal of this thesis was to study Deep Learning (DL) approaches to combine MRI with non-image clinical data in two different classification scenarios: brain tumor segmentation and patient outcome prediction. There are studies that combine these two types of data, however, in two steps: extracting MRI features and then combining them with relevant non-image data. Here, end-to-end DL architectures with two input layers are presented, as well as an infrastructure that allows the easy development of future Machine Learning (ML) /DL models that consumes these two types of data in a clinical context. In this way, the classification in both scenarios is done in a single step, where Convolution Layers perform the feature extraction in MRI input.In brain tumor segmentation, the model with combined data achieved a slightly better Dice Similarity Coefficient (DSC) (0.894 ± 0.025) over image only model (0.882 ± 0.025). As for patient outcome prediction, when trying to predict the Progression-Free Survival (PFS) class (“bad”,” medium” and “good” outcomes), the combined model didn't improve when compared with the model where only MRI was used. Both models, however, outperformed models where only non-image data was used.The segmentation results point to a positive influence when adding the clinical information to MRI. Nevertheless, there is a lot more to investigate in this field, not only in the model architecture, but also in selecting relevant clinical information. In same way, more tests should be run for patient outcome prediction, especially using Overall Survival (OS) information.",
    "similarity": 0.31997694967345375
  },
  {
    "text1": "The introduction of Machine Learning (ML) on the orbit of the resolution of problemstypically associated within the human behaviour has brought great expectations tothe future. In fact, the possible development of machines capable of learning, in asimilar way as of the humans, could bring grand perspectives to diverse areas likehealthcare, the banking sector, retail, and any other area in which we could avoid theconstant attention of a person dedicated to the solving of a problem; furthermore, thereare those problems that are still not at the hands of humans to solve - these are nowat the disposal of intelligent machines, bringing new possibilities to the humankinddevelopment.ML algorithms, specifically Deep Learning (DL) methods, lack a bigger acceptance bypart of the community, even though they are present in various systems in our dailybasis. This lack of confidence, mandatory to let systems make big, important decisionswith great impact in the everyday life is due to the difficulty on understanding thelearning mechanisms and previsions that result by the same - some algorithms representthemselves as ”black boxes”, translating an input into an output, while not being totallytransparent to the outside. Another complication rises, when it is taken into accountthat the same algorithms are trained to a specific task and in accordance to the trainingcases found on their development, being more susceptible to error in a real environment- one can argue that they do not constitute a true Artificial Intelligence (AI).Following this line of thought, this dissertation aims at studying a new theory,Hierarchical Temporal Memory (HTM), that can be placed in the area of MachineIntelligence (MI), an area that studies the capacity of how the software systems canlearn, in an identical way to the learning of a human being. The HTM is still a freshtheory, that lays on the present perception of the functioning of the human neocortexand assumes itself as under constant development; at the moment, the theory dictatesthat the neocortex zones are organized in an hierarchical structure, being a memorysystem, capable of recognizing spatial and temporal patterns. In the course of thisproject, an analysis was made to the functioning of the theory and its applicabilityto the various tasks typically solved with ML algorithms, like image classification, sound recognition and time series forecasting. At the end of this dissertation, after theevaluation of the different results obtained in various approaches, it was possible toconclude that even though these results were positive, the theory still needs to mature,not only in its theoretical basis but also in the development of libraries and frameworksof software, to capture the attention of the AI community.",
    "text2": "Achieving great and undeniable success in a great variety of industries and businesses has made the term Big Data very popular among the scientific community. Big Data (BD) refers to the ever fast-growing research area in Computer Science (CS) that comprises many work areas across the world. The healthcare sector is widely known to be highly proficient inthe production of big quantities of data. It can go from health information, such as thepatient’s blood pressure and cholesterol levels, to more private and sensitive data, such asthe medical procedures history or the report of ongoing diseases.The application of sophisticated techniques enables a profound and rigorous analysis ofdata, something a human cannot do in real-time. However, a machine is capable of rapidlycollect, group, storage and examine vast amounts of data and extract unknown and possi bly interesting knowledge from it. The algorithms used can discover hidden relationshipsbetween attributes that prove to be very useful for a corporation’s work. Buried structureswithin the produced data can also be detected by these techniques. Machine Learning (ML)methods can be adjusted and modelled to different input representations - this adaptabilityis one of the factors that contributes to its blooming prosperity.The main goal is to make predictions on data, by building utterly efficient models that canaccurately take in the data and thus predict a certain outcome. This is especially importantto the healthcare industry since it can considerably improve the lives of many patients.Everything from detecting a type of disease, predicting the chance of morbidity after ahospital stay, to aid in the decision making of treatment strategies are vital to patients aswell as to clinicians.Any improvement over established methods that have been previously studied, testedand published are an asset that will improve the patient’s satisfaction about the healthcareperformance in medical institutions. This can be achieved by refining those algorithms orimplementing new approaches that will make better predictions on the given data.The main objective of this dissertation is to propose ML approaches having acknowledged and evaluated the existent methods used in clinical data. In order to fulfill this goal,an analysis of the state of the art of medical knowledge repositories and scientific paperspublished related to the selected keywords selected was performed. In this line of work,it is crucial to understand, compare and discuss the results obtained to those previouslypublished. Thus, one of the goals is to suggest new ways of solving those problems andmeasuring them up against the existent ones.",
    "similarity": 0.302352277521968
  },
  {
    "text1": "There is a shortage of manufacturing management software solutions for businesses with various manual processes, and that offer a wide range of products. Existing solutions can become very expensive for small and medium-sized enterprises, and can discourage them to take the next step towards the 4th Industrial Revolution. This dissertation consists of joint work with Tipoprado, Artes Gráficas, to develop a package tracking and production performance analysis platform. The company has a notable number of different clients and offers different types of services. This way, different packages may go through different paths on the production pipeline. Given this, to offer a more close and customized service, Tipoprado, wants to develop a package tracking platform. This tracking is not geographical (delivery case), but about the package location over the production pipeline, giving clients the possibility to consult, in real-time, the actual state of their orders. Apart from this, implementing this platform produces a significant level of data about packages and clients. One of the main goals is to treat, process and analyze this data, to improve production efficiency and be able to help the its managers make crucial decisions about the referred pipeline. Production planning and predictions on delivery dates is the ultimate goal. This dissertation studies and implements the tracking method that best applies to Tipoprado production pipeline, together with data analysis, and prediction options. The given platform will transport the company to a tech production vision, and kick start its journey through the fourth industrial revolution. It is also expected to increase customer engagement levels, which correlate with a higher number of sales.",
    "text2": "Logistics services, including express mail delivery areas, have been growing significantlyby the increase in the volume of e-commerce activity worldwide. It is expected that therise in the level of digital competencies of companies and citizens will not only promoteconsiderable growth in this sector over the next few years, but also demand higher levels ofefficiency, quality, and modernization of digital platforms for interaction with customers.In terms of continuous monitoring, new technologies offer potential, namely the use ofGPS devices to collating coordinates. With system integration, the collected coordinates canbe temporarily saved and then sent to a remote server.Door-to-door service requires exact locations, so there are certain technologies, whichallow us to collect that information accurately without the minimum margin of error. In thecontext of door-to-door distribution, most companies have simple technology that providesa piece of insufficient information regarding the status of their order, they only presentinformation that the postal service may be delivered, refused, or the addressee may not befound.Regarding door-to-door distribution, technologies can be implemented to improve thecurrent industry solutions, providing more detailed information about the order status.Thus, a solution was developed based on international standards, that allow live trackingapplication ensuring also data security through blockchain technologies.",
    "similarity": 0.3036932132963989
  },
  {
    "text1": "The system that detects and identifies human activities are named human action recognition. On the video approach, human activity is classified into four different categories, depending on the complexity of the steps and the number of body parts involved in the action, namely gestures, actions, interactions, and activities, which is challenging for video Human action recognition to capture valuable and discriminative features because of the human body’s variations. So, deep learning techniques have provided practical applications in multiple fields of signal processing, usually surpassing traditional signal processing on a large scale. Recently, several applications, namely surveillance, human-computer interaction, and video recovery based on its content, have studied violence’s detection and recognition. In recent years there has been a rapid growth in the production and consumption of a wide variety of video data due to the popularization of high quality and relatively low-price video devices. Smartphones and digital cameras contributed a lot to this factor. At the same time, there are about 300 hours of video data updates every minute on YouTube. Along with the growing production of video data, new technologies such as video captioning, answering video surveys, and video-based activity/event detection are emerging every day. From the video input data, the detection of human activity indicates which activity is contained in the video and locates the regions in the video where the activity occurs.This dissertation has conducted an experiment to identify and detect violence with spatial action localization, adapting a public dataset for effect. The idea was used an annotated dataset of general action recognition and adapted only for violence detection.",
    "text2": "There has been an increasing investment in cancer research that generated an enormous amount of biological and clinical data, especially after the advent of the next-generation sequencing technologies. To analyze the large datasets provided by omics data of cancer samples, scientists have successfully been recurring to machine learning algorithms, identifyingpatterns and developing models by using statistical techniques to make accuratepredictions.Deep learning is a branch of machine learning, best known by its applications in artificialintelligence (computer vision, speech recognition, natural language processing androbotics). In general, deep learning models differ from machine learning “shallow” methods(single hidden layer) because they recur to multiple layers of abstraction. In this way, itis possible to learn high level features and complex relations in the given data.Given the context specified above, the main target of this work is the development andevaluation of deep learning methods for the analysis of cancer omics datasets, covering bothunsupervised methods for feature generation from different types of data, and supervisedmethods to address cancer diagnostics and prognostic predictions.We worked with a Neuroblastoma (NB) dataset from two different platforms (RNA-Seqand microarrays) and developed both supervised (Deep Neural Networks (DNN), Multi-TaskDeep Neural Network (MT-DNN)) and unsupervised (Stacked Denoising Autoencoders (SDA))deep architectures, and compared them with shallow traditional algorithms.Overall we achieved promising results with deep learning on both platforms, meaningthat it is possible to retrieve the advantages of deep learning models on cancer omics data.At the same time we faced some difficulties related to the complexity and computationalpower requirements, as well as the lack of samples to truly benefit from the deep architectures.There was generated code that can be applied to other datasets, wich is available in agithub repository https://github.com/lmpeixoto/deepl_learning [49].",
    "similarity": 0.3059095106186519
  },
  {
    "text1": "Atualmente existem várias soluções comerciais que utilizam a tecnologia RFID para diversos fins aplicacionais. Na literatura estão também documentados várias abordagens e algoritmos para localização de dispositivos RFID. Partindo deste contexto, o objetivo principal da presente dissertação era modelar e conceber uma solução global de monitorização/localização baseada na tecnologia RFID (pontos de acesso e etiquetas), que fosse adequada para vários tipos de organismos/empresas. Ou seja, nunca foi intenção desta dissertação propor novos algoritmos de localização por RFID.Seguindo uma metodologia de desenvolvimento de software orientada aos modelos, e apoiada na tecnologia UML, o desenvolvimento do sistema percorreu as seguintes fases: (i) levantamento e documentação de requisitos, baseados na identificação das necessidades de três tipos de organismos/empresas e utilizando o modelo de Volere, (ii) identificação dos utilizadores do sistema, (iii) conceção do sistema, tarefa que incluiu a elaboração de casos de uso detalhados, diagramas de sequência ao nível do sistema, o modelo de dados persistentes do sistema, diagrama de classes e diagramas de sequência ao nível da implementação, (iv) implementação de um protótipo em Java e (iv) realização de testes com o protótipo.Muito mais do que um algoritmo, ou conjunto de algoritmos, de localização, o sistema desenvolvido é uma solução integrada de localização baseada na tecnologia RFID. A estratégia seguida no desenvolvimento do sistema assenta em 3 princípios: (1) uma dada empresa ou organização deseja monitorizar pessoas e bens, de forma impedir/permitir o acesso a determinadas zonas do espaço físico do edifício dessa empresa, (2) uma das tecnologias mais versátil para este atingir este fim é a RFID, (3) combinando a potência do sinal RF, enviado pela mesma etiqueta RFID, e recebido em pelo menos três pontos de acesso, é possível obter uma estimativa da localização do emissor desse sinal RF. Deste modo, o sistema desenvolvido pressupõe que existem três pontos de acesso (conjunto de APs) em cada local de acesso a zonas críticas do edifício, geometricamente localizados de forma a facilitar a trilateração de medições do sinal RF. Entre as funcionalidades do sistema de localização desenvolvido incluem-se: acesso ao sistema controlado, gestão de utilizadores do sistema, gestão de etiquetas RFID (atribuição, recolha, programação), definição da geometria de cada piso do edifício (usando os conceitos de ponto, segmento e zona), definição das zonas permitidas e interditas a cada tipo de utilizador, gestão dos pontos de acesso e dos conjuntos de pontos de acesso,localização de etiquetas RFID por trilateração e emissão de alertas, para uma ou mais entidades de segurança, nos casos em que ocorrer a “invasão” de uma zona interdita.Em termos de resultados, pode dizer-se que se concebeu um protótipo funcional que cumpre a maioria dos requisitos propostos, possui uma interface fácil de utilizar e é suficientemente genérico para poder ser usado por empresas de tipos diferentes. Dado que o código e os modelos estão perfeitamente sincronizados, alterar ou adicionar funcionalidades ao sistema é relativamente seguro e com um custo moderado. Em termos da qualidade das estimativas da localização, os resultados não são muito positivos. Duas alternativas para melhorar este aspeto passariam por (i) melhorar o algoritmo de localização e (ii) usar um tipo de hardware RFID mais sofisticado e vocacionado para ser aplicado num sistema de localização.",
    "text2": "O uso de painéis de digital signage ou displays (ou, em português, painéis digitais) está cada vez mais a ser implementado nos locais públicos e semipúblicos, uma vez que é uma forma actual de apresentar, de um modo dinâmico, informação, publicidade e conteúdos de entretenimento. Desta forma, as pessoas expostas a esta tecnologia passam a ter um acesso mais rápido e actualizado à informação sobre tudo o que as rodeia.Os ecrãs dos displays têm evoluído no sentido da melhoria da sua qualidade. Além disso, a descida dos preços torna esta tecnologia bastante mais acessível para ser aplicada em vários sectores, nomeadamente na indústria, no comércio, na educação, na saúde, etc., substituindo os meios tradicionais publicitários e informativos, baseados em papel.Uma rede de painéis digitais permite a actualização dos seus conteúdos de forma remota, com base num servidor central que controla toda a informação apresentada na rede, enquanto que nos meios tradicionais a actualização de conteúdos é muito mais cara, demorada e de difícil gestão.Como as pessoas olham pouco tempo para os painéis digitais, exige-se um esforço muito grande no estudo do local onde estes são instalados e na modelação dos conteúdos a serem apresentados, de forma a que o ambiente se torne o mais atractivo possível e, deste modo, se promova a atenção de quem passa pelos painéis. Também existem displays que usam tecnologias mais sofisticadas, permitindo a adaptação automática dos conteúdos apresentados em função do contexto envolvente, fazendo com que a informação seja mais direccionada ao público, sem a necessidade de controlo humano.Dado o crescente sucesso, à escala planetária, da digital signage, têm surgindo cada vez mais soluções de software aplicadas nesta vertente. Por conseguinte, o tema principal desta dissertação incidirá sobre o desenvolvimento de uma aplicação web para painéis de digital signage, sugerida pela empresa Ubisign, com o objectivo de permitir configurar visualizações com informação sobre eventos provenientes do Google Calendar.Uma vez que a promoção de eventos geralmente exige custos elevados de design e produção, é necessário minimizá-los no contexto das redes de digital signage. Para tal, existem determinadas ferramentas on-line de gestão de eventos, como o Google Calendar, com a função de permitir que o utilizador especifique eventos que vão ocorrer e efectue o seu escalonamento com base em calendários. Do ponto de vista de um developer, estas ferramentas evitam a necessidade de implementar outros softwares de gestão de eventos, permitindo também desenvolver outras aplicações que comuniquem com estas ferramentas, através de APIs apropriadas e bem documentadas.Para tirar partido disto, a aplicação a desenvolver terá de recorrer à API Google Calendar para disponibilizar, de forma personalizada, informação sobre eventos que estejam planeados para um dado sítio com uma rede de digital signage instalada e, para esse efeito, terá de ser integrada no serviço Ubisign.com.",
    "similarity": 0.3435842896715473
  },
  {
    "text1": "Atualmente existem várias soluções comerciais que utilizam a tecnologia RFID para diversos fins aplicacionais. Na literatura estão também documentados várias abordagens e algoritmos para localização de dispositivos RFID. Partindo deste contexto, o objetivo principal da presente dissertação era modelar e conceber uma solução global de monitorização/localização baseada na tecnologia RFID (pontos de acesso e etiquetas), que fosse adequada para vários tipos de organismos/empresas. Ou seja, nunca foi intenção desta dissertação propor novos algoritmos de localização por RFID.Seguindo uma metodologia de desenvolvimento de software orientada aos modelos, e apoiada na tecnologia UML, o desenvolvimento do sistema percorreu as seguintes fases: (i) levantamento e documentação de requisitos, baseados na identificação das necessidades de três tipos de organismos/empresas e utilizando o modelo de Volere, (ii) identificação dos utilizadores do sistema, (iii) conceção do sistema, tarefa que incluiu a elaboração de casos de uso detalhados, diagramas de sequência ao nível do sistema, o modelo de dados persistentes do sistema, diagrama de classes e diagramas de sequência ao nível da implementação, (iv) implementação de um protótipo em Java e (iv) realização de testes com o protótipo.Muito mais do que um algoritmo, ou conjunto de algoritmos, de localização, o sistema desenvolvido é uma solução integrada de localização baseada na tecnologia RFID. A estratégia seguida no desenvolvimento do sistema assenta em 3 princípios: (1) uma dada empresa ou organização deseja monitorizar pessoas e bens, de forma impedir/permitir o acesso a determinadas zonas do espaço físico do edifício dessa empresa, (2) uma das tecnologias mais versátil para este atingir este fim é a RFID, (3) combinando a potência do sinal RF, enviado pela mesma etiqueta RFID, e recebido em pelo menos três pontos de acesso, é possível obter uma estimativa da localização do emissor desse sinal RF. Deste modo, o sistema desenvolvido pressupõe que existem três pontos de acesso (conjunto de APs) em cada local de acesso a zonas críticas do edifício, geometricamente localizados de forma a facilitar a trilateração de medições do sinal RF. Entre as funcionalidades do sistema de localização desenvolvido incluem-se: acesso ao sistema controlado, gestão de utilizadores do sistema, gestão de etiquetas RFID (atribuição, recolha, programação), definição da geometria de cada piso do edifício (usando os conceitos de ponto, segmento e zona), definição das zonas permitidas e interditas a cada tipo de utilizador, gestão dos pontos de acesso e dos conjuntos de pontos de acesso,localização de etiquetas RFID por trilateração e emissão de alertas, para uma ou mais entidades de segurança, nos casos em que ocorrer a “invasão” de uma zona interdita.Em termos de resultados, pode dizer-se que se concebeu um protótipo funcional que cumpre a maioria dos requisitos propostos, possui uma interface fácil de utilizar e é suficientemente genérico para poder ser usado por empresas de tipos diferentes. Dado que o código e os modelos estão perfeitamente sincronizados, alterar ou adicionar funcionalidades ao sistema é relativamente seguro e com um custo moderado. Em termos da qualidade das estimativas da localização, os resultados não são muito positivos. Duas alternativas para melhorar este aspeto passariam por (i) melhorar o algoritmo de localização e (ii) usar um tipo de hardware RFID mais sofisticado e vocacionado para ser aplicado num sistema de localização.",
    "text2": "A capacidade de agregar dados é uma característica fundamental na conceção de sistemas de informação escaláveis, que permite a determinação de propriedades globais importantes de forma descentralizada, para a coordenação de aplicações distribuídas, ou para fins de monitorização.Agregados simples como mínimos/ máximos, contagens, somas e médias foram já extensivamente estudados no passado. No entanto, este tipo de agregados pode não ser suficiente para caracterizar distribuições de dados enviesadas e na presença de valores atípicos (outliers), tornando-se então relevante a determinação de uma estimativa dos valores na rede (e.g. histograma, função de distribuição cumulativa), dado que métricas como médias ou desvio padrão escondem em muitos casos alterações na propriedade monitorizada que são relevantes para decisão de controlo.São ainda relativamente escassos os trabalhos que se focam sobre a agregação de métricas mais expressivas. Uma proposta recente nesse domínio [SNSP10] refere atingir uma precisão nas estimativas superior à atingida em abordagens anteriores. Trata-se de um algoritmo para a determinação de funções cumulativas de distribuições.Apesar do contributo, essa proposta mostra limitações na tolerância a faltas e no suporte à monitorização contínua de propriedades, dado que para acompanhar alterações dos valores amostrados, a estratégia usada exige que o protocolo seja reiniciado periodicamente. Para além disso, os pressupostos dessa abordagem não admitem a perda de mensagens nem a sua duplicação.Assim, e tomando como ponto de partida o actual estado da arte, é apresentado nesta tese um algoritmo distribuído para a determinação de funções cumulativas de probabilidade em redes de larga escala. As suas principais vantagens são a imunidade à perda de mensagens, a velocidade de convergência e a precisão que se obtém na aproximação à distribuição original. É simultaneamente adaptável a alterações no valor amostrado e resiliente a dinamismo no número de nodos na rede. Usa também um mecanismo de quiesciência dos nodos assim que a variação local da estimativa é inferior a um determinado limiar. Nessa circunstância, o nodo deixa de transmitir. Isto leva à diminuição do número de mensagens trocadas entre nodos.As distribuições determinadas em todos os nodos permitem a tomada de decisões que tirem partido do facto de se estar a agregar uma função probabilística. Assim o nodo pode excluir outliers ou observar determinados quantis da propriedade. Para além disso, cada nodo da rede possui uma estimativa global sobre o estado geral da propriedade distribuída, o que lhe permite também a tomada de decisões com base em conhecimento local.São apresentados nesta tese resultados de simulação que confirmam a validade da abordagem seguida. É também apresentada uma revisão da literatura relacionada cujo âmbito incluiu as técnicas mais representativas da agregação de dados para métricas escalares e as técnicas de agregação de dados para métricas complexas.",
    "similarity": 0.3235457063711912
  },
  {
    "text1": "Nowadays, most companies resort to data analytics frameworks to extract value from theincreasing amounts of digital information. These systems give substantial competitive ad vantages to companies since they allow to support situations such as possible marketingdecisions or predict user behaviors.Therefore, organizations tend to leverage the cloud to store and perform analytics overthe data. Database services in the cloud present significant advantages as a high levelof efficiency and flexibility, and the reduction of costs inherent to the maintenance andmanagement of private infrastructures. The problem is that these services are often a targetfor malicious attacks, which means that sensitive and private personal information can becompromised.The current secure analytical processing solutions use a limited set of cryptographictechniques or technologies, which makes it impossible to explore different trade-offs ofperformance, security, and functionality requirements for different applications. Moreover,these systems also do not explore the combination of multiple cryptographic techniquesand trusted hardware to protect sensitive data.The work presented here addresses this challenge, by using cryptographic schemes andthe Intel SGX technology to protect confidential information, ensuring a practical solutionwhich can be adapted to applications with different requirements. In detail, this dissertationbegins by exposing a baseline study about cryptographic schemes and the Intel SGX tech nology, followed by the state-of-the-art revision about secure data analytics frameworks.A new solution based on the Apache Spark framework, called SafeSpark, is proposed. Itprovides a modular and extensible architecture and prototype, which allows protecting in formation and processing analytical queries over encrypted data, using three cryptographicschemes and the SGX technology. We validated the prototype with an experimental evalu ation, where we analyze the performance costs of the solution and also its resource usage.For this purpose, we use the TPC-DS benchmark to evaluate the proposed solution, andthe results show that it is possible to perform analytical processing on protected data witha performance impact between 1.13x and 4.1x.",
    "text2": "Current identity management systems rely on centralized databases to store user’s personal data, which posesa great risks for data security, as these infrastructure create a critical point of failure for the whole system. Besidethat service providers have to bear huge maintenance costs and comply with strict data protection regulations.Self-sovereign identity (SSI) is a new identity management paradigm that tries to answer some of theseproblems by providing a decentralized user-centric identity management system that gives users full control oftheir personal data. Some of its underlying concepts include Decentralized Identifiers (DIDs), Verifiable Claimsand Credentials. This approach does not rely on any central authority to enforce trust as it often uses Blockchainor other Decentralized Ledger Technologies (DLT) as the trust anchor of the system, although other decentralizednetwork or databases could also be used for the same purpose.This thesis focuses on finding alternative solutions to DLT, in the context of SSI. Despite being the most usedsolution some DLTs are known to lack scalability and performance, and since a global identity managementsystem heavily relies on these two requirements it might not be the best solution to the problem.This document provides an overview of the state of the art and main standards of SSI, and then focuses ona non-DLT approach to SSI, referencing non-DLT implementations and alternative decentralized infrastructuresthat can be used to replace DLTs in SSI. It highlights some of the limitations associated with using DLTs foridentity management and presents a SSI framework based on decentralized names systems and networks. Thisframework couples all the main functionalities needed to create different SSI agents, which were showcased ina proof of concept application.",
    "similarity": 0.30294679530041074
  },
  {
    "text1": "Nowadays, most companies resort to data analytics frameworks to extract value from theincreasing amounts of digital information. These systems give substantial competitive ad vantages to companies since they allow to support situations such as possible marketingdecisions or predict user behaviors.Therefore, organizations tend to leverage the cloud to store and perform analytics overthe data. Database services in the cloud present significant advantages as a high levelof efficiency and flexibility, and the reduction of costs inherent to the maintenance andmanagement of private infrastructures. The problem is that these services are often a targetfor malicious attacks, which means that sensitive and private personal information can becompromised.The current secure analytical processing solutions use a limited set of cryptographictechniques or technologies, which makes it impossible to explore different trade-offs ofperformance, security, and functionality requirements for different applications. Moreover,these systems also do not explore the combination of multiple cryptographic techniquesand trusted hardware to protect sensitive data.The work presented here addresses this challenge, by using cryptographic schemes andthe Intel SGX technology to protect confidential information, ensuring a practical solutionwhich can be adapted to applications with different requirements. In detail, this dissertationbegins by exposing a baseline study about cryptographic schemes and the Intel SGX tech nology, followed by the state-of-the-art revision about secure data analytics frameworks.A new solution based on the Apache Spark framework, called SafeSpark, is proposed. Itprovides a modular and extensible architecture and prototype, which allows protecting in formation and processing analytical queries over encrypted data, using three cryptographicschemes and the SGX technology. We validated the prototype with an experimental evalu ation, where we analyze the performance costs of the solution and also its resource usage.For this purpose, we use the TPC-DS benchmark to evaluate the proposed solution, andthe results show that it is possible to perform analytical processing on protected data witha performance impact between 1.13x and 4.1x.",
    "text2": "Encryption has been essential to protect modern systems and services. It became the security foundation ofdatabases, payment systems, cloud services, and others. Cryptography enabled the creation and validation ofdigital signatures, where the protection of the private key is very important to prevent false signatures. Cryptocur rencies rely on this mechanism.Crypto wallets hold private keys used to sign transactions and prove ownership of a digital asset. These haveto keep the private key secure, but accessible to its owner, as it may be needed frequently. With the increasingnumber of decentralized web applications that interact with a blockchain, this subject has become more prevalent,as they usually require frequent signatures from the user.The mass adoption of cryptocurrencies by non-technical users urged the creation of crypto wallets that aresecure but prioritize usability. Some of these are hosted services that store the private keys in their serversand others are non-hosted, where the user is responsible for storing it. When implemented as a browser plugin,these wallets allow the user to seamlessly interact with a web application. The rise of cloud technology broughtforth multi-signature on the cloud, by combining different cloud services owned by the user. These give the usercontrol of his private key and are less vulnerable to cyber attacks.In this work, it is presented a comprehensive analysis of existing crypto wallet approaches in usability andsecurity to understand the existing problems. The next step was to propose multiple possible solutions to thoseproblems and produce their implementations. These take advantage of previously studied multi-cloud technologyand are used to attempt to improve usability and security. To evaluate the proposed solutions and to comparethem to the existing ones, we have developed a framework that consisted of various objective tests based onprevious work, which have the goal of evaluating security and usability.Finally, the proposed and existing solutions were compared using the proposed framework.",
    "similarity": 0.3047252602922915
  },
  {
    "text1": "Nos dias de hoje, tem-se notado um aumento do número e diversidade de dados digitaisque circulam, são tratados, analisados e utilizados à escala global. Os números são significativos,e, por isso, as empresas começam a tomar partido de serviços de terceiros, parabeneficiar das vantagens de computação que estes proporcionam.Posto isto, serviços de nuvem disponibilizados pela Amazon, Google ou Microsoft, são utilizadospor essas empresas, que procuram garantias não só de disponibilidade mas tambémde proteção dos seus dados. Como temos observado ao longo dos anos, os serviços denuvem têm vindo a sofrer imensos ataques, onde falhas de segurança nos servidores dearmazenamento acabam por ser responsáveis pela libertação de enormes quantidades deinformação confidencial.De modo a resolver as preocupações existentes de aplicações que lidam com dadossensíveis e confiáveis foram propostas várias bases de dados capazes de armazenar e processardados de forma segura na cloud. Contudo, o maior esforço de investigação encontra-seem desenvolver novos esquemas criptográficos que protegem os dados em texto cifrado detal modo que as bases de dados consigam processar interrogações como se fosse texto simples.Esta abordagem apesar de eficiente acaba por libertar informação sensível que podeser utilizada para quebrar a segurança dos sistemas. Para além disso, a investigação existentetem dado prioridade às bases de dados SQL devido à sua grande aplicabilidade. Estadissertação toma uma abordagem diferente e apresenta uma nova base de dados NoSQLcom processamento seguro, TrustNosQL, assente nas propriedades de segurança de hardwareconfiável. Mais precisamente, este trabalho tem três contribuições principais. O primeiro éuma análise compreensiva do estado da arte atual em base de dados com processamentoseguro. Este estudo permite posicionar o sistema apresentado em relação às capacidadese propriedades de segurança dos sistemas existentes. A segunda contribuição é abase de dados NoSQL com processamento seguro, TrustNoSQL, a primeira base de dadosNoSQL que processa de forma segura as interrogações utilizando a tecnologia Intel SGX. Aúltima contribuição é uma extensa avaliação do sistema apresentado com uma plataformade avaliação de base de dados reconhecida pela indústria.",
    "text2": "O desenvolvimento de aplicações e serviços baseados em web está a crescer todos os diascada vez mais. As facilidades que nos oferecem, entre elas a alta-disponibilidade e acessibilidade,levou a que as grandes empresas de tecnologia investissem neste tipo de tecnologias,surgindo assim aplicações como o Evernote, o Google Photos, o Dropbox, o Slack, entre outras.Associadas à utilização constante destas aplicações e serviços pelos seus clientes estãoas enormes quantidade de dados criados, bem como os dados gerados a partir destes. Coma necessidade de armazenar e processar esses de forma rápida e eficiente, estes serviçostem vindo a optar pela utilização de serviços de computação em nuvem de terceiros.Existem vantagens claras associadas à migração de dados para estas plataformas, desdea redução de custos associados armazenamento, manutenção e compra de infraestruturas,até às conveniências oferecidas pela disponibilização ferramentas de monitorização econfiguração avançadas, entre muitas outras. Associado também à utilização desta plataformasde cloud computing estão também os problemas com a privacidade dos dados por elasarmazenadas. Apesar dos esforços, por parte dos fornecedores destes serviços, em negaro acesso a entidades não autorizadas, existem ameaças fora do seu controlo e temos vistomuitas vezes que o acesso a dados sensíveis por terceiros tem um risco elevado associado.Com vista a combater este aspeto existem hoje em dia soluções capazes de garantir a confidencialidadedos dados em bases de dados relacionais e não relacionais, através de técnicascriptográficas. Estas soluções estão usualmente associadas a arquiteturas específicas deforma a precaverem sempre esta questão de segurança dos dados em todos os momentos.Estas arquiteturas implicam um maior esforço computacional do lado do cliente, pois édesse lado que se encontra toda a lóogica da aplicacional e mecanismos de segurança.Esta dissertação oferece uma nova arquitetura web onde maior parte do trabalho aplicacionalé delegado para as infraestruturas de nuvem maximizando assim o desempenhoda aplicação, tirando para isso partido da arquitetura browser servidor característica destessistemas.",
    "similarity": 0.30819173544278494
  },
  {
    "text1": "The assembly of miniature electronic components requires an adequate scale of the size of the weldingterminators in printed circuit boards to minimize the stresses due to deformation. An optimumterminator layout minimizes the surface tension of the liquid solder, but requires efficient simulationalgorithms to compute the results in an acceptable time slot. Current Surface Evolver is a softwaretool to study surfaces, shaped by surface tension and other energies, and its execution efficiency can beimproved to take advantage of shared memory systems based on multi-core and many-core computingdevices.This dissertation aims to analyze the Surface Evolver, identifying the computational bottlenecksand working on solutions to improve the overall performance of the application. Parallel algorithmswere developed to explore the architectural features of current multi-core and many-core computingdevices namely the Xeon Phi, and including the growing vectorization features of newer processingdevices.After an analysis of the application and its profiling, the original data structure was identified asthe critical bottleneck for software performance: it is implemented with linked lists, which preventsthe use of the vectorization features of current devices and leads to inefficient parallel algorithms,both key elements to improve the performance of the Surface Evolver. The modification of the datastructure was a key task in this dissertation.The calculation force was identified as one of the most time consuming tasks of Surface Evolver andit was the target function of this work. This algorithm iterates over all vertices, edges and faces so isa good example to conclude how vectorization and parallelism affects the performance of simulationsoftware used in the variety fields of science and engineering. In the end of this work it is possibleto see that vectorization can greatly improve the performance of an application, bringing significantspeedups to Surface Evolver.The measured execution times are presented and discussed, throughout the various developmentstages of the application, aiming to analyze the impact of the application of high performance techniqueson the Surface Evolver, suggesting yet further future improvements that were well identified inthe end of this work.",
    "text2": "TopoSEM is a software package with the aim of reconstructing a 3D surface topography of a microscopic samplefrom a set of 2D Scanning Electron Microscopy (SEM) images. TopoSEM is also able to produce a stability reporton the calibration of the SEM hardware based solely on output images.One of the key steps in both of these workflows is the use of a Digital Image Correlation (DIC) algorithm, ano-contact imaging technique, to measure full-field displacements of an input image. A novel DIC implementationfine-tuned for 3D reconstructions was originally developed in MATLAB to satisfy the feature requirement of thisproject. However, near real-time usability of the TopoSEM is paramount for its users, and the main barrier towardsthis goal is the under-performing DIC implementation.This dissertation work ported the original MATLAB implementation of TopoSEM to sequential C++ and itsperformance was further optimised: (i) to improve memory accesses, (ii) to explore the available vector exten sions in each core of current multiprocessor chips processors to perform computationally intensive operationson vectors and matrices of single and double-precision floating point values, and (iii) to additionally improve theexecution performance through parallelization on multi-core devices, by using multiple threads with a front wavepropagation scheduler.The initial MATLAB implementation took 3279.4 seconds to compute the full-field displacement of a 2576pixels by 2086 pixels image on a quad-core laptop. With all added improvements, the new parallel C++ versionon the same laptop lowered the execution time to 1.52 seconds, achieving an overall speedup of 2158.",
    "similarity": 0.3003047091412743
  },
  {
    "text1": "The assembly of miniature electronic components requires an adequate scale of the size of the weldingterminators in printed circuit boards to minimize the stresses due to deformation. An optimumterminator layout minimizes the surface tension of the liquid solder, but requires efficient simulationalgorithms to compute the results in an acceptable time slot. Current Surface Evolver is a softwaretool to study surfaces, shaped by surface tension and other energies, and its execution efficiency can beimproved to take advantage of shared memory systems based on multi-core and many-core computingdevices.This dissertation aims to analyze the Surface Evolver, identifying the computational bottlenecksand working on solutions to improve the overall performance of the application. Parallel algorithmswere developed to explore the architectural features of current multi-core and many-core computingdevices namely the Xeon Phi, and including the growing vectorization features of newer processingdevices.After an analysis of the application and its profiling, the original data structure was identified asthe critical bottleneck for software performance: it is implemented with linked lists, which preventsthe use of the vectorization features of current devices and leads to inefficient parallel algorithms,both key elements to improve the performance of the Surface Evolver. The modification of the datastructure was a key task in this dissertation.The calculation force was identified as one of the most time consuming tasks of Surface Evolver andit was the target function of this work. This algorithm iterates over all vertices, edges and faces so isa good example to conclude how vectorization and parallelism affects the performance of simulationsoftware used in the variety fields of science and engineering. In the end of this work it is possibleto see that vectorization can greatly improve the performance of an application, bringing significantspeedups to Surface Evolver.The measured execution times are presented and discussed, throughout the various developmentstages of the application, aiming to analyze the impact of the application of high performance techniqueson the Surface Evolver, suggesting yet further future improvements that were well identified inthe end of this work.",
    "text2": "The Energy-Split tool receives as input pieces of a very large molecular system and computesall intra and inter-molecular energies, separately calculating the energies of each fragmentand then the total energy of the molecule. It takes into account the connectivity informationamong atoms in a molecule to compute (i) the energy of all terms involving atoms covalentlybonded, namely bonds, angles, dihedral angles, and improper angles, and (ii) Coulomband the Van der Waals energies, that are independent of the atom’s connections, whichhave to be computed for every atom in the system. The required operations to obtain thetotal energy of a large molecule are computationally intensive, which require an efficienthigh-performance computing approach to obtain results in an acceptable time slot.The original Energy-Split Tcl code was thoroughly analyzed to be ported to a parallel andmore efficient C++ version. New data structures were defined with data locality features, totake advantage of the advanced features present in current laptop or server systems. Theseinclude the vector extensions to the scalar processors, an efficient on-chip memory hierarchy,and the inherent parallelism in multicore devices. To improve the Energy-Split’s sequentialvariant a parallel version was developed using auxiliary libraries. Both implementationswere tested on different multicore devices and optimized to take the most advantage of thefeatures in high performance computing.Significant results by applying professional performance engineering approaches, namely(i) by identifying the data values that can be represented as Boolean variables (such asvariables used in auxiliar data structures on the traversal algorithm that computes theEuclidean distance between atoms), leading to significant performance improvements due tothe reduced memory bottleneck (over 10 times faster), and (ii) using an adequate compressformat (CSR) to represent and operate on sparse matrices (namely matrices with Euclideandistances between atoms pairs, since all distances further the cut-off distance (user defined)are considered as zero, and these are the majority of values).After the first code optimizations, the performance of the sequential version was improvedby around 100 times when compared to the original version on a dual-socket server. Theparallel version improved up to 24 times, depending on the molecules tested, on the sameserver. The overall picture shows that the Energy-Split code is highly scalable, obtainingbetter results with larger molecule files, even when the atom’s arrangement influences thealgorithm’s performance.",
    "similarity": 0.3365565170494938
  },
  {
    "text1": "The assembly of miniature electronic components requires an adequate scale of the size of the weldingterminators in printed circuit boards to minimize the stresses due to deformation. An optimumterminator layout minimizes the surface tension of the liquid solder, but requires efficient simulationalgorithms to compute the results in an acceptable time slot. Current Surface Evolver is a softwaretool to study surfaces, shaped by surface tension and other energies, and its execution efficiency can beimproved to take advantage of shared memory systems based on multi-core and many-core computingdevices.This dissertation aims to analyze the Surface Evolver, identifying the computational bottlenecksand working on solutions to improve the overall performance of the application. Parallel algorithmswere developed to explore the architectural features of current multi-core and many-core computingdevices namely the Xeon Phi, and including the growing vectorization features of newer processingdevices.After an analysis of the application and its profiling, the original data structure was identified asthe critical bottleneck for software performance: it is implemented with linked lists, which preventsthe use of the vectorization features of current devices and leads to inefficient parallel algorithms,both key elements to improve the performance of the Surface Evolver. The modification of the datastructure was a key task in this dissertation.The calculation force was identified as one of the most time consuming tasks of Surface Evolver andit was the target function of this work. This algorithm iterates over all vertices, edges and faces so isa good example to conclude how vectorization and parallelism affects the performance of simulationsoftware used in the variety fields of science and engineering. In the end of this work it is possibleto see that vectorization can greatly improve the performance of an application, bringing significantspeedups to Surface Evolver.The measured execution times are presented and discussed, throughout the various developmentstages of the application, aiming to analyze the impact of the application of high performance techniqueson the Surface Evolver, suggesting yet further future improvements that were well identified inthe end of this work.",
    "text2": "When assembling bottom terminated components in printed circuit boards, connectivity isextended through metallized terminals. To minimize thermal fatigue failure of the welds, softwaretools have been developed to model liquid surfaces shaped by various forces and constraints.Surface Evolver (SE) is the software tool used by Bosch in their media entertainment products tomodel liquid surfaces through the analysis of discrete parts of that surface. However, dependingon the level of detail, this process may have long execution times, which is not consistent withthe demand of industry and mainly in an interactive software where users expect the results tobe obtained quickly.This dissertation aims to improve the efficiency of SE, through the optimization of the totalenergy computation, taking advantage of vectorization, parallel computing and other highperformance techniques.The analysis and profile of the current SE version were crucial to support the decisions takento improve the computational performance of the software. Scalability tests, taking into accountthe Amdahl’s law, call graphs and other profiling analysis helped to identify bottlenecks, wherean effort should be invested to improve the software. One of the heaviest computations identifiedin SE is the computation of the total energy of the configuration.SE was identified to be a memory-bounded software, mainly due to its current mesh datastructure, implemented with linked lists, which limits the use of the vectorization features oncurrent CPU cores and also does not support data parallelization techniques and data locality.A new data structure was proposed to overcome these performance constraints, which led to afaster execution of SE.The results showed an improvement on the total energy computation, an increase of vectorizableoperations, software prefetching techniques and scheduling optimizations which, alongsidethe alternative data structure, increased the performance of the SE.",
    "similarity": 0.32715275029679464
  },
  {
    "text1": "O termo microserviços não é propriamente recente, existem inúmeras referências ao longo da última década sobre este conceito, no entanto não existe um verdadeiro consenso sobre quem foi o primeiro a introduzir esta abordagem. Independentemente da indefinição sobre o autor, as vantagens e os desafios da sua utilização como base ao desenvolvimento de novas aplicações são hoje bem conhecidos. É também possível verificar que esta arquitetura de software, que inicialmente era mais utilizada em desenvolvimentos nativos para a Cloud, é cada vez mais utilizada em centros de dados locais, o que lança novos desafios às infraestruturas de rede dos centros de dados.O simples facto dos microserviços serem independentes entre si, permite que sejam desenvolvidos, distribuídos e atualizados individualmente, desta forma conseguimos atualizações mais rápidas e com maior frequência, endereçando a constante mudança de requisitos aplicacionais que se verifica em variadíssimas áreas de negócio.No entanto a adoção de novas plataformas deve garantir que estes novos paradigmas integram, e idealmente beneficiam de tecnologias ou soluções já existentes. Num ambiente altamente distribuído, como é o caso de arquiteturas baseadas em microserviços, é evidente que a componente de comunicações tem um papel preponderante na qualidade do serviço, pelo que nos casos em que o centro de dados onde se pretende utilizar a plataforma de orquestração utiliza redes baseadas em software (SDN), o ideal é que as soluções integrem de forma bastante profunda. Esta integração é ainda mais relevante se o referido centro de dados apresentar uma arquitetura híbrida, isto é, composto por capacidade de computação em múltiplos datacenter físicos, mas também em provedores de Clouds públicas (Azure, AWS, Google Cloud, etc.).Este trabalho pretende enumerar os principais desafios à utilização de containers em centros de dados, bem como descrever a melhor forma de integrar a solução de gestão de rede de centros de dados do fabricante Cisco (ACI - Application Centric Infrastructure) com a solução de orquestração de containers mais utilizada atualmente (Kubernetes). É também âmbito deste trabalho apresentar uma proposta à integração do ambiente descrito anteriormente (ACI+Kubernetes) com soluções de orquestração de containers alojados em Clouds públicas, nomeadamente na cloud da Microsoft (Azure).",
    "text2": "O desenvolvimento de aplicações tem sido alvo de recentes alterações, procurando cada vez mais rapidamente entregar as aplicações aos clientes. Aliado a isto, a procura de uma integração mais eficaz com as várias equipas de desenvolvimento leva à procura por alternativas ao que era feito anteriormente. Indo um pouco ao encontro do que é pretendido, acaba por surgir a arquitetura utilizando microserviços, que apresenta várias vantagens, sendo que muitas vezes é apresentada como a alternativa perfeita à arquitetura monolítica. Por estas razões, em conjunção com a adoção desta arquitetura por grandes empresas, regista um grande crescimento e aceitação nos últimos anos, tanto no mercado, como em contextos académicos. A verdade é que com pesquisas profundas em vários artigos é possível verificar que esta arquitetura também apresenta vários inconvenientes, principalmente relacionados com a sua natureza distribuída, que muitas das vezes acabam por passar despercebidos devido às suas prometidas vantagens e por serem vagamente referidos na maioria dos trabalhos na comunidade cientifica. Este paradigma distribuído acaba por levantar todo um novo conjunto de desafios e associado com o facto de ser uma arquitetura recente, muitas das equipas de desenvolvimento não estão preparadas para fazer a sua implementação corretamente. Como resultado, as aplicações, tem dificuldades em cumprir os objetivos pretendidos. Para mitigar estas questões, começaram a ser desenvolvidos vários padrões para problemas bastante comuns, para a grande maioria das aplicações. Atualmente existem vários padrões para esta arquitetura já desenvolvidos, sendo que para cada problema, podem existir vários padrões desenvolvidos,como o problema de leitura de dados distribuídos em vários serviços. Cada um destes padrões tem as sociados vários compromissos e por esse motivo é importante identificar cada um, de modo a escolher o padrão que melhor se adeque à aplicação que se aspira desenvolver. Para a realização deste estudo empírico, foi definida uma aplicação referência que servirá como base. A seguir, são definidos vários casos de estudo onde são desenvolvidas as diversas aplicações com os padrões em questão. No final, foi feita uma comparação e uma análise dos compromissos relacionados com vários atributos de qualidade.",
    "similarity": 0.31783306329378563
  },
  {
    "text1": "O termo microserviços não é propriamente recente, existem inúmeras referências ao longo da última década sobre este conceito, no entanto não existe um verdadeiro consenso sobre quem foi o primeiro a introduzir esta abordagem. Independentemente da indefinição sobre o autor, as vantagens e os desafios da sua utilização como base ao desenvolvimento de novas aplicações são hoje bem conhecidos. É também possível verificar que esta arquitetura de software, que inicialmente era mais utilizada em desenvolvimentos nativos para a Cloud, é cada vez mais utilizada em centros de dados locais, o que lança novos desafios às infraestruturas de rede dos centros de dados.O simples facto dos microserviços serem independentes entre si, permite que sejam desenvolvidos, distribuídos e atualizados individualmente, desta forma conseguimos atualizações mais rápidas e com maior frequência, endereçando a constante mudança de requisitos aplicacionais que se verifica em variadíssimas áreas de negócio.No entanto a adoção de novas plataformas deve garantir que estes novos paradigmas integram, e idealmente beneficiam de tecnologias ou soluções já existentes. Num ambiente altamente distribuído, como é o caso de arquiteturas baseadas em microserviços, é evidente que a componente de comunicações tem um papel preponderante na qualidade do serviço, pelo que nos casos em que o centro de dados onde se pretende utilizar a plataforma de orquestração utiliza redes baseadas em software (SDN), o ideal é que as soluções integrem de forma bastante profunda. Esta integração é ainda mais relevante se o referido centro de dados apresentar uma arquitetura híbrida, isto é, composto por capacidade de computação em múltiplos datacenter físicos, mas também em provedores de Clouds públicas (Azure, AWS, Google Cloud, etc.).Este trabalho pretende enumerar os principais desafios à utilização de containers em centros de dados, bem como descrever a melhor forma de integrar a solução de gestão de rede de centros de dados do fabricante Cisco (ACI - Application Centric Infrastructure) com a solução de orquestração de containers mais utilizada atualmente (Kubernetes). É também âmbito deste trabalho apresentar uma proposta à integração do ambiente descrito anteriormente (ACI+Kubernetes) com soluções de orquestração de containers alojados em Clouds públicas, nomeadamente na cloud da Microsoft (Azure).",
    "text2": "O desenvolvimento de aplicações e serviços baseados em web está a crescer todos os diascada vez mais. As facilidades que nos oferecem, entre elas a alta-disponibilidade e acessibilidade,levou a que as grandes empresas de tecnologia investissem neste tipo de tecnologias,surgindo assim aplicações como o Evernote, o Google Photos, o Dropbox, o Slack, entre outras.Associadas à utilização constante destas aplicações e serviços pelos seus clientes estãoas enormes quantidade de dados criados, bem como os dados gerados a partir destes. Coma necessidade de armazenar e processar esses de forma rápida e eficiente, estes serviçostem vindo a optar pela utilização de serviços de computação em nuvem de terceiros.Existem vantagens claras associadas à migração de dados para estas plataformas, desdea redução de custos associados armazenamento, manutenção e compra de infraestruturas,até às conveniências oferecidas pela disponibilização ferramentas de monitorização econfiguração avançadas, entre muitas outras. Associado também à utilização desta plataformasde cloud computing estão também os problemas com a privacidade dos dados por elasarmazenadas. Apesar dos esforços, por parte dos fornecedores destes serviços, em negaro acesso a entidades não autorizadas, existem ameaças fora do seu controlo e temos vistomuitas vezes que o acesso a dados sensíveis por terceiros tem um risco elevado associado.Com vista a combater este aspeto existem hoje em dia soluções capazes de garantir a confidencialidadedos dados em bases de dados relacionais e não relacionais, através de técnicascriptográficas. Estas soluções estão usualmente associadas a arquiteturas específicas deforma a precaverem sempre esta questão de segurança dos dados em todos os momentos.Estas arquiteturas implicam um maior esforço computacional do lado do cliente, pois édesse lado que se encontra toda a lóogica da aplicacional e mecanismos de segurança.Esta dissertação oferece uma nova arquitetura web onde maior parte do trabalho aplicacionalé delegado para as infraestruturas de nuvem maximizando assim o desempenhoda aplicação, tirando para isso partido da arquitetura browser servidor característica destessistemas.",
    "similarity": 0.3032359607151851
  },
  {
    "text1": "Despite the advances made in recent decades, information technologies still have a lotto offer to the health sector. In the scientific community, the idea of technology as avery important part of improving healthcare is already unanimous. Health institutionsare increasingly willing to invest in technologies that support the daily activities life ofhealth professionals, especially at the time of decision making so that it is as fast andas accurate as possible.Thus, the number of hospital information systems has increased, especially the sys tems supporting and easing the diagnosis, treatment and follow-up of the patient.However, these systems are also necessary for decision-making on the part of the ins titutions computer processes, such as intelligent agents, which indirectly influence thequality of the services provided. Of all the choices that have been made within thedeveloped systems, the use of BI has proved quite effective in the presentation of infor mation as well as in the construction of decision support systems. As a consequence,this dissertation project aims to develop a BI platform to continuously monitor theintelligent agents of the CHP as well as their activities.The current digital revolution brings several challenges, the constant emergence ofinnovative technologies often put at stake the work done due to the eventual obsoles cence that it can present in comparison with those that are built with these innovations.Thus, health institutions, should always be alert and keep an eye on their informationsystems, evaluating whether they have become archaic or even if there are new soluti ons that respond better to the problems they have daily at hand. In this way, they willbe updated at technological level and competitive at market level since, inevitably, thequality of the provided services improves significantly.With all these innovations new problems arise, hospital units are increasingly com plex environments at the level of computer systems due to their heterogeneity. Theinformation generated and stored in each system has characteristics and structuresthat can be quite different, which causes the information to be individualized. In thisway, the main issue addressed in this dissertation emerges, the interoperability. , theinteroperability. To answer all these challenges, AIDA was created, a system based on intelligent agents that aim to implement interoperability in health institutions. The in telligent agents have tasks of various types, but have the similarity of communicatingwith heterogeneous systems in order to exchange information of great importance oreven manage and store information in databases. Therefore, the need to monitor theseagents as well as their activities arises in order to maintain the interoperability andquality of the services provided by the institution where they are implemented. Thus,this dissertation aims to developa platform that monitors continuously and in real timethe agents of the CHP.This project was based on the DSR methodology, that initially defines the problemfor which one intends to design a solution, outlining the objectives to be achieved. Theremaining phases deal with the development and evaluation of the developed solution.As proof of concept, the SWOT analysis and the technology acceptance study basedon TAM3 were chosen. The results of the proof of concept were quite positive andrevealed an excellent growth potential for the developed solution.",
    "text2": "Over the last years, the implementation and evolution of computer resources has been improving both the financial and temporal efficiency of clinical processes, as well as the security in the transmission and maintenance of their data, also ensuring the reduction of clinical risk. Currently, the importance of all the information flowing in healthinstitutions is unquestionable. In this way, it is essential that institutions, more specifi cally hospital institutions, have a good Hospital Information System (HIS) in order to collect and analyze information, also helping to support decision making. The most common application of these type of systems is the Electronic Health Record (EHR),which, despite bringing many benefits, is still associated with a low level of usability.However, the different systems present in hospitals are distributed and heterogeneous. Since the interaction between these systems is crucial these days, there is the Agency for Integration, Diffusion and Archive (AIDA) implemented in some Portuguese hospitals. AIDA is a platform developed to enable the dissemination and inte gration of information generated in a health environment by different systems, inclu ding for example information on Complementary Diagnostic and Therapeutic Means (MCDT).Previous research has shown that health professionals often do not analyze and actaccurately and appropriately on test results. Preventing errors during the access toMCDT is essential as this is a crucial step in the diagnostic process, thus avoidingnegative consequences for the patient.In this sense, a new MCDT visualization platform (AIDA-MCDT) was implementedin this project, specifically in the Hospital Center of Porto (CHP), with several newfunctionalities in order to make this process faster, intuitive and efficient, always guaranteeing the confidentiality and protection of patients’ personal data and significantlyimproving the usability of the system, leading to a better delivery of health care.",
    "similarity": 0.31804563347426745
  },
  {
    "text1": "O Desenvolvimento Orientado pelo Comportamento (Behaviour-Driven-Development, BDD) é um paradigma de desenvolvimento de software que permite especificar as necessidades dos utilizadores e os seus critérios de aceitação. A especificação de um sistema é feita através da descrição de cenários de utilização que serão depois implementados. Rocha Silva (2022) propôs uma linguagem de especificação de cenários de utilização, para interfaces web, que utiliza os widgets da própria interface na especificação, permitindo não só especificar os requisitos do sistema, mas também referir como estes deverão ser implementados. No processo de BDD podem surgir na especificação cenários contraditórios que, passando despercebidos, podem levar a que a especificação tenha de ser revista na fase de implementação. Todo este processo acarreta custos, pelo que surgiu a necessidade de criar um método de determinar se uma interface está especificada sem quaisquer contradições (isto é, se a especificação é ou não consistentena descrição do sistema). O objetivo deste trabalho é então definir um método que permite, para uma interface web especificada na linguagem proposta por Rocha Silva (2022), determinar se a especificação apresenta ou não contradições (ou seja, é inconsistente) nos seus cenários. Para cumprir este objetivo será utilizada a ferramenta IVY workbench que permite analisar, de forma automática, modelos escritos em MAL interactors do comportamento de sistemas interativos (permitindo verificar propriedades sobre estes). O primeiro passo do projeto será, então, desenvolver uma ferramenta (o modelador) capaz de traduzir uma interface webespecificada na linguagem proposta por Rocha Silva (2022) para MAL interactors, de modo a que esta possa ser analisada na ferramenta IVY Workbench. Depois, serão ainda apresentadas as propriedades CTL que serão verificadas na ferramenta IVY Workbench para determinar se uma determinada especificação é consistente. Por fim, será apresentado um método de, utilizando a ferramenta IVY Workbench e o modelo em MAL interactors gerado pelo modelador com as devidas propriedades CTL, determinar não só se a especificação é inconsistente mas, caso o seja, os cenários que dão origem a essa inconsistência.",
    "text2": "Sendo certo que o recurso à tecnologia no ensino é cada vez mais notório, a utilização de sistemas informáticos de tutoria continua aquém do seu potencial, ainda que seja um tema abordado há já algumas décadas. Assim, surgiu a iniciativa Leonardo e o respetivo desenvolvimento de uma ferramenta computacional para sistemas de avaliação de conhecimento, com vista a ser aplicada, pelo menos, no suporte de processos de avaliação de alunos, na Universidade do Minho. De entre os módulos que caracterizam estes agentes de software, no contexto desta dissertação, destacam se a base de conhecimento, o mecanismo de raciocínio e o modelo do estudante. Dado que o esforço maior recai em habilitar os tutores artificiais à adaptação, em tempo real, da avaliação ao nível de conhecimento atual dos alunos, surge a necessidade de desenvolvimento de um mecanismo de raciocínio, que seja capaz de determinar, criteriosamente, o que deve ser apresentado de seguida num dado momento avaliativo. O trabalho desta dissertação focou-se na conceção e implementação de um sistema de avaliação baseado em conhecimento para o sistema Leonardo, com a capacidade de ajustar de forma dinâmica, à medida da perícia e conhecimento dos estudantes alvos do processo de avaliação, o seu comportamento, acompanhando de perto a evolução do processo de aprendizagem dos estudantes. Essencialmente, neste trabalho implementou-se a “máquina” de raciocínio para o sistema Leonardo poder sustentar de forma efetiva a avaliação de estudantes ao longo do tempo, numa ou mais áreas do conhecimento.",
    "similarity": 0.302100316580926
  },
  {
    "text1": "In today's world, data is a ubiquitous concept, and the healthcare ecosystem is no exception, as healthcare organisations are inundated with data that is key to the quality of care. In recent years, the digitalisation of healthcare has changed the way this complex system operates, and it is possible to see the potential for new innovative solutions that apply new insights from Big Data, Data Science and Artificial Intelligence to revolutionise healthcare as a whole. The implementation of digital solutions in healthcare can provide new insights from data and be an extremely helpful tool to improve care and population health, leading to increased clinical efficiency and effectiveness, improved cost and resource containment for the healthcare system, and consequently improved professional satisfaction and patient experience. Thus, data science can be a powerful and impactful tool in the healthcare ecosystem, as efforts need to be made in data exploration and visualisation solutions that are appropriate for healthcare professionals to facilitate their decision-making processes. The main objective of this thesis is to use data modelling methods to create a user-friendly data visualisation dashboard that is suitable for specific end users, in this case doctors, to assist them in task and time management and thus healthcare decision making. It will also highlight the potential positive impact of data science in healthcare and the importance of developing data visualisation solutions that are appropriate for healthcare professionals and able to combine the data and information they need on a single viewing platform.",
    "text2": "The importance of making predictions in health is mainly linked to the decision-makingprocess. Make survival predictions accurately is a very difficult task for healthcare professionalsand a major concern for patients. On the one hand, it can help physicians decidebetween palliative care or other medical practice for a patient. On the other hand, the notionof remaining lifetime could help patients in the realization of dreams. However, theprediction of survivability is directly related to the experience of health professionals andtheir ability to memorize.Most decisions are made based on probability and statistics, but these are based on largegroups of people and may not be suitable to predict what will happen in particular cases.Consequently, the use of machine learning techniques have been explored in healthcare. Theirability to help solve diagnostic and prognosis problems has been increasingly exploited.The main contribution of this work is a prediction tool of survival of patients with cancerof the colon and/or rectum, after treatment and a few years after treatment. The characteristicsthat distinguishes it is the balance between the number of required inputs and theirperformance in terms of prediction. The tool is compatible with mobile devices, includesa online learning component that allows for automatic recalculation and flexibly of theprediction models, by adding new cases.The tool aims to facilitate the access of healthcare professionals for instruments thatenrich their practice and improve their results. This increases the productivity of healthcareprofessionals, enabling them to make decisions faster and with a lower error rate.",
    "similarity": 0.3083513677285319
  },
  {
    "text1": "O serviço de urgência é uma das áreas hospitalares com maior afluência, onde a procura e o graude complexidade são elevados e imprevisíveis. Para além disso, o acesso é irrestrito e as exigências sãocrescentes, assim como a necessidade de gestão de recursos para evitar o colapso das instituições ediminuir os tempos de espera excessivos, que são das consequências mais preocupantes na área dasaúde.Este projeto surge da oportunidade de estágio e proposta de tema de dissertação/projeto académico,na empresa de consultoria tecnológica para a área da saúde, Glintt HealthCare Solutions, SA. O principalobjetivo, é o estudo teórico e desenvolvimento de um protótipo funcional de um sistema, tendo em vistaa realização de recomendações/sugestões aos profissionais de saúde a nível hospitalar, mais concreta mente nos Serviços de Urgência. Este sistema irá ter em conta, informação de utentes, como historialmédico e estado de saúde (p.e. doenças crónicas, medicação, informações recolhidas na triagem, alergiasconhecidas, etc.).De forma mais específica, a solução tecnológica proposta para dar resposta ao problema e contextoacima referido, contém várias etapas. Num primeiro momento, é realizada uma investigação relativaaos softwares de urgência já existentes nos hospitais em diferentes contextos(nacional e internacional).Seguidamente, perceber, no panorama português, onde se encontram os dados relevantes em contextode urgência, para que possam ser recolhidos e posteriormente utilizados. Numa etapa mais intermédiae após a definição dos requisitos essenciais, pretende-se a definição e conceção de uma arquiteturainteroperável, que englobe os mesmos. É nesta fase que se procede à análise das abordagens a integrarna arquitetura, bem como ao estudo do funcionamento do motor de inferência, responsável por gerar asrecomendações e sugestões destinadas a apoiar a tomada de decisão por parte do utilizador. A ideia,numa fase final, é que a arquitetura definida, seja implementada e posteriormente sujeita a avaliação evalidação, por parte dos profissionais ligados à empresa.Deste modo, este projeto visa otimizar a gestão de recursos na saúde, agilizando o atendimento emelhorando a eficiência, beneficiando tanto pacientes, como profissionais de saúde.",
    "text2": "Desde os primórdios dos tempos que o ser humano procura optimizar e automatizar todosos processos que se apresentam como morosos e repetitivos. O processo de pricing deprodutos nos retalhistas é um sistema complexo e que consome tempo ao processo internodos mesmos. Este projeto de investigação tem como objectivo o desenvolvimento de umaplataforma que seja capaz de optimizar e automatizar o processo de pricing de produtos,tendo como base um modelo baseado em múltiplas regras.Com o aumento do volume de vendas online, surgem, no âmbito do processo de pricing,diversos problemas relativos aos processos associados à expansão de uma plataforma deE-commerce. Aparece assim, a necessidade de um sistema capaz de responder a estes problemas e auxiliar na eficácia, rapidez e tomada de decisão de quem lida diariamente comesta questão complexa. Assim, propõe-se o desenvolvimento de um sistema que deveráser capaz de auxiliar a tomada de decisão na definição do preço de venda dos produtoscomercializados em qualquer plataforma de E-commerce.A solução que é desenvolvida ao longo deste projeto de investigação, terá que ser passível de gerir, em tempo real, o processo de pricing de um retalhista, bem como auxiliarna decisão da definição de preços. O foco deste projeto de investigação será dado a sistemas de apoio à decisão orientados a modelos, uma vez que é de extrema importância aversatilidade e a adaptação do sistema a múltiplos contextos e variáveis.Como tal, e de forma a responder às questões de investigação que orientam este projetode investigação, estrutura-se o conteúdo em quatro capítulos fundamentais: o Estado daArte, a Metodologia de investigação e Ferramentas de desenvolvimento, o Desenvolvimentodo trabalho e as Conclusões.Durante o capítulo dedicado ao Estado da Arte abordam-se definições e conceitos essenciais ao capítulo de Desenvolvimento deste projeto, tal como o conceito de Sistemas de Apoioà Decisão, a definição do conceito de Motores de Regras e de Algoritmos de Inferência.Para estruturar a forma como se irá conduzir este projeto de investigação, no capítulo deMetodologia e Ferramentas de Desenvolvimento, apresenta-se a metodologia de investigação e as ferramentas de desenvolvimento aplicadas neste estudo, tal como o ambiente noqual a solução final foi desenvolvida.O capítulo de Desenvolvimento define-se pela exposição da investigação e lógica aplicadano desenvolvimento de um Sistema de apoio à Decisão para o Processo de pricing. Porúltimo, o capítulo em que se expõem as conclusões deste projeto de investigação, tem comoobjectivo analisar os princípios teóricos que servem de base a provas de conceito, seguindo-se pela exposição da análise SWOT. O desenvolvimento desta análise é enquadrado nametodologia de investigação definida inicialmente, Design Research, avaliando a soluçãodesenvolvida de modo a perceber se os requisitos iniciais foram cumpridos.Assim, e de forma a concluir esta investigação, e relacionar todos os conceitos abordadose tecnologias utilizadas, as questões de investigação são respondidas de forma a expor aviabilidade da solução apresentada.",
    "similarity": 0.30358379501385047
  },
  {
    "text1": "Tools that detect security problems are very important nowadays and for the people doingcode reviews it is even more important to have tools that identify vulnerabilities in the code.In this way companies that provide applications can be more confident that the code theydeploy is almost vulnerabilities free.A subset of these tools, known as Static Application Security Testing (SAST) tools, rely onthe analysis of the source code aiming at looking for patterns that correspond to vulnerabili ties. These analyzers use mainly language processors to help them extract from the sourcecode the information they need. Languages exist for many years but they never ceased toexist because they are in constant development.The description of languages is supported bygrammars. Grammars also evolve to sustain the referred languages evolution. They wereprimarily used for compilers to analyse the structure of the language and parse it; nowadaysthey help many other tools like SAST for example.Having a tool that can detect vulnerabilities is very useful like was said, but to identifythose vulnerabilities it is necessary to find patterns in languages. By finding these abstractpatterns the work is simplified since all concrete languages will present similar vulnerabilities.For example, SQl Injection is a vulnerability that is shared across almost all languages; so,it is possible to define one general pattern to capture that common vulnerability in eachlanguage.Those patterns are defined over Abstract Syntax Trees (AST). To build an AST whileparsing a program, Checkmarx uses a set of functions called Visitors that are associated to theproductions of the programming language Grammar. In that context, the Language Factorytool developed by Checkmarx generates automatically some visitors and let programmers togenerate the others by dragging and dropping rules. The main objective of Language Factorytool is to aid programmers understanding how to create visitors and, at the same time, togenerate as many visitors as possible to be used directly. When Checkmarx is working ona new Language to to include support for that language in the CxSAST tool, the use ofLanguage Factory will help creating the appropriate Visitors making this process simplerand faster.The Master’s project reported in this dissertation appears in that framework aiming at theimprovement of the Checkmarx Language Factory making it capable of infer more Visitorsfrom the new language’s Grammar.",
    "text2": "Tools for Programming Languages processing, like Static Analysers (for instance, a StaticApplication Security Testing (SAST) tool, one of Checkmarx’s main products), must beadapted to cope with a given input when the source programming language changes.Complexity of the programming language is one of the key factors that deeply impact thetime of giving support to it.This Master’s Project aims at proposing an approach for assessing language complexity,measuring, at a first stage, the complexity of its underlying context-free grammar (CFG).From the analysis of concrete case studies, factors have been identified that make thesupport process more time-consuming, in particular in the stages of language recognitionand in the transformation to an abstract syntax tree (AST). In this sense, at a second stage, aset of language features is analysed in order to take into account the referred factors thatalso impact on the language processing.The main objective of the Master’s work here reported is to help development teams toimprove the estimation of time and effort needed to adapt the SAST Tool in order to copewith a new programming language.In this dissertation a tool is proposed, that allows for the evaluation of the complexity of alanguage based on a set of metrics to classify the complexity of its grammar, along with a setof language properties. The tool compares the new language complexity so far determinedwith previously supported languages, to predict the effort to process the new language.",
    "similarity": 0.30350820890480373
  },
  {
    "text1": "Tools that detect security problems are very important nowadays and for the people doingcode reviews it is even more important to have tools that identify vulnerabilities in the code.In this way companies that provide applications can be more confident that the code theydeploy is almost vulnerabilities free.A subset of these tools, known as Static Application Security Testing (SAST) tools, rely onthe analysis of the source code aiming at looking for patterns that correspond to vulnerabili ties. These analyzers use mainly language processors to help them extract from the sourcecode the information they need. Languages exist for many years but they never ceased toexist because they are in constant development.The description of languages is supported bygrammars. Grammars also evolve to sustain the referred languages evolution. They wereprimarily used for compilers to analyse the structure of the language and parse it; nowadaysthey help many other tools like SAST for example.Having a tool that can detect vulnerabilities is very useful like was said, but to identifythose vulnerabilities it is necessary to find patterns in languages. By finding these abstractpatterns the work is simplified since all concrete languages will present similar vulnerabilities.For example, SQl Injection is a vulnerability that is shared across almost all languages; so,it is possible to define one general pattern to capture that common vulnerability in eachlanguage.Those patterns are defined over Abstract Syntax Trees (AST). To build an AST whileparsing a program, Checkmarx uses a set of functions called Visitors that are associated to theproductions of the programming language Grammar. In that context, the Language Factorytool developed by Checkmarx generates automatically some visitors and let programmers togenerate the others by dragging and dropping rules. The main objective of Language Factorytool is to aid programmers understanding how to create visitors and, at the same time, togenerate as many visitors as possible to be used directly. When Checkmarx is working ona new Language to to include support for that language in the CxSAST tool, the use ofLanguage Factory will help creating the appropriate Visitors making this process simplerand faster.The Master’s project reported in this dissertation appears in that framework aiming at theimprovement of the Checkmarx Language Factory making it capable of infer more Visitorsfrom the new language’s Grammar.",
    "text2": "Software applications evolve over the years at a cost: their architecture modularity tends to be degraded. This happens mainly because software application maintenance often leads to architectural degradation. In this context, software architects need to elaborate strategies for detecting architectural degradation symptoms and thus maintaining the software architectural quality. The elaborations of these strategies often rely on tools with domain-specific languages (DSLs), which help them to specify software architecture rules. These tools also enforce the adherence of these rules in the evolving program. However, their adoption in mainstream software development is largely dependent on the usability of the language. Unfortunately, it is also often hard to identify their usability strengths and weaknesses early, as there is no guidance on how to objectively reveal them. Usability is a multi-faceted quality characteristic, which is challenging to quantify before a DSL is actually used by its stakeholders. There is even less support and experience on how to quantitatively evaluate the usability of DSLs used in software maintenance tasks. To this end in this dissertation, a usability measurement framework was developed based on the Cognitive Dimensions of Notations (CDN). The framework was evaluated both qualitatively and quantitatively using two textual DSLs for architecture rules in the context of two evolving object-oriented systems. The results suggested that the proposed metrics were useful: (1) to early identify the DSL usability limitations to be addressed, (2) to reveal specific features of the DSLs favoring software maintenance tasks, and (3) to successfully analyze eight usability dimensions that are critical in many DSLs. However, along with these results this evaluation also revealed that this kind of tools lack support for communication among the stakeholders, creating a gap in the software development. To solve this problem we proposed heuristics for tools that use DSLs for detecting architecture degradation symptoms. These heuristics will permit the exchange of information between the stakeholders, thereby, also increasing the tool usability. Finally, we chose TamDera as the tool to implement these heuristics in our study domain. Therefore, we implemented in the new version of TamDera the communication support for the stakeholders by using a new architecture and a new environment with the developed heuristics.",
    "similarity": 0.31308526450915475
  },
  {
    "text1": "Tools that detect security problems are very important nowadays and for the people doingcode reviews it is even more important to have tools that identify vulnerabilities in the code.In this way companies that provide applications can be more confident that the code theydeploy is almost vulnerabilities free.A subset of these tools, known as Static Application Security Testing (SAST) tools, rely onthe analysis of the source code aiming at looking for patterns that correspond to vulnerabili ties. These analyzers use mainly language processors to help them extract from the sourcecode the information they need. Languages exist for many years but they never ceased toexist because they are in constant development.The description of languages is supported bygrammars. Grammars also evolve to sustain the referred languages evolution. They wereprimarily used for compilers to analyse the structure of the language and parse it; nowadaysthey help many other tools like SAST for example.Having a tool that can detect vulnerabilities is very useful like was said, but to identifythose vulnerabilities it is necessary to find patterns in languages. By finding these abstractpatterns the work is simplified since all concrete languages will present similar vulnerabilities.For example, SQl Injection is a vulnerability that is shared across almost all languages; so,it is possible to define one general pattern to capture that common vulnerability in eachlanguage.Those patterns are defined over Abstract Syntax Trees (AST). To build an AST whileparsing a program, Checkmarx uses a set of functions called Visitors that are associated to theproductions of the programming language Grammar. In that context, the Language Factorytool developed by Checkmarx generates automatically some visitors and let programmers togenerate the others by dragging and dropping rules. The main objective of Language Factorytool is to aid programmers understanding how to create visitors and, at the same time, togenerate as many visitors as possible to be used directly. When Checkmarx is working ona new Language to to include support for that language in the CxSAST tool, the use ofLanguage Factory will help creating the appropriate Visitors making this process simplerand faster.The Master’s project reported in this dissertation appears in that framework aiming at theimprovement of the Checkmarx Language Factory making it capable of infer more Visitorsfrom the new language’s Grammar.",
    "text2": "Infrastructure as Code (IaC) is an innovative DevOps approach to infrastructure configuration and management.Instead of using traditional interactive tools — such as command line — or cloud provider webinterfaces, it automates several tasks through extensive use of scripting languages and tools.Being a relatively new field, with a fast-paced developing set of tools, it is of crucial importance to assistits users and its developers to tackle security concerns that might affect the environments these tools aremeant to manage. Some of those security concerns must always be handled within an actual live, runningenvironment. This is the case, for example, of checking for service availability. Issues like this are alreadybeing addressed by existing dynamic analysis tools. Others should be handled using a static analysisapproach, which, in turn, should prevent those security concerns from ever becoming a live security issue.In this dissertation, we focus on trying to bridge the gap between the set of security checks currentlybeing addressed by tools that follow these approaches. We identify 150 security checks currently beingperformed only by dynamic analysis tools, and we implement 23% of them in KICS, a Checkmarx-backed,open source, static code analysis tool for IaC solutions.The new checks we contribute to KICS address misconfiguration and non-compliance problems that canbe prevented using static analysis, mainly focusing on access control, but also on network security. Overall,this dissertation addresses 34 security checks, effectively bridging the gap between static and dynamicanalysis for IaC in the KICS context.Although not always possible, we strive to make available each security check to Ansible, CloudFormation,and Terraform. These new security checks and the necessary changes to KICS were submitted to the GitHubproject’s repository, were approved by the KICS team, and are now into its master branch. This means thatnew KICS releases will make available these security checks to its current users and to a broader audience,and, hopefully, will foster the development of community-based extensions and enhancements, such assupport for other IaC platforms and security domains that we were unable to tackle due to time constraints.",
    "similarity": 0.30086311735693533
  },
  {
    "text1": "Nowadays, we have the ability to trace everything, to extract valuable data from wherever we want, all tokeep us connected and to improve our lifestyle. This huge amount of information, produced every day,needs to be treated, manipulated, and analysed, requiring convincing data structures to do so.Dataframes, regularly used worldwide, are powerful data structures used to analyse and manipulatedata of any kind. A Dataframe organizes data into a 2-dimensional table of rows and columns, similar toSQL tables or CSV files. Furthermore, it can span alongside thousands of computers or servers, makingit easier to work with huge amounts of data, called big data, using distributed systems and parallel computing.This Dataframe’s distributed nature led to the rise of distinct scalable and parallel Dataframe tools. Themost used Dataframe tool, pandas, only performs on sequential execution and has some limitations whenthere is the need to handle huge volumes of data, and some tools such as Modin, Polars, RAPIDS, andso forth, appeared in order to overcome those limitations. The vast offer of these scalable tools broughtthe need to make an analysis and comparison between these frameworks and pandas, studying theirbehaviour and results with different workflows. This comparison is not linear and there is a need to usea benchmarking tool, in order to produce a homogeneous and reliable evaluation of the different frameworks.To perform this analysis, we worked with several workflows, manipulating real and synthetically produceddata on distributed and parallel environments and on different hardware configurations.We designed and developed a benchmarking tool that supports a set of Dataframe frameworks, is flexibleto the addition of new frameworks, and is able to perform micro-benchmarking evaluation with the analysisof a group of individual and common operations used on data science, and macro-benchmarking evaluation with the analysis of workflows that represent a set of chained operations. Both of these evaluationsaggregate performance and energy consumption results for each framework.",
    "text2": "The Energy-Split tool receives as input pieces of a very large molecular system and computesall intra and inter-molecular energies, separately calculating the energies of each fragmentand then the total energy of the molecule. It takes into account the connectivity informationamong atoms in a molecule to compute (i) the energy of all terms involving atoms covalentlybonded, namely bonds, angles, dihedral angles, and improper angles, and (ii) Coulomband the Van der Waals energies, that are independent of the atom’s connections, whichhave to be computed for every atom in the system. The required operations to obtain thetotal energy of a large molecule are computationally intensive, which require an efficienthigh-performance computing approach to obtain results in an acceptable time slot.The original Energy-Split Tcl code was thoroughly analyzed to be ported to a parallel andmore efficient C++ version. New data structures were defined with data locality features, totake advantage of the advanced features present in current laptop or server systems. Theseinclude the vector extensions to the scalar processors, an efficient on-chip memory hierarchy,and the inherent parallelism in multicore devices. To improve the Energy-Split’s sequentialvariant a parallel version was developed using auxiliary libraries. Both implementationswere tested on different multicore devices and optimized to take the most advantage of thefeatures in high performance computing.Significant results by applying professional performance engineering approaches, namely(i) by identifying the data values that can be represented as Boolean variables (such asvariables used in auxiliar data structures on the traversal algorithm that computes theEuclidean distance between atoms), leading to significant performance improvements due tothe reduced memory bottleneck (over 10 times faster), and (ii) using an adequate compressformat (CSR) to represent and operate on sparse matrices (namely matrices with Euclideandistances between atoms pairs, since all distances further the cut-off distance (user defined)are considered as zero, and these are the majority of values).After the first code optimizations, the performance of the sequential version was improvedby around 100 times when compared to the original version on a dual-socket server. Theparallel version improved up to 24 times, depending on the molecules tested, on the sameserver. The overall picture shows that the Energy-Split code is highly scalable, obtainingbetter results with larger molecule files, even when the atom’s arrangement influences thealgorithm’s performance.",
    "similarity": 0.30217745691662784
  },
  {
    "text1": "The main objective of this dissertation is to make a contribution in the automation of web applications' development, starting from prototypes of their graphical user interlaces. The integration of model-based user interface development concepts with the more traditional user-centred development approach allows for a rethinking of GUI design development, independent of implementation details, and redefining models to realize these graphical interfaces. In the end, the intent is to increase the level of abstraction of the development process, promote better adaptation of applications to different devices and execution environments, and decrease the effort required to develop the graphical interlaces. Due to the exponential increase in the use of internet-based services and applications, there is an also increasing demand for Web designers and developers. At the same time, the proliferation of languages, frameworks and libraries illustrates the current state of immaturity of web development technologies. This state of affairs creates difficulties in the development and maintenance of Web applications. An approach is presented that allows designers to use prototyping tools, in this case Adobe XD, to design graphical interfaces, and then automatically converts them to Vue.js + Bootstrap code, thus creating a first version of the implementation. This is done through the interpretation of the SVG file that Adobe XD exports. The goal is not to produce the final version of the Ul. Instead, we aim to produce a first version of the code, which can then be refined by the developer. This enables us to place less requirements on the prototype, regarding the amount of information that it must contain. In the end, we get a skeleton of Vue.js code that is easy to maintain and reuse to further improve the project.",
    "text2": "DevOps presents a mix of agile methodologies that allow an application’s release cycle to be shortened. Thistranslates into a faster delivery of value to the stakeholders.However, the value creation chain does not finish at the end of that cycle. It is necessary to monitor the artifactsproduced at a system level, and at the application level, in order to ensure the compliance of the functional andnon functional requirements.Today, there seems to be a clear separation between the monitoring process and the application developmentprocess. As the development and operations processes have merged in DevOps, this dissertation pretends toinvestigate how to integrate several aspects of monitoring into the regular lifecycle of an application’s development.The inclusion of external services further emphasizes the need to include an observability component into aninfrastructure.The main goal of this dissertation is to develop a solution for the deployment of an infrastructure using stateof-the-art technologies and frameworks, while also providing observability to the system and to the applicationsrunning on it.To do so, it required the investigation of the methodologies and concepts that are the base of the softwaredevelopment lifecycle, focusing on the latter stages of that process: the deployment, and monitoring phases.These methodologies and concepts were complemented with the study of state-of-the-art technologies andframeworks that aim to ease the burden of setting up an infrastructure quickly and with the necessary tools toevolve it after the initial setup and with each new software release. Furthermore, it also involved the research oftools that enable the collection of metrics from applications, as well as processing such data and displaying it inuseful ways for operators and stakeholders.In this context, this dissertation aims to provide a solution for the deployment of MobileID applications at INESCTEC, using the Mobile Driving Licence as the primary case study. The proposed design and implementationwith a container orchestration framework and CI/CD pipelines, enables faster development of different MobileIDapplications, while also providing continuous monitoring to the deployments.With this implementation, it was possible to assess how container orchestration frameworks provide greaterflexibility to applications, and how this observability can be augmented with the use of dedicated monitoringsystems.",
    "similarity": 0.30352998427790673
  },
  {
    "text1": "O rápido crescimento da complexidade dos sistemas de software exige, agora mais do que nunca, uma validação rigorosa dos mesmos por forma a manter ou até mesmo aumentar a confiança nestes sistemas. Em particular nos sistemas críticos, onde as falhas podem ter consequências catastróficas podendo até incluir a perca de várias vidas humanas, é de externa importância o desenvolvimento de técnicas capazes de garantir altos níveis de confiança para estes sistemas.Nesta tese é proposta a utilização de uma técnica formal para a verificação de programas Ada, que pretende aumentar a confiança em sistemas cuja implementação seja realizada nesta linguagem de programação. Mais precisamente, pretende-se a aplicação da técnica de verificação de modelos para a análise do código fonte de programas concorrentes Ada, com especial foco para o domínio dos sistemas críticos.A verificação de modelos é uma técnica bem-sucedida no que diz respeito à garantia de um aumento de fiabilidade destes sistemas. No entanto, a aplicação desta técnica a sistemas de software enfrenta ainda vários obstáculos, e as ferramentas e técnicas para ajudar a ultrapassar estes obstáculos estão ainda a ser desenvolvidas. A ferramenta desenvolvida no contexto desta tese (ATOS) visa responder a problemas como (i) a construção de modelos a partir de programas e (ii) a especificação de propriedades para estes modelos de acordo com as pretendidas para os programas.A construção manual de modelos que simulam o comportamento de programas é um processo complexo, temporalmente dispendioso, e sujeito a falhas devido à complexidade destes sistemas. De forma a ultrapassar este problema o ATOS propõe a extração automática de modelos a partir de programas Ada. Por outro lado, o mapeamento das propriedades desejadas dos programas em propriedades dos modelos pode ser urna tarefa com um grau de complexidade elevado, pois requer entre outros a utilização de um formalismo logico ao qual a maioria dos programadores não está acostumada. 0 ATOS ajuda no mapeamento destas propriedades, oferecendo vários mecanismos de suporte à sua especificação.",
    "text2": "Atualmente, o maior desafio no desenvolvimento de software é referente à a portabilidade das aplicações para as várias plataformas disponíveis, especialmente pela crescente heterogeneidade nos componentes de hardware, de middleware e de software base.O desenho de modelos abstratos de software é uma das formas mais elegantes e eficientes para solucionar este desafio. A Model-Driven Software Engineering (MDSE) ́é uma metodologia de desenvolvimento em que os modelos são chave em todo o ciclo de vida do projeto, desde a captura de requisitos, passando pelas fases de modelação e desenvolvimento, e por fim nos processos de teste e instalação.O objetivo primário desta dissertação foca-se na construção de uma ferramenta, o MDA SMART, capaz de interpretar modelos abstratos de software, parametrizáveis, e de gerar automaticamente código fonte para várias plataformas. A ferramenta, caracterizada por uma arquitetura robusta e extensível, é idealizada para permitir a manipulação de modelosde forma ágil, para ser modular o suficiente para integrar novos perfis meta-modelo e para escalar eficientemente para novas plataformas.O MDA SMART resulta da articulação de uma Domain-Specific Language (DSL) para a gestão dos meta-modelos e consequentes processos de transformação. Na utilização da DSL são obtidos processos de transformação rigorosos, com elevado desempenho e que visam maximizar a consistência e portabilidade dos modelos através de medidas ajustadas a destoarem a heterogeneidade entre as plataformas. Adicionalmente, a ferramenta visa compatibilizar os modelos de lógica de negócio com os referentes às interfaces gráficas que, conjugados, vão permitir a obtenção de modelos e código fonte com alto nível de consistência e completude.",
    "similarity": 0.30977474850561304
  },
  {
    "text1": "O rápido crescimento da complexidade dos sistemas de software exige, agora mais do que nunca, uma validação rigorosa dos mesmos por forma a manter ou até mesmo aumentar a confiança nestes sistemas. Em particular nos sistemas críticos, onde as falhas podem ter consequências catastróficas podendo até incluir a perca de várias vidas humanas, é de externa importância o desenvolvimento de técnicas capazes de garantir altos níveis de confiança para estes sistemas.Nesta tese é proposta a utilização de uma técnica formal para a verificação de programas Ada, que pretende aumentar a confiança em sistemas cuja implementação seja realizada nesta linguagem de programação. Mais precisamente, pretende-se a aplicação da técnica de verificação de modelos para a análise do código fonte de programas concorrentes Ada, com especial foco para o domínio dos sistemas críticos.A verificação de modelos é uma técnica bem-sucedida no que diz respeito à garantia de um aumento de fiabilidade destes sistemas. No entanto, a aplicação desta técnica a sistemas de software enfrenta ainda vários obstáculos, e as ferramentas e técnicas para ajudar a ultrapassar estes obstáculos estão ainda a ser desenvolvidas. A ferramenta desenvolvida no contexto desta tese (ATOS) visa responder a problemas como (i) a construção de modelos a partir de programas e (ii) a especificação de propriedades para estes modelos de acordo com as pretendidas para os programas.A construção manual de modelos que simulam o comportamento de programas é um processo complexo, temporalmente dispendioso, e sujeito a falhas devido à complexidade destes sistemas. De forma a ultrapassar este problema o ATOS propõe a extração automática de modelos a partir de programas Ada. Por outro lado, o mapeamento das propriedades desejadas dos programas em propriedades dos modelos pode ser urna tarefa com um grau de complexidade elevado, pois requer entre outros a utilização de um formalismo logico ao qual a maioria dos programadores não está acostumada. 0 ATOS ajuda no mapeamento destas propriedades, oferecendo vários mecanismos de suporte à sua especificação.",
    "text2": "O recurso a ferramentas de geração automática de código permite economizar tempo quando se desenvolvem soluções de software, factor importante em questões de produtividade.Existe um conjunto de padrões de conceção [Gamma et al., 1995] que representam soluções genéricas para problemas relativos ao desenvolvimento de aplicações de software, numa perspetiva orientada aos objetos. Para cada um deles pode ser vista a sua estrutura de classes, métodos e relacionamentos, bem como as situações mais adequadas para a sua utilização. Bastará consultar o catálogo de padrões de conceção [Gamma et al., 1995] e utilizar aquele que mais se adequar à resolução de determinado problema que surja no desenvolvimento de um novo programa.A existência de uma aplicação de software capaz de fazer a geração automática do código associado aos padrões de conceção, agiliza o desenvolvimento de novas aplicações, porque fornece de imediato o respetivo código.O que se propõe com o desenvolvimento desta dissertação é uma solução de software, capaz de efetuar a geração automática de código para os padrões de conceção catalogados em [Gamma et al., 1995]. Juntamente com o programa desenvolvido, é também apresentado um levantamento do estado da arte sobre os padrões de conceção, considerando também situações atuaisda sua aplicabilidade. Em seguida, é descrita a especificação da aplicação elaborada, bem como o seu processo de desenvolvimento, acompanhado de um exemplo de utilização. Por fim, encontram-se dois casos de estudo, servindo para provar que o programa elaborado pode ser utilizado em contextos reais.",
    "similarity": 0.31402609709870244
  },
  {
    "text1": "O cloud computing tem sido amplamente adotado na área das tecnologias de informação na última década, devido às diversas vantagens que providencia, entre elas a possibilidade de redução de custos com infraestruturas. Embora a utilização da cloud possa minorar os custos de operação de aplicações Web, verifica-se que a definição dos preços praticados pelos fornecedores de serviços tem-se tornado cada vez mais complexa, ameaçando uma das principais razões que leva os utilizadores a migrar para a cloud: a redução de custos. Derivado deste aumento de complexidade, o surgimento de soluções de monitorização e otimização de custos de cloud tem vindo a aumentar por forma a combater este problema. Apesar de existirem algumas soluções capazes de auxiliar na otimização de custos, verifica-se que a visibilidade sobre os custos e dados de utilização é limitada, não sendo possível consultar a informação com a granularidade que os utilizadores pretendem. Por todos estes motivos, a equipa de Investigação e Desenvolvimento da Eurotux Informática, S.A. decidiu investir no desenvolvimento de uma solução que auxiliasse os seus colaboradores e clientes num problema que enfrentam no dia a dia. Após estudar as soluções existentes, identificou-se, junto dos principais intervenientes, os requisitos que a solução deveria cumprir. A criação de uma aplicação em Flask em conjunto com uma Elas& Stack constitui a base tecnológica da solução. A modularidade, escalabilidade e robustez da solução foi tida em conta em todo o processo de elaboração da solução. O resultado final é uma ferramenta totalmente funcional que permite satisfazer as necessidades impostas. A integração com os principais fornecedores de cloud estudados foi amplamente conseguida. A avaliação da mesma foi realizada tendo por base diversos casos de estudo de clientes reais da empresa.",
    "text2": "A UN1Qnx, S.A., soluções de autenticidade ciber-físicas, é uma empresa sediada em Braga,que desenvolve e comercializa sistemas físicos, eletrónicos e cibernéticos de validação eautenticação de produtos, sendo o objetivo a proteção da marca e o combate à contrafação.Neste momento, a empresa possui um serviço de autenticação de produtos localizado numamáquina virtual na cloud, mais especificamente na Microsoft Azure. Contudo, a utilizaçãodeste serviço é intermitente e passa por períodos de inatividade. Porém, quando utilizado,cada execução do serviço é computacionalmente custosa, o que obriga à utilização de umamáquina virtual que tem em conta o caso de máxima utilização. Assim, nos intervalos entreutilizações os custos acumulam-se sem aproveitar os recursos alocados. Deste modo, estatese passa por otimizar a utilização dos recursos na cloud, tendo em vista tirar proveito daescalabilidade e elasticidade das tecnologias de computação na nuvem, bem como melhorara latência dos pedidos.A otimização dos recursos passa por comparar diferentes serviços de diferentes forne cedores e selecionar o que se apresenta como a melhor opção. A fim de realizar estascomparações, fez-se antes uma investigação baseada na metodologia Design Science Research.Primeiramente, explorou-se o ambiente da solução (computação na nuvem) e o ambientedo problema, isto é, qual a situação atual da empresa no que diz respeito ao funcionamentodo serviço de validação e dos recursos afetos ao mesmo.Em segundo lugar, fez-se uma averiguação sobre o estado da arte das tecnologias usadas,das tecnologias que poderiam vir a ser usadas e de outras empresas da mesma área, sobrequais os seus produtos e o seu modo de funcionamento. Por último, investigaram-se métodosde seleção e comparação entre várias opções.Em terceiro lugar, realizou-se a parte mais trabalhosa e demorada: o desenvolvimentoprático. Nesta fase realizaram-se testes de performance, a colocação do serviço num dockercontainer e a utilização de kubernetes. Ainda nesta última parte, houve vária experimentaçãocom diversas arquiteturas. Por fim, o sistema estabilizou numa arquitetura assíncrona, quefez reduzir os custos e, permitiu com que o serviço se adequasse melhor à quantidade detrabalho a processar.",
    "similarity": 0.302727286874786
  },
  {
    "text1": "O cloud computing tem sido amplamente adotado na área das tecnologias de informação na última década, devido às diversas vantagens que providencia, entre elas a possibilidade de redução de custos com infraestruturas. Embora a utilização da cloud possa minorar os custos de operação de aplicações Web, verifica-se que a definição dos preços praticados pelos fornecedores de serviços tem-se tornado cada vez mais complexa, ameaçando uma das principais razões que leva os utilizadores a migrar para a cloud: a redução de custos. Derivado deste aumento de complexidade, o surgimento de soluções de monitorização e otimização de custos de cloud tem vindo a aumentar por forma a combater este problema. Apesar de existirem algumas soluções capazes de auxiliar na otimização de custos, verifica-se que a visibilidade sobre os custos e dados de utilização é limitada, não sendo possível consultar a informação com a granularidade que os utilizadores pretendem. Por todos estes motivos, a equipa de Investigação e Desenvolvimento da Eurotux Informática, S.A. decidiu investir no desenvolvimento de uma solução que auxiliasse os seus colaboradores e clientes num problema que enfrentam no dia a dia. Após estudar as soluções existentes, identificou-se, junto dos principais intervenientes, os requisitos que a solução deveria cumprir. A criação de uma aplicação em Flask em conjunto com uma Elas& Stack constitui a base tecnológica da solução. A modularidade, escalabilidade e robustez da solução foi tida em conta em todo o processo de elaboração da solução. O resultado final é uma ferramenta totalmente funcional que permite satisfazer as necessidades impostas. A integração com os principais fornecedores de cloud estudados foi amplamente conseguida. A avaliação da mesma foi realizada tendo por base diversos casos de estudo de clientes reais da empresa.",
    "text2": "O desenvolvimento de aplicações e serviços baseados em web está a crescer todos os diascada vez mais. As facilidades que nos oferecem, entre elas a alta-disponibilidade e acessibilidade,levou a que as grandes empresas de tecnologia investissem neste tipo de tecnologias,surgindo assim aplicações como o Evernote, o Google Photos, o Dropbox, o Slack, entre outras.Associadas à utilização constante destas aplicações e serviços pelos seus clientes estãoas enormes quantidade de dados criados, bem como os dados gerados a partir destes. Coma necessidade de armazenar e processar esses de forma rápida e eficiente, estes serviçostem vindo a optar pela utilização de serviços de computação em nuvem de terceiros.Existem vantagens claras associadas à migração de dados para estas plataformas, desdea redução de custos associados armazenamento, manutenção e compra de infraestruturas,até às conveniências oferecidas pela disponibilização ferramentas de monitorização econfiguração avançadas, entre muitas outras. Associado também à utilização desta plataformasde cloud computing estão também os problemas com a privacidade dos dados por elasarmazenadas. Apesar dos esforços, por parte dos fornecedores destes serviços, em negaro acesso a entidades não autorizadas, existem ameaças fora do seu controlo e temos vistomuitas vezes que o acesso a dados sensíveis por terceiros tem um risco elevado associado.Com vista a combater este aspeto existem hoje em dia soluções capazes de garantir a confidencialidadedos dados em bases de dados relacionais e não relacionais, através de técnicascriptográficas. Estas soluções estão usualmente associadas a arquiteturas específicas deforma a precaverem sempre esta questão de segurança dos dados em todos os momentos.Estas arquiteturas implicam um maior esforço computacional do lado do cliente, pois édesse lado que se encontra toda a lóogica da aplicacional e mecanismos de segurança.Esta dissertação oferece uma nova arquitetura web onde maior parte do trabalho aplicacionalé delegado para as infraestruturas de nuvem maximizando assim o desempenhoda aplicação, tirando para isso partido da arquitetura browser servidor característica destessistemas.",
    "similarity": 0.3058914241654054
  },
  {
    "text1": "Current identity management systems rely on centralized databases to store user’s personal data, which posesa great risks for data security, as these infrastructure create a critical point of failure for the whole system. Besidethat service providers have to bear huge maintenance costs and comply with strict data protection regulations.Self-sovereign identity (SSI) is a new identity management paradigm that tries to answer some of theseproblems by providing a decentralized user-centric identity management system that gives users full control oftheir personal data. Some of its underlying concepts include Decentralized Identifiers (DIDs), Verifiable Claimsand Credentials. This approach does not rely on any central authority to enforce trust as it often uses Blockchainor other Decentralized Ledger Technologies (DLT) as the trust anchor of the system, although other decentralizednetwork or databases could also be used for the same purpose.This thesis focuses on finding alternative solutions to DLT, in the context of SSI. Despite being the most usedsolution some DLTs are known to lack scalability and performance, and since a global identity managementsystem heavily relies on these two requirements it might not be the best solution to the problem.This document provides an overview of the state of the art and main standards of SSI, and then focuses ona non-DLT approach to SSI, referencing non-DLT implementations and alternative decentralized infrastructuresthat can be used to replace DLTs in SSI. It highlights some of the limitations associated with using DLTs foridentity management and presents a SSI framework based on decentralized names systems and networks. Thisframework couples all the main functionalities needed to create different SSI agents, which were showcased ina proof of concept application.",
    "text2": "The high growth in the use of digital identities creates the need to develop mechanismsthat can protect the personal data of each individual. The way identity is treated todayprevents each of us from being able to control our personal information. This is due to thecentralized architecture in which the personal data are inserted, that is, all these data are kepttogether and controlled by the entities responsible for providing the most varied services,which is wrong since the identity belongs to the person and thus it must be responsiblefor controlling that identity. Centralized identity management brings within itself severalproblems, whether intentional (that is, data correlation for profiling) or unintentional (thatis, data breach).To face this problem, multiple entities across the world are developing decentralizedidentity managment systems based on a self-sovereign identity architecture where eachindividual is responsible for managing and storing a set of credentials, each with parts oftheir personal information. A self-sovereign identity architecture allows users to provide onlysmall parts of their personal information or even to omit any type of personal identification,using cryptographic techniques like selective disclosure and zero-knowledge proofs, whichallows them to have more control over their privacy.Taking into account the current problems of digital identity, this dissertation aims toexplore the state of the art and develop a proof of concept, through the implementation ofa system based on self-sovereign identity, which is able to cover the use cases for digitalidentity. Thus, this document shows the architecture implemented, with a blockchain,responsible for the storage of all public data, and a user agent, responsible for facilitating allinteractions of the various users with the developed system.The proof of concept developed allows not only to validate that it is possible to correctmany of the problems associated with centralized identity management, but also to explorenew cryptographic strategies in order to improve the way each of us manages our ownidentity.",
    "similarity": 0.3140403640680649
  },
  {
    "text1": "Smartphones increasingly play an important role in everyday life, whether to communicateor perform tasks that require more computing power. This has become an indispensableobject in the lives of many people so their use increases more and more. This growth isassociated with an increase in network traffic due to the existing applications and Internetservices.This increase in traffic is also due to the development and growth of 3G and 4G mobilenetworks, which allow Internet access when out of Wi-Fi networks. Such access requiresa mobile data plan that is normally limited to a certain level. Expiring this plan, access tothe Internet from mobile networks is prohibited or limited to a certain rate which is ofteninadequate for the requirements of the applications used.This disturbance is commonly associated with the consumption of bandwidth in orderto reproduce contents downloaded from the network. These contents are often associatedwith the normal operation of the applications, i.e., expected contents, however, there arecontents that were not requested by the user, for instance advertisements contributing todata plan exhaustion.This justifies the need for studying and understanding the traffic involved between theuser device and the network in order to assist the end user in identifying how much datahas been consumed and distinguishing by the type of traffic involved. To answer this need,a systematic methodology is developed and proposed in this work considering as inputspopular user applications - YouTube, Facebook and Instagram - with potencial impact onthe user data plan. Therefore, the present dissertation is a contribution in the field of trafficanalysis and characterization, shedding light in the process of identifying and measuringtraffic not requested by the user.",
    "text2": "Computer networks security is becoming an important and challenging topic. In particular, onecurrently witnesses increasingly complex attacks which are also bound to become more and moresophisticated with the advent of artificial intelligence technologies.Intrusion detection systems are a crucial component in network security. However, the limitednumber of publicly available network datasets and their poor traffic variety and attack diversity are amajor stumbling block in the proper development of these systems.In order to overcome such difficulties and therefore maximise the detection of anomalies in thenetwork, it is proposed the use of Adversarial Deep Learning techniques to increase the amount andvariety of existing data and, simultaneously, to improve the learning ability of the classification modelsused for anomaly detection.This master’s dissertation main goal is the development of a system that proves capable of improving the detection of anomalies in the network through the use of Adversarial Deep Learning techniques,in particular, Generative Adversarial Networks. With this in mind, firstly, a state-of-the-art analysis anda review of existing solutions were addressed. Subsequently, efforts were made to build a modular solution to learn from imbalanced datasets with applications not only in the field of anomaly detection inthe network, but also in all areas affected by imbalanced data problems. Finally, it was demonstratedthe feasibility of the developed system with its application to a network flow dataset.",
    "similarity": 0.3170057132963989
  },
  {
    "text1": "The trend of increasing size of datasets in storage-based applications has promoted the research of newmethods and technologies for efficiently storing, processing, and analyzing large amounts of data. As aresult, Log Structured Merge (LSM) Key-Value Stores (KVSs) have been highly adopted since theirdesign allows high write throughput and enforces sequential disk access patterns. Additionally, with theadvent of Non-Volatile Main Memory (NVMM), new storage technologies have emerged that offerfaster access times compared to traditional block-based storage devices, thus accelerating KVSs.However, while NVMM devices offer faster access to data, they are typically limited in capacity and areoften more expensive. To address this trade-off, contemporary storage solutions harness the capabilities ofheterogeneous storage devices in two fundamental manners: caching and tiering. In this dissertation, weshow that, on one hand, read-dominated workloads benefit from a caching approach, but their performancedegrades under tiering. On the other hand, for write-dominated workloads, the tiering approach presentsbetter performance, while storing the entire dataset on NVMM actually degrades performance.To overcome these challenges, this dissertation proposes KEIGO, a novel storage middleware that al lows LSM-based KVS to efficiently use storage hierarchies composed of NVMM and block-based devices.KEIGO is aware of the different I/O operations done by the KVS (e.g., foreground requests, and backgroundflushes and compactions) and the characteristics of the underlying devices (e.g., concurrency, read/writeasymmetry). This knowledge serves as a pivotal factor in optimizing KEIGO’s performance in the face ofdynamic and mixed production workloads such as those observed in Nutanix and Meta. Moreover, KEIGOrequires minimal code modifications to integrate into production-ready LSM KVSs.Conducted experiments show that KEIGO significantly enhances the throughput of LSM KVS solu tions, including RocksDB, Speedb, and LevelDB, by as much as 12.4×. Furthermore, it substantiallyreduces tail latency by up to 21.3× over both general-purpose storage solutions and LSM KVSs builtfrom the ground up for hierarchical storage.",
    "text2": "Deep Learning (DL) has become fundamental to the advancement of several areas, such as computervision, natural language processing and expert systems. Utilizing DL techniques demands vast amountsof data and processing power, which raises challenges to the training performance of DL models. High Performance Computing (HPC) systems are becoming increasingly popular to support DL training, byoffering extensive computing capabilities, however, due to convenience and usability, many DL jobs runningon these infrastructures resort to the shared Parallel File System (PFS) for storing and accessing trainingdata. Under such scenario, where multiple Input/Output (I/O)-intensive applications operate concurrently,the PFS can quickly get saturated with simultaneous storage requests and become a critical performancebottleneck, leading to throughput variability and performance loss.To solve these issues, this dissertation presents a storage middleware agnostic to any DL solution,Monarch, that deploys storage tiering to accelerate DL models’ training performance and decrease the I/Opressure imposed over the PFS. It leverages from existing storage tiers of supercomputers (e.g., computenode’s local storage, shared PFS), as well as the I/O patterns of DL solutions to improve data placementacross storage tiers. Furthermore, this middleware is non-intrusive and easily installed in HPC centers,thus enabling its wide adoption and applicability.The performance and applicability of Monarch are validated with the TensorFlow and PyTorch DLframeworks. Results show that, when the training dataset can only be partially stored at the local storagetier, Monarch decreases TensorFlow’s and PyTorch’s training time by up to 28% and 37% for I/O-intensivemodels, respectively. Furthermore, Monarch can reduce the number of I/O operations submitted to thePFS by up to 56%.",
    "similarity": 0.31134072022160664
  },
  {
    "text1": "Risk assessment is an important topic for financial institution nowadays, especially in the context of loan applications or loan requests and credit scoring. Some of these institutions have already implemented their own custom credit scoring systems to evaluate their clients’ risk supporting the loan application decision with this indicator. In fact, the information gathered by financial institutions constitutes a valuable source of data for the creation of information assets from which credit scoring mechanisms may be developed.Historically, most financial institutions support their decision mechanisms on regression algorithms, however, these algorithms are no longer considered the state of the art on decision algorithms. This fact has led to the interest on the research of new types of learning algorithms from machine learning able to deal with the credit scoring problem.The work presented in this dissertation has as an objective the evaluation of state of the art algorithms for credit decision proposing new optimization to improve their performance. In parallel, a suggestion system on credit scoring is also proposed in order to allow the perception of how algorithm produce decisions on clients’ loan applications, provide clients with a source of research on how to improve their chances of being granted with a loan and also develop client profiles that suit specific credit conditions and credit purposes.At last, all the components studied and developed are combined on a platform able to deal with the problem of credit scoring through an experts system implemented upon a multi-agent system. The use of multi-agent systems to solve complex problems in today’s world is not a new approach. Nevertheless, there has been a growing interest in using its properties in conjunction with machine learning and data mining techniques in order to build efficient systems. The work presented aims to demonstrate the viability and utility of this type of systems for the credit scoring problem.",
    "text2": "Risk assessment is an important topic for financial institution nowadays, especially in the context of loan applications or loan requests and credit scoring. Some of these institutions have already implemented their own custom credit scoring systems to evaluate their clients’ risk supporting the loan application decision with this indicator. In fact, the information gathered by financial institutions constitutes a valuable source of data for the creation of information assets from which credit scoring mechanisms may be developed.Historically, most financial institutions support their decision mechanisms on regression algorithms, however, these algorithms are no longer considered the state of the art on decision algorithms. This fact has led to the interest on the research of new types of learning algorithms from machine learning able to deal with the credit scoring problem.The work presented in this dissertation has as an objective the evaluation of state of the art algorithms for credit decision proposing new optimization to improve their performance. In parallel, a suggestion system on credit scoring is also proposed in order to allow the perception of how algorithm produce decisions on clients’ loan applications, provide clients with a source of research on how to improve their chances of being granted with a loan and also develop client profiles that suit specific credit conditions and credit purposes.At last, all the components studied and developed are combined on a platform able to deal with the problem of credit scoring through an experts system implemented upon a multi-agent system. The use of multi-agent systems to solve complex problems in today’s world is not a new approach. Nevertheless, there has been a growing interest in using its properties in conjunction with machine learning and data mining techniques in order to build efficient systems. The work presented aims to demonstrate the viability and utility of this type of systems for the credit scoring problem.",
    "similarity": 0.398854028664338
  },
  {
    "text1": "In the last years, the number of Machine Learning algorithms and their parameters has increased significantly.This allows for more accurate models to be found, but it also increases the complexity of the task of training amodel, as the search space expands significantly.As datasets keep growing in size, traditional approaches based on extensive search start to become costlyin terms of computational resources and time, especially in data streaming scenarios. With this growth, newchallenges in Machine Learning started to appear. The speed at which data arrives and different ways of storingdata are forcing organizations to address and explore new ways of adapting fast enough so their ML modelsdon’t become obsolete.This dissertation aims to develop an approach based on meta-learning that tackles two main challenges: predict ing the performance metrics of a future model and recommending the best algorithm/configuration for traininga model for a specific Machine Learning problem. Throughout this dissertation, all the study objectives andquestions, along with the relevant contextualization will be exposed.The proposed solution, when compared to an AutoML approach is up to 130x faster and only 2% worse in termsof average model quality, showing it is a good solution for scenarios in which models need to be updated regularly,such as in streaming scenarios with Big Data, in which some accuracy can be traded for a much shorter modeltraining time.",
    "text2": "In the last few years, data management engines have become increasingly modular, separating some of itsmain layers, such as data storage and transactional management. The exposure of the transactional manage ment component brings new challenges, in particular its correct configuration and tuning when running differentworkloads. In this sense, this dissertation focuses on the autonomous optimization of a particular transactionalmiddleware, pH1, while keeping in mind the tuning of other similar systems.It is becoming more and more important to develop algorithms that can automatically optimize these systemswhose performance is heavily dependent on a proper configuration. The use of machine learning techniques forsimilar problems (database knob tuning) has become common in the literature [1, 2, 3, 4], especially in a blackbox perspective where it does not have visibility over particular details of the system.Usually, these systems are located in realistic online environments, where workloads can change at differenttimes. Even though there are numerous research projects for automatic knob tuning, these projects have notentirely addressed this problem and are mostly developed for offline training when the workloads remain static.We propose OPAL as the component that when executing transactional workloads is able to dynamically adjustits configurations in an online environment with a continuous space. Our approach allows for online changes anduses reinforcement learning as a starting point taking into consideration tuning algorithms in continuous spaces,as is the case of DDPG [5].",
    "similarity": 0.3025888056053446
  },
  {
    "text1": "Deep Learning (DL) has become fundamental to the advancement of several areas, such as computervision, natural language processing and expert systems. Utilizing DL techniques demands vast amountsof data and processing power, which raises challenges to the training performance of DL models. High Performance Computing (HPC) systems are becoming increasingly popular to support DL training, byoffering extensive computing capabilities, however, due to convenience and usability, many DL jobs runningon these infrastructures resort to the shared Parallel File System (PFS) for storing and accessing trainingdata. Under such scenario, where multiple Input/Output (I/O)-intensive applications operate concurrently,the PFS can quickly get saturated with simultaneous storage requests and become a critical performancebottleneck, leading to throughput variability and performance loss.To solve these issues, this dissertation presents a storage middleware agnostic to any DL solution,Monarch, that deploys storage tiering to accelerate DL models’ training performance and decrease the I/Opressure imposed over the PFS. It leverages from existing storage tiers of supercomputers (e.g., computenode’s local storage, shared PFS), as well as the I/O patterns of DL solutions to improve data placementacross storage tiers. Furthermore, this middleware is non-intrusive and easily installed in HPC centers,thus enabling its wide adoption and applicability.The performance and applicability of Monarch are validated with the TensorFlow and PyTorch DLframeworks. Results show that, when the training dataset can only be partially stored at the local storagetier, Monarch decreases TensorFlow’s and PyTorch’s training time by up to 28% and 37% for I/O-intensivemodels, respectively. Furthermore, Monarch can reduce the number of I/O operations submitted to thePFS by up to 56%.",
    "text2": "Computer networks security is becoming an important and challenging topic. In particular, onecurrently witnesses increasingly complex attacks which are also bound to become more and moresophisticated with the advent of artificial intelligence technologies.Intrusion detection systems are a crucial component in network security. However, the limitednumber of publicly available network datasets and their poor traffic variety and attack diversity are amajor stumbling block in the proper development of these systems.In order to overcome such difficulties and therefore maximise the detection of anomalies in thenetwork, it is proposed the use of Adversarial Deep Learning techniques to increase the amount andvariety of existing data and, simultaneously, to improve the learning ability of the classification modelsused for anomaly detection.This master’s dissertation main goal is the development of a system that proves capable of improving the detection of anomalies in the network through the use of Adversarial Deep Learning techniques,in particular, Generative Adversarial Networks. With this in mind, firstly, a state-of-the-art analysis anda review of existing solutions were addressed. Subsequently, efforts were made to build a modular solution to learn from imbalanced datasets with applications not only in the field of anomaly detection inthe network, but also in all areas affected by imbalanced data problems. Finally, it was demonstratedthe feasibility of the developed system with its application to a network flow dataset.",
    "similarity": 0.3099804031354983
  },
  {
    "text1": "Nos primórdios a Internet era usada apenas por algumas pessoas. Nessa altura muitas das grandes empresas de tecnologia ainda não tinham aparecido. Porém tudo mudou quando a Internet entrou nos circuitos comerciais, provocando o aparecimento de estruturas para fazer a ligação das pessoas ao seu mundo. Desde aí que as grandes empresas têm adotado novas formas de encarar o mercado, aumentando gradualmente a sofisticação da forma de o fazerem. As empresas começaram a monitorizar a atividade dos seus clientes para que com isso melhorar a oferta dos seus bens e serviços ao público em geral. Todavia o conhecimento acerca daquilo que o cliente gosta não é suficiente para o atrair. Uma empresa também precisa que a informação apresentada ao cliente seja feita da maneira mais rápida possível. Por exemplo, se um cliente esperar mais do que “três” segundos para que o site seja carregado, o cliente irá abandoná-lo e, provavelmente, procurar um outro site de uma empresa concorrente. A Google avalia a rapidez dos sites e com isso dá-lhes uma pontuação. Os sites com piores pontuações são apresentados em últimos, o que tem, como sabemos, um grande impacto na escolha dos clientes. Mas não é só com os clientes que as empresas se tem de preocupar. Internamente os serviços dos funcionários de uma empresa podem ser afetados por uma Internet lenta, o que conduz a uma perda de performance e ao aumento da frustração do próprio funcionário no local de trabalho. Por estas razões é importante que as empresas estejam constantemente a monitorizar o tráfego passado pelos seus servidores, para serem capazes de verificar se os motivos da lentidão dos seus serviços de rede são internos ou não. Neste trabalho de dissertação desenvolvemos um trabalho baseadoem process mining, que através de uma ferramenta de monitorização de rede, wireshark, permite avaliar a qualidade de serviço da rede através da observação e análise das logs produzidas por alguns dos seus equipamentos, em particular, dos seus routers. Como são geradas várias logs para cada um tipo de router foi necessário fazer a sua conciliação, para que, a partir daí, se pudesse obter o percurso que os vários pacotes realizaram na sua movimentação pela rede. Desta forma, é possível criar um modelo matemático capaz de determinar um índice de bem-estar relativo à qualidade de serviço da rede de uma empresa. Basicamente, este índice permitirá avaliar odesempenho da rede e permitir aos seus gestores identificar, por exemplo, quais os pontos da rede que apresentam menor desempenho (ou estrangulamentos de serviço) e prevenir futuras quebras no serviço geral da rede em análise.",
    "text2": "As arquiteturas monolíticas estão, em grande parte, presentes na maioria das plataformas de e-commerce, o queleva a um processo de modificação mais complicado e entregas demoradas ao cliente, uma vez que não estápreparada para trabalho em paralelo.A arquitetura de microsserviços veio proporcionar outra forma de desenvolvimento destas plataformas, permitindoo trabalho em simultâneo por diferentes equipas, produzindo novas entregas para o cliente de forma maisacelerada e segura. Todavia, esta possui alguns desafios e complexidades, o que leva muitas vezes à escolha deuma arquitetura monolítica para o desenvolvimento da aplicação.A maioria das aplicações não são imutáveis, pois mesmo estando entregues ao cliente são sujeitas amodificações. Esta necessidade de modificar a aplicação leva a preocupações acerca da rapidez com que asnovas funcionalidades são entregues ao cliente. É preciso tomar decisões no início do desenvolvimento sobreque arquitetura seguir, de modo a tomar a decisão mais vantajosa. No caso de aplicações monolíticas a mudançapara uma arquitetura de microsserviços facilita este aspeto, bem como muitos outros. Contudo, esta separaçãopode-se tornar quase impossível se o monolítico não for bem preparado para uma eventual futura mudança.Uma das maiores dificuldades numa migração de um monolítico para microsserviços, relaciona-se coma definição do que deve ser cada microsserviço e na comunicação entre estes. A migração deve partir daidentificação de partes do código que possam ser isoladas sem ter muito impacto no resto do código. Com odesenho de um diagrama de packages é possível obter uma visão sobre a estrutura do sistema, percebendo quecomponentes são mais fáceis e mais difíceis de extrair. Deve-se começar por extrair aqueles que contém menosdependências, adquirindo as vantagens de uma migração incremental que permite que sejam reduzidos os errosefetuados, porém, pode haver situações em que se queira extrair um componente com mais dependências.É necessário compreender o porquê da migração para uma arquitetura de microsserviços. Esta decisãonão deve ser tomada apenas porque a arquitetura de microsserviços está em voga, mas sim por razõesfundamentadas. Dentro destas razões encontra-se a rapidez com que as mudanças são efetuadas e colocadasem produção, pois é mais fácil realizar modificações e voltar a instalar os microsserviços sem que toda a aplicaçãotenha que reiniciar. Isto permite uma melhor estruturação da equipa, possibilitando que várias equipas possamtrabalhar em simultâneo para a mesma aplicação, não prejudicando em nada outros microsserviço. Outra razãoé a necessidade de escalar os microsserviços independentemente, providenciando maior robustez, pois a falhade um serviço não leva à falha de toda a aplicação ou então pela escolha de tecnologia, podendo-se implementaros microsserviço com a tecnologia que seja mais adequada e eficiente.",
    "similarity": 0.3005020775623269
  },
  {
    "text1": "Na literatura do domínio do processamento analítico de dados facilmente se podem encontrar métodos e soluções que respondem ao problema de seleção de vistas multidimensionais no processo de implementação de um cubo OLAP. Uma forma que se evidencia como sendo extremamente vantajosa, é a de fazer a seleção baseada em critérios que se apoiem essencialmente nos conteúdos que são consultados sobre o cubo de dados ao longo das sessões de consulta OLAP. As principais vantagens que advêm desta monitorização, está relacionada com a possibilidade de efetuar correspondências rigorosas com a informação em que os agentes de decisão mais se apoiam para efetuar as suas tomadas de decisão. Ao ser feita a identificação da informação que se evidencia como sendo a mais relevante, ou pelo menos a mais frequentemente consultada, várias ilações se podem retirar, como, por exemplo, a definição de perfis de utilização, a expressão de preferências, a identificação de metodologias de trabalho, ou então a definição de processos que procurem construir cubos iceberg com forte probabilidade de explorações futuras sobre o cubo. Este último aspeto constitui, basicamente, o trabalho desta dissertação. Ao se efetuar a materialização dos conteúdos mais pesquisados no servidor OLAP, obtém-se um melhor desempenho ao nível do servidor, uma vez que o preparamos antecipadamente com os dados que mais vezes são solicitados, reduzindo assim o número de vezes que seria necessário recorrer ao data warehouse para retornar os resultados pretendidos por uma dada query multidimensional. Em termos gerais, neste trabalho de dissertação, desenvolveu-se um estudo detalhado acerca das ideias e práticas que levam ao desenvolvimento de um dado método de seleção, que seja capaz de indicar de forma precisa as partes de um cubo que são mais utilizadas, sugerindo com base nessa informação uma nova estrutura para o cubo em questão que utilize menos recursos computacionais, nomeadamente espaço em disco e tempo de processamento.",
    "text2": "Na atualidade, graças às elevadas capacidades computacionais e gráficas existentes, é possíveldotar os sistemas de processamento analítico com ferramentas de visualização e manipulação deinformação muito atrativas e de fácil utilização, em particular quando utilizamos para issodashboards. Os dashboards tornam a interação com a informação proveniente de um sistema deprocessamento analítico mais interativa e eficaz, muito graças à modularidade inerente aos seuscomponentes gráficos e à sua qualidade inata de representar a informação graficamente. Amodularidade também é uma característica importante uma vez que permite modificar o sistemautilizando apenas cliques do rato, enquanto que, por sua vez, a representação gráfica dainformação facilita a sua análise e interiorização (Few, 2006a). Estas qualidades, entre outras,fazem com que os dashboards sejam uma ferramenta fulcral na análise da informação e nosuporte à tomada de decisão no seio de uma empresa, tendo sempre em mente que o sucesso deuma empresa está dependente da capacidade que os seus responsáveis e funcionários têm detomar decisões acertadas em tempo útil. Em geral, os dashboards podem ser utilizados paramonitorizar o desempenho de uma empresa, tanto a nível global como a nível individual, definirestratégias de marketing, analisar tendências, entre outros. Nesta dissertação pretendeu-seinvestigar a utilização de dashboards em sistemas de processamento analítico, abordando desde oseu desenho até à sua implementação e exploração prática. Complementarmente, de forma ademonstrar a utilidade e vantagens desse tipo de instrumentos, procedeu-se à implementação deum sistema piloto, incorporando na sua estrutura uma coleção de dashboards providos demecanismos de auto-adaptabilidade aos requisitos dos utilizadores.",
    "similarity": 0.3192329735409304
  },
  {
    "text1": "Na literatura do domínio do processamento analítico de dados facilmente se podem encontrar métodos e soluções que respondem ao problema de seleção de vistas multidimensionais no processo de implementação de um cubo OLAP. Uma forma que se evidencia como sendo extremamente vantajosa, é a de fazer a seleção baseada em critérios que se apoiem essencialmente nos conteúdos que são consultados sobre o cubo de dados ao longo das sessões de consulta OLAP. As principais vantagens que advêm desta monitorização, está relacionada com a possibilidade de efetuar correspondências rigorosas com a informação em que os agentes de decisão mais se apoiam para efetuar as suas tomadas de decisão. Ao ser feita a identificação da informação que se evidencia como sendo a mais relevante, ou pelo menos a mais frequentemente consultada, várias ilações se podem retirar, como, por exemplo, a definição de perfis de utilização, a expressão de preferências, a identificação de metodologias de trabalho, ou então a definição de processos que procurem construir cubos iceberg com forte probabilidade de explorações futuras sobre o cubo. Este último aspeto constitui, basicamente, o trabalho desta dissertação. Ao se efetuar a materialização dos conteúdos mais pesquisados no servidor OLAP, obtém-se um melhor desempenho ao nível do servidor, uma vez que o preparamos antecipadamente com os dados que mais vezes são solicitados, reduzindo assim o número de vezes que seria necessário recorrer ao data warehouse para retornar os resultados pretendidos por uma dada query multidimensional. Em termos gerais, neste trabalho de dissertação, desenvolveu-se um estudo detalhado acerca das ideias e práticas que levam ao desenvolvimento de um dado método de seleção, que seja capaz de indicar de forma precisa as partes de um cubo que são mais utilizadas, sugerindo com base nessa informação uma nova estrutura para o cubo em questão que utilize menos recursos computacionais, nomeadamente espaço em disco e tempo de processamento.",
    "text2": "Com o emergir da era da informação foram muitas as empresas que recorreram a data warehouses para armazenar a crescente quantidade de dados que dispõem sobre os seus negócios. Com essa evolução dos volumes de dados surge também a necessidade da sua melhor exploração para que sejam úteis de alguma forma nas avaliações e decisões sobre o negócio. Os sistemas de processamento analítico (ou OLAP – On-Line Analytical Processing) vêm dar resposta a essas necessidades de auxiliar o analista de negócio na exploração e avaliação dos dados, dotando-o de autonomia de exploração, disponibilizando-lhe uma estrutura multiperspetiva e de rápida resposta. Contudo para que o acesso a essa informação seja rápido existe a necessidade de fazer a materialização de estruturas multidimensionais com esses dados já pré-calculados, reduzindo o tempo de interrogação ao tempo de leitura da resposta e evitando o tempo de processamento de cada query. A materialização completa dos dados necessários torna-se na prática impraticável dada a volumetria de dados a que os sistemas estão sujeitos e ao tempo de processamento necessário para calcular todas as combinações possíveis. Dado que o analista do negócio é o elemento diferenciador na utilização efetiva das estruturas, ou pelo menos aquele que seleciona os dados que são consultados nessas estruturas, este trabalho propõe um conjunto de técnicas que estudam o comportamento do utilizador, de forma a perceber o seu comportamento sazonal e as vistas alvo das suas explorações, para que seja possível fazer a definição de novas estruturas contendo as vistas mais apropriadas à materialização e assim melhor satisfaçam as necessidades de exploração dos seus utilizadores.Nesta dissertação são definidas estruturas que acolhem os registos de consultas dos utilizadores e com esses dados são aplicadas técnicas de identificação de perfis de utilização e padrões de utilização, nomeadamente a definição de sessões OLAP, a aplicação de cadeias de Markov e a determinação de classes de equivalência de atributos consultados. No final deste estudo propomos a definição de uma assinatura OLAP capaz de definir o comportamento OLAP do utilizador com os elementos identificados nas técnicas estudadas e, assim, possibilitar ao administrador de sistema uma definição de reestruturação das estruturas multidimensionais “à medida” da utilização feita pelos analistas.",
    "similarity": 0.37087830738370425
  },
  {
    "text1": "Na atual conjuntura em que vivemos é crucial que seja realizado um estudo aprofundadosobre a utilização dos recursos da cidade, especialmente em zonas urbanas. Além disso,uma rede de estradas bem conservada deveria ser uma prioridade para o desenvolvimentoeconómico e bem-estar dos habitantes de qualquer país.Com o desenvolvimento da tecnologia, em particular na área das Cidades Inteligentes(“Smart cities”), é importante implementar sistemas de apoio, de modo a centralizar toda ainformação existente sobre um aspeto de interesse, de maneira a “virtualizar” as cidades.Neste trabalho pretende-se desenvolver esse suporte em torno de uma rede de transportespúblicos, compilando toda a informação que essa rede nos poderá fornecer para que possaser útil a várias entidades.Neste contexto, a presente dissertação pretende estudar duas vertentes no âmbito dasCidades Inteligentes. Na primeira será realizado um estudo do estado do pavimento atravésde sensores de aceleração (acelerómetros), sendo estes sensores colocados numa rede urbanade transportes públicos já existentes, assim a rota será conhecida pela entidade responsável,como por exemplo a Câmara Municipal do distrito em questão. Assim, espera-se quecom esta informação seja possível uma tomada de decisão mais adequada, face ao estadodo pavimento, de maneira a que possam ser realizados os trabalhos necessários para areconstrução do mesmo. Na segunda vertente será realizado um estudo da monitorizaçãodo trânsito em áreas em que o fluxo é elevado, com base na mesma rede de transportespúblicos, sendo a informação obtida através dos mesmos sensores.",
    "text2": "Nos últimos anos, cada vez mais pessoas que anteriormente viviam em zonas rurais migram para centros urbanos à procura de novas oportunidades. Face a este movimento, vários problemas e adversidades foram-se agravando, nomeadamente, o aumento do fluxo rodoviário, que cria problemas de trânsito, o aumento dos níveis de poluição, o acesso à saúde, entre outros. Desta forma, torna-se imperativo gerir de forma eficaz e sustentável os recursos, com a finalidade de melhorar a qualidade de vida dos habitantes destas cidades.Neste contexto, juntamente com os avanços tecnológicos que se tem observado, surge o conceito de Cidades Inteligentes, que recorrendo a redes de sensores recolhem todos os dados necessários para ”virtualizar” as cidades. Desse modo, a informação coletada está centralizada, para que assim seja possível gerir os recursos disponíveis de forma informada, responsável e eficiente, para que seja possível responder às necessidades da população. Com este trabalho, pretende-se estudar dois problemas concretos no âmbito das Cidades Inteligentes, nomeadamente na área do Transporte Inteligente, recorrendo à simulação de redes de sensores, constituídas por sensores de aceleração instalados na rede de transporte públicos da cidade, a partir da qual vão ser recolhidos dados. O primeiro problema que se tenciona solucionar está relacionado com a monitorização do estado do pavimento. Com os dados provenientes dos acelerómetros, espera-se ser possível estimar o estado de conservação das vias rodoviárias e, desta forma, as entidades responsáveispassam a ser capazes de realizar decisões informadas e apropriadas face ao estado de determinada estrada, procedendo assim à sua restauração caso necessário. Uma segunda vertente que se pretende explorar foca a monitorização da congestão das vias rodoviárias em que, com base na mesma rede de transportes, se projeta ser possível determinar os níveis de fluxo rodoviário. Por fim, é ainda expectável que beneficiando dos transportes públicos dos quais já se está a tirar proveito, seja plausível medir os níveis de poluição aérea.",
    "similarity": 0.3150639007806598
  },
  {
    "text1": "A presente dissertação baseia-se na expectativa de diminuir o trabalho e tempo necessário para o desenvolvimento de uma loja online por programadores. Com a evolução do comércio, começaram a surgir cada vez mais negócios com lojas online, sendo por isso cada vez maiores as exigências e condições para que estas se tornassem um sucesso. Todas as lojas online costumam ter aspetos em comum como o carrinho de compras, a autenticação, entre outros componentes básicos sobre os quais se poderia salvar tempo de desenvolvimento se não se tivesse de reescrever sempre o mesmo código. Esta dissertação teve início com a investigação dos parâmetros necessários para que uma loja on-line funcionasse, pelo que em seguida foi desenvolvido uma loja online de venda de jogos e produtos relacionados. Após a investigação foi possível identificar vários aspetos e parâmetros necessários para odesenvolvimento web tanto no frontend como no backend, conseguindo-se assim fazer a distinção entre componentes e as suas relações.De seguida foi abordado o principal objetivo da dissertação que consistia em desenvolver uma ferramenta de criação de lojas online automática seguindo as configurações de diferentes programadores. Esta ferramenta pretende diminuir o tempo despendido pelos programadores em cada novo projeto, ao lhes dar a oportunidade de obter o código de lojas online com diferentes layouts e diferentes parâmetros definidos por eles. Após a criação deste projeto template usando a configuração dos programadores, o objetivo é que eles o adaptem aos pedidos dos seus clientes de uma forma simples, tendo sido usada uma programação modular ao longo deste projeto para facilitar a sua utilização. O projeto desenvolvido nesta dissertação focou-se na autenticação, algumas páginas relacionadas com o produto, na organização do código, na programação modular e na capacidade de os inputs dos programadores alterarem o resultado da ferramenta. No final deste trabalho, foi possível obter uma framework funcional com os pontos anteriormente mencionados, pelo que se atingiu o principal objetivo de desenvolver uma ferramenta que simplificasse o trabalho dos programadores.",
    "text2": "O desenvolvimento de todo o código necessário para uma loja online é um trabalho demorado e complexo. Todas as lojas online têm diferentes exigências e condições, no entanto, existem pontos comuns entre vários tipos de loja. Supondo a possibilidade de extrair esses aspetos comuns, seria possível a criação de um esqueleto de código com todos os componentes básicos, sobre os quais um programador poderia acrescentar e moldar a loja online, reduzindo assim o tempo necessário para a desenvolver. A elaboração desta dissertação começou pela criação de uma loja online que suportasse um negócio fictício de venda de bicicletas e produtos relacionados. Este passo serviu para identificar e avaliar quais seriam os parâmetros necessários especificar, e em que sentido fariam diferença na construção de um website de vendas bem como, distinguir os componentes comuns e as suas relações.A presente dissertação tem como propósito principal o desenvolvimento de uma ferramenta para a criação de lojas online. Esta ferramenta pretende ser usada por programadores para produzir o código padrão que é comum a qualquer implementação de uma solução de loja online. Através da recolha de parâmetros sobre a loja online a ser criada, são construídos os ficheiros necessários para a implementação do site.A aplicação concebida focou-se na utilização de apenas alguns dos componentes básicos, nomeadamente, “Utilizadores” e “Categorias” no back-end, “Registo e Login” e “Perfil” no front-end, mostrando assim ser possível usar a framework desenvolvida para uma implementação parcial de uma loja online. A abordagem modular permite expandir a aplicação, criando e adicionando outros componentes à estrutura parcial existente.",
    "similarity": 0.38041000567366423
  },
  {
    "text1": "The constant technological evolution of the last decades makes more and more companies to focus on providing more resources to their customers, showing new perspectives for the development of solutions with highlevels of performance, availability, scalability and flexibility.One of the biggest contributions in this regard was the appearance of Application Programming Interfaces(APIs), increasingly crucial as integration, automation and efficiency become more important. With the abruptemergence of APIs, API security has become a significant topic in the tech world. If an API does not haveadequate security, it can be vulnerable to attacks that can compromise a company’s data or system. Securityshould be considered from the beginning of any API development project and built into each step of the processto ensure that the API is adequately protected.In this dissertation we intended to investigate the functioning of APIs, with special focus on the Representational State Transfer (REST) architecture and their security, allowing us to verify that, despite several techniquesand tools for the creation of solid and robust REST APIs have already been studied in detail and applied to awide variety of domains, REST services still need practical approaches specialized in the design and security oftheir APIs. It is proposed to fill this gap with the definition of a set of metrics capable of helping in the creation ofa REST API with good design principles and absent of any vulnerabilities.In the context of UN1Qnx as a company that develops authenticity solutions, an IT infrastructure capable ofhandling multiple customers and systems is essential for its business.Bearing this need in mind, the opportunity arose to implement in practice the result of all the research carriedout throughout the dissertation through the development of an Application Programming Interface (API) thatfollows the principles of architectural style based on REST in order to allow managing the data flow of theUN1Qnx system together with the definition of mechanisms to integrate the entire UN1Qnx service with third-party applications and services in order to automate procedures for creating and changing data.",
    "text2": "DevOps presents a mix of agile methodologies that allow an application’s release cycle to be shortened. Thistranslates into a faster delivery of value to the stakeholders.However, the value creation chain does not finish at the end of that cycle. It is necessary to monitor the artifactsproduced at a system level, and at the application level, in order to ensure the compliance of the functional andnon functional requirements.Today, there seems to be a clear separation between the monitoring process and the application developmentprocess. As the development and operations processes have merged in DevOps, this dissertation pretends toinvestigate how to integrate several aspects of monitoring into the regular lifecycle of an application’s development.The inclusion of external services further emphasizes the need to include an observability component into aninfrastructure.The main goal of this dissertation is to develop a solution for the deployment of an infrastructure using stateof-the-art technologies and frameworks, while also providing observability to the system and to the applicationsrunning on it.To do so, it required the investigation of the methodologies and concepts that are the base of the softwaredevelopment lifecycle, focusing on the latter stages of that process: the deployment, and monitoring phases.These methodologies and concepts were complemented with the study of state-of-the-art technologies andframeworks that aim to ease the burden of setting up an infrastructure quickly and with the necessary tools toevolve it after the initial setup and with each new software release. Furthermore, it also involved the research oftools that enable the collection of metrics from applications, as well as processing such data and displaying it inuseful ways for operators and stakeholders.In this context, this dissertation aims to provide a solution for the deployment of MobileID applications at INESCTEC, using the Mobile Driving Licence as the primary case study. The proposed design and implementationwith a container orchestration framework and CI/CD pipelines, enables faster development of different MobileIDapplications, while also providing continuous monitoring to the deployments.With this implementation, it was possible to assess how container orchestration frameworks provide greaterflexibility to applications, and how this observability can be augmented with the use of dedicated monitoringsystems.",
    "similarity": 0.30190954089278416
  },
  {
    "text1": "There has been an increasing investment in cancer research that generated an enormous amount of biological and clinical data, especially after the advent of the next-generation sequencing technologies. To analyze the large datasets provided by omics data of cancer samples, scientists have successfully been recurring to machine learning algorithms, identifyingpatterns and developing models by using statistical techniques to make accuratepredictions.Deep learning is a branch of machine learning, best known by its applications in artificialintelligence (computer vision, speech recognition, natural language processing androbotics). In general, deep learning models differ from machine learning “shallow” methods(single hidden layer) because they recur to multiple layers of abstraction. In this way, itis possible to learn high level features and complex relations in the given data.Given the context specified above, the main target of this work is the development andevaluation of deep learning methods for the analysis of cancer omics datasets, covering bothunsupervised methods for feature generation from different types of data, and supervisedmethods to address cancer diagnostics and prognostic predictions.We worked with a Neuroblastoma (NB) dataset from two different platforms (RNA-Seqand microarrays) and developed both supervised (Deep Neural Networks (DNN), Multi-TaskDeep Neural Network (MT-DNN)) and unsupervised (Stacked Denoising Autoencoders (SDA))deep architectures, and compared them with shallow traditional algorithms.Overall we achieved promising results with deep learning on both platforms, meaningthat it is possible to retrieve the advantages of deep learning models on cancer omics data.At the same time we faced some difficulties related to the complexity and computationalpower requirements, as well as the lack of samples to truly benefit from the deep architectures.There was generated code that can be applied to other datasets, wich is available in agithub repository https://github.com/lmpeixoto/deepl_learning [49].",
    "text2": "Personalized medicine is a constantly growing area. Important goals of this field are early diagnosis and the discovery of new personalized treatments. Gene expression data play a key role at this level, as variations in these data can often offer explanations for some phenotypes. To this end, Machine Learning (ML) models capable of predicting biologically relevant information, have been widely used. Deep Learning (DL) is a branch of ML that has become popular over the past few years. The increasing amounts of data that have been generated, and the growing use of this type of models in biomedical areas, have been accelerating the analysis of biological processes associated with cancer and other complex diseases.In this work, we focused on developing a framework that allows to create and evaluate distinct work-flows for the application of a variety of machine and deep learning models, working over gene expression data, including different options regarding data preprocessing pipelines, distinct ML and DL models, including traditional ML models, Dense Neural Networks, Convolutional Neural Networks and Variational Autoencoders. The framework has been validated using different case studies, where the data sources were two of the main repositories of gene expression data (TCGA and GTEx). The goal of each case study was to predict important variables for clinical application. A variety of models were developed and evaluated for each case study, generally with competitive performance. For the first case study, the task was to predict the type of cancer from TCGA data, and the best performing DL model was a dense neural network, being outperformed by a logistic regression model. In the second case, where the task was to predict the hypoxia score, the best DL model was a two dimensional convolutional neural network (2D CNN), being outperformed by the LightGBM model. As for the third case study, where the objective was to predict the aneuploidy score, the best model was an one dimensional convolutional neural network (1D CNN). For the fourth case, where the task was to predict body mass index, the best model was again a 1D CNN. Finally, in the fifth case study, where the main goal was to predict gene expression for a set of genes based on landmark genes, the best DL model was found by an 1D CNN, still slightly outperformed by linear regression. Some of the DL models developed in this work show promising results. However, these need to be improved in the future as they are not clinically applicable at this time. This framework can be reused for new problems and can be easily expanded.",
    "similarity": 0.30819669626853513
  },
  {
    "text1": "There has been an increasing investment in cancer research that generated an enormous amount of biological and clinical data, especially after the advent of the next-generation sequencing technologies. To analyze the large datasets provided by omics data of cancer samples, scientists have successfully been recurring to machine learning algorithms, identifyingpatterns and developing models by using statistical techniques to make accuratepredictions.Deep learning is a branch of machine learning, best known by its applications in artificialintelligence (computer vision, speech recognition, natural language processing androbotics). In general, deep learning models differ from machine learning “shallow” methods(single hidden layer) because they recur to multiple layers of abstraction. In this way, itis possible to learn high level features and complex relations in the given data.Given the context specified above, the main target of this work is the development andevaluation of deep learning methods for the analysis of cancer omics datasets, covering bothunsupervised methods for feature generation from different types of data, and supervisedmethods to address cancer diagnostics and prognostic predictions.We worked with a Neuroblastoma (NB) dataset from two different platforms (RNA-Seqand microarrays) and developed both supervised (Deep Neural Networks (DNN), Multi-TaskDeep Neural Network (MT-DNN)) and unsupervised (Stacked Denoising Autoencoders (SDA))deep architectures, and compared them with shallow traditional algorithms.Overall we achieved promising results with deep learning on both platforms, meaningthat it is possible to retrieve the advantages of deep learning models on cancer omics data.At the same time we faced some difficulties related to the complexity and computationalpower requirements, as well as the lack of samples to truly benefit from the deep architectures.There was generated code that can be applied to other datasets, wich is available in agithub repository https://github.com/lmpeixoto/deepl_learning [49].",
    "text2": "Currently, Advanced Driver Assistance Systems (ADAS) have been gradually increasing theirpresence in everyday life, thanks in part to its ability to recognize several distinct typesof objects in the road, namely, traffic signs. These systems employ Convolutional NeuralNetworks (CNNs), a type of classification algorithms that relies on an enormous amount ofdata in order to be effective. Current traffic sign datasets suffer from a scarcity of samplesdue to the necessity of compiling and labeling them manually. Such task is highly resourceand time consuming. Thus, researches resort to other mechanisms to deal with this problem,such as increasing the architectural complexity of the neural networks or performing dataaugmentation.This work addresses the data shortage issue by exploring the feasibility of developing asynthetic dataset. Such set would not require gathering and labelling manually thousandsof real word traffic sign images, requiring only easily collectable information and no humanintervention.The only data required is a set of templates for each sign given that a particular sign mayhave more than one template. This is required to cope with outdated pictograms that arestill present in streets and roads.We apply several colour and geometric processing methods to the templates aiming toachieve a look similar to real signs, from the CNN point of view. One of such methods isthe usage of Perlin noise to both simulate shadows and avoid the clean and homogeneouslook that templates have.Two use cases for synthetic data usage are presented: considering the synthetic datasetas a standalone training set, and merging synthetic data with real samples when real datais available. The first option provided results that not only clearly surpass any previousattempt on using synthetic data for traffic sign recognition, but are also encouraginglyplacing the accuracies obtained close to state-of-the-art results, with much simpler networks.The second approach provided results on three distinct test datasets that consistently beatstate-of-the-art results, either in accuracy or in simplicity of the network.",
    "similarity": 0.3053213786679087
  },
  {
    "text1": "There has been an increasing investment in cancer research that generated an enormous amount of biological and clinical data, especially after the advent of the next-generation sequencing technologies. To analyze the large datasets provided by omics data of cancer samples, scientists have successfully been recurring to machine learning algorithms, identifyingpatterns and developing models by using statistical techniques to make accuratepredictions.Deep learning is a branch of machine learning, best known by its applications in artificialintelligence (computer vision, speech recognition, natural language processing androbotics). In general, deep learning models differ from machine learning “shallow” methods(single hidden layer) because they recur to multiple layers of abstraction. In this way, itis possible to learn high level features and complex relations in the given data.Given the context specified above, the main target of this work is the development andevaluation of deep learning methods for the analysis of cancer omics datasets, covering bothunsupervised methods for feature generation from different types of data, and supervisedmethods to address cancer diagnostics and prognostic predictions.We worked with a Neuroblastoma (NB) dataset from two different platforms (RNA-Seqand microarrays) and developed both supervised (Deep Neural Networks (DNN), Multi-TaskDeep Neural Network (MT-DNN)) and unsupervised (Stacked Denoising Autoencoders (SDA))deep architectures, and compared them with shallow traditional algorithms.Overall we achieved promising results with deep learning on both platforms, meaningthat it is possible to retrieve the advantages of deep learning models on cancer omics data.At the same time we faced some difficulties related to the complexity and computationalpower requirements, as well as the lack of samples to truly benefit from the deep architectures.There was generated code that can be applied to other datasets, wich is available in agithub repository https://github.com/lmpeixoto/deepl_learning [49].",
    "text2": "The use of deep learning techniques in medical image analysis has been a subject of growinginterest in recent years. One of the most important applications of these techniques is thedetection and segmentation of tumors in histological images. This dissertation focused oninvestigating the use of deep learning models to segment tumors, with the aim of providingmedical specialists with a tool that can help them make more precise diagnoses.Tumor growth patterns are an important histological characteristic that can provideinformation about the aggressiveness and degree of malignancy of a tumor. Specifically,the epithelial-mesenchymal transition on the tumor front is a pattern that has been shownto confer high aggressiveness and a great capacity to invade tissues and cause metastases,leading to a poor prognosis regarding the evolution of the tumor. Therefore, detectingand segmenting tumors in histological images can be a critical step in the diagnosis andtreatment of tumors.The research process involved several steps, including preprocessing the images to preparethem for deep learning models. This step involved developing methods to enhance thequality of the images and make them suitable for training deep learning models. Two typesof deep learning architectures, the U-Net and Tiramisu, were trained in a supervised way,and different types of loss functions were experimented with to measure their efficiency incontrolling the training process. Additionally, different types of hyperparameters were tried,and the best value was chosen for each hyperparameter.Finally, the effectiveness of the models was evaluated and compared both qualitativelyand quantitatively based on their performance in image segmentation. The results obtainedshow that deep learning models surpassed the initially predicted values and reached a valueabove 94% based on the training data. for the Interception over the Union metric. This resultdemonstrates the potential of deep learning techniques to detect and segment tumors inhistological images and reinforces the importance of continuing to investigate this topic. Thebest results of the present work were achieved with total loss, as explained on page 89.",
    "similarity": 0.30375115420129273
  },
  {
    "text1": "File systems are widely used for storing digital information, as they offer abstractions thatallow data to be intuitively separated and organized through files and directories, accordingto the requirements of applications and users. The continuous growth of data volume andcomplexity leads to the constant evolution of these systems. However, the complexity ofintegration of new features and lack of continuous support, leads to many file systems notbeing adopted in practice.In this sense, stackable file systems have emerged, which allow the development of complexfile systems, providing existing systems with new functionalities through independentprocessing layers. Despite this, the development of these systems presents some challenges,namely in terms of speed of implementation, portability, and resilience, since they aredeveloped in kernel. In this way, later solutions emerged that allowed the development offile systems in user space, thus mitigating some of the problems identified in the developmentof this type of file systems. However, these solutions have not been properly explored in thedevelopment of remote file systems.Therefore, this dissertation presents RSafeFS, a platform that extends the SafeFS system toallow developing modular, flexible and extensible remote file systems in user space. Theproposed solution enables extensible remote file system implementations that adjust to therequirements of different types of applications and storage workloads. It was then necessaryto develop a layer that would allow an RSafeFS instance to operate as a system server, anda communication layer, based on remote procedure calls (RPCs), to allow interoperabilitybetween client and server instances. To demonstrate the ease of integration of new features,taking advantage of the modularity and flexibility of RSafeFS, the developed prototype wasequipped with two layers of caching, namely data and metadata, which aim to improvesystem peformance. The results obtained with this prototype reveal that the file systemsdeveloped through RSafeFS obtain performances comparable to remote storage solutionsbased on FUSE. Furthermore, with the processing layers developed it is possible to adjustthe system to different types of workloads, allowing, for example, to improve systemperformance by 1.5× in certain workloads.",
    "text2": "The high growth in the use of digital identities creates the need to develop mechanismsthat can protect the personal data of each individual. The way identity is treated todayprevents each of us from being able to control our personal information. This is due to thecentralized architecture in which the personal data are inserted, that is, all these data are kepttogether and controlled by the entities responsible for providing the most varied services,which is wrong since the identity belongs to the person and thus it must be responsiblefor controlling that identity. Centralized identity management brings within itself severalproblems, whether intentional (that is, data correlation for profiling) or unintentional (thatis, data breach).To face this problem, multiple entities across the world are developing decentralizedidentity managment systems based on a self-sovereign identity architecture where eachindividual is responsible for managing and storing a set of credentials, each with parts oftheir personal information. A self-sovereign identity architecture allows users to provide onlysmall parts of their personal information or even to omit any type of personal identification,using cryptographic techniques like selective disclosure and zero-knowledge proofs, whichallows them to have more control over their privacy.Taking into account the current problems of digital identity, this dissertation aims toexplore the state of the art and develop a proof of concept, through the implementation ofa system based on self-sovereign identity, which is able to cover the use cases for digitalidentity. Thus, this document shows the architecture implemented, with a blockchain,responsible for the storage of all public data, and a user agent, responsible for facilitating allinteractions of the various users with the developed system.The proof of concept developed allows not only to validate that it is possible to correctmany of the problems associated with centralized identity management, but also to explorenew cryptographic strategies in order to improve the way each of us manages our ownidentity.",
    "similarity": 0.3051114328884412
  },
  {
    "text1": "File systems are widely used for storing digital information, as they offer abstractions thatallow data to be intuitively separated and organized through files and directories, accordingto the requirements of applications and users. The continuous growth of data volume andcomplexity leads to the constant evolution of these systems. However, the complexity ofintegration of new features and lack of continuous support, leads to many file systems notbeing adopted in practice.In this sense, stackable file systems have emerged, which allow the development of complexfile systems, providing existing systems with new functionalities through independentprocessing layers. Despite this, the development of these systems presents some challenges,namely in terms of speed of implementation, portability, and resilience, since they aredeveloped in kernel. In this way, later solutions emerged that allowed the development offile systems in user space, thus mitigating some of the problems identified in the developmentof this type of file systems. However, these solutions have not been properly explored in thedevelopment of remote file systems.Therefore, this dissertation presents RSafeFS, a platform that extends the SafeFS system toallow developing modular, flexible and extensible remote file systems in user space. Theproposed solution enables extensible remote file system implementations that adjust to therequirements of different types of applications and storage workloads. It was then necessaryto develop a layer that would allow an RSafeFS instance to operate as a system server, anda communication layer, based on remote procedure calls (RPCs), to allow interoperabilitybetween client and server instances. To demonstrate the ease of integration of new features,taking advantage of the modularity and flexibility of RSafeFS, the developed prototype wasequipped with two layers of caching, namely data and metadata, which aim to improvesystem peformance. The results obtained with this prototype reveal that the file systemsdeveloped through RSafeFS obtain performances comparable to remote storage solutionsbased on FUSE. Furthermore, with the processing layers developed it is possible to adjustthe system to different types of workloads, allowing, for example, to improve systemperformance by 1.5× in certain workloads.",
    "text2": "Logistics services, including express mail delivery areas, have been growing significantlyby the increase in the volume of e-commerce activity worldwide. It is expected that therise in the level of digital competencies of companies and citizens will not only promoteconsiderable growth in this sector over the next few years, but also demand higher levels ofefficiency, quality, and modernization of digital platforms for interaction with customers.In terms of continuous monitoring, new technologies offer potential, namely the use ofGPS devices to collating coordinates. With system integration, the collected coordinates canbe temporarily saved and then sent to a remote server.Door-to-door service requires exact locations, so there are certain technologies, whichallow us to collect that information accurately without the minimum margin of error. In thecontext of door-to-door distribution, most companies have simple technology that providesa piece of insufficient information regarding the status of their order, they only presentinformation that the postal service may be delivered, refused, or the addressee may not befound.Regarding door-to-door distribution, technologies can be implemented to improve thecurrent industry solutions, providing more detailed information about the order status.Thus, a solution was developed based on international standards, that allow live trackingapplication ensuring also data security through blockchain technologies.",
    "similarity": 0.3074118609921934
  },
  {
    "text1": "Personalized medicine is a constantly growing area. Important goals of this field are early diagnosis and the discovery of new personalized treatments. Gene expression data play a key role at this level, as variations in these data can often offer explanations for some phenotypes. To this end, Machine Learning (ML) models capable of predicting biologically relevant information, have been widely used. Deep Learning (DL) is a branch of ML that has become popular over the past few years. The increasing amounts of data that have been generated, and the growing use of this type of models in biomedical areas, have been accelerating the analysis of biological processes associated with cancer and other complex diseases.In this work, we focused on developing a framework that allows to create and evaluate distinct work-flows for the application of a variety of machine and deep learning models, working over gene expression data, including different options regarding data preprocessing pipelines, distinct ML and DL models, including traditional ML models, Dense Neural Networks, Convolutional Neural Networks and Variational Autoencoders. The framework has been validated using different case studies, where the data sources were two of the main repositories of gene expression data (TCGA and GTEx). The goal of each case study was to predict important variables for clinical application. A variety of models were developed and evaluated for each case study, generally with competitive performance. For the first case study, the task was to predict the type of cancer from TCGA data, and the best performing DL model was a dense neural network, being outperformed by a logistic regression model. In the second case, where the task was to predict the hypoxia score, the best DL model was a two dimensional convolutional neural network (2D CNN), being outperformed by the LightGBM model. As for the third case study, where the objective was to predict the aneuploidy score, the best model was an one dimensional convolutional neural network (1D CNN). For the fourth case, where the task was to predict body mass index, the best model was again a 1D CNN. Finally, in the fifth case study, where the main goal was to predict gene expression for a set of genes based on landmark genes, the best DL model was found by an 1D CNN, still slightly outperformed by linear regression. Some of the DL models developed in this work show promising results. However, these need to be improved in the future as they are not clinically applicable at this time. This framework can be reused for new problems and can be easily expanded.",
    "text2": "Achieving great and undeniable success in a great variety of industries and businesses has made the term Big Data very popular among the scientific community. Big Data (BD) refers to the ever fast-growing research area in Computer Science (CS) that comprises many work areas across the world. The healthcare sector is widely known to be highly proficient inthe production of big quantities of data. It can go from health information, such as thepatient’s blood pressure and cholesterol levels, to more private and sensitive data, such asthe medical procedures history or the report of ongoing diseases.The application of sophisticated techniques enables a profound and rigorous analysis ofdata, something a human cannot do in real-time. However, a machine is capable of rapidlycollect, group, storage and examine vast amounts of data and extract unknown and possi bly interesting knowledge from it. The algorithms used can discover hidden relationshipsbetween attributes that prove to be very useful for a corporation’s work. Buried structureswithin the produced data can also be detected by these techniques. Machine Learning (ML)methods can be adjusted and modelled to different input representations - this adaptabilityis one of the factors that contributes to its blooming prosperity.The main goal is to make predictions on data, by building utterly efficient models that canaccurately take in the data and thus predict a certain outcome. This is especially importantto the healthcare industry since it can considerably improve the lives of many patients.Everything from detecting a type of disease, predicting the chance of morbidity after ahospital stay, to aid in the decision making of treatment strategies are vital to patients aswell as to clinicians.Any improvement over established methods that have been previously studied, testedand published are an asset that will improve the patient’s satisfaction about the healthcareperformance in medical institutions. This can be achieved by refining those algorithms orimplementing new approaches that will make better predictions on the given data.The main objective of this dissertation is to propose ML approaches having acknowledged and evaluated the existent methods used in clinical data. In order to fulfill this goal,an analysis of the state of the art of medical knowledge repositories and scientific paperspublished related to the selected keywords selected was performed. In this line of work,it is crucial to understand, compare and discuss the results obtained to those previouslypublished. Thus, one of the goals is to suggest new ways of solving those problems andmeasuring them up against the existent ones.",
    "similarity": 0.3077222945827448
  },
  {
    "text1": "Personalized medicine is a constantly growing area. Important goals of this field are early diagnosis and the discovery of new personalized treatments. Gene expression data play a key role at this level, as variations in these data can often offer explanations for some phenotypes. To this end, Machine Learning (ML) models capable of predicting biologically relevant information, have been widely used. Deep Learning (DL) is a branch of ML that has become popular over the past few years. The increasing amounts of data that have been generated, and the growing use of this type of models in biomedical areas, have been accelerating the analysis of biological processes associated with cancer and other complex diseases.In this work, we focused on developing a framework that allows to create and evaluate distinct work-flows for the application of a variety of machine and deep learning models, working over gene expression data, including different options regarding data preprocessing pipelines, distinct ML and DL models, including traditional ML models, Dense Neural Networks, Convolutional Neural Networks and Variational Autoencoders. The framework has been validated using different case studies, where the data sources were two of the main repositories of gene expression data (TCGA and GTEx). The goal of each case study was to predict important variables for clinical application. A variety of models were developed and evaluated for each case study, generally with competitive performance. For the first case study, the task was to predict the type of cancer from TCGA data, and the best performing DL model was a dense neural network, being outperformed by a logistic regression model. In the second case, where the task was to predict the hypoxia score, the best DL model was a two dimensional convolutional neural network (2D CNN), being outperformed by the LightGBM model. As for the third case study, where the objective was to predict the aneuploidy score, the best model was an one dimensional convolutional neural network (1D CNN). For the fourth case, where the task was to predict body mass index, the best model was again a 1D CNN. Finally, in the fifth case study, where the main goal was to predict gene expression for a set of genes based on landmark genes, the best DL model was found by an 1D CNN, still slightly outperformed by linear regression. Some of the DL models developed in this work show promising results. However, these need to be improved in the future as they are not clinically applicable at this time. This framework can be reused for new problems and can be easily expanded.",
    "text2": "Recent endeavours over the past few years have been applying generative Deep Learning (DL) models to generate novel proteins using an array of different approaches. Such initiatives represent a specially important development towards major contributions to the field of protein engineering. To contribute to this, various DL architectures can be applied to the different datasets to generate proteins with a particular set of properties. The field of DL applied to the generation of novel molecules has been presenting results that encourage further research on this subject. An increasing number of novel, computationally generated, molecules being synthesized with successful results creates grounds for stimulation of new endeavours and diversification of the current applications.The goal of the work presented in this dissertation is to apply different generative DL architectures to the design of novel protein sequences for a targeted set of optimized properties. The developed framework, termed GenProtEA, stands as the main contribution of this work. The framework envisages the implementation of generative DL architectures for the design of novel proteins and leverages the use sampling techniques and Evolutionary Computation to steer the generative process towards a specific set of properties. Evolutionary Algorithms (EAs) can be applied both to single and multi-objective optimization problems which in itself presents an added advantage. The optimization problems were designed considering the literature concerning protein design. The problems ranged from a simple maximization of the average hydrophobicity of the protein sequence to more complex problems such as minimizing two sets of events in a sequence or maximizing a probability of a protein being generated by a defined profile Hidden Markov Model (HMM). The results of the proposed case studies and the respective analysis accompany the framework in this endeavour.Two different generative DL architectures were deployed, trained, and evaluated, using loss and accuracy metrics to perform the analysis.: a Generative Adversarial Network (GAN) and a Variational Autoencoder (VAE). For the GAN architecture, new proteins are sampled varying the latent seed used in the generative process and then selecting the best candidates for each of the case studies. Besides following a same sampling approach to obtain new protein designs, the VAE latent space is explored using EAs. The results of this work show that the use of EAs in the optimization, steering the generative process, can produce the best results, allowing for more variability in the experiments designed and resulting in a much greater set of possibly functional novel proteins.",
    "similarity": 0.33124847238064203
  },
  {
    "text1": "Personalized medicine is a constantly growing area. Important goals of this field are early diagnosis and the discovery of new personalized treatments. Gene expression data play a key role at this level, as variations in these data can often offer explanations for some phenotypes. To this end, Machine Learning (ML) models capable of predicting biologically relevant information, have been widely used. Deep Learning (DL) is a branch of ML that has become popular over the past few years. The increasing amounts of data that have been generated, and the growing use of this type of models in biomedical areas, have been accelerating the analysis of biological processes associated with cancer and other complex diseases.In this work, we focused on developing a framework that allows to create and evaluate distinct work-flows for the application of a variety of machine and deep learning models, working over gene expression data, including different options regarding data preprocessing pipelines, distinct ML and DL models, including traditional ML models, Dense Neural Networks, Convolutional Neural Networks and Variational Autoencoders. The framework has been validated using different case studies, where the data sources were two of the main repositories of gene expression data (TCGA and GTEx). The goal of each case study was to predict important variables for clinical application. A variety of models were developed and evaluated for each case study, generally with competitive performance. For the first case study, the task was to predict the type of cancer from TCGA data, and the best performing DL model was a dense neural network, being outperformed by a logistic regression model. In the second case, where the task was to predict the hypoxia score, the best DL model was a two dimensional convolutional neural network (2D CNN), being outperformed by the LightGBM model. As for the third case study, where the objective was to predict the aneuploidy score, the best model was an one dimensional convolutional neural network (1D CNN). For the fourth case, where the task was to predict body mass index, the best model was again a 1D CNN. Finally, in the fifth case study, where the main goal was to predict gene expression for a set of genes based on landmark genes, the best DL model was found by an 1D CNN, still slightly outperformed by linear regression. Some of the DL models developed in this work show promising results. However, these need to be improved in the future as they are not clinically applicable at this time. This framework can be reused for new problems and can be easily expanded.",
    "text2": "Parkinson’s Disease (PD) is a neurodegenerative disorder of the central nervous system. Resting tremor, akinesia, and bradykinesia (slow movements), rigidity, shuffling walking, and postural instabilityare some of the symptoms that not only negatively impacts patients’ life, but also the life of people aroundthem.Current approaches for monitoring patients’ motor autonomy are limited to the observer and self reported methods. The observer-based examinations, patients perform a set of standard PD examinations.The self-reported method relies on patients’ daily activities diaries. These approaches are commonly used,but are limited to a few sessions per year, they do not address common motor daily tasks, and their results are object of subjective interpretation by the clinical expert.By combining kinematic-driven data from wearable sensor with AI, the main goal of this dissertation is to develop an automatic software for recognition of human activities (e.g., walking, standing, turning, sitting, and lying) in PD to assist the clinical experts with objective and concrete data.A data collection protocol was developed and captured, resulting in a database comprised of data collected from eighteen PD patients who performed three trials of six different daily activities: walk; 180º turning; sit on chair; get up from chair; lay on bed and get up from bed.A Deep Learning (DL) framework based on Convolutional Neural Network capable of recognizing daily activities was developed and attained a performance of F1 Score equal to 0.90892.As a complementary goal an automatic software for human walk initial contact (IC) and final contact (FC) recognition using kinematic data was also developed. IC and FC are tremendously important to provide patient on-demand motor assistance and estimation of walking-associated metrics.A Deep Learning framework based on Bidirectional Long Short-Term Memory Neural Networkcapable of walking IC/FC events detection was developed and attained a performance of MCC Score equal to 0.538386.Promising results were attained for both DL frameworks, however, this dissertation suggests that there is still room for further improvements. Enriching the dataset with more data from different patient, data balancing and feature extraction techniques, experimenting new models’ architectures should be considered in future works.",
    "similarity": 0.30372840964640707
  },
  {
    "text1": "Personalized medicine is a constantly growing area. Important goals of this field are early diagnosis and the discovery of new personalized treatments. Gene expression data play a key role at this level, as variations in these data can often offer explanations for some phenotypes. To this end, Machine Learning (ML) models capable of predicting biologically relevant information, have been widely used. Deep Learning (DL) is a branch of ML that has become popular over the past few years. The increasing amounts of data that have been generated, and the growing use of this type of models in biomedical areas, have been accelerating the analysis of biological processes associated with cancer and other complex diseases.In this work, we focused on developing a framework that allows to create and evaluate distinct work-flows for the application of a variety of machine and deep learning models, working over gene expression data, including different options regarding data preprocessing pipelines, distinct ML and DL models, including traditional ML models, Dense Neural Networks, Convolutional Neural Networks and Variational Autoencoders. The framework has been validated using different case studies, where the data sources were two of the main repositories of gene expression data (TCGA and GTEx). The goal of each case study was to predict important variables for clinical application. A variety of models were developed and evaluated for each case study, generally with competitive performance. For the first case study, the task was to predict the type of cancer from TCGA data, and the best performing DL model was a dense neural network, being outperformed by a logistic regression model. In the second case, where the task was to predict the hypoxia score, the best DL model was a two dimensional convolutional neural network (2D CNN), being outperformed by the LightGBM model. As for the third case study, where the objective was to predict the aneuploidy score, the best model was an one dimensional convolutional neural network (1D CNN). For the fourth case, where the task was to predict body mass index, the best model was again a 1D CNN. Finally, in the fifth case study, where the main goal was to predict gene expression for a set of genes based on landmark genes, the best DL model was found by an 1D CNN, still slightly outperformed by linear regression. Some of the DL models developed in this work show promising results. However, these need to be improved in the future as they are not clinically applicable at this time. This framework can be reused for new problems and can be easily expanded.",
    "text2": "Neurodegenerative diseases impair the functioning of the brain and are characterized by alterations in the morphology of specific brain regions. Some of the main disorders include Alzheimer's, Parkinson's, and Huntington's diseases, and the number of cases increases exponentially since ageing is one of the main risk factors. Trying to identify the areas in which this type of disease appears is something that can have a very positive impact in this area of Medicine and can guarantee a more appropriate treatment or allow the improvement of the quality of life of patients. With the current technological advances, computer tools are capable of performing a structural or functional analysis of neuroimaging data from Magnetic Resonance Images(MRI). Therefore, Medical Informatics uses these techniques to create and manage medical neuroimaging data to improve the diagnosis and management of these patients. MRI is the image type used in the analysis of the brain area and points to a promising and reliable diagnostic tool since it allows high-quality images in various planes or strategies and MRI methods are fundamental diagnostic tools in clinical practice, allowing the diagnosis of pathologic processes such as stroke or brain tumours. However, structural MRI has limitations for the diagnosis of neurodegenerative disorders since it mainly identifies atrophy of brain regions.Currently, there is increased interest in informatics applications capable of monitoring and quantifying human brain imaging alterations, with potential for neurodegenerative disorders diagnosis and monitoring. One of these applications is Radiomics, which corresponds to a methodolog ythat allows the extraction of features from images of a given region of the brain. Specific quantitative metrics from MRI are acquired by this tool, and they correspond to a set of features, including texture, shape, among others. To standardize Radiomics application, specific libraries have been proposed to be used by the bioinformatics and biomedical communities, such as PyRadiomics, which corresponds to an open source Python package for extracting Radiomics of MRIs.Therefore, this dissertation was developed based on magnetic resonance images and the study of DeepLearning (DL) techniques to assist researchers and neuroradiologists in the diagnosis and prediction of neurodegenerative disease development. Two different main tasks were made: first, a segmentation, using FreeSurfer, of different regions of the brain and then, a model was build from radiomic features extracted from each part of the brain and interpreted for knowledge extraction.",
    "similarity": 0.32432377383086197
  },
  {
    "text1": "Public lighting, despite being one of the most important services a city must provide, it is also one of the main sources of energy consumption and consequently running costs. One way to drastically improve the efficiency of these systems is by using object detection in order to make each of the public lighting poles aware of their surroundings, giving them the ability to adapt to the environment. This is one of the main goals of an industry leader company's project in the area of public lighting, where this study is inserted. In this project, each public lighting pole is upgraded with a set of sensors: radar, microphone and camera(what we refer to as fog computing). By developing a multimodal machine learning model, the goal is to leverage the data from the different sensors to improve the object detection capabilities of traditional unimodal machine learning model. Additionally, the developed model will be deployed into an edge device that is also installed in the public lighting pole, due to data privacy concerns and network latency problems that would otherwise occur with traditional server-side approaches. This constrain raises the main question that this study will try to answer, which is how to develop a complex multimodal machine learning model for low-power efficient edge devices. In this study, a multi-agent architecture will be proposed, that authors can adapt to their own multimodal machine learning problems with edge devices. To prove the efficient of the proposed system, a proof of concept implementation will be carried out that involves the aforementioned sensors, as well as the You Only Look Once (YOLO) object detection model, with a feature-level data fusion approach. Finally, the implemented system will be deployed to an edge device, where the hardware performance will be tested and compared to similar work in the literature.",
    "text2": "The high growth in the use of digital identities creates the need to develop mechanismsthat can protect the personal data of each individual. The way identity is treated todayprevents each of us from being able to control our personal information. This is due to thecentralized architecture in which the personal data are inserted, that is, all these data are kepttogether and controlled by the entities responsible for providing the most varied services,which is wrong since the identity belongs to the person and thus it must be responsiblefor controlling that identity. Centralized identity management brings within itself severalproblems, whether intentional (that is, data correlation for profiling) or unintentional (thatis, data breach).To face this problem, multiple entities across the world are developing decentralizedidentity managment systems based on a self-sovereign identity architecture where eachindividual is responsible for managing and storing a set of credentials, each with parts oftheir personal information. A self-sovereign identity architecture allows users to provide onlysmall parts of their personal information or even to omit any type of personal identification,using cryptographic techniques like selective disclosure and zero-knowledge proofs, whichallows them to have more control over their privacy.Taking into account the current problems of digital identity, this dissertation aims toexplore the state of the art and develop a proof of concept, through the implementation ofa system based on self-sovereign identity, which is able to cover the use cases for digitalidentity. Thus, this document shows the architecture implemented, with a blockchain,responsible for the storage of all public data, and a user agent, responsible for facilitating allinteractions of the various users with the developed system.The proof of concept developed allows not only to validate that it is possible to correctmany of the problems associated with centralized identity management, but also to explorenew cryptographic strategies in order to improve the way each of us manages our ownidentity.",
    "similarity": 0.3409062129006728
  },
  {
    "text1": "Public lighting, despite being one of the most important services a city must provide, it is also one of the main sources of energy consumption and consequently running costs. One way to drastically improve the efficiency of these systems is by using object detection in order to make each of the public lighting poles aware of their surroundings, giving them the ability to adapt to the environment. This is one of the main goals of an industry leader company's project in the area of public lighting, where this study is inserted. In this project, each public lighting pole is upgraded with a set of sensors: radar, microphone and camera(what we refer to as fog computing). By developing a multimodal machine learning model, the goal is to leverage the data from the different sensors to improve the object detection capabilities of traditional unimodal machine learning model. Additionally, the developed model will be deployed into an edge device that is also installed in the public lighting pole, due to data privacy concerns and network latency problems that would otherwise occur with traditional server-side approaches. This constrain raises the main question that this study will try to answer, which is how to develop a complex multimodal machine learning model for low-power efficient edge devices. In this study, a multi-agent architecture will be proposed, that authors can adapt to their own multimodal machine learning problems with edge devices. To prove the efficient of the proposed system, a proof of concept implementation will be carried out that involves the aforementioned sensors, as well as the You Only Look Once (YOLO) object detection model, with a feature-level data fusion approach. Finally, the implemented system will be deployed to an edge device, where the hardware performance will be tested and compared to similar work in the literature.",
    "text2": "This thesis was developed as part of a curricular internship at Bosch Car Multimédia SA, in collaboration with the University of Minho, More specifically, an exploratory research thesis aligned with an R&D project that is being developed internally and whose objective is to detect impacts on vehicles that cause damage based on data obtained through sensors, The usefulness of the work developed in this thesis and the project in which it is inserted, in a real context, would be to help vehicle rental companies and car-sharing services to better monitor the conditions of vehicles in their fleets, This would be achieved by placing a device in vehicles that continuously monitored their status, reducing the need for validation and human interaction after use, The main focus of this thesis was to explore how the fusion of information from different sensors could improve the decision-rnaking capabilities of a system whose purpose is to determine whether impacts on the exterior of a vehicle, captured with a set of sensors, resulted in damage, This conjugation of sensory information is known as sensor fusion. ft is a process of combining information from different homogeneous and heterogeneous sensors to obtain a better representation of what is being observed, The approach chosen to achieve this goal consisted of training a set of Machine Learning (ML) algorithms with two distinct datasets, one based only on one data source and the other multiple sources combined. Each pair of models was further evaluated on unseen data, and their performances were compared based on the va lues obtained, Based on the results obtained, it can be said that the application of sensor fusion allowed for better learning by the models, which led to greater robustness in data never seen before. Of the four chosen algorithms, XGBoost, Random Forest (RF), Support Vector Machine (SVM), and Artificial Neural Network (ANN), all had at least one of the evaluation metrics, the Matthews Correlation Coefficient (MCC) and number of False Positive (FP)s in the test set, superior in model-based fused data. Of these, XGBoost and ANN stand out where the results were significantly better in both metrics,",
    "similarity": 0.30681207840815383
  },
  {
    "text1": "Cidades Inteligentes é um conceito que ainda não se encontra muito bem estabelecido.Contudo, é de consenso comum que este consiste em fornecer a todos os seus cidadãosuma melhor qualidade de vida. Nestas cidades inteligentes encontramos múltiplos cená rios aplicacionais que podem ser explorados de forma a alcançar os objectivos necessários.Um exemplo destes cenários são os sistemas energéticos que, dada a evolução constante,sofrem uma grande sobrecarga. Consequentemente, é necessário recorrer a certas medidaspara aumentar a eficiência destes. Uma solução é a implementação de sistemas de análisede consumo de energia e de previsão de dados. Os dados são extraídos de fontes bastantediversas (sensores, câmaras e outros), dados estes que, posteriormente, são processados eexportados para data warehouses. Contudo, com a evolução tecnológica que se tem vindoa verificar, a quantidade de dados oportunos aumentou significativamente, bem como ascaracterísticas relativas à forma de como são recolhidos e tratados. Hoje em dia, a diver sidade destes dados é intensa, dependendo muito das circunstâncias operacionais e dossistemas envolvidos, o que gera vulgarmente cenários aplicacionais novos e estranhos paraos sistemas que usualmente estão envolvidos no seu tratamento. Neste sentido, existe anecessidade de inovar os processos de tratamento destes dados e, deste modo, aumentar aoperacionalidade e possibilidade de suportar uma cidade inteligente. Para tal, é necessárioimplementar processos de ETL e de previsão de dados para haver a capacidade de toma das de decisões de forma a manter uma cidade inteligente. Abordamos, nesta dissertação,os sistemas de análise de consumo de energia, visto serem um dos cenários aplicacionaismais explorados com a evolução tecnológica. Havendo a necessidade de aumentar a efi ciência desta área identificamos, planeamos e testamos algumas das medidas passíveis deimplementar para a previsão de dados futuros que permitam ajudar à tomada de decisão.Alcançando, por fim, a seleção de um algoritmo bastante preciso para a previsão destesdados.",
    "text2": "Atualmente, mais da metade da população mundial vive em centros urbanos e as estatísticas indicam queem 2050 essa percentagem rondará os 70%. A forte concentração da população em urbes, apresentagrandes desafios, principalmente devido à densidade populacional, habitação, circulação, ou a escalabi lidade de serviços. Gerir esta realidade, garantindo as condições indispensáveis para uma alta qualidadede vida, é um desafio que as tecnologias inteligentes poderão ajudar a conseguir. A União Europeia de fine cidades inteligentes, ou smart cities, como um conjunto de sistemas e de pessoas que interagem deforma inteligente utilizando energia, materiais, serviços e recursos de forma sustentável. Assim, estima-seque o valor das tecnologias relacionadas com o controle e a monitorização do tráfego em smart cities éproporcional à redução dos acidentes de trânsito, congestionamentos urbanos, e outros impactos sociais.São exemplos, a necessidade de comunicação ou controle de tráfego a partir de ferramentas inteligentesque na atualidade é difícil de manipular já que possuem grande impacto económico e social. Para esseefeito, é necessário a implementação de técnicas ou estratégias (amostragem, agregação e filtragem) quevão permitir monitorar fluxos de dados, a fim de garantir eficiência no tratamento de grandes volumes dedados nos múltiplos contextos das cidades. O objetivo desta dissertação é efetuar uma análise critica so bre estratégias de monitorização veicular, seu impacto e suas limitações frentes aos grandes volumes detráfego gerados pelas smart cities. Avaliam-se ainda técnicas contextuais que serviram para a construçãode soluções frente aos desafios da mobilidade e transportabilidade no contexto urbano.",
    "similarity": 0.30132011772853184
  },
  {
    "text1": "Cada vez mais a relação entre as tecnologias da informação e a saúde seestreitam. Concretamente, na neuroimagiologia, essa ligação tem vindo a tornar-se cada vezmais importante principalmente após o surgimento da imagem de Ressonância Magnética(MRI – Magnetic Ressonance Imaging).Com o desenvolvimento da tecnologia, para além das aquisições MRI convencionais, surgiramoutras técnicas como a aquisição de imagens de tensor de difusão (DTI – Diffusion TensorImaging) e da MRI funcional (fMRI). Estas técnicas permitem a obtenção de uma imageminterior do corpo. Um dos órgãos mais estudados com estas imagens é o cérebro, que é alvode vários estudos mas que devido à sua complexidade ainda é bastante desconhecido.Enquanto que com a MRI estrutural pode-se efetuar uma análise volumétrica às diferentesestruturas do cérebro, com a DTI é possível verificar a integridade da substância brancaatravés das fibras virtualmente criadas que representam o movimento das moléculas de água.Vários estudos referem os benefícios de uma análise multimodal com estas duas técnicas.Para tratamento e análise destas imagens é necessário uma gestão de várias aplicaçõesinformáticas que processam os dados e corregistam as imagens de forma automática. Um dosgrandes desafios consta, não só na utilização individual de cada ferramenta na qual é exigidoalgum conhecimento técnico, como na combinação das várias aplicações que apresentam osdados resultantes em diferentes formatos.Uma solução passa pela pesquisa e definição de fluxos de trabalho para que exista umaabordagem simples dos procedimentos a ter com as várias ferramentas e da sua combinaçãocom outras. No entanto, esta solução não impedirá o gasto de recursos de tempo e o trabalhomoroso de um estudo que contenha vários sujeitos.Assim, neste trabalho, para além de serem apresentados os vários fluxos de trabalho possíveispara análise multimodal, será exposto um módulo automatizado que será inserido numaaplicação de multimodalidade já existente: BrainCat.A presente dissertação apresenta um meio de facilitar as análises multimodais para que aqualidade quer a nível de investigação científica quer a nível dos diagnósticos clínicos aumente.",
    "text2": "Os avanços tecnológicos verificados nos dia de hoje assim como a quantidadede informação e comunicação que lhes estão associados, atribuem umpapel de grande importância aos sistemas de monitorização. É no seio destaevolução, que a competição existente entre os vários setores de mercado nãoestão acessíveis a erros e falhas, principalmente ao nível dos equipamentostecnológicos. Assim, neste contexto de intolerância, assiste-se a uma proliferaçãoe a uma utilização cada vez maior de sistemas de monitorização eprevenção.Mais importante que monitorizar é prevenir. Ter a capacidade de evitaruma falha, e permitir a resolução de algum problema atempadamente é umamais valia para o desempenho, atribuindo fiabilidade e qualidade ao serviço.A gestão e a verificação de equipamentos, bem como de processos associadosaos mesmos permitem um maior controlo e domínio dum sistema.Assim esta dissertação tem como objetivo principal a implementação dumsistema para monitorizar a atividade de um ou mais sistemas multi-agente,com capacidade para intervir e avisar o administrador do sistema quandoocorre um problema.O sistema construído, que assenta numa estrutura formada por três unidadesdistintas, unidade de análise, unidade de processamento e unidade deinterface com o utilizador, permitem a implementação de processos para trocae integração de informação, exercendo assim uma comunicação fundamentalentre sistemas e utilizadores . É um sistema direcionado principalmenteà gestão e monitorização do desempenho de diferentes equipamentos assimcomo dos processos em execução nos mesmos. Este trabalho foi desenvolvido em colaboração com um Hospital no Norte do País e o ambiente escolhidopara a implementação da plataforma foi unicamente laboratorial.A concretização deste projeto esteve dividida em quatro fases: Início,Pesquisas, Construção da Aplicação e Escrita da Dissertação. Na primeirafase, o Início, foi feito o levantamento dos principais requisitos para o sistema,definição dos objetivos, e elaboração de um plano de trabalho. Na segundafase, Pesquisas, procedeu-se ao levantamento de informação sobre os conceitosteóricos relacionados com o tema em causa, como artigos científicos quedão suporte ao tema, entre outros trabalhos já publicados na mesma área.No final desta etapa já se encontravam definidas as ideias base da aplicaçãoa construir de acordo com as necessidades. Na terceira fase deste projeto, aConstrução englobou a modelação e implementação da plataforma de monitorização,de acordo com as especificações definidas anteriormente. A quartaetapa englobou a escrita da dissertação, o que incluiu um enquadramentodos conceitos teóricos em função da aplicação desenvolvida.",
    "similarity": 0.32513273314866115
  },
  {
    "text1": "One of the challenging problems in bioinformatics is to computationally characterize sequences, structures and functions of proteins. Sequence-derived structural and physico-chemical properties of proteins have been used in the development of machine learning models in protein related problems. However, tools and platforms to calculate features and perform Machine learning (ML) with proteins are scarce and have their limitations in terms of effectiveness, user-friendliness and capacity. Here, a generic modular automated platform for the classification of proteins based on their physicochemical properties using different ML algorithms is proposed. The tool developed, as a Python package, facilitates the major tasks of ML and includes modules to read and alter sequences, calculate protein features, preprocess datasets, execute feature reduction and selection, perform clustering, train and optimize ML models and make predictions. As it is modular, the user retains the power to alter the code to fit specific needs. This platform was tested to predict membrane active anticancer and antimicrobial peptides and further used to explore viral fusion peptides. Membrane-interacting peptides play a crucial role in several biological processes. Fusion peptides are a subclass found in enveloped viruses, that are particularly relevant for membrane fusion. Determining what are the properties that characterize fusion peptides and distinguishing them from other proteins is a very relevant scientific question with important technological implications. Using three different datasets composed by well annotated sequences, different feature extraction techniques and feature selection methods (resulting in a total of over 20 datasets), seven ML models were trained and tested, using cross validation for error estimation and grid search for model selection. The different models, feature sets and feature selection techniques were compared. The best models obtained for distinct metric were then used to predict the location of a known fusion peptide in a protein sequence from the Dengue virus. Feature importances were also analysed. The models obtained will be useful in future research, also providing a biological insight of the distinctive physicochemical characteristics of fusion peptides. This work presents a freely available tool to perform ML-based protein classification and the first global analysis and prediction of viral fusion peptides using ML, reinforcing the usability and importance of ML in protein classification problems.",
    "text2": "Interstitial lung diseases (ILD) are defined as a set of more than 200 pulmonary disorders. Among these, the ones broadly termed as pneumonia represent a major cause of morbidity and mortality in the world. The chest radiograph (CXR) was the first x-ray based lung imaging technique to emerge and is still widely used as a diagnostic method for pneumonia and other lung diseases. However, correct interpretation of CXR requires analysis by experts and stays vulnerable to errors and observer-related variation. To counteract these problems, artificial intelligence (Al) methods have been applied for the automated analysis of CXR and other medical images. The deep learning (DL) branch of AI and in the particular the methods based on convolutional neural networks (CNN), recently obtained impressive results in these tasks. This dissertation presents a DL approach to classify pneumonia from medical CXR image datasets. Two different models based on the development of CNN were trained from a preprocessed dataset of CXR images obtained from 8562 individuals classified as normal (n=7214) or with pneumonia (n=1348) (Dataset XP1’). Model 1 applied a normal cross entropy loss function, and model 2 an alternative loss function aiming at counteracting the unbalance in normal/pneumonia class frequency. For performance enhancing both models underwent a hyper optimization procedure. The optimized model 1 and 2 were tested on a test set from PI'. To better understand the predictability and generalization potential we then tested both models on an unrelated test set of 624 images (Dataset XP2). Interestingly, model 1 obtained better performance when tested on XP2 than in XP1', scoring an accuracy of 85%, recall of 93% and precision of 85% for the detection of the pneumonia class. The higher homogeneity present on dataset XP2 compared with dataset XP1' could be a plausible justification. As for model 2, it correctly predicted more pneumonia cases an test set XP1' than model 1. However, on test set XP2 the results were poor, predicting most cases as pneumonia and scoring a recall value of only 26% for the pneumonia class. Testing the DL models on unseen data is a relevant but not always performed validation. Overall, the higher accuracy, recall and precision levels of model 1 in XP2 suggests it has a higher potential to be applied for real-word application although its performance should be further improved and evaluated. This work opened promising new lines of research for the future development of a high-performance CNN-based automated method to classify CXR and assist in the diagnostic of pneumonia.",
    "similarity": 0.3081985016368673
  },
  {
    "text1": "The brain functional connectivity extracted from rs-fMRI has been used as a powerful tool to study the different networks in the brain. This neuronal network, found in normal condition, can be associated to different cognitive processes. The applicability of these networks in the future is promising, since is a greater technique to study the effects of several diseases or even treatments on normal brain functional connectivity. Firstly, this question should be addressed: are these networks possible to be described and to be used as features to classify a group or a particular subject?.In order to answer this question, it was settled the use of a Machine Learning method, which has been developed great advances in the recent years, due the good performances in the Deep Learning (DL) method. Therefore, it was created a workflow since the beginning, started with data acquisition until the application of DL methods and the process of creation and fine-tune of these models. In the end, several studies using the functional connectivity were done, namely the assessment of the brain functional connectivity to be used as a “fingerprint”. Additionally, it were performed some tests regarding the groups’ classification.After settled the correct approach and validate the DL framework, the “fingerprint” study showed a great improvement on impairment classification, even for simple models. We proved that rs-fMRI can be use in research field to identify singular brain patterns as well as the differences between the subjects, which could be applied as group differentiator in a population.",
    "text2": "Methods for the study of the functional connectivity in the brain have seen severaldevelopments over the last years, however not yet in a fully realized manner. Machine learning andcomplex network analysis are two promising techniques that together can help the process of betterexploring functional connectivity for future clinical applications.Machine learning and pattern recognition algorithms are helpful for mining vast amountsof neural data with increasing precision of measures and also for detecting signals from anoverwhelming noise component (Lemm, Blankertz, Dickhaus, & Müller, 2011). Complex networkanalysis, a subset of graph theory, is an approach that allows the quantitative assessment ofnetwork properties such as functional segregation, integration, resilience, and centrality (Rubinov& Sporns, 2010). These properties can be fed into classification algorithms as features. This is anew and complex approach that has no standard procedures defined, so the aim of this work is toexplore the use of fMRI-derived complex network measures combined with machine learningalgorithms in a clinical dataset.In order to do so, a set of classifiers is implemented on a feature dataset built with brainregional volumes and topological network measures that, in turn, were constructed based onfunctional connectivity data extracted from a resting-state functional MRI study. The set of classifiersincludes the nearest neighbor, support vector machine, linear discriminant analysis and decisiontree methods. A set of feature selection methods was also implemented before the classificationtasks. Every possible combination of feature selection methods and classifiers was implementedand the performance was evaluated by a cross-validation procedure.Although the results achieved weren’t exceptionally good, the present work generatedknowledge on how to implement this recent approach and allowed the conclusion that, for mostcases, feature selection improves the performance of the classifier. The results also showed thatthe decision tree algorithm produces relatively good results without being associated with a featureselection method and that the SVM classifier, together with RFE feature selection method, producedresults on the same level as other work done with a similar approach.",
    "similarity": 0.3236149584487535
  },
  {
    "text1": "A huge amount of medical data is being generated each day, leaving the doctors unableto analyze such volume and make a good diagnosis for the patient. The emergence of BigData frameworks for data analysis leverages the automatic analysis of healthcare data in afaster and accurate manner, by scanning which information is relevant, and, consequently,detecting diseases in earlier stages.Nowadays, it is estimated that about 9% to 38% of the world’s population has sleep ap nea. Unawareness of the disease’s presence can lead to the development of cardiovasculardiseases, and consequently, death. The detection of sleep apnea syndrome through the tra ditional method, Polysomnography (PSG), becomes not only expensive but also inconvenientfor the patient. Therefore, systems based on Electrocardiogram (ECG) can improve the qua lity of a patient’s health by overcoming these inconveniences. This master thesis relies ondeep learning (DL) networks, such as convolutional and recurrent neural networks for sleepapnea detection. The computational complexity of these models depends on its size, typesof layers and data. This complexity also increases the computation time of the training taskleading to several hours spent training on a single machine. For this work, we proposea sleep apnea detection system based on ECGs, alongside with a distributed version of it,which parallelizes the training computation, reducing the overall learning time, while notcompromising the model performance.The results obtained for sleep apnea detection encourage the use of electrocardiogramsfor the detection of this disease. Our model achieved a value of 93% of sensitivity onthe Physionet database, being the highest value compared to other studies described inthe literature. Besides this, on the distributed environment it was accomplished similaroutput quality, reducing the training time by approximately 50%, from the centralized todistributed learning.The model was trained with the Sleep Heart Health Study (SHHS) data, achieving the highestresults compared to the work described in the literature that used the same dataset. Incomparison with the previous dataset, the model trained and tested with the SHHS wasnot able to attain a similar quality output. However, this corroborates the large diversity ofthe SHHS data. Moreover, when it was tested if this model could classify the Physionet data,it achieved promising results of 73,7%, 73,8%, 68,3% and 63,5% of accuracy, sensitivity, F1-score, and precision, respectively, which lead us to conclude that the SHHS trained modelcould be able to generalize to new data. In addition to this, on the distributed environment it was achieved equal output perfor mance for SHHS, reducing the training time by approximately 90%.",
    "text2": "Prognosis and patient stratification for brain tumors is an important and clinically relevant task and a precise treatment outcome prediction would allow to choose an adequate therapy strategy and schedule the most appropriate follow-up examinations. Magnetic Resonance Imaging (MRI) is an already know imaging technique to assess these tumors. Next to medical imaging, other clinical information is important for patient management, e.g. genetic markers like O6-Methyl-Guanine-Methyl-Transferase (MGMT) methylation is a well-known prognostic marker in Glioblastoma (GBM) tumors.Therefore, the main goal of this thesis was to study Deep Learning (DL) approaches to combine MRI with non-image clinical data in two different classification scenarios: brain tumor segmentation and patient outcome prediction. There are studies that combine these two types of data, however, in two steps: extracting MRI features and then combining them with relevant non-image data. Here, end-to-end DL architectures with two input layers are presented, as well as an infrastructure that allows the easy development of future Machine Learning (ML) /DL models that consumes these two types of data in a clinical context. In this way, the classification in both scenarios is done in a single step, where Convolution Layers perform the feature extraction in MRI input.In brain tumor segmentation, the model with combined data achieved a slightly better Dice Similarity Coefficient (DSC) (0.894 ± 0.025) over image only model (0.882 ± 0.025). As for patient outcome prediction, when trying to predict the Progression-Free Survival (PFS) class (“bad”,” medium” and “good” outcomes), the combined model didn't improve when compared with the model where only MRI was used. Both models, however, outperformed models where only non-image data was used.The segmentation results point to a positive influence when adding the clinical information to MRI. Nevertheless, there is a lot more to investigate in this field, not only in the model architecture, but also in selecting relevant clinical information. In same way, more tests should be run for patient outcome prediction, especially using Overall Survival (OS) information.",
    "similarity": 0.3024222245898146
  },
  {
    "text1": "Hoje em dia, o recurso às novas tecnologias nas mais diferentes áreas doconhecimento tem sido evidente. A área da educação não foi, pois, exceção.Cada vez mais se tentam arranjar ferramentas tecnológicas que permitam aqualquer aluno ter acesso a um processo de aprendizagem mais simples eeficaz. Dentro desse leque variadíssimo de ferramentas encontramos os ITS(intelligent tutoring system). Genericamente, estes sistemas têm comoobjetivo fornecer instruções a alunos sem a intervenção direta de umprofessor. Para que isso possa acontecer, com sucesso, é necessário que estessistemas possuam uma base de conhecimento fiável, com conteúdosadequados em todas as vertentes de ensino que promovem. Nesta dissertaçãotivemos como base de trabalho a conceção e o desenvolvimento de ummódulo de avaliação para um sistema de ensino inteligente, com capacidadepara fazer a monitorização de todas as atividades desenvolvidas ao longo deum processo de aprendizagem ou de aferição de conhecimento. Com estamonitorização pretende-se fazer a criação de perfis de aprendizagem paratodos os alunos que utilizem o sistema, de forma a que se possa personalizaros processos de ensino, indo em contra às principais necessidades deaprendizagem dos alunos. Nesta dissertação descrevemos o trabalhorealizado no desenvolvimento do módulo de avaliação referido, dandoparticular atenção aos aspetos relacionados com a seleção e implementaçãodos mecanismos de profiling para a criação automática de perfis deaprendizagem, aos diferentes métodos de avaliação estudados, à preparaçãodos dados e serviços subjacentes ao seu armazenamento e processamento, àarquitetura do sistema de avaliação desenvolvido e, por fim, à demonstraçãodas funcionalidades implementadas.",
    "text2": "As Plataformas Móveis estão cada mais enraizadas no nosso quotidiano. O conforto de escolher ondeusar e a facilidade de as utilizar em qualquer lugar criam formas de informação e comunicação para asmais diversas áreas, facilitando assim num grande conjunto de tarefas. Para algumas destas áreas, adisponibilização de uma Plataforma Móvel pode ser a chave para o sucesso dos objetivos pretendidos, oferecendoao utilizador uma experiência completamente inovadora face aos métodos mais convencionais.A área do ensino encaixa perfeitamente nestes moldes, tendo em conta que o uso destas plataformaspode aumentar o envolvimento dos alunos nos seus deveres, através da projeção simples e intuitivados vários exercícios e ferramentas adequadas que fomentem os seus conhecimentos e aprendizagem,ajudando-os a alcançar melhores resultados.Tendo isso em consideração, neste trabalho de dissertação, desenvolveu-se, numa primeira etapa,uma fundamentação teórica relativamente ao uso de Plataformas Móveis e a sua evolução ao longo dosanos, abordando-se com isso uma perspetiva totalmente voltada para a área do ensino. Numa segundafase, foram detalhados e analisados os diferentes tipos de Plataformas Móveis que atualmente imperamno mercado dos smartphones, bem como alguns exemplos de plataformas especialmente criadas paraservirem como Sistemas de Aprendizagem. Numa última etapa, com a escolha do tipo de plataformaa desenvolver para a dissertação, idealizou-se e implementou-se um sistema de interação adaptativopara suporte a processos de aferição do conhecimento de estudantes ao longo do tempo, em domíniosespecíficos.",
    "similarity": 0.30248669631141567
  },
  {
    "text1": "Achieving great and undeniable success in a great variety of industries and businesses has made the term Big Data very popular among the scientific community. Big Data (BD) refers to the ever fast-growing research area in Computer Science (CS) that comprises many work areas across the world. The healthcare sector is widely known to be highly proficient inthe production of big quantities of data. It can go from health information, such as thepatient’s blood pressure and cholesterol levels, to more private and sensitive data, such asthe medical procedures history or the report of ongoing diseases.The application of sophisticated techniques enables a profound and rigorous analysis ofdata, something a human cannot do in real-time. However, a machine is capable of rapidlycollect, group, storage and examine vast amounts of data and extract unknown and possi bly interesting knowledge from it. The algorithms used can discover hidden relationshipsbetween attributes that prove to be very useful for a corporation’s work. Buried structureswithin the produced data can also be detected by these techniques. Machine Learning (ML)methods can be adjusted and modelled to different input representations - this adaptabilityis one of the factors that contributes to its blooming prosperity.The main goal is to make predictions on data, by building utterly efficient models that canaccurately take in the data and thus predict a certain outcome. This is especially importantto the healthcare industry since it can considerably improve the lives of many patients.Everything from detecting a type of disease, predicting the chance of morbidity after ahospital stay, to aid in the decision making of treatment strategies are vital to patients aswell as to clinicians.Any improvement over established methods that have been previously studied, testedand published are an asset that will improve the patient’s satisfaction about the healthcareperformance in medical institutions. This can be achieved by refining those algorithms orimplementing new approaches that will make better predictions on the given data.The main objective of this dissertation is to propose ML approaches having acknowledged and evaluated the existent methods used in clinical data. In order to fulfill this goal,an analysis of the state of the art of medical knowledge repositories and scientific paperspublished related to the selected keywords selected was performed. In this line of work,it is crucial to understand, compare and discuss the results obtained to those previouslypublished. Thus, one of the goals is to suggest new ways of solving those problems andmeasuring them up against the existent ones.",
    "text2": "Neurodegenerative diseases impair the functioning of the brain and are characterized by alterations in the morphology of specific brain regions. Some of the main disorders include Alzheimer's, Parkinson's, and Huntington's diseases, and the number of cases increases exponentially since ageing is one of the main risk factors. Trying to identify the areas in which this type of disease appears is something that can have a very positive impact in this area of Medicine and can guarantee a more appropriate treatment or allow the improvement of the quality of life of patients. With the current technological advances, computer tools are capable of performing a structural or functional analysis of neuroimaging data from Magnetic Resonance Images(MRI). Therefore, Medical Informatics uses these techniques to create and manage medical neuroimaging data to improve the diagnosis and management of these patients. MRI is the image type used in the analysis of the brain area and points to a promising and reliable diagnostic tool since it allows high-quality images in various planes or strategies and MRI methods are fundamental diagnostic tools in clinical practice, allowing the diagnosis of pathologic processes such as stroke or brain tumours. However, structural MRI has limitations for the diagnosis of neurodegenerative disorders since it mainly identifies atrophy of brain regions.Currently, there is increased interest in informatics applications capable of monitoring and quantifying human brain imaging alterations, with potential for neurodegenerative disorders diagnosis and monitoring. One of these applications is Radiomics, which corresponds to a methodolog ythat allows the extraction of features from images of a given region of the brain. Specific quantitative metrics from MRI are acquired by this tool, and they correspond to a set of features, including texture, shape, among others. To standardize Radiomics application, specific libraries have been proposed to be used by the bioinformatics and biomedical communities, such as PyRadiomics, which corresponds to an open source Python package for extracting Radiomics of MRIs.Therefore, this dissertation was developed based on magnetic resonance images and the study of DeepLearning (DL) techniques to assist researchers and neuroradiologists in the diagnosis and prediction of neurodegenerative disease development. Two different main tasks were made: first, a segmentation, using FreeSurfer, of different regions of the brain and then, a model was build from radiomic features extracted from each part of the brain and interpreted for knowledge extraction.",
    "similarity": 0.3114825448074701
  },
  {
    "text1": "Achieving great and undeniable success in a great variety of industries and businesses has made the term Big Data very popular among the scientific community. Big Data (BD) refers to the ever fast-growing research area in Computer Science (CS) that comprises many work areas across the world. The healthcare sector is widely known to be highly proficient inthe production of big quantities of data. It can go from health information, such as thepatient’s blood pressure and cholesterol levels, to more private and sensitive data, such asthe medical procedures history or the report of ongoing diseases.The application of sophisticated techniques enables a profound and rigorous analysis ofdata, something a human cannot do in real-time. However, a machine is capable of rapidlycollect, group, storage and examine vast amounts of data and extract unknown and possi bly interesting knowledge from it. The algorithms used can discover hidden relationshipsbetween attributes that prove to be very useful for a corporation’s work. Buried structureswithin the produced data can also be detected by these techniques. Machine Learning (ML)methods can be adjusted and modelled to different input representations - this adaptabilityis one of the factors that contributes to its blooming prosperity.The main goal is to make predictions on data, by building utterly efficient models that canaccurately take in the data and thus predict a certain outcome. This is especially importantto the healthcare industry since it can considerably improve the lives of many patients.Everything from detecting a type of disease, predicting the chance of morbidity after ahospital stay, to aid in the decision making of treatment strategies are vital to patients aswell as to clinicians.Any improvement over established methods that have been previously studied, testedand published are an asset that will improve the patient’s satisfaction about the healthcareperformance in medical institutions. This can be achieved by refining those algorithms orimplementing new approaches that will make better predictions on the given data.The main objective of this dissertation is to propose ML approaches having acknowledged and evaluated the existent methods used in clinical data. In order to fulfill this goal,an analysis of the state of the art of medical knowledge repositories and scientific paperspublished related to the selected keywords selected was performed. In this line of work,it is crucial to understand, compare and discuss the results obtained to those previouslypublished. Thus, one of the goals is to suggest new ways of solving those problems andmeasuring them up against the existent ones.",
    "text2": "The process of Automatic Speech Recognition (ASR) opens doors to a vast amount of possibleimprovements in customer experience. The use of this type of technology has increasedsignificantly in recent years, this change being the result of the recent evolution in ASRsystems. The opportunities to use ASR are vast, covering several areas, such as medical,industrial, business, among others. We must emphasize the use of these voice recognitionsystems in telecommunications companies, namely, in the automation of consumer assistanceoperators, allowing the service to be routed to specialized operators automatically throughthe detection of matters to be dealt with through recognition of the spoken utterances. Inrecent years, we have seen big technological breakthrough in ASR, achieving unprecedentedaccuracy results that are comparable to humans. We are also seeing a move from whatis known as the Traditional approach of ASR systems, based on Hidden Markov Models(HMM), to the newer End-to-End ASR systems that obtain benefits from the use of deepneural networks (DNNs), large amounts of data and process parallelization.The literature review showed us that the focus of this previous work was almost exclusivelyfor the English and Chinese languages, with little effort being made in the development ofother languages, as it is the case with Portuguese. In the research carried out, we did notfind a model for the European Portuguese (EP) dialect that is freely available for generaluse. Focused on this problem, this work describes the development of a End-to-End ASRsystem for EP. To achieve this goal, a set of procedures was followed that allowed us topresent the concepts, characteristics and all the steps inherent to the construction of thesetypes of systems. Furthermore, since the transcribed speech needed to accomplish our goalis very limited for EP, we also describe the process of collecting and formatting data from avariety of different sources, most of them freely available to the public. To further try andimprove our results, a variety of different data augmentation techniques were implementedand tested. The obtained models are based on a PyTorch implementation of the Deep Speech2 model.Our best model achieved an Word Error Rate (WER) of 40.5%, in our main test corpus,achieving slightly better results to those obtained by commercial systems on the same data.Around 150 hours of transcribed EP was collected, so that it can be used to train other ASRsystems or models in different areas of investigation. We gathered a series of interestingresults on the use of different batch size values as well as the improvements provided bythe use of a large variety of data augmentation techniques. Nevertheless, the ASR theme is vast and there is still a variety of different methods and interesting concepts that we couldresearch in order to seek an improvement of the achieved results.",
    "similarity": 0.3091999779860946
  },
  {
    "text1": "There always have been a huge interest in working with public data from online socialmedia users, with the exponential growth of social media usage, this interest and re searches on the area keep increasing.This thesis aims to address prediction and classification tasks on online social net work data. The goal is to predict psycho-demographic - personality and demographic -traits by doing text emotion analysis on social networks as Twitter and Facebook. Ourmain motivation was to raise awareness to what can be done with users’ social mediaor network information or usual behaviours on the web, such as from text analysiswe can trace their personality, know their tastes, how they behave and so on, and tospread the emotion-text relation on social networks subject, because it only started tobe studied recently and there’s so much data and information to do it.To perform these tasks mentioned above we carried an extensive review of literatureof previous works to define the state-of-art of the project and to learn and identify workstrategies. Almost all of the past researches, based their results on a vast sample ofusers and data, but because some frameworks and APIs were shutdown in recent years,such as MyPersonality from Facebook adding to some frameworks being paid for,resulted in a small sample of users’ data to analyze in our thesis which can prejudicethe results.We start by gathering data from Twitter and Facebook with users consent. On Twit ter we focused on tweets and retweets, on Facebook we focused on all of what theuser typed by using the DataSelfie plugin that stored all that data on a server thatcan be retrieved later. Our next step was to find emotions on their text data with thehelp of a lexicon that categorized words by eight different emotions, two of them wereput away because we focused only on the six major emotions - this is explained later- and we had to remove stopwords and apply stemming to all of the text and do aword-matching of every word of our data with every word from the lexicon. Afterthis, we asked our participants to fulfill a \"Big-Five\" personality questionnaire and toprovide us their age, so we added the Big-Five traits and age to each users individualdataset. We got their final versions, ready to apply machine-learning algorithms tofind correlations between emotions and personality or demographic attributes. Wefocused on practical and methodological aspects of the user attribute prediction task.We used many techniques and algorithms that we thought it were best fit for the datawe had and for the goal that we had to achieve.We gathered data in two datasets that we tested, one of them we called \"Mixed Lan guage Dataset\", contains all text entries from each user, and the other \"User Dataset\",contains one entry per user after we analyze every text entry for all users in order tohave a more general view on each one. For the first mentioned dataset we achievebest results with the decision trees algorithms, from 58% on the agreeableness trait,to 68% on the neuroticism trait. This dataset had a problem with the way data wasspread, so it was impossible to predict age and gender with efficiency. As for the lat ter, regarding demographic characteristics all of the classifiers had a good classifyingpercentage, from K-nearest’s 73% to Naive Bayes’ 95%. The most solid classifier forpersonality traits was the one using the CART decision tree algorithm, it ranged from50% on the openness trait to 76% on the agreeableness one. There were classifiers withterrible results, there were others that were a bit dull, and there were some that stoodout as we stated above. We had a small sample, and that was a problem as it wasn’tconsistent or solid in terms of data value and that can change our results, we believethat our results would be way better if we applied the same mechanisms to a muchbigger sample.Concluding, we demonstrate how we can predict personality or demographic traits- BigFive traits, age or gender - from studying emotions in text. As stated above, wehope this thesis will alert people for what can be done with their online information,we only focus on psycho-demographic profiling, but there are many other things thatcan be done.",
    "text2": "Nowadays the success of a business is dependent on the ability to effectively integrate in an intricatenetwork of entities that are connected by material and information flows, inventory management beingone of the main concerns. These flows are characterized by decision-making processes that will varydepending on the environment, entities and business models in the network. So, these networks needa decision-making system capable of providing solutions that dictate the optimal way the network and itsentities provide and collect inventory in order to reduce costs and maximize profit. In the context of thisdissertation, the problem arises when there is a stock disruption in the network and outside entities can nolonger answer the stores’ supply requests and these stores become the entities responsible for requesting and delivering products to each other. This problem is modeled as an Inventory Routing problem,since it encompasses inventory management and routing decisions. The main goal of the system can bedescribed as maximizing the collection of products per travel distance, without causing stock-outs at anysupplier, for the entire network. The problem at hand is an optimization problem.In order to solve this optimization problem, first, the structural characteristics and key aspects were identified and studied, followed by the mathematical conceptualization, which involved the definition of theobjective function and the corresponding set of constraints. The mathematical formulation allows theproblem to be translated into a specific and precise mathematical language, making it possible to evaluatesolutions, by means of a fitness function, and apply optimization algorithms to solve the problem. Theseoptimization algorithms can be approximate or exact methods and their suitability to the problem dependson many factors such as the size, structure and complexity of the problem. So, the choice of the optimization algorithms must be preceded by a careful analysis of the problem at hand and its characteristics.After this, in the implementation phase, two adaptations of the genetic algorithm, two adaptions of thesimulated annealing algorithm, two adaptations of the tabu search algorithm were developed. Additionaly,another algorithm responsible for generating reference solutions was also developed (Dynamic2). In order to test and compare the developed optimization algorithms, three different sized scenarios were generated.Each of these scenarios has a different amount of data associated with it, whether it be in the number ofstores, types of products or number of requests. As to compare the results of the different instances ofthe algorithms fairly in each scenario, these were made to generate roughly the same number of solutions.In scenarios 1 and 3, all the optimization algorithms developed were successful in finding solutions withhigher fitness values than the baseline Dynamic2 solution. In scenario 2, due to time constraints andcomputational complexities, only the Genetic algorithm and the Genetic algorithm with Elitism using aninitial population consisting of solutions generated by the Dynamic2 algorithm, managed to find solutionswith higher fitness value than the baseline solution. In this scenario, the developed optimization algorithmswere also tested using feasible solutions generated through random mechanisms as initial solutions. Theseinstances also achieve solutions with improved fitness values when compared to their respective initial solutions or populations.Furthermore, in scenarios 1 and 3, the Genetic algorithm with an initial population consisting of feasiblesolutions generated through random mechanisms was the optimization algorithm that found the best solutions, with these solutions having fitness values 56.14% and 92.07% greater than the baseline Dynamic2solution’s, respectively. In scenario 2, the Genetic algorithm with Elitism, utilizing an initial population consisting of solutions generated by the mentioned Dynamic2 algorithm, found the solution with the highestfitness value, being approximately 1.00% higher than the baseline solution.",
    "similarity": 0.30688866985027957
  },
  {
    "text1": "There always have been a huge interest in working with public data from online socialmedia users, with the exponential growth of social media usage, this interest and re searches on the area keep increasing.This thesis aims to address prediction and classification tasks on online social net work data. The goal is to predict psycho-demographic - personality and demographic -traits by doing text emotion analysis on social networks as Twitter and Facebook. Ourmain motivation was to raise awareness to what can be done with users’ social mediaor network information or usual behaviours on the web, such as from text analysiswe can trace their personality, know their tastes, how they behave and so on, and tospread the emotion-text relation on social networks subject, because it only started tobe studied recently and there’s so much data and information to do it.To perform these tasks mentioned above we carried an extensive review of literatureof previous works to define the state-of-art of the project and to learn and identify workstrategies. Almost all of the past researches, based their results on a vast sample ofusers and data, but because some frameworks and APIs were shutdown in recent years,such as MyPersonality from Facebook adding to some frameworks being paid for,resulted in a small sample of users’ data to analyze in our thesis which can prejudicethe results.We start by gathering data from Twitter and Facebook with users consent. On Twit ter we focused on tweets and retweets, on Facebook we focused on all of what theuser typed by using the DataSelfie plugin that stored all that data on a server thatcan be retrieved later. Our next step was to find emotions on their text data with thehelp of a lexicon that categorized words by eight different emotions, two of them wereput away because we focused only on the six major emotions - this is explained later- and we had to remove stopwords and apply stemming to all of the text and do aword-matching of every word of our data with every word from the lexicon. Afterthis, we asked our participants to fulfill a \"Big-Five\" personality questionnaire and toprovide us their age, so we added the Big-Five traits and age to each users individualdataset. We got their final versions, ready to apply machine-learning algorithms tofind correlations between emotions and personality or demographic attributes. Wefocused on practical and methodological aspects of the user attribute prediction task.We used many techniques and algorithms that we thought it were best fit for the datawe had and for the goal that we had to achieve.We gathered data in two datasets that we tested, one of them we called \"Mixed Lan guage Dataset\", contains all text entries from each user, and the other \"User Dataset\",contains one entry per user after we analyze every text entry for all users in order tohave a more general view on each one. For the first mentioned dataset we achievebest results with the decision trees algorithms, from 58% on the agreeableness trait,to 68% on the neuroticism trait. This dataset had a problem with the way data wasspread, so it was impossible to predict age and gender with efficiency. As for the lat ter, regarding demographic characteristics all of the classifiers had a good classifyingpercentage, from K-nearest’s 73% to Naive Bayes’ 95%. The most solid classifier forpersonality traits was the one using the CART decision tree algorithm, it ranged from50% on the openness trait to 76% on the agreeableness one. There were classifiers withterrible results, there were others that were a bit dull, and there were some that stoodout as we stated above. We had a small sample, and that was a problem as it wasn’tconsistent or solid in terms of data value and that can change our results, we believethat our results would be way better if we applied the same mechanisms to a muchbigger sample.Concluding, we demonstrate how we can predict personality or demographic traits- BigFive traits, age or gender - from studying emotions in text. As stated above, wehope this thesis will alert people for what can be done with their online information,we only focus on psycho-demographic profiling, but there are many other things thatcan be done.",
    "text2": "The process of Automatic Speech Recognition (ASR) opens doors to a vast amount of possibleimprovements in customer experience. The use of this type of technology has increasedsignificantly in recent years, this change being the result of the recent evolution in ASRsystems. The opportunities to use ASR are vast, covering several areas, such as medical,industrial, business, among others. We must emphasize the use of these voice recognitionsystems in telecommunications companies, namely, in the automation of consumer assistanceoperators, allowing the service to be routed to specialized operators automatically throughthe detection of matters to be dealt with through recognition of the spoken utterances. Inrecent years, we have seen big technological breakthrough in ASR, achieving unprecedentedaccuracy results that are comparable to humans. We are also seeing a move from whatis known as the Traditional approach of ASR systems, based on Hidden Markov Models(HMM), to the newer End-to-End ASR systems that obtain benefits from the use of deepneural networks (DNNs), large amounts of data and process parallelization.The literature review showed us that the focus of this previous work was almost exclusivelyfor the English and Chinese languages, with little effort being made in the development ofother languages, as it is the case with Portuguese. In the research carried out, we did notfind a model for the European Portuguese (EP) dialect that is freely available for generaluse. Focused on this problem, this work describes the development of a End-to-End ASRsystem for EP. To achieve this goal, a set of procedures was followed that allowed us topresent the concepts, characteristics and all the steps inherent to the construction of thesetypes of systems. Furthermore, since the transcribed speech needed to accomplish our goalis very limited for EP, we also describe the process of collecting and formatting data from avariety of different sources, most of them freely available to the public. To further try andimprove our results, a variety of different data augmentation techniques were implementedand tested. The obtained models are based on a PyTorch implementation of the Deep Speech2 model.Our best model achieved an Word Error Rate (WER) of 40.5%, in our main test corpus,achieving slightly better results to those obtained by commercial systems on the same data.Around 150 hours of transcribed EP was collected, so that it can be used to train other ASRsystems or models in different areas of investigation. We gathered a series of interestingresults on the use of different batch size values as well as the improvements provided bythe use of a large variety of data augmentation techniques. Nevertheless, the ASR theme is vast and there is still a variety of different methods and interesting concepts that we couldresearch in order to seek an improvement of the achieved results.",
    "similarity": 0.30736663664327113
  },
  {
    "text1": "O tema principal abordado nesta dissertação é a classificação de imagens através de redes neuronais. O crescimento do estudo desta área da inteligência artificial permite a que, atualmente, os sistemas sejam mais eficientes. A forma mais ancestral da gestão dos parques de estacionamento passa pela colocação de sensores de movimento ou de presença nos lugares de estacionamento. Tal organização leva a grandes despesas na aquisição e manutenção do material. A implementação de um sistema de gestão centralizado e com recurso a métodos inteligentes, além de diminuir as despesas dos materiais, uma vez que uma câmara vem substituir os vários sensores, também leva a um maior conforto por parte dos utilizadores ao nível da simplicidade em encontrar uma vaga no parque de estacionamento.A metodologia desta dissertação passa por implementar várias redes neuronais e decidir qual é a que obtém um maior número de previsões realizadas com sucesso. Foram utilizados dois tipos de redes neuronais: as Multi-Layer Preceptron (MLP) e as Convolution Neural Networks (CNN). Todas as redes em estudo foram alimentadas com o dataset criado na plataforma CoppeliaSim, onde são criadas simulações de imagens captadas por uma câmara num parque de estacionamento.Os resultados dos testes realizados mostram que tanto as redes MLP como as redes CNN obtêm bons resultados no projeto implementado, comprovando que as imagens podem ser observadas como uma sequência de pixéis e, dessa forma, padronizadas.O presente trabalho constitui uma forte contribuição na crescente área de estudo das redes neuronais pois demonstra que, selecionando os parâmetros de rede adequados, é possível aumentar a sua eficiência. Mais ainda, as redes MLP conseguem apresentar melhores resultados comparativamente àsredes CNN, preparadas e desenhadas para a interpretação de imagens.",
    "text2": "A crescente adoção de assistentes digitais faz com que os casos de uso para os quais estes são utilizados sejam cada vez mais abrangentes. Isto aliado ao facto dos dispositivos IoT estarem cada vez mais acessíveis, leva a que comece a ser comum os utilizadores controlaremdiversos dos seus dispositivos através dos assistentes digitais.O presente documento retrata a dissertação com o tema Gestão e controlo de dispositivos IoT através a interação com assistentes digitais. O principal foco desta passa pela investigaçãoda gestão de múltiplos dispositivos de IoT, inseridos no mesmo ambiente e que possam ser geridos/controlados através de uma plataforma de interação por voz, neste caso um assistente digital.Embora já existam soluções disponíveis para desenvolvimento de aplicações neste sentido, estas são muito recentes carecendo tanto ao nível do número de funcionalidades como da flexibilidade oferecida para sua utilização.Esta investigação resulta numa proposta de arquitetura para aplicações deste domínio eda implementação de um sistema que permita fazer a gestão e controlo de um conjunto de dispositivos inteligentes inseridos no contexto de uma smart home. A arquitetura destesistema e das aplicações que o constituem dever ao possibilitar a inclusão de novas funcionalidades inexistentes nos assistentes digitais atuais e a implementação de algumas destas funcionalidades devera ser apresentada como casos de estudo ao longo do presente documento.",
    "similarity": 0.30072022160664824
  },
  {
    "text1": "In the last few years, de novo molecular design has increasingly been using generative models, from theemergent field of Deep Learning (DL), to propose novel compounds that are likely to possess desiredproperties/activities, in areas such as drug discovery, materials sciences or biotechnology. A panoplyof deep generative models, such as Recurrent Neural Networks, Variational Autoencoders, AdversarialAutoencoders and Generative Adversarial Networks, can be trained on existing datasets, and provide forthe generation of novel compounds, typically with similar properties of interest. Additionally, differentoptimization strategies, including transfer learning, Bayesian optimization, reinforcement learning, andconditional generation, can be used to direct the generation process towards desired aims, regarding theirbiological activities, synthesis processes or chemical features. Various instances of experimental validationof these emerging methods have surfaced, with de novo generated molecules being synthesized andproving successful in in vitro, and even in vivo, assays. These successful practical realizations encouragefurther research into this blooming field.This dissertation aims to explore the application of generative DL to the de novo molecular design, witha focus on the targeted generation of new compounds. Two frameworks were developed to support thisendeavor and stand as the main contributions of this work. The first, termed DeepMolGen, standardizesthe implementation and usage of various generative DL architectures for molecular design. The second,termed EAMO, employs multi-objective evolutionary algorithms to navigate the latent space of autoencoderbased models, optimizing the generation of molecules with desired characteristics. These frameworks wereaccompanied with a systematic and critical review on deep generative models, the related optimizationmethods for targeted compound design, and their applications.Four state-of-the-art architectures were implemented, trained and evaluated under the DeepMolGenframework using a standard dataset and common metrics such as validity, uniqueness, novelty and theMOSES benchmark. The results showed that DeepMolGen was capable of performing the intended tasksand that most of the implemented models performed on par with their publications. Similarly, four casestudies from the literature were optimized with EAMO and the results compared to previous works. Theseexperiments showed that EAMO could control abstract chemical properties and is competitive with otherstate-of-the-art methods. Lastly, the three best performing models were combined with transfer learningand EAMO within a pipeline for the generation of sweeteners. The resulting set of 102 promising moleculeswas reviewed by expert chemists and the pipeline improved with their feedback. A second set of 99compounds was then generated and the preliminary observations pointed to significantly improved results.",
    "text2": "Interstitial lung diseases (ILD) are defined as a set of more than 200 pulmonary disorders. Among these, the ones broadly termed as pneumonia represent a major cause of morbidity and mortality in the world. The chest radiograph (CXR) was the first x-ray based lung imaging technique to emerge and is still widely used as a diagnostic method for pneumonia and other lung diseases. However, correct interpretation of CXR requires analysis by experts and stays vulnerable to errors and observer-related variation. To counteract these problems, artificial intelligence (Al) methods have been applied for the automated analysis of CXR and other medical images. The deep learning (DL) branch of AI and in the particular the methods based on convolutional neural networks (CNN), recently obtained impressive results in these tasks. This dissertation presents a DL approach to classify pneumonia from medical CXR image datasets. Two different models based on the development of CNN were trained from a preprocessed dataset of CXR images obtained from 8562 individuals classified as normal (n=7214) or with pneumonia (n=1348) (Dataset XP1’). Model 1 applied a normal cross entropy loss function, and model 2 an alternative loss function aiming at counteracting the unbalance in normal/pneumonia class frequency. For performance enhancing both models underwent a hyper optimization procedure. The optimized model 1 and 2 were tested on a test set from PI'. To better understand the predictability and generalization potential we then tested both models on an unrelated test set of 624 images (Dataset XP2). Interestingly, model 1 obtained better performance when tested on XP2 than in XP1', scoring an accuracy of 85%, recall of 93% and precision of 85% for the detection of the pneumonia class. The higher homogeneity present on dataset XP2 compared with dataset XP1' could be a plausible justification. As for model 2, it correctly predicted more pneumonia cases an test set XP1' than model 1. However, on test set XP2 the results were poor, predicting most cases as pneumonia and scoring a recall value of only 26% for the pneumonia class. Testing the DL models on unseen data is a relevant but not always performed validation. Overall, the higher accuracy, recall and precision levels of model 1 in XP2 suggests it has a higher potential to be applied for real-word application although its performance should be further improved and evaluated. This work opened promising new lines of research for the future development of a high-performance CNN-based automated method to classify CXR and assist in the diagnostic of pneumonia.",
    "similarity": 0.3162537773860489
  },
  {
    "text1": "Automatic text annotation systems are mechanisms that aim to provide assistance to users who need to extract and annotate relevant information in a given text. Usually, this type of system is developed for very specific application domains, in order to facilitate research processes on text content. The works of this dissertation will be developed based on the Tombo da Mitra, a codex that contains the inventory of the properties of the Archbishop’s Table of Braga, in the 17th century. The quantity and diversity of the elements referred to in the book are impressive, as it contains all the names and surnames, settlements, professions, types of land and buildings, among many other elements, which are very important for the study and learning of geography, culture, economy, architecture, religion and portuguese language of the 17th century. The annotation of these elements expressively shows their location in time and space, as well as their potential relationships, facilitating the study of the book and providing linguistic researchers, teachers and students with a valuable instrument to reach and reinforce knowledge about the book. In this dissertation, we present a tool specially designed for the annotation of documents in the Livro das Propriedades, allowing the management and listing of annotation tags and providing a clearer view of the content of the manuscript.",
    "text2": "It is now possible to prove that technology has proven to be a strong ally in the mostdiverse areas, from economics and management to health or banking. Education is therefore no exception. The insertion of technology and software that provide students witheducational and motivational support for their learning has been a major challenge. It isbased on this lack of support that a project called “Leonardo” emerged at the Universityof Minho. This project considers the development of educational software, which aimsto provide students with a supervised learning method that will allow students to improve their knowledge and also observe their results. All of this will allow you to drawlessons that support your progress in a given area of study. This dissertation proposes,therefore, the development of a data warehousing system, which allows the collectionof information about users and their interactions with the referred system. In this way,it will be possible to obtain a multidimensional data analysis platform, which allows tomonitor the student’s state of knowledge over time, thus allowing him / her to evaluatehis / her progress, in a given field of study, during the interaction with a student. the system.",
    "similarity": 0.30144838186609013
  },
  {
    "text1": "Automatic text annotation systems are mechanisms that aim to provide assistance to users who need to extract and annotate relevant information in a given text. Usually, this type of system is developed for very specific application domains, in order to facilitate research processes on text content. The works of this dissertation will be developed based on the Tombo da Mitra, a codex that contains the inventory of the properties of the Archbishop’s Table of Braga, in the 17th century. The quantity and diversity of the elements referred to in the book are impressive, as it contains all the names and surnames, settlements, professions, types of land and buildings, among many other elements, which are very important for the study and learning of geography, culture, economy, architecture, religion and portuguese language of the 17th century. The annotation of these elements expressively shows their location in time and space, as well as their potential relationships, facilitating the study of the book and providing linguistic researchers, teachers and students with a valuable instrument to reach and reinforce knowledge about the book. In this dissertation, we present a tool specially designed for the annotation of documents in the Livro das Propriedades, allowing the management and listing of annotation tags and providing a clearer view of the content of the manuscript.",
    "text2": "The MiddleWare layer is an abstraction method that acts as an intermediary in a softwareinfastructure implementing interoperability between existing applications, operating systems,networks and the hardware of a distributed system.It is considered a cross-platform tool capable of providing an essential programmingabstraction to this type of systems, allowing for easier management of the inherent heterogeneity in these. A Middleware solution application allows a responsible user to orchestratemessage flows, to prepare their contents so that they always reach their destination in theformat they need. It also provides the users with the possibility to obtain information inreal time regarding the performance of the systems it encompasses, allowing evaluation andconsequent action to improve efficiency, in order to achieve the requirements of the systems’operation.The project to be developed, aims to take advantage of Internet of Things and Middlewaretechnologies and concepts, applying them to the creation of a service monitoring tool essential to a more efficient performance of a distributed system. The services and architecturesto focus with greater attention are Micro-Services, SOA Architecture, ETL processes andEvents, of which one will be chosen to be the focus in the development of the project.",
    "similarity": 0.3081827241402608
  },
  {
    "text1": "Over the past few years, the world has been witnessing a huge demographic change: theaging population has been growing at an alarming rate. This problem has been a matterof concern for many countries since it has been posing several challenges to healthcaresystems worldwide. In Portugal, which is one of the countries with the largest aging population,this demographic change has led to several issues. In fact, in Portugal, the nursinghomes have been getting a higher demand, and health professionals are overloaded withwork. Furthermore, the fact that nursing homes still use paper to record information and toclinically manage their residents is another tremendous problem since this method is moreprone to errors and time-consuming.In this context, the present master’s dissertation emerged and consisted in the designand development of a mobile application for the health professionals, i.e. the nurses anddoctors, working in a Portuguese nursing home, more specifically in one of the nursinghomes of Santa Casa da Miseric´ordia de Vila Verde. This mobile application was developedto help the health professionals to clinically manage the residents and to assist them at thepoint-of-care, namely to schedule, perform, and record their daily tasks and to have accessand manipulate information.Additionally, the present dissertation also included the definition of clinical and performanceindicators to assist the decision-making process. It is important to mention that amobile solution was chosen since a hand-held device, which can be used anywhere andany time, is able to give access and store all the needed information at the point-of-care.Thereby, this project was developed in order for the nursing home to shift from thepaper-based to the computer-based management of data as well as to introduce technologicalimprovements in the facility, more specifically, Health Information and CommunicationTechnology. Thus, by taking advantage of the benefits provided by these improvements,the mobile application could help the health professionals to provide better care, namelyby reducing time-waste and errors, and, consequently, enhance elders’ quality of life. Furthermore,the solution could relieve some of the workload of the health professionals andhelp them make more informed and evidence-based decisions and, hence, improve thedecision-making process.",
    "text2": "Over the last years, the implementation and evolution of computer resources has been improving both the financial and temporal efficiency of clinical processes, as well as the security in the transmission and maintenance of their data, also ensuring the reduction of clinical risk. Currently, the importance of all the information flowing in healthinstitutions is unquestionable. In this way, it is essential that institutions, more specifi cally hospital institutions, have a good Hospital Information System (HIS) in order to collect and analyze information, also helping to support decision making. The most common application of these type of systems is the Electronic Health Record (EHR),which, despite bringing many benefits, is still associated with a low level of usability.However, the different systems present in hospitals are distributed and heterogeneous. Since the interaction between these systems is crucial these days, there is the Agency for Integration, Diffusion and Archive (AIDA) implemented in some Portuguese hospitals. AIDA is a platform developed to enable the dissemination and inte gration of information generated in a health environment by different systems, inclu ding for example information on Complementary Diagnostic and Therapeutic Means (MCDT).Previous research has shown that health professionals often do not analyze and actaccurately and appropriately on test results. Preventing errors during the access toMCDT is essential as this is a crucial step in the diagnostic process, thus avoidingnegative consequences for the patient.In this sense, a new MCDT visualization platform (AIDA-MCDT) was implementedin this project, specifically in the Hospital Center of Porto (CHP), with several newfunctionalities in order to make this process faster, intuitive and efficient, always guaranteeing the confidentiality and protection of patients’ personal data and significantlyimproving the usability of the system, leading to a better delivery of health care.",
    "similarity": 0.3325225069252078
  },
  {
    "text1": "The continuous social and economic development has led, over time, to an increase inconsumption, as well as a greater demand from the consumer for what he buys. In thissense retailers have the need to respond to these challenges and explore new opportunities.Naturally, the selling price of a product assumes a fundamental role in the purchasedecision, and in that way the retailers must carefully analyze and define the best price foreach product, based on several factors, such as: perceived value of the product, positioningof the product, the company strategy, competition.Faced with all these challenges, the use of Information Systems is essential for retailers sothat it can support them in the pricing decision. These information systems are becomingincreasingly complex, including demand forecasts, and making recommendations based onbalanced buying patterns due by the economic evolution of markets.In a first phase the ideia was to make a study on two main price recommendation systems:Rules Motors and Price Optimization. As the objective of the dissertation is to change thealgorithm of Regular Price Optimization of the software tool Profimetrics, part of the studywas conducted according to the methodology of the tool. After an analysis of the company’scurrent algorithm, the changes were made to perfect it. Subsequently, we used the casestudy methodology, in the application of the algorithm developed to a retail company.Through this case study it was possible to make a brief diagnosis in order to comparethe current algorithm of the company with the developed algorithm.",
    "text2": "Nutrition is fundamental to human well-being and health, especially when applied topatients who need special health care. In these cases, it is crucial that each patient hasadequate nutrition to meet their needs, in order to accelerate their recovery process.Recommender systems make it possible to offer suggestions to users, adapted to theirpreferences and to previously obtained information about them. Food recommender systemsare recommender systems applied to nutrition and diet. They are usually implementedfeeding plans recommendation platforms based on food and the person using it.In this sense, the existing gap in the use of these recommendation systems applied tonutrition in health care is notorious. This is mainly due to the difficulty in associating thenutritional value of each food with the needs of patients.The main objective of this project is to fill the existing void, through the development andimplementation of a platform that will allow the planning of meals taking into account thenutritional plan of the food and the specific needs associated with the users of the Vila VerdeSocial Canteen.The use of machine learning algorithms will allow us to identify how the connectionbetween food and patient requirements can be made, making this task possible, which iscomplex due to the wide domain associated with it.This platform will be used for the generation of kitchen meal plans, which shall beproduced using the algorithms developed after a bibliographic study and an investigation ofthe existing work, in order to understand how they can be implemented and which are themost adequate to the nutritional recommendations system.",
    "similarity": 0.3149465087400898
  },
  {
    "text1": "Na atualidade, graças às elevadas capacidades computacionais e gráficas existentes, é possíveldotar os sistemas de processamento analítico com ferramentas de visualização e manipulação deinformação muito atrativas e de fácil utilização, em particular quando utilizamos para issodashboards. Os dashboards tornam a interação com a informação proveniente de um sistema deprocessamento analítico mais interativa e eficaz, muito graças à modularidade inerente aos seuscomponentes gráficos e à sua qualidade inata de representar a informação graficamente. Amodularidade também é uma característica importante uma vez que permite modificar o sistemautilizando apenas cliques do rato, enquanto que, por sua vez, a representação gráfica dainformação facilita a sua análise e interiorização (Few, 2006a). Estas qualidades, entre outras,fazem com que os dashboards sejam uma ferramenta fulcral na análise da informação e nosuporte à tomada de decisão no seio de uma empresa, tendo sempre em mente que o sucesso deuma empresa está dependente da capacidade que os seus responsáveis e funcionários têm detomar decisões acertadas em tempo útil. Em geral, os dashboards podem ser utilizados paramonitorizar o desempenho de uma empresa, tanto a nível global como a nível individual, definirestratégias de marketing, analisar tendências, entre outros. Nesta dissertação pretendeu-seinvestigar a utilização de dashboards em sistemas de processamento analítico, abordando desde oseu desenho até à sua implementação e exploração prática. Complementarmente, de forma ademonstrar a utilidade e vantagens desse tipo de instrumentos, procedeu-se à implementação deum sistema piloto, incorporando na sua estrutura uma coleção de dashboards providos demecanismos de auto-adaptabilidade aos requisitos dos utilizadores.",
    "text2": "Com o emergir da era da informação foram muitas as empresas que recorreram a data warehouses para armazenar a crescente quantidade de dados que dispõem sobre os seus negócios. Com essa evolução dos volumes de dados surge também a necessidade da sua melhor exploração para que sejam úteis de alguma forma nas avaliações e decisões sobre o negócio. Os sistemas de processamento analítico (ou OLAP – On-Line Analytical Processing) vêm dar resposta a essas necessidades de auxiliar o analista de negócio na exploração e avaliação dos dados, dotando-o de autonomia de exploração, disponibilizando-lhe uma estrutura multiperspetiva e de rápida resposta. Contudo para que o acesso a essa informação seja rápido existe a necessidade de fazer a materialização de estruturas multidimensionais com esses dados já pré-calculados, reduzindo o tempo de interrogação ao tempo de leitura da resposta e evitando o tempo de processamento de cada query. A materialização completa dos dados necessários torna-se na prática impraticável dada a volumetria de dados a que os sistemas estão sujeitos e ao tempo de processamento necessário para calcular todas as combinações possíveis. Dado que o analista do negócio é o elemento diferenciador na utilização efetiva das estruturas, ou pelo menos aquele que seleciona os dados que são consultados nessas estruturas, este trabalho propõe um conjunto de técnicas que estudam o comportamento do utilizador, de forma a perceber o seu comportamento sazonal e as vistas alvo das suas explorações, para que seja possível fazer a definição de novas estruturas contendo as vistas mais apropriadas à materialização e assim melhor satisfaçam as necessidades de exploração dos seus utilizadores.Nesta dissertação são definidas estruturas que acolhem os registos de consultas dos utilizadores e com esses dados são aplicadas técnicas de identificação de perfis de utilização e padrões de utilização, nomeadamente a definição de sessões OLAP, a aplicação de cadeias de Markov e a determinação de classes de equivalência de atributos consultados. No final deste estudo propomos a definição de uma assinatura OLAP capaz de definir o comportamento OLAP do utilizador com os elementos identificados nas técnicas estudadas e, assim, possibilitar ao administrador de sistema uma definição de reestruturação das estruturas multidimensionais “à medida” da utilização feita pelos analistas.",
    "similarity": 0.3109776763891152
  },
  {
    "text1": "Atualmente, o maior desafio no desenvolvimento de software é referente à a portabilidade das aplicações para as várias plataformas disponíveis, especialmente pela crescente heterogeneidade nos componentes de hardware, de middleware e de software base.O desenho de modelos abstratos de software é uma das formas mais elegantes e eficientes para solucionar este desafio. A Model-Driven Software Engineering (MDSE) ́é uma metodologia de desenvolvimento em que os modelos são chave em todo o ciclo de vida do projeto, desde a captura de requisitos, passando pelas fases de modelação e desenvolvimento, e por fim nos processos de teste e instalação.O objetivo primário desta dissertação foca-se na construção de uma ferramenta, o MDA SMART, capaz de interpretar modelos abstratos de software, parametrizáveis, e de gerar automaticamente código fonte para várias plataformas. A ferramenta, caracterizada por uma arquitetura robusta e extensível, é idealizada para permitir a manipulação de modelosde forma ágil, para ser modular o suficiente para integrar novos perfis meta-modelo e para escalar eficientemente para novas plataformas.O MDA SMART resulta da articulação de uma Domain-Specific Language (DSL) para a gestão dos meta-modelos e consequentes processos de transformação. Na utilização da DSL são obtidos processos de transformação rigorosos, com elevado desempenho e que visam maximizar a consistência e portabilidade dos modelos através de medidas ajustadas a destoarem a heterogeneidade entre as plataformas. Adicionalmente, a ferramenta visa compatibilizar os modelos de lógica de negócio com os referentes às interfaces gráficas que, conjugados, vão permitir a obtenção de modelos e código fonte com alto nível de consistência e completude.",
    "text2": "O recurso a ferramentas de geração automática de código permite economizar tempo quando se desenvolvem soluções de software, factor importante em questões de produtividade.Existe um conjunto de padrões de conceção [Gamma et al., 1995] que representam soluções genéricas para problemas relativos ao desenvolvimento de aplicações de software, numa perspetiva orientada aos objetos. Para cada um deles pode ser vista a sua estrutura de classes, métodos e relacionamentos, bem como as situações mais adequadas para a sua utilização. Bastará consultar o catálogo de padrões de conceção [Gamma et al., 1995] e utilizar aquele que mais se adequar à resolução de determinado problema que surja no desenvolvimento de um novo programa.A existência de uma aplicação de software capaz de fazer a geração automática do código associado aos padrões de conceção, agiliza o desenvolvimento de novas aplicações, porque fornece de imediato o respetivo código.O que se propõe com o desenvolvimento desta dissertação é uma solução de software, capaz de efetuar a geração automática de código para os padrões de conceção catalogados em [Gamma et al., 1995]. Juntamente com o programa desenvolvido, é também apresentado um levantamento do estado da arte sobre os padrões de conceção, considerando também situações atuaisda sua aplicabilidade. Em seguida, é descrita a especificação da aplicação elaborada, bem como o seu processo de desenvolvimento, acompanhado de um exemplo de utilização. Por fim, encontram-se dois casos de estudo, servindo para provar que o programa elaborado pode ser utilizado em contextos reais.",
    "similarity": 0.31319402625557025
  },
  {
    "text1": "Risk assessment is an important topic for financial institution nowadays, especially in the context of loan applications or loan requests and credit scoring. Some of these institutions have already implemented their own custom credit scoring systems to evaluate their clients’ risk supporting the loan application decision with this indicator. In fact, the information gathered by financial institutions constitutes a valuable source of data for the creation of information assets from which credit scoring mechanisms may be developed.Historically, most financial institutions support their decision mechanisms on regression algorithms, however, these algorithms are no longer considered the state of the art on decision algorithms. This fact has led to the interest on the research of new types of learning algorithms from machine learning able to deal with the credit scoring problem.The work presented in this dissertation has as an objective the evaluation of state of the art algorithms for credit decision proposing new optimization to improve their performance. In parallel, a suggestion system on credit scoring is also proposed in order to allow the perception of how algorithm produce decisions on clients’ loan applications, provide clients with a source of research on how to improve their chances of being granted with a loan and also develop client profiles that suit specific credit conditions and credit purposes.At last, all the components studied and developed are combined on a platform able to deal with the problem of credit scoring through an experts system implemented upon a multi-agent system. The use of multi-agent systems to solve complex problems in today’s world is not a new approach. Nevertheless, there has been a growing interest in using its properties in conjunction with machine learning and data mining techniques in order to build efficient systems. The work presented aims to demonstrate the viability and utility of this type of systems for the credit scoring problem.",
    "text2": "Software applications evolve over the years at a cost: their architecture modularity tends to be degraded. This happens mainly because software application maintenance often leads to architectural degradation. In this context, software architects need to elaborate strategies for detecting architectural degradation symptoms and thus maintaining the software architectural quality. The elaborations of these strategies often rely on tools with domain-specific languages (DSLs), which help them to specify software architecture rules. These tools also enforce the adherence of these rules in the evolving program. However, their adoption in mainstream software development is largely dependent on the usability of the language. Unfortunately, it is also often hard to identify their usability strengths and weaknesses early, as there is no guidance on how to objectively reveal them. Usability is a multi-faceted quality characteristic, which is challenging to quantify before a DSL is actually used by its stakeholders. There is even less support and experience on how to quantitatively evaluate the usability of DSLs used in software maintenance tasks. To this end in this dissertation, a usability measurement framework was developed based on the Cognitive Dimensions of Notations (CDN). The framework was evaluated both qualitatively and quantitatively using two textual DSLs for architecture rules in the context of two evolving object-oriented systems. The results suggested that the proposed metrics were useful: (1) to early identify the DSL usability limitations to be addressed, (2) to reveal specific features of the DSLs favoring software maintenance tasks, and (3) to successfully analyze eight usability dimensions that are critical in many DSLs. However, along with these results this evaluation also revealed that this kind of tools lack support for communication among the stakeholders, creating a gap in the software development. To solve this problem we proposed heuristics for tools that use DSLs for detecting architecture degradation symptoms. These heuristics will permit the exchange of information between the stakeholders, thereby, also increasing the tool usability. Finally, we chose TamDera as the tool to implement these heuristics in our study domain. Therefore, we implemented in the new version of TamDera the communication support for the stakeholders by using a new architecture and a new environment with the developed heuristics.",
    "similarity": 0.34623810670841865
  },
  {
    "text1": "Em contexto educativo e numa sociedade em permanente mudança, há uma necessidade premente de adaptaras metodologias pedagógicas, no sentido de adequar os processos de ensino e de aprendizagem às característicasdos alunos, implementando diferentes abordagens, que permitam captar a evolução do aluno e incrementara sua atenção, motivação e empenho nas matérias a estudar, como forma de promover o sucesso da aprendizagem.Durante os últimos anos várias iniciativas de investigação e de aplicação têm sido desenvolvidas com oobjetivo de integrar técnicas e modelos de Gamificação no domínio dos sistemas de ensino e de aprendizagem,com vista ao desenvolvimento da motivação e desenvolvimento dos alunos nas mais variadas áreas do conhecimento.Nesta dissertação demonstramos a aplicação de técnicas de Gamificação em sistemas educacionais,através da incorporação de elementos de jogos nas suas várias vertentes, convencidos que estas permitem contribuirpositivamente para o desenvolvimento dos processos de aprendizagem e, em particular, para o aumentoda concentração e interesse dos alunos nesses sistemas. Para esse fim, utilizámos um sistema específico deavaliação de conhecimento, com o objetivo de combater a diminuição da motivação e potenciar o uso e a exploraçãodesse sistema. Tendo isso presente, começamos por analisar os benefícios que a Gamificação podeter em contextos educativos, analisando aspetos que permitam aumentar a motivação dos alunos, melhorar oseu processo de aquisição de conhecimento e, consequentemente, o seu sucesso académico. Posteriormente,concebemos um modelo de gamificação específico e fizemos a sua implementação no sistema de avaliaçãoreferido recorrendo a linguagens como a Python, a JavaScript e a HTML, entre outras.",
    "text2": "Sendo certo que o recurso à tecnologia no ensino é cada vez mais notório, a utilização de sistemas informáticos de tutoria continua aquém do seu potencial, ainda que seja um tema abordado há já algumas décadas. Assim, surgiu a iniciativa Leonardo e o respetivo desenvolvimento de uma ferramenta computacional para sistemas de avaliação de conhecimento, com vista a ser aplicada, pelo menos, no suporte de processos de avaliação de alunos, na Universidade do Minho. De entre os módulos que caracterizam estes agentes de software, no contexto desta dissertação, destacam se a base de conhecimento, o mecanismo de raciocínio e o modelo do estudante. Dado que o esforço maior recai em habilitar os tutores artificiais à adaptação, em tempo real, da avaliação ao nível de conhecimento atual dos alunos, surge a necessidade de desenvolvimento de um mecanismo de raciocínio, que seja capaz de determinar, criteriosamente, o que deve ser apresentado de seguida num dado momento avaliativo. O trabalho desta dissertação focou-se na conceção e implementação de um sistema de avaliação baseado em conhecimento para o sistema Leonardo, com a capacidade de ajustar de forma dinâmica, à medida da perícia e conhecimento dos estudantes alvos do processo de avaliação, o seu comportamento, acompanhando de perto a evolução do processo de aprendizagem dos estudantes. Essencialmente, neste trabalho implementou-se a “máquina” de raciocínio para o sistema Leonardo poder sustentar de forma efetiva a avaliação de estudantes ao longo do tempo, numa ou mais áreas do conhecimento.",
    "similarity": 0.3020492762670204
  },
  {
    "text1": "Streaming content has completely changed the way we consume it. The arising of theInternet, and streaming services, has allowed people to access a big collection of musicwithout buying it, just by subscribing to a service or to use it for free with the consumptionof publicity.But, and for those who have a local collection? They can’t use these platforms unless theservice allows the user to buy the content, store it in a local environment, play it there, andthe user could play it remote by streaming.The use of clouds appears to be a good solution for this group of people. Unfortenelly,when the collection is really big, the additional costs of storage of the cloud could be a bigproblem. In addition, normally, the user interface of these services isn’t enjoyable, i.e., isn’tuser-friendly.So, a hybrid system could be the ideal, a streaming service with cloud services that allowstoring the private collection. This is the best for the user but will force them to store all thecollection or at minimum a part of the collection which they want to access, in an externalsource, with a strict organizational structure. For a new user, this couldn’t be a problem butis for a user who already has a big collection.This dissertation has proposed a remote access service to these private collections so thatwith just a simple gadget (smartphone, pc, ...) the user can access the content stored on theirprivate server anywhere on the planet, without change the original location of the collection.This service was built using only normalized and open-source technologies.Based on the proposed architecture, was also developed a prototype with the mainfunction of the system, like the possibility to play music from the private collection ona smartphone Android. The conclusion of the tests made to the prototype was that thisalternative solution could be very good for the people who want that their collection remainsin one place, and, at the same time, can play it remotely.",
    "text2": "The constant growth of integration and popularity of “Internet of Things”devices is affecting home automation systems, where new technologies wereintroduced, in the recent years for this particular sector. These automationsystems integrate devices that can be anywhere in the house, connectedto a home network, either through a wire or wireless connection. A homeautomation system can be used to control air conditioning, lighting, poolcontrol systems, home-entertainment systems and much more.Within the field of home-entertainment systems, the best known technologiesare the Digital Living Network Alliance and the Digital Audio AccessProtocol, which provide interoperability to allow sharing of digital mediacontent between devices across a home network. However, these technologieshave the disadvantage of being proprietary, maintaining restrict documentationaccess, complex architectures and concepts and not optimal to specificpurposes, like audio distribution.The main goal of this project was to prove that is possible to use standardizedprotocols, such as the Simple Network Manager Protocol and opensource tools in order to develop a music distribution service that allows theimplementation of similar features than the ones already existing proprietarytechnologies. As such, the implementation prototype system allows a userto manage and play audio from a music collection that is stored in a singlehome audio server. The system architecture enables audio streaming betweenthe server and the various devices in the same local network. Further more,the music collection, can integrate virtual audio files that are available fromexternal music sources, like iTunes, etc.",
    "similarity": 0.3003998748994728
  },
  {
    "text1": "Technological evolution is impacting several industries, e.g., by allowing them to deliver higher levelsof functionality. The automotive industry is an example of how technology is supporting the developmentof new solutions in vehicle safety and comfort.Advanced Driver Assistance Systems (ADAS) are cases of solutions that evolved significantly inrecent years. This is possible not only due to the progress of electronic solutions but also becauseof higher quality in software. The smartphone is an example of this evolution with a broad rangeof applicability since these devices have been used to develop ADAS, making them an interestingcost-effective platform to develop such systems.Previous research has shown smartphones’ ability to output sensors data with the necessary qualityfor a broad number of applications with special focus in inertial sensors. However, such studiestend to be difficult to reproduce or lack the desired detail levels of their experimental methods. Concernsabout how good are smartphone sensors and their use to develop ADAS emerge when readingexisting literature, particularly, how the context of collecting data is controlled and which variablesimpact the collection process.In order to assess the feasibility of using smartphones as sensing devices, questions arise on howdifferent parts of the collection setup affect the quality of data collected. Motivated by those questions,a study considering four different hypotheses is proposed to assess the impact of a controlled set ofvariables, namely: brands of inertial sensors, car mounts, sensor sampling rates, and vehicles. A setof controlled experiments is performed to assess the impact of each variable in the collection processof inertial sensors, more precisely the vertical acceleration.To perform the experiments, three special-purpose tools were developed. Smartphones used inthe experiments feature an application to collect and export their sensors data. A researcher of anexperiment operates another smartphone application to annotate road anomalies found while driving.A desktop application automates the computation and statistical validation of the vertical accelerationcorrelation from different setups.Dynamic Time Warping was used to compute the correlation coefficient of vertical accelerationas measured by different devices. Results show a baseline correlation coefficient of 0.892 with astandard configuration of software and hardware. When one of the independent variables is changed,the resulting coefficients range from 0.827 to 0.848.Randomization tests were executed to statistically validate experiments results, making use of aRandom Shuffle algorithm on surrogate data. Such tests rejected all four proposed null hypothesesregarding dissimilarities on vertical acceleration sensed by different setups.From the controlled experiment a deeper understanding of the variables influencing data collectionwith smartphones was obtained. Results showed that varying the inertial sensors, car mounts, ratesof sampling, or vehicles had a low impact on vertical acceleration sensed by smartphones. This isa good indicator that smartphones can be used to develop ADAS without the need to standardizeevery part of the collection setup. Thus, it possible to foresee the deployment of a system to a wideraudience by taking advantage of existing equipment.",
    "text2": "The future of vehicles is for them to become smarter: able to perceive the its surroundings, detect dangeroussituations, and act accordingly. To realize this vision, vehicles must collect information and share it with others,allowing them to have shared knowledge of an event that their sensors could not yet detect. However, somevehicles may not have enough computational resources to process the information and comply with low-delayrequirements, and may need to offload the data to edge computing platforms to extend their own processingcapabilities.While offloading, a vehicle may have multiple access networks at their disposal and by choosing the bestnetwork it may maximize the amount of data it can offload. These access networks include the mobile 5Gnetwork and Wi-Fi access points, which the operator can integrate within the 5G system to take advantage ofunlicensed spectrum in the 2.4, 5 and 60 GHz ranges. In the current work, we focused on leveraging Wi-Fi andallowing vehicles to decide which access network to use among three Wi-Fi 802.11n/ac/ad networks.We developed a Wi-Fi performance monitoring and decision-making system (WiPerf) that can: (i) collectthroughput measurements and channel state information for multiple Wi-Fi networks; (ii) estimate throughputusing passive measurements; (iii) predict the next 40 seconds of throughput; (iv) decide which network to use,based on the throughput forecasts and on the time it takes to switch to another network. The system wasimplemented in a real-world setup with two vehicles and two TP-Link Talon AD7200 access points. We performedan initial set of experiments to collect a dataset to develop estimation and forecasting models, and a second setof experiments to validate our decision-making system.For throughput estimation, we developed the UKF-SR model, a novel approach that combines Symbolic Re gression with a non-linear recursive Bayes filter. Results showed that our solution was superior to NN, DT, andRF models, with these having higher RMSE values by at least 4.94 %, 38.09 %, and 9.59 % for 802.11n/ac/ad,respectively. Considering forecasting, we adapted previously developed spatial-clustering models, that forecastthroughput based on a set of similar historic samples, and compared them with a time-series approach, us ing ARIMA and VAR models. VAR showed the best results among the time-series models, but they were stilloutclassed by spatial-clustering, considering both MAE and MASE values.We integrated the estimation and forecasting models with a decision-making algorithm. The algorithm sched ules which networks the vehicle should use considering the time if takes to switch networks, to maximize theamount of data it can offload. Compared with the optimal solution, based on the real throughput measurementsand without forecasting (perfect prediction), the results show that our approach has near-optimal performancewith an average throughput of only 4.43 % less than the optimal one.",
    "similarity": 0.3034786882316147
  },
  {
    "text1": "Technological evolution is impacting several industries, e.g., by allowing them to deliver higher levelsof functionality. The automotive industry is an example of how technology is supporting the developmentof new solutions in vehicle safety and comfort.Advanced Driver Assistance Systems (ADAS) are cases of solutions that evolved significantly inrecent years. This is possible not only due to the progress of electronic solutions but also becauseof higher quality in software. The smartphone is an example of this evolution with a broad rangeof applicability since these devices have been used to develop ADAS, making them an interestingcost-effective platform to develop such systems.Previous research has shown smartphones’ ability to output sensors data with the necessary qualityfor a broad number of applications with special focus in inertial sensors. However, such studiestend to be difficult to reproduce or lack the desired detail levels of their experimental methods. Concernsabout how good are smartphone sensors and their use to develop ADAS emerge when readingexisting literature, particularly, how the context of collecting data is controlled and which variablesimpact the collection process.In order to assess the feasibility of using smartphones as sensing devices, questions arise on howdifferent parts of the collection setup affect the quality of data collected. Motivated by those questions,a study considering four different hypotheses is proposed to assess the impact of a controlled set ofvariables, namely: brands of inertial sensors, car mounts, sensor sampling rates, and vehicles. A setof controlled experiments is performed to assess the impact of each variable in the collection processof inertial sensors, more precisely the vertical acceleration.To perform the experiments, three special-purpose tools were developed. Smartphones used inthe experiments feature an application to collect and export their sensors data. A researcher of anexperiment operates another smartphone application to annotate road anomalies found while driving.A desktop application automates the computation and statistical validation of the vertical accelerationcorrelation from different setups.Dynamic Time Warping was used to compute the correlation coefficient of vertical accelerationas measured by different devices. Results show a baseline correlation coefficient of 0.892 with astandard configuration of software and hardware. When one of the independent variables is changed,the resulting coefficients range from 0.827 to 0.848.Randomization tests were executed to statistically validate experiments results, making use of aRandom Shuffle algorithm on surrogate data. Such tests rejected all four proposed null hypothesesregarding dissimilarities on vertical acceleration sensed by different setups.From the controlled experiment a deeper understanding of the variables influencing data collectionwith smartphones was obtained. Results showed that varying the inertial sensors, car mounts, ratesof sampling, or vehicles had a low impact on vertical acceleration sensed by smartphones. This isa good indicator that smartphones can be used to develop ADAS without the need to standardizeevery part of the collection setup. Thus, it possible to foresee the deployment of a system to a wideraudience by taking advantage of existing equipment.",
    "text2": "In the past 30 years, accumulated evidence has been supporting viral infection as one factorresponsible for 15-20% of human malignancies worldwide (W. S. Liang et al. 2014;McLaughlin-Drubin and Munger 2008). Studies on oncogenic viruses have proved their importanceon cellular malfunction along the carcinogenic process, and showed that their associationwith cancer can amount from 15% to 100% (McLaughlin-Drubin and Munger 2008),depending on the type of tumour. With the large amount of genomic and metagenomic informationavailable on public international consortia, such as TCGA database, it is nowadayspossible to indirectly infer viral infections from the human centred omics studies, as a portionof the reads will align in viruses and bacteria.Taking as starting point the research made by Tang et al. 2013, we focused on cervical(CESC), hepatocellular (LIHC) and head and neck squamous cell (HNSC) carcinomas, whichare known to show a high proportion of viral-positive cases (Tang et al. 2013). We downloadedRNAseq data from 309, 424 and 566 samples, respectively, and run the unmapped reads againsta reference database of viruses (downloaded from NCBI) by using the tools Batch,SAMTOOLS, Bowtie and PRINTSEQ. Quantification of each virus was performed using partsper million reads (ppm) and only viruses with ppm above 10 were considered as positivelyinfecting the sample. We confirmed that around 94% of CESC samples were infected, mostlyby HPV (Human papillomavirus) and specifically by the HPV16 strain. Nearly 32% of LIHCwere infected by HBV (hepatitis B virus). Almost 17% of HNSC samples were infected, andthe HPV16 was the most common present virus.The evaluation of differential enrichment of metabolic pathways between infected and noninfectedgroups, for each cancer type, was performed in GSEA. Signs of enrichment for infectionand immune related pathways were evident in CESC infected group, while in LIHC andHNSC infected groups the enrichment was mostly related with DNA replication and repair.This seems to indicate that infection is especially active in CESC, contradicting previous claimsthat tumorigenesis in cervix was not directly linked with infection. For the three cancer types,the viruses integrate their genome in the host genome, affecting DNA replication, maintenanceand repair. In our investigation of integration of HPV16 genome in one HNSC tumor sample,we confirmed integration in the human RAD51B gene that codes a protein involved in DNArepair by homologous recombination. We thus confirmed that HPV16 can act both as indirectand direct carcinogen. The infection, most probably through the integration of the viral genome in the host genome,increased the amount of somatic mutations in the infected group in LIHC, but not in HNSCwhere tobacco consumption is also an important carcinogen. The low number of non-infectedsamples in CESC did not allow a reliable evaluation of changes in the amount of somatic mutations.Even so, in both LIHC and HNSC infected groups, some somatic mutations occurredin the context of immune-related pathways, showing that they can contribute to render theseindividuals susceptible to infection.Also, when checking expression of HPV16 genes in five samples each from CESC andHNSC, we confirmed that E6 and E7 genes are amongst the ones more expressed in manysamples, while E2 is not expressed. E6 and E7 have been said to be preferentially integrated inthe host genome, while E2, which controls their expression, is not integrated or it is disrupted.It is believed that the overexpression of E6 and E7 initiates carcinogenesis.The viral infection rates inferred here from mining the omics databases are very similar tothe ones evaluated by standard methods (Tang et al. 2013), showing that public internationalconsortia can indirectly provide interesting insights into the involvement of viral infection intumorigenesis. The high number of samples per tumor, the wide geographic origin of the samples,and the high-throughput characterisation for different omics platforms allows multilayercomparisons and evaluations, in a scale not affordable before.",
    "similarity": 0.30067196854615313
  },
  {
    "text1": "ROC (Receiver Operating Characteristic) curve is a statistic tool that allows the evaluationof the accuracy of a classification system. These curves are drawn on a two-dimensionalgraph, with the ordinate representing the true positive fraction or sensitivity and the abscissarepresenting the false positive fraction or 1-specificity. The index that evaluates the accuracyof these graphs is represented by the area under the curve (AUC) where the larger that areais the bigger the test performance is.Its first appearance dates to the year of 1950. Nevertheless, computationally , the firstsoftware only appeared around 1993 and since then several tools have been made availablefor its analysis. Regarding the theoretical part of the subject, there is a vast bibliographyexisting which introduces all the necessary concepts to analyze a ROC curve visuallyand statistically. However, only a few of those documents discuss the evaluation and thecomparison of software that attain these same curves, consisting of old works in whichthe vast majority corresponds to software that when compared to the current scenario areoutdated or fell out of use.The R software environment with a programming language mainly for statistical use iscurrently one of the best tools to perform the ROC analysis. The variety of packages in thiswork environment make it an interesting study product, which allows us to take advantageof the different features in different the packages or enjoy the same features but by differentmeans and formats. Like R there are several tools that can perform this same analysis, as isthe case of STATA software, which receives regular updates that have been improving thistool recurrently. With the versatility of allowing us to work from a command line or throughmenus predefined by the software itself, it makes it a very accessible and convenient tool toexplore.The R language is also related to the package called shiny, which can create browserapplications through its own commands, making it possible to transpose the differentcommands of packages R into a single application. Due to the wide variety of ROC packagesin R, it is interesting to link them to shiny. Therefore, a library in the application format wasdesigned to group the different packages on the same browser page. The result of this isROSY application available on https://pquintasbcl.shinyapps.io/ROSY/.Due to the increasing use of ROC analysis in different systems, it is essential to explorethe best computational methods to process it in a correct way. Therefore, in this work theresearch and selection of different software/tools to perform this type of analysis is done,based on the different existing bibliographic documents in order to compare them and create a checklist, which will allow us to visualize the fundamental characteristics present in eachsoftware analyzed.",
    "text2": "Neurodegenerative diseases impair the functioning of the brain and are characterized by alterations in the morphology of specific brain regions. Some of the main disorders include Alzheimer's, Parkinson's, and Huntington's diseases, and the number of cases increases exponentially since ageing is one of the main risk factors. Trying to identify the areas in which this type of disease appears is something that can have a very positive impact in this area of Medicine and can guarantee a more appropriate treatment or allow the improvement of the quality of life of patients. With the current technological advances, computer tools are capable of performing a structural or functional analysis of neuroimaging data from Magnetic Resonance Images(MRI). Therefore, Medical Informatics uses these techniques to create and manage medical neuroimaging data to improve the diagnosis and management of these patients. MRI is the image type used in the analysis of the brain area and points to a promising and reliable diagnostic tool since it allows high-quality images in various planes or strategies and MRI methods are fundamental diagnostic tools in clinical practice, allowing the diagnosis of pathologic processes such as stroke or brain tumours. However, structural MRI has limitations for the diagnosis of neurodegenerative disorders since it mainly identifies atrophy of brain regions.Currently, there is increased interest in informatics applications capable of monitoring and quantifying human brain imaging alterations, with potential for neurodegenerative disorders diagnosis and monitoring. One of these applications is Radiomics, which corresponds to a methodolog ythat allows the extraction of features from images of a given region of the brain. Specific quantitative metrics from MRI are acquired by this tool, and they correspond to a set of features, including texture, shape, among others. To standardize Radiomics application, specific libraries have been proposed to be used by the bioinformatics and biomedical communities, such as PyRadiomics, which corresponds to an open source Python package for extracting Radiomics of MRIs.Therefore, this dissertation was developed based on magnetic resonance images and the study of DeepLearning (DL) techniques to assist researchers and neuroradiologists in the diagnosis and prediction of neurodegenerative disease development. Two different main tasks were made: first, a segmentation, using FreeSurfer, of different regions of the brain and then, a model was build from radiomic features extracted from each part of the brain and interpreted for knowledge extraction.",
    "similarity": 0.3094707308131009
  },
  {
    "text1": "ROC (Receiver Operating Characteristic) curve is a statistic tool that allows the evaluationof the accuracy of a classification system. These curves are drawn on a two-dimensionalgraph, with the ordinate representing the true positive fraction or sensitivity and the abscissarepresenting the false positive fraction or 1-specificity. The index that evaluates the accuracyof these graphs is represented by the area under the curve (AUC) where the larger that areais the bigger the test performance is.Its first appearance dates to the year of 1950. Nevertheless, computationally , the firstsoftware only appeared around 1993 and since then several tools have been made availablefor its analysis. Regarding the theoretical part of the subject, there is a vast bibliographyexisting which introduces all the necessary concepts to analyze a ROC curve visuallyand statistically. However, only a few of those documents discuss the evaluation and thecomparison of software that attain these same curves, consisting of old works in whichthe vast majority corresponds to software that when compared to the current scenario areoutdated or fell out of use.The R software environment with a programming language mainly for statistical use iscurrently one of the best tools to perform the ROC analysis. The variety of packages in thiswork environment make it an interesting study product, which allows us to take advantageof the different features in different the packages or enjoy the same features but by differentmeans and formats. Like R there are several tools that can perform this same analysis, as isthe case of STATA software, which receives regular updates that have been improving thistool recurrently. With the versatility of allowing us to work from a command line or throughmenus predefined by the software itself, it makes it a very accessible and convenient tool toexplore.The R language is also related to the package called shiny, which can create browserapplications through its own commands, making it possible to transpose the differentcommands of packages R into a single application. Due to the wide variety of ROC packagesin R, it is interesting to link them to shiny. Therefore, a library in the application format wasdesigned to group the different packages on the same browser page. The result of this isROSY application available on https://pquintasbcl.shinyapps.io/ROSY/.Due to the increasing use of ROC analysis in different systems, it is essential to explorethe best computational methods to process it in a correct way. Therefore, in this work theresearch and selection of different software/tools to perform this type of analysis is done,based on the different existing bibliographic documents in order to compare them and create a checklist, which will allow us to visualize the fundamental characteristics present in eachsoftware analyzed.",
    "text2": "The process of Automatic Speech Recognition (ASR) opens doors to a vast amount of possibleimprovements in customer experience. The use of this type of technology has increasedsignificantly in recent years, this change being the result of the recent evolution in ASRsystems. The opportunities to use ASR are vast, covering several areas, such as medical,industrial, business, among others. We must emphasize the use of these voice recognitionsystems in telecommunications companies, namely, in the automation of consumer assistanceoperators, allowing the service to be routed to specialized operators automatically throughthe detection of matters to be dealt with through recognition of the spoken utterances. Inrecent years, we have seen big technological breakthrough in ASR, achieving unprecedentedaccuracy results that are comparable to humans. We are also seeing a move from whatis known as the Traditional approach of ASR systems, based on Hidden Markov Models(HMM), to the newer End-to-End ASR systems that obtain benefits from the use of deepneural networks (DNNs), large amounts of data and process parallelization.The literature review showed us that the focus of this previous work was almost exclusivelyfor the English and Chinese languages, with little effort being made in the development ofother languages, as it is the case with Portuguese. In the research carried out, we did notfind a model for the European Portuguese (EP) dialect that is freely available for generaluse. Focused on this problem, this work describes the development of a End-to-End ASRsystem for EP. To achieve this goal, a set of procedures was followed that allowed us topresent the concepts, characteristics and all the steps inherent to the construction of thesetypes of systems. Furthermore, since the transcribed speech needed to accomplish our goalis very limited for EP, we also describe the process of collecting and formatting data from avariety of different sources, most of them freely available to the public. To further try andimprove our results, a variety of different data augmentation techniques were implementedand tested. The obtained models are based on a PyTorch implementation of the Deep Speech2 model.Our best model achieved an Word Error Rate (WER) of 40.5%, in our main test corpus,achieving slightly better results to those obtained by commercial systems on the same data.Around 150 hours of transcribed EP was collected, so that it can be used to train other ASRsystems or models in different areas of investigation. We gathered a series of interestingresults on the use of different batch size values as well as the improvements provided bythe use of a large variety of data augmentation techniques. Nevertheless, the ASR theme is vast and there is still a variety of different methods and interesting concepts that we couldresearch in order to seek an improvement of the achieved results.",
    "similarity": 0.3054871525456109
  },
  {
    "text1": "A predominância de um mundo orientado pelas Tecnologias de Informação (TI) é umanoção que está bem presente no quotidiano, desde a mais ínfima tarefa rotineira ao dia-adianum posto de trabalho. De todas as atividades onde as TI incidem, destaca-se nestetrabalho a aplicação das mesmas numa área cujo foco é de extrema importância – a saúde.O setor da saúde, tal como outras áreas organizacionais, não é uma exceção à influênciadas tecnologias e tornou-se uma área que integra a informação como um bem fundamentalpara seu o bom funcionamento.O crescente aumento do volume de dados de registos eletrónicos e de fontes diversascom que os profissionais de saúde lidam todos os dias originou uma nova necessidade –a transformação desses dados em informação para extração de conhecimento. Consequentemente,a dificuldade do processamento de tamanho volume de informação potenciou oaparecimento dos sistemas de Business Intelligence (BI), capazes de lidar com a quantidadede dados armazenada e cujo objetivo passa por apresentar informação sob a forma de conhecimentopara suportar o processo de tomada de decisão.A grande motivação para a implementação de sistemas de BI surgiu da possibilidadede conceção de uma forma de disponibilizar a informação de forma rápida, eficaz e visualmenteapelativa cuja interpretação seja algo intuitiva. A informação relevante podeser disponibilizada em diversos formatos, como por exemplo num Dashboard – técnica devisualização interativa crucial na análise da informação e no suporte à decisão.O pressuposto principal desta dissertação é evidenciar que na modalidade cirúrgica deuma unidade hospitalar é também possível transmitir informação que permita auxiliar osprofissionais de saúde na gestão de um bloco operatório. Deste modo, foram construídosindicadores de diversas categorias que poderão ser relevantes face às possíveis necessidadeshospitalares.Na seleção da tecnologia a utilizar para o desenvolvimento da plataforma de BI optou-sepelo Power BI, ferramenta de Business Intelligence bastante intuitiva e que permite a partilhados elementos visuais que vão influenciar a leitura do profissional de saúde responsávelpela gestão da unidade cirúrgica.Após o desenvolvimento dos Dashboards, pode-se afirmar que o resultado foi satisfatório,uma vez que foram criados indicadores de desempenho que permitem perceber a importânciade um sistema de BI para a gestão mais eficiente de uma unidade cirúrgica.",
    "text2": "Existem hoje em dia diversas soluções de Business Intelligence no mercado que permitem aanálise de informação de forma intuitiva, permitindo o acesso a utilizadores de negócio dasmais diversas áreas. Estas soluções vieram assim tornar o processo de análise de informaçãoágil, permitindo que esteja presente em mais processos de negócio, executados por utilizadoresnão especialistas. Estes processos de negócio exigem por vezes a manipulação de dadosmanualmente. A tarefa de manipulação manual de dados provenientes de diversas fontesé um processo complexo, onde há a necessidade de proceder à implementação de queries,pipelines customizados, entre outras tarefas específicas. Estas tarefas estão assim fora doalcance de profissionais sem conhecimento técnico de programação e desenvolvimentode software. Existe assim a necessidade de construção de uma ferramenta que permita ainteração e manipulação de dados sem conhecimento técnico que seja transversal a diferentescontextos com a possibilidade destes também terem diferenças ao nível de tecnologias debase de dados.O Tableau, ferramenta de visualização e interação com dados provenientes de diversasfontes, anunciou que iria disponibilizar uma api para aceder e interagir com a informaçãopresente nos dashboards, possibilitando assim o desenvolvimento de software por terceiros.Por conseguinte, surgiu então a oportunidade de criar um produto que no formato deplugin tivesse como objetivo preencher a lacuna de manipular e interagir com os dadospresentes numa base de dados sem estar constrangido a um cenário ou tecnologia específica.Desta maneira conseguimos expandir o conjunto de ações disponíveis aos utilizadores paraalém das atuais que estão de momento restritas apenas à visualização e interação com dadosprovenientes de diversas fontes, sem qualquer possibilidade de alteração e preservação denova informação.Este documento relata o plano de trabalhos sobre a manipulação de dados e estruturas, emmúltiplos contextos com a possibilidade de alteração de tecnologia de base de dados. Tendoisto em conta, está estipulado o desenvolvimento de um produto de um motor dinâmico demanipulação de queries dinâmico, que permita a interação por parte dos utilizadores comdiferentes contextos e que secundariamente seja de fácil integração em diferentes ferramentasde visualização através de interfaces gráficas.",
    "similarity": 0.3036142097776447
  },
  {
    "text1": "The high growth in the use of digital identities creates the need to develop mechanismsthat can protect the personal data of each individual. The way identity is treated todayprevents each of us from being able to control our personal information. This is due to thecentralized architecture in which the personal data are inserted, that is, all these data are kepttogether and controlled by the entities responsible for providing the most varied services,which is wrong since the identity belongs to the person and thus it must be responsiblefor controlling that identity. Centralized identity management brings within itself severalproblems, whether intentional (that is, data correlation for profiling) or unintentional (thatis, data breach).To face this problem, multiple entities across the world are developing decentralizedidentity managment systems based on a self-sovereign identity architecture where eachindividual is responsible for managing and storing a set of credentials, each with parts oftheir personal information. A self-sovereign identity architecture allows users to provide onlysmall parts of their personal information or even to omit any type of personal identification,using cryptographic techniques like selective disclosure and zero-knowledge proofs, whichallows them to have more control over their privacy.Taking into account the current problems of digital identity, this dissertation aims toexplore the state of the art and develop a proof of concept, through the implementation ofa system based on self-sovereign identity, which is able to cover the use cases for digitalidentity. Thus, this document shows the architecture implemented, with a blockchain,responsible for the storage of all public data, and a user agent, responsible for facilitating allinteractions of the various users with the developed system.The proof of concept developed allows not only to validate that it is possible to correctmany of the problems associated with centralized identity management, but also to explorenew cryptographic strategies in order to improve the way each of us manages our ownidentity.",
    "text2": "As the years go by, the interaction between humans and machines seems to gain more and more importancefor many different reasons, whether it's taken into consideration personal or commercial use. On a timewhere technology is reaching many parts of our lives, it's important to keep thriving for a healthy progressand help not only to improve but also to maintain the benefits that everyone gets from it. This relationshipcan be tackled through many points, but here the focus will be on the mind.Emotions are still a mystery. The concept itself brings up serious questions because of its complex nature.Till the date, scientists still struggle to understand it, so it's crucial to pave the right path for the growth ontechnology on the aid of such topic. There is some consensus on a few indicators that provide importantinsights on mental state, like words used, facial expressions, voice.The context of this work is on the use of voice and, based on the field of Automatic Speech EmotionRecognition, it is proposed a full pipeline of work with a wide scope by resorting to sound capture andsignal processing software, to learning and classifying through algorithms belonging on the Semi SupervisedLearning paradigm and visualization techniques for interpretation of results. For the classification of thesamples,using a semi-supervised approach with Neural Networks represents an important setting to tryalleviating the dependency of human labelling of emotions, a task that has proven to be challenging and,in many cases, highly subjective, not to mention expensive. It is intended to rely mostly on empiric resultsmore than theoretical concepts due to the complexity of the human emotions concept and its inherentuncertainty, but never to disregard prior knowledge on the matter.",
    "similarity": 0.30360240246459735
  },
  {
    "text1": "We are facing a period where software projects have a huge dimension involvingsmall resources, high risk and a wide range of available approaches. In thisscenario the Software Development Methodologies (SDMs) can prove to be auseful ally, but very dangerous and even fatal if misused. The big issue aroundthis matter is how to choose the appropriated SDM that ts a speci c project.In the given scope, this dissertation describes a framework for comparing SDMsdelivering a set of procedures that should be followed when the choice of anSDM is made. The dissertation approaches the framework by applying it to agroup of SDMs that were selected by their popularity and signi cance. Thisexercise is done to prove the concept of the framework and to provide a basecomparison, with each chosen SDM, that can, and should, be extended by thosewho choose to use the framework.The classi cation is achieved by de ning a scale that goes from total satisfactionto no satisfaction, with an intermediate level of partial satisfaction, that is appliedto a set of keys. These keys are based in SWEBOK (Software EngineeringBody Of Knowledge) that describes and explains the di erent Knowledge Areas(KA) stating their common issues and best practices. To explain the framework,the dissertation analyzes each KA and evaluates the selected SDMs byassessing how their approach complies with SWEBOK's knowledge areas, usingthe previous stated scale.The framework delivered can be enriched by its user who should provide weightsto each KA regarding the project in which the SDM will be used and previousexperiences",
    "text2": "Software applications evolve over the years at a cost: their architecture modularity tends to be degraded. This happens mainly because software application maintenance often leads to architectural degradation. In this context, software architects need to elaborate strategies for detecting architectural degradation symptoms and thus maintaining the software architectural quality. The elaborations of these strategies often rely on tools with domain-specific languages (DSLs), which help them to specify software architecture rules. These tools also enforce the adherence of these rules in the evolving program. However, their adoption in mainstream software development is largely dependent on the usability of the language. Unfortunately, it is also often hard to identify their usability strengths and weaknesses early, as there is no guidance on how to objectively reveal them. Usability is a multi-faceted quality characteristic, which is challenging to quantify before a DSL is actually used by its stakeholders. There is even less support and experience on how to quantitatively evaluate the usability of DSLs used in software maintenance tasks. To this end in this dissertation, a usability measurement framework was developed based on the Cognitive Dimensions of Notations (CDN). The framework was evaluated both qualitatively and quantitatively using two textual DSLs for architecture rules in the context of two evolving object-oriented systems. The results suggested that the proposed metrics were useful: (1) to early identify the DSL usability limitations to be addressed, (2) to reveal specific features of the DSLs favoring software maintenance tasks, and (3) to successfully analyze eight usability dimensions that are critical in many DSLs. However, along with these results this evaluation also revealed that this kind of tools lack support for communication among the stakeholders, creating a gap in the software development. To solve this problem we proposed heuristics for tools that use DSLs for detecting architecture degradation symptoms. These heuristics will permit the exchange of information between the stakeholders, thereby, also increasing the tool usability. Finally, we chose TamDera as the tool to implement these heuristics in our study domain. Therefore, we implemented in the new version of TamDera the communication support for the stakeholders by using a new architecture and a new environment with the developed heuristics.",
    "similarity": 0.3101964240745404
  },
  {
    "text1": "The recent advances in metabolomics experimental techniques have provided novel approachesfor many research issues in the biological fields. Indeed, the ability to identifyand quantify numerous compounds in biological samples provides significant advances infunctional genomics, biomarker identification, sample characterization or drug discoveryand development. To take full advantage of these data advanced bioinformatics methodsfor data analysis and mining have been required.A number of methods and tools for metabolomics data analysis have been put forwardrecently, being one of the major limitations still faced the lack of integrated frameworks forextracting relevant knowledge from these data and being able to integrate these data withprevious biochemical knowledge. Also, the lack of reproducibility in many data analysesor data mining processes is a strong obstacle for biological discovery.In recent work from the host group, specmine, a metabolomics and spectral data analysis/mining framework, in the form of a package for the R system, has been developed toaddress some of these issues.In this thesis, an integrated web-based platform for metabolomics data analysis and mining,named WebSpecmine, was designed and developed, based on the specmine package, thusproviding an easier and friendly user interface. This website provides means for analysingmetabolomics data from different formats, including tasks such as pre-processing, univariateand multivariate analysis and metabolite identification. This web-based platform wasdeveloped collaboratively and, therefore, this work focused mainly in data from nuclearmagnetic ressonance and mass spectrometry.Also, the package faced some limitations regarding types of analysis not yet provided,such as metabolite identification for other data formats besides Mass Spectrometry coupledto Liquid Chromatography. Therefore, the extension of the metabolite identification featurewas addressed, by implementing such analysis for Nuclear Magnetic Ressonance data inthe specmine package, as well as making it available in the website.The website was validated by applying it to reproduce the pipelines from previous studiesthat made use of the specmine package. Furthermore, a case study involving bananapeels and the analysis of their characteristics and potential made use of the newly createdwebsite to further validate its functionality. All the analyses here executed were stored andare available in the web application, as public projects.",
    "text2": "The recent advances in different analytical techniques able to produce spectral data, includingRaman, Infrared (IR) or Ultraviolet-Visible (UV-vis) spectroscopies, have provided novelapproaches for many research issues in the biological and chemical fields. Indeed, they haveallowed to address tasks in functional genomics, sample characterization and classification,or drug discovery. To take full advantage of these data, advanced bioinformatics methodsare required for data analysis and mining.A number of methods and tools for spectral data analysis have been put forward recently,being one of the major limitations still faced the lack of integrated frameworks for extractingrelevant knowledge from these data and being able to integrate these data with previousbiochemical knowledge. Also, the lack of reproducibility in many data analysis or datamining processes is a strong obstacle for biological discovery, being common the lack ofdata and data analysis pipelines in the published work.In recent work from the host group, specmine, a metabolomics and spectral data analysis/mining framework, in the form of a package for the R system, has been developed toaddress some of these issues. In this thesis, the main aim was to design and develop anintegrated web-based platform for spectral data analysis and mining, based on the specminepackage, providing an easier and more user friendly interface, but also addressing some ofthe package’s current limitations.The developed platform contains features that cover the main steps of the metabolomicsdata analysis workflow, with modules for data reading and dataset creation, data preprocessingand a variety of analysis types. It includes an authentication system, allowingthe user to have his own personal workspace where projects can be stored and accessedlater, with the option to share projects with other users. The different modules were validatedusing real data from previously published studies in the host group, related to theanalysis of the characteristics and potential of natural products, addressing as well theexploration and integration of data from distinct experimental techniques, attesting theplatform’s robustness and utility.",
    "similarity": 0.44568833073395575
  },
  {
    "text1": "Com o surgimento da computação em cloud, tem havido uma crescente adoção da containerisação(containerisation) e orquestração de containers para o desenvolvimento de software. As empresas queaderem a práticas de ContinuousIntegration/ContinuousDelivery(CI/CD)e microserviços beneficiammuito da adoção destas tecnologias, pois os containerstem permitido o aprovisionamento mais rápido eautomatizado de aplicações, melhorando a sua escalabilidade e capacidade de tolerância a faltas.A Feedzai é uma empresa que usa algoritmos de machine learning para combater a fraude financeira,usando um sistema distribuído complexo constituído por múltiplas tecnologias. Escrever configuraçõespara ambientes de teste nestas condições é frequentemente um desafio para o engenheiro de testes,especialmente se feito manualmente, resultando num maior custo em horas-humano necessárias paradesempenhar esta tarefa. Quando se trata de ambientes de teste, estas configurações dependem muito datopologia requerida pelo teste, o que resulta num potencialmente grande e crescente número de ficheirosde configuração para gerir. É obrigatório resolver este problema cedo, de forma a antecipar uma stacktecnológica difícil de gerir à medida que os casos de teste que terão de ser cobertos crescem. Esteproblema foi alvo de várias tentativas de solução por parte de engenheiros na Feedzai, mas as soluçõesresultantes provaram, com o passar do tempo, ser insuficientes, resolvendo apenas parte do problema.Esta dissertação apresenta a arquitetura e principais decisões de implementação do ProgrammableEnvironmentsforQuickOrchestrationofDeployments(Pequod), uma framework que se propõe a resolver o problema supramencionado ao permitir ao programador lançar um ambiente composto por uma stack tecnológica arbitrária usando uma qualquer tecnologia de containerisação/orquestração escolhida pelomesmo. Com esta ferramenta, o programador apenas escolhe quais os componentes que serão lançados e descreve as dependências entre os mesmos; a lógica de configurar estes componentes usando atecnologia escolhida é executada pelo Pequod, sem que o programador tenha de ficar familiarizado comesta. O desenho da Domain-SpecificLanguage(DSL)que permite ao programador definir o ambiente deforma transparente é também discutido aqui.O presente documento apresenta também uma avaliação das capacidades desta framework usando doisprodutos distintos da Feedzai. Os resultados desta avaliação revelaram que esta nova framework está emconformidade com os objetivos delineados de início, resolvendo os problemas que as soluções antecessoras não resolviam.",
    "text2": "Na área de ciência de dados, o machine learning está-se a revelar uma ferramenta essencial para resolver problemas complexos. As empresas estão a investir em equipas de ciência de dados e Machine Learning para desenvolver modelos que apresentem valor para os clientes. No entanto, estes modelos são uma pequena percentagem de uma pipeline de projetos de Machine Learning (ML) e, para entregar um produto de ML completo, é necessário um número maior de componentes. DevOps é uma mentalidade de engenharia e um conjunto de práticas que visa unificar o processo de desenvolvimento e o processo de operações em um software, MLOps é um conceito similar a DevOps mas aplicado ao desenvolvimento e entrega de soluções de ML. O nível de automatização das etapas em uma pipeline de ML define a maturidade do processo de ML, que reflete a velocidade de treino de novos modelos com novos dados ou de treino de novos modelos com diferentes implementações. Um sistema de ML é um sistema de software, desenvolvimento e atualizações contínuas são necessárias para garantir um sistema que escale conforme as necessidades. O principal objetivo desta tese é apoiar a criação de um sistema integrado de ML com uma arquitetura que proporcione a capacidade de ser continuamente operada em um ambiente de produção. Um conceito para avaliação de desempenho de algoritmos deve ser elaborado e implementado. O principal obetivo e melhorar e ace'erar o cicio de desenvolvimento de modelos de ML na empresa. Para atingir este objetivo surge a necessidade de definir uma arquitetura com especificações e a implementação de processos automatizadas num pipeline de ML existente, este processo têm como objetivo alcançar uma ferramenta de benchmark de modelos, com capacidade de analisar o desempenho do modelo, um motor de inferência e um banco de dados para armazenar todas as métricas computadas. Um sistema baseado em IA em desenvolvimento fornece o caso de estudo para desenvolver e validar a arquitetura. Os avanços atuais na área da condução semiautomática introduz a necessidade de sistemas de monitoramento que podem localizar e detectar eventos especificas no veículo. Os conjuntos de sensores são instalados dentro da cabine para alimentar sistemas inteligentes que visam analisar e sinalizar certos comportamentos que podem impactar a segurança e o conforto dos passageiros..",
    "similarity": 0.3060649113287832
  },
  {
    "text1": "Software applications evolve over the years at a cost: their architecture modularity tends to be degraded. This happens mainly because software application maintenance often leads to architectural degradation. In this context, software architects need to elaborate strategies for detecting architectural degradation symptoms and thus maintaining the software architectural quality. The elaborations of these strategies often rely on tools with domain-specific languages (DSLs), which help them to specify software architecture rules. These tools also enforce the adherence of these rules in the evolving program. However, their adoption in mainstream software development is largely dependent on the usability of the language. Unfortunately, it is also often hard to identify their usability strengths and weaknesses early, as there is no guidance on how to objectively reveal them. Usability is a multi-faceted quality characteristic, which is challenging to quantify before a DSL is actually used by its stakeholders. There is even less support and experience on how to quantitatively evaluate the usability of DSLs used in software maintenance tasks. To this end in this dissertation, a usability measurement framework was developed based on the Cognitive Dimensions of Notations (CDN). The framework was evaluated both qualitatively and quantitatively using two textual DSLs for architecture rules in the context of two evolving object-oriented systems. The results suggested that the proposed metrics were useful: (1) to early identify the DSL usability limitations to be addressed, (2) to reveal specific features of the DSLs favoring software maintenance tasks, and (3) to successfully analyze eight usability dimensions that are critical in many DSLs. However, along with these results this evaluation also revealed that this kind of tools lack support for communication among the stakeholders, creating a gap in the software development. To solve this problem we proposed heuristics for tools that use DSLs for detecting architecture degradation symptoms. These heuristics will permit the exchange of information between the stakeholders, thereby, also increasing the tool usability. Finally, we chose TamDera as the tool to implement these heuristics in our study domain. Therefore, we implemented in the new version of TamDera the communication support for the stakeholders by using a new architecture and a new environment with the developed heuristics.",
    "text2": "O recurso a ferramentas de geração automática de código permite economizar tempo quando se desenvolvem soluções de software, factor importante em questões de produtividade.Existe um conjunto de padrões de conceção [Gamma et al., 1995] que representam soluções genéricas para problemas relativos ao desenvolvimento de aplicações de software, numa perspetiva orientada aos objetos. Para cada um deles pode ser vista a sua estrutura de classes, métodos e relacionamentos, bem como as situações mais adequadas para a sua utilização. Bastará consultar o catálogo de padrões de conceção [Gamma et al., 1995] e utilizar aquele que mais se adequar à resolução de determinado problema que surja no desenvolvimento de um novo programa.A existência de uma aplicação de software capaz de fazer a geração automática do código associado aos padrões de conceção, agiliza o desenvolvimento de novas aplicações, porque fornece de imediato o respetivo código.O que se propõe com o desenvolvimento desta dissertação é uma solução de software, capaz de efetuar a geração automática de código para os padrões de conceção catalogados em [Gamma et al., 1995]. Juntamente com o programa desenvolvido, é também apresentado um levantamento do estado da arte sobre os padrões de conceção, considerando também situações atuaisda sua aplicabilidade. Em seguida, é descrita a especificação da aplicação elaborada, bem como o seu processo de desenvolvimento, acompanhado de um exemplo de utilização. Por fim, encontram-se dois casos de estudo, servindo para provar que o programa elaborado pode ser utilizado em contextos reais.",
    "similarity": 0.4572979098463863
  },
  {
    "text1": "O aumento exponencial da informação médica e a procura pela otimização da prestação de cuidados de saúde, conduziu à introdução das tecnologiasde informação na área da saúde. Não existe qualquer dúvida de que a introdução do Processo Clínico Eletrónico (PCE) na área da saúde é uma maisvalia para a qualidade dos cuidados prestados aos utentes. Para além depromover uma maior qualidade dos serviços prestados, a implementação eintegração deste tipo de sistemas em ambiente hospitalar, aumenta a segurança dos utentes e reduz os custos. No entanto, a adoção e aceitação desistemas de PCE na área médica não se tem revelado uma tarefa fácil. Umdos principais fatores apontados para o fracasso da adoção destes sistemasestá associado ao seu baixo nível de usabilidade.Dentro desta problemática, a presente dissertação pretende avaliar a usabilidadee a aceitação dos sistemas de informação em ambiente hospitalar quegarantem o registo eletrónico da informação relativa aos seus utentes. Paraalém disto, é realizada também uma avaliação global das funcionalidadesinerentes ao PCE implementado no Centro Hospitalar do Alto Ave (CHAA),com o intuito de alcançar um ambiente hospitalar livre de papel.",
    "text2": "O desenvolvimento industrial, a constante inovação e a necessidade de melhoriacontínua por parte das organizações originou um crescimento exponencial do volumede dados armazenados existindo, por isso, uma maior quantidade de informação relacionadacom cada instituição. Cada vez mais as instituições dependem do tipo de dadosque armazenam e acumulam.Atualmente, uma organização tem de fazer uma gestão eficiente das suas bases dedados de modo a extrair o máximo de conhecimento possível para apoiar no processode tomada de decisão e assim garantir competitividade no mundo dos negócios e dosmercados. A necessidade de implementação de um sistema de apoio à decisão no seiode uma instituição fez emergir o conceito de Business Intelligence: processo responsávelpela transformação dos dados em informação útil e organizada, e a subsequenteconversão dessa informação em conhecimento valioso para a tomada de decisão.A área da saúde é bastante susceptível, tanto a nível clínico como administrativo, àqualidade e rapidez das decisões tomadas, uma vez que estas decisões colocam sempreem causa a vida humana. Assim, é de extrema importância a utilização de sistemas deapoio à decisão nas unidades de saúde.O propósito deste projeto prende-se, essencialmente, com a exploração e aplicaçãode uma ferramenta de BI aplicada no contexto da saúde. Por outro lado, pretende-setambém avaliar a aplicabilidade de uma ferramenta open source em sistemas complexose integrados como os das instituições hospitalares. Neste sentido, a ferramentaexplorada e avaliada foi o Pentaho. Foi realizada uma monitorização e simulação dosdados clínicos relativos às listas de espera para consulta e cirurgia e à ocupação dassalas do bloco operatório de um hospital no norte de Portugal.Verificou-se que o Pentaho, enquanto ferramenta open source, é inteiramente capazde ser implementada e integrada numa instituição hospitalar, com a potencialidadede uma ferramenta proprietária. Sendo assim conclui-se que o Pentaho é uma ferramentade BI bastante eficiente, capaz de apresentar soluções válidas e atrativas para aresolução de problemas e o para suporte à tomada de decisões.",
    "similarity": 0.3148396267677504
  },
  {
    "text1": "Today, AI is very important in our lives as its used all around us without our knowledge. From simple things such as personal assistants like Alexa and Siri, and advertising algorithms focusing on our tastes -Netflix on the recommendation of movies or, even more common, the presentation of advertising basedon our search history -, to robots and to smart houses, cities or even vehicles. The presence of AI isincreasing and even if we are still far away from our ’General AI’ ideology, a machine capable of anythingautonomously, each day we get closer.In the last decade multiple applications of AI have been through breakthroughs. For example, the firstimplementations of autonomous vehicles were introduced by Tesla and other companies. A number ofdiscoveries must have been made to achieve this revolution of AI performance and, among them, is two ofthe most important developments: Object Detection and Semantic Segmentation, closely related to eachother. These are responsible for understanding the environment so the machine can take actions, beingthe latter an improvement of the first in terms of sensibility error associated to each entity detected as wellas being able to detect its corresponding type, in a pixel level. These machines require more and moredata to analyse, having many types of sensors in order to collect information, such as radars, cameras,LiDAR, among others.This work falls in the study of the use of Semantic Segmentation techniques and its application oncategorising data from image related sensors in order to explain its breakthroughs and challenges, as wellas improving and overcoming such obstacles. Data will consist mainly of scans from outdoor/self-drivingcars POV (KITTI360) with the ability to be used with other types of data such as indoor scans (COCO), toexplain both road and more day-to-day images semantic compositions, applied on a state-of-art solution.Consecutively we will perform a process of optimisation in order to reduce computation costs. Currentlythe works of DeepLab (with the research of deeplabv3[1]) have achieved a high success on SemanticSegmentation overcoming previous problems such as handling component boundaries with more refinedlines while keeping it fairly easy to run on more less powerful machines, being the start point for this work.",
    "text2": "Both energy consumption analysis and energy-aware development have gained the attentionof both developers and researchers over the past years. The interest is more notoriousdue to the proliferation of mobile devices, where energy is a key concern.There is a gap identified in terms of tools and information to detect and identify anomalousenergy consumption in Android applications. A large part of the existing tools arebased on external hardware (costly solutions in terms of setup-time), through predictivemodels (requiring previous hardware calibration) or static code analysis methods. We couldnot identify so far a tool capable of monitor all relevant system resources and componentsthat an application uses and appoint its energy consumption, while being easily integratedwith the application and/or with its development environment. Due to the lack of a toolcapable of gathering all this information, a natural consequence is the lack of informationabout the energy consumption of applications and factors that can influence it.This dissertation aims to carry out a study on the energy consumption of applications andmobile devices in the Android platform, having developed in this scope the GreenSourceinfrastructure, a repository containing the source code, representative metadata and metricsrelatively to a large number of applications (and respective execution in physical devices).In order to gather the results, an auxiliary tool has been developed to automatize theprocess of testing and collect the respective results for each one of the applications. This toolis a software-based solution, allowing to obtain results in terms of consumption throughexecutions made directly on a physical device running the Android platform.The developed framework, the AnaDroid, has the capability to perform static and dynamicanalysis of an application, being able to monitor power consumption and usage ofresources for each application through tests execution. This is done following a whiteboxtesting approach, in order to test applications at source code level. It invokes calls tothe TrepnLib library at strategic locations of the application code (through instrumentationtechniques) to gain control over relevant portions of the source code, like methods and unittests. In this way the programmer can have results about the use, state and consumption ofresources such as energy, CPU, GPU, memory, sensor usage and complexity of developedtest cases.The information gathered through the use of the AnaDroid over a large set of applicationswas stored in GreenSource backend. With the collected results, we expect to be able tocharacterize and classify applications, as well the tests developed for it. It is intended thatthis will be made publicly available and serve as a reference for future works and studies.",
    "similarity": 0.3000987860518169
  },
  {
    "text1": "O uso de painéis de digital signage ou displays (ou, em português, painéis digitais) está cada vez mais a ser implementado nos locais públicos e semipúblicos, uma vez que é uma forma actual de apresentar, de um modo dinâmico, informação, publicidade e conteúdos de entretenimento. Desta forma, as pessoas expostas a esta tecnologia passam a ter um acesso mais rápido e actualizado à informação sobre tudo o que as rodeia.Os ecrãs dos displays têm evoluído no sentido da melhoria da sua qualidade. Além disso, a descida dos preços torna esta tecnologia bastante mais acessível para ser aplicada em vários sectores, nomeadamente na indústria, no comércio, na educação, na saúde, etc., substituindo os meios tradicionais publicitários e informativos, baseados em papel.Uma rede de painéis digitais permite a actualização dos seus conteúdos de forma remota, com base num servidor central que controla toda a informação apresentada na rede, enquanto que nos meios tradicionais a actualização de conteúdos é muito mais cara, demorada e de difícil gestão.Como as pessoas olham pouco tempo para os painéis digitais, exige-se um esforço muito grande no estudo do local onde estes são instalados e na modelação dos conteúdos a serem apresentados, de forma a que o ambiente se torne o mais atractivo possível e, deste modo, se promova a atenção de quem passa pelos painéis. Também existem displays que usam tecnologias mais sofisticadas, permitindo a adaptação automática dos conteúdos apresentados em função do contexto envolvente, fazendo com que a informação seja mais direccionada ao público, sem a necessidade de controlo humano.Dado o crescente sucesso, à escala planetária, da digital signage, têm surgindo cada vez mais soluções de software aplicadas nesta vertente. Por conseguinte, o tema principal desta dissertação incidirá sobre o desenvolvimento de uma aplicação web para painéis de digital signage, sugerida pela empresa Ubisign, com o objectivo de permitir configurar visualizações com informação sobre eventos provenientes do Google Calendar.Uma vez que a promoção de eventos geralmente exige custos elevados de design e produção, é necessário minimizá-los no contexto das redes de digital signage. Para tal, existem determinadas ferramentas on-line de gestão de eventos, como o Google Calendar, com a função de permitir que o utilizador especifique eventos que vão ocorrer e efectue o seu escalonamento com base em calendários. Do ponto de vista de um developer, estas ferramentas evitam a necessidade de implementar outros softwares de gestão de eventos, permitindo também desenvolver outras aplicações que comuniquem com estas ferramentas, através de APIs apropriadas e bem documentadas.Para tirar partido disto, a aplicação a desenvolver terá de recorrer à API Google Calendar para disponibilizar, de forma personalizada, informação sobre eventos que estejam planeados para um dado sítio com uma rede de digital signage instalada e, para esse efeito, terá de ser integrada no serviço Ubisign.com.",
    "text2": "Nos últimos anos os sistemas distribuídos têm sofrido um crescimento exponencial. Estes sistemas, normalmente implementados na plataforma Java, são compostos por um vasto conjunto de componentes de middleware, os quais desempenham várias tarefas de comunicação e de coordenação. Esta tendência influencia a modelação e a arquitetura de novas aplicações cada vez mais complexas obrigando a um enorme esforço e a um custo elevado na avaliação do seu desempenho. A concorrência e a sua distribuição, bem como o facto de muitos problemas só se manifestarem pela grande escala em si, não permite que a sua avaliação seja feita com recurso a simples ferramentas que não tenham em conta estas características. Avaliação realista e controlada de aplicações distribuídas é ainda hoje muito difícil de alcançar, especialmente em cenários de larga escala. Modelos de simulação pura podem ser uma solução para este problema, mas criar modelos abstratos a partir de implementações reais nem sempre é possível ou mesmo desejável, sobretudo na fase de desenvolvimento na qual ainda podem não existir todos os componentes ou a sua funcionalidade estar incompleta. Para colmatar esta falha, nesta dissertação é apresentada o Minha, uma plataforma que permite uma avaliação realista das aplicações através da combinação de modelos abstratos de simulação e implementações reais num ambiente centralizado. Esta plataforma combina a execução de código real sob análise, com modelos de simulação do ambiente envolvente, isto é, da rede e da aplicação. Este sistema permite reproduzir as condições de um sistema em grande escala e através da manipulação de bytecode Java, suporta componentes de middleware inalterados. A utilidade deste sistema é demonstrada aplicando-o ao WS4D, uma pilha que cumpre a especificação Device Profile for Web Services.",
    "similarity": 0.3289625700966151
  },
  {
    "text1": "O uso de painéis de digital signage ou displays (ou, em português, painéis digitais) está cada vez mais a ser implementado nos locais públicos e semipúblicos, uma vez que é uma forma actual de apresentar, de um modo dinâmico, informação, publicidade e conteúdos de entretenimento. Desta forma, as pessoas expostas a esta tecnologia passam a ter um acesso mais rápido e actualizado à informação sobre tudo o que as rodeia.Os ecrãs dos displays têm evoluído no sentido da melhoria da sua qualidade. Além disso, a descida dos preços torna esta tecnologia bastante mais acessível para ser aplicada em vários sectores, nomeadamente na indústria, no comércio, na educação, na saúde, etc., substituindo os meios tradicionais publicitários e informativos, baseados em papel.Uma rede de painéis digitais permite a actualização dos seus conteúdos de forma remota, com base num servidor central que controla toda a informação apresentada na rede, enquanto que nos meios tradicionais a actualização de conteúdos é muito mais cara, demorada e de difícil gestão.Como as pessoas olham pouco tempo para os painéis digitais, exige-se um esforço muito grande no estudo do local onde estes são instalados e na modelação dos conteúdos a serem apresentados, de forma a que o ambiente se torne o mais atractivo possível e, deste modo, se promova a atenção de quem passa pelos painéis. Também existem displays que usam tecnologias mais sofisticadas, permitindo a adaptação automática dos conteúdos apresentados em função do contexto envolvente, fazendo com que a informação seja mais direccionada ao público, sem a necessidade de controlo humano.Dado o crescente sucesso, à escala planetária, da digital signage, têm surgindo cada vez mais soluções de software aplicadas nesta vertente. Por conseguinte, o tema principal desta dissertação incidirá sobre o desenvolvimento de uma aplicação web para painéis de digital signage, sugerida pela empresa Ubisign, com o objectivo de permitir configurar visualizações com informação sobre eventos provenientes do Google Calendar.Uma vez que a promoção de eventos geralmente exige custos elevados de design e produção, é necessário minimizá-los no contexto das redes de digital signage. Para tal, existem determinadas ferramentas on-line de gestão de eventos, como o Google Calendar, com a função de permitir que o utilizador especifique eventos que vão ocorrer e efectue o seu escalonamento com base em calendários. Do ponto de vista de um developer, estas ferramentas evitam a necessidade de implementar outros softwares de gestão de eventos, permitindo também desenvolver outras aplicações que comuniquem com estas ferramentas, através de APIs apropriadas e bem documentadas.Para tirar partido disto, a aplicação a desenvolver terá de recorrer à API Google Calendar para disponibilizar, de forma personalizada, informação sobre eventos que estejam planeados para um dado sítio com uma rede de digital signage instalada e, para esse efeito, terá de ser integrada no serviço Ubisign.com.",
    "text2": "A capacidade de agregar dados é uma característica fundamental na conceção de sistemas de informação escaláveis, que permite a determinação de propriedades globais importantes de forma descentralizada, para a coordenação de aplicações distribuídas, ou para fins de monitorização.Agregados simples como mínimos/ máximos, contagens, somas e médias foram já extensivamente estudados no passado. No entanto, este tipo de agregados pode não ser suficiente para caracterizar distribuições de dados enviesadas e na presença de valores atípicos (outliers), tornando-se então relevante a determinação de uma estimativa dos valores na rede (e.g. histograma, função de distribuição cumulativa), dado que métricas como médias ou desvio padrão escondem em muitos casos alterações na propriedade monitorizada que são relevantes para decisão de controlo.São ainda relativamente escassos os trabalhos que se focam sobre a agregação de métricas mais expressivas. Uma proposta recente nesse domínio [SNSP10] refere atingir uma precisão nas estimativas superior à atingida em abordagens anteriores. Trata-se de um algoritmo para a determinação de funções cumulativas de distribuições.Apesar do contributo, essa proposta mostra limitações na tolerância a faltas e no suporte à monitorização contínua de propriedades, dado que para acompanhar alterações dos valores amostrados, a estratégia usada exige que o protocolo seja reiniciado periodicamente. Para além disso, os pressupostos dessa abordagem não admitem a perda de mensagens nem a sua duplicação.Assim, e tomando como ponto de partida o actual estado da arte, é apresentado nesta tese um algoritmo distribuído para a determinação de funções cumulativas de probabilidade em redes de larga escala. As suas principais vantagens são a imunidade à perda de mensagens, a velocidade de convergência e a precisão que se obtém na aproximação à distribuição original. É simultaneamente adaptável a alterações no valor amostrado e resiliente a dinamismo no número de nodos na rede. Usa também um mecanismo de quiesciência dos nodos assim que a variação local da estimativa é inferior a um determinado limiar. Nessa circunstância, o nodo deixa de transmitir. Isto leva à diminuição do número de mensagens trocadas entre nodos.As distribuições determinadas em todos os nodos permitem a tomada de decisões que tirem partido do facto de se estar a agregar uma função probabilística. Assim o nodo pode excluir outliers ou observar determinados quantis da propriedade. Para além disso, cada nodo da rede possui uma estimativa global sobre o estado geral da propriedade distribuída, o que lhe permite também a tomada de decisões com base em conhecimento local.São apresentados nesta tese resultados de simulação que confirmam a validade da abordagem seguida. É também apresentada uma revisão da literatura relacionada cujo âmbito incluiu as técnicas mais representativas da agregação de dados para métricas escalares e as técnicas de agregação de dados para métricas complexas.",
    "similarity": 0.3316938044726708
  },
  {
    "text1": "As arquiteturas monolíticas estão, em grande parte, presentes na maioria das plataformas de e-commerce, o queleva a um processo de modificação mais complicado e entregas demoradas ao cliente, uma vez que não estápreparada para trabalho em paralelo.A arquitetura de microsserviços veio proporcionar outra forma de desenvolvimento destas plataformas, permitindoo trabalho em simultâneo por diferentes equipas, produzindo novas entregas para o cliente de forma maisacelerada e segura. Todavia, esta possui alguns desafios e complexidades, o que leva muitas vezes à escolha deuma arquitetura monolítica para o desenvolvimento da aplicação.A maioria das aplicações não são imutáveis, pois mesmo estando entregues ao cliente são sujeitas amodificações. Esta necessidade de modificar a aplicação leva a preocupações acerca da rapidez com que asnovas funcionalidades são entregues ao cliente. É preciso tomar decisões no início do desenvolvimento sobreque arquitetura seguir, de modo a tomar a decisão mais vantajosa. No caso de aplicações monolíticas a mudançapara uma arquitetura de microsserviços facilita este aspeto, bem como muitos outros. Contudo, esta separaçãopode-se tornar quase impossível se o monolítico não for bem preparado para uma eventual futura mudança.Uma das maiores dificuldades numa migração de um monolítico para microsserviços, relaciona-se coma definição do que deve ser cada microsserviço e na comunicação entre estes. A migração deve partir daidentificação de partes do código que possam ser isoladas sem ter muito impacto no resto do código. Com odesenho de um diagrama de packages é possível obter uma visão sobre a estrutura do sistema, percebendo quecomponentes são mais fáceis e mais difíceis de extrair. Deve-se começar por extrair aqueles que contém menosdependências, adquirindo as vantagens de uma migração incremental que permite que sejam reduzidos os errosefetuados, porém, pode haver situações em que se queira extrair um componente com mais dependências.É necessário compreender o porquê da migração para uma arquitetura de microsserviços. Esta decisãonão deve ser tomada apenas porque a arquitetura de microsserviços está em voga, mas sim por razõesfundamentadas. Dentro destas razões encontra-se a rapidez com que as mudanças são efetuadas e colocadasem produção, pois é mais fácil realizar modificações e voltar a instalar os microsserviços sem que toda a aplicaçãotenha que reiniciar. Isto permite uma melhor estruturação da equipa, possibilitando que várias equipas possamtrabalhar em simultâneo para a mesma aplicação, não prejudicando em nada outros microsserviço. Outra razãoé a necessidade de escalar os microsserviços independentemente, providenciando maior robustez, pois a falhade um serviço não leva à falha de toda a aplicação ou então pela escolha de tecnologia, podendo-se implementaros microsserviço com a tecnologia que seja mais adequada e eficiente.",
    "text2": "O desenvolvimento de aplicações e serviços baseados em web está a crescer todos os diascada vez mais. As facilidades que nos oferecem, entre elas a alta-disponibilidade e acessibilidade,levou a que as grandes empresas de tecnologia investissem neste tipo de tecnologias,surgindo assim aplicações como o Evernote, o Google Photos, o Dropbox, o Slack, entre outras.Associadas à utilização constante destas aplicações e serviços pelos seus clientes estãoas enormes quantidade de dados criados, bem como os dados gerados a partir destes. Coma necessidade de armazenar e processar esses de forma rápida e eficiente, estes serviçostem vindo a optar pela utilização de serviços de computação em nuvem de terceiros.Existem vantagens claras associadas à migração de dados para estas plataformas, desdea redução de custos associados armazenamento, manutenção e compra de infraestruturas,até às conveniências oferecidas pela disponibilização ferramentas de monitorização econfiguração avançadas, entre muitas outras. Associado também à utilização desta plataformasde cloud computing estão também os problemas com a privacidade dos dados por elasarmazenadas. Apesar dos esforços, por parte dos fornecedores destes serviços, em negaro acesso a entidades não autorizadas, existem ameaças fora do seu controlo e temos vistomuitas vezes que o acesso a dados sensíveis por terceiros tem um risco elevado associado.Com vista a combater este aspeto existem hoje em dia soluções capazes de garantir a confidencialidadedos dados em bases de dados relacionais e não relacionais, através de técnicascriptográficas. Estas soluções estão usualmente associadas a arquiteturas específicas deforma a precaverem sempre esta questão de segurança dos dados em todos os momentos.Estas arquiteturas implicam um maior esforço computacional do lado do cliente, pois édesse lado que se encontra toda a lóogica da aplicacional e mecanismos de segurança.Esta dissertação oferece uma nova arquitetura web onde maior parte do trabalho aplicacionalé delegado para as infraestruturas de nuvem maximizando assim o desempenhoda aplicação, tirando para isso partido da arquitetura browser servidor característica destessistemas.",
    "similarity": 0.3011094465487026
  },
  {
    "text1": "The HTTP protocol is a stateless protocol, that means, each request made by the useris an independent request, there is no notion of state. So, to add it to the applicationswe need an additional tool to implement this notion of state. For this, cookies are used,allowing the websites to identify the authenticated users. A cookie is a file stored in thecustomer’s browser and sent together with HTTP requests, allowing the website to recognizethe customer and send a response corresponding to the request made.This dissertation aims to strengthen the protection of data associated with authenticationsessions through the identification and analysis of authentication cookies using machinelearning techniques. If web applications are vulnerable to malicious attacks, such as BrokenAuthentication or XSS (Cross-Site Scripting), attackers can gain access to the informationstored in the cookie. Using this information they can steal the user’s session, being able toauthenticate themselves in the web application to obtain access to data/services.Using machine learning techniques, we can identify within a set composed of severaltypes of cookies, which cookies are associated with authentication. The objective is therecognition of this type of cookies, since this is the one that needs greater security, takingcare in case the attacker even gaining access to this file, there is no possibility of decipheringthe information that puts the users session at risk.In addition to the classification of cookies, the detection and analysis of the encoding usedwill be carried out. The tool will then be integrated into the security testing software, BurpSuite, working as an extension in order to facilitate and reduce the time necessary for a QAanalyst to spend checking cookies.",
    "text2": "Nutrition is fundamental to human well-being and health, especially when applied topatients who need special health care. In these cases, it is crucial that each patient hasadequate nutrition to meet their needs, in order to accelerate their recovery process.Recommender systems make it possible to offer suggestions to users, adapted to theirpreferences and to previously obtained information about them. Food recommender systemsare recommender systems applied to nutrition and diet. They are usually implementedfeeding plans recommendation platforms based on food and the person using it.In this sense, the existing gap in the use of these recommendation systems applied tonutrition in health care is notorious. This is mainly due to the difficulty in associating thenutritional value of each food with the needs of patients.The main objective of this project is to fill the existing void, through the development andimplementation of a platform that will allow the planning of meals taking into account thenutritional plan of the food and the specific needs associated with the users of the Vila VerdeSocial Canteen.The use of machine learning algorithms will allow us to identify how the connectionbetween food and patient requirements can be made, making this task possible, which iscomplex due to the wide domain associated with it.This platform will be used for the generation of kitchen meal plans, which shall beproduced using the algorithms developed after a bibliographic study and an investigation ofthe existing work, in order to understand how they can be implemented and which are themost adequate to the nutritional recommendations system.",
    "similarity": 0.30104833317413315
  },
  {
    "text1": "In traffic environments, road signs have a key role to control, warn, and command or prohibitthe driver of certain actions. Traffic sign maintenance is essential to prevent negativeevents. In order for these traffic signs to play the role they were designed for, periodic onsiteinspections are essential and followed out to determine if signs are in good conditionand visible, both during the day and night. However, periodic inspections are time and costconsuming.Another issue is related to the drivers’ awareness to the traffic signs on the road. Manyfactors, both internal and external to the driver, may potentially contribute to him missing asign. Given the purpose of this dissertation, we will focus primarily on the external factorssuch as the sign being damaged or occluded, or distractions caused by the many gadgetsinside the vehicle. Due to all these extraneous influences, a traffic sign recognition systemmay help the driver to respect these signs and increase significantly their safety, as well asthe others around them.Some high-end vehicles already have such a warning system, at least for danger signs.However, drivers with these vehicles represent a small fraction of the total driving force.This dissertation aims at bringing such a system to a much broader audience.Smartphones are one of the most used devices by society today, mostly due to the manyfunctionalities they provide in day to day life and their relative accessible monetary value.The increased computational power and cameras’ quality improvement of these devicesover the years make them good candidates to support the access to this kind of technologyto all. In other words, smartphones of this day and age have the necessary resources to beused as instruments for sign recognition.Hence, we propose a dual purpose community based approach. On the one hand, eachdriver can use his mobile device to detect, recognize and geolocate traffic signs, contributingto the traffic sign central repository. Detection is performed using Cascade Classifiers,while a Convolutional Neural Network supports the recognition phase. The repository,based on the information received from the clients, can be used to provide sign statusreports and to enable more direct and timely inspection instead of relying on prescheduledglobal inspections. On the other hand, drivers would have access to the database of trafficsigns, therefore being able to receive real-time notifications regarding traffic signs such asspeed limit signs, school proximity, or road construction signs. Hence, allowing the systemto perform its function even if the recognition phase is not active when used in a lowcomputational power device.",
    "text2": "Both energy consumption analysis and energy-aware development have gained the attentionof both developers and researchers over the past years. The interest is more notoriousdue to the proliferation of mobile devices, where energy is a key concern.There is a gap identified in terms of tools and information to detect and identify anomalousenergy consumption in Android applications. A large part of the existing tools arebased on external hardware (costly solutions in terms of setup-time), through predictivemodels (requiring previous hardware calibration) or static code analysis methods. We couldnot identify so far a tool capable of monitor all relevant system resources and componentsthat an application uses and appoint its energy consumption, while being easily integratedwith the application and/or with its development environment. Due to the lack of a toolcapable of gathering all this information, a natural consequence is the lack of informationabout the energy consumption of applications and factors that can influence it.This dissertation aims to carry out a study on the energy consumption of applications andmobile devices in the Android platform, having developed in this scope the GreenSourceinfrastructure, a repository containing the source code, representative metadata and metricsrelatively to a large number of applications (and respective execution in physical devices).In order to gather the results, an auxiliary tool has been developed to automatize theprocess of testing and collect the respective results for each one of the applications. This toolis a software-based solution, allowing to obtain results in terms of consumption throughexecutions made directly on a physical device running the Android platform.The developed framework, the AnaDroid, has the capability to perform static and dynamicanalysis of an application, being able to monitor power consumption and usage ofresources for each application through tests execution. This is done following a whiteboxtesting approach, in order to test applications at source code level. It invokes calls tothe TrepnLib library at strategic locations of the application code (through instrumentationtechniques) to gain control over relevant portions of the source code, like methods and unittests. In this way the programmer can have results about the use, state and consumption ofresources such as energy, CPU, GPU, memory, sensor usage and complexity of developedtest cases.The information gathered through the use of the AnaDroid over a large set of applicationswas stored in GreenSource backend. With the collected results, we expect to be able tocharacterize and classify applications, as well the tests developed for it. It is intended thatthis will be made publicly available and serve as a reference for future works and studies.",
    "similarity": 0.30075429960740546
  },
  {
    "text1": "Hoje em dia, a tomada de decisões de forma rápida e eficaz é essencial nas organizações de saúde. Neste sentido, surgem os Sistemas de Apoio à Decisão, as plataformas de Business Intelligence e os Sistemas de Tratamento de Dados. De forma a apoiar a decisão no âmbito farmacêutico surgem plataformas de previsão, as quais pretendem auxiliar ao máximo a tomada de decisão por parte dos prestadores de saúde. No âmbito desta dissertação, foi realizado um projeto com o objetivo de extrair conhecimento de forma automatizada a partir de informações passadas e traduzi-las de forma a desenvolver um sistema de previsão de vendas para a área farmacêutica.Tradicionalmente, na área da previsão, é comum a utilização de modelos estatísticos, no entanto é interessante perceber se o Deep Learning consegue acompanhar os resultados obtidos através destes modelos. Para o efeito, foi elaborado um estudo comparativo entre modelos de previsibilidade, conseguidos através de modelos estatísticos e conexionistas. Para os primeiros fez-se uso de funções de modelação disponíveis em librarias da linguagem de programação R e no segundo foram aplicadas redes neuronais recorrentes, nomeadamente as Long Short Term Memory, através de bibliotecas disponíveis em Python para construção de um modelo deep learning. As metodologias desenvolvidas através dos diferentes modelos de previsibilidade foram aplicadas a três casos de estudo, cada um associado a um conjunto de dados diferente. Assim, tornou-se possível analisar o comportamento dos modelos desenvolvidos quando aplicados a conjuntos de dados distintos.Por último, foram apresentados os resultados obtidos para os três casos de estudo, referentes à aplicação de ambas as práticas, e feita uma comparação das mesmas. Foi verificado o sucesso da utilização de algoritmos de Deep Learning na área da previsão, obtendo melhores resultados que aqueles conseguidos através dos tradicionais modelos de previsão estatísticos. Este trabalho permitiu perceber o potencial que o deep learning apresenta, sendo no entanto necessário mais trabalho futuro para dar enfâse a esta afirmação.",
    "text2": "O controlo e a prevenção de infeções nosocomiais são essenciais para aredução de custos, bem como para a melhoria dos cuidados prestados numainstituição de saúde. Por outro lado, o tratamento de dados que permitamcompreender, caracterizar e monitorizar as infeções possibilita um controloe uma prevenção mais eficaz das mesmas. Sendo um método automatizadoe eficiente para o tratamento de dados, a tecnologia de Business Intelligencepermite a extração de informação importante para gerar conhecimento quepode auxiliar o processo de tomada de decisão dos profissionais de saúde.O principal objetivo deste trabalho é o desenvolvimento e implementaçãode uma plataforma de Business Intelligence que permita o estudo da incidênciade infeção nosocomial nas Unidades de Medicina do Centro Hospitalardo Porto. Este estudo é feito através da apresentação de um conjunto deindicadores clínicos (informações importantes extraídas dos dados referentesa infeções nosocomiais) que ajudam a analisar e caracterizar estas infeções.Por conseguinte, depois de identificados os indicadores relevantes, torna-sepertinente desenvolver um sistema que permita tratar os dados, extrair osindicadores destes e apresentá-los, de forma atrativa, na plataforma. Porsua vez, a plataforma facilita a análise das informações que disponibiliza,apoiando a tomada de decisões, nomeadamente através da identificação dosprincipais fatores de risco. Assim, o sistema atua como um Sistema de Apoioà Decisão Clínica, podendo auxiliar no controlo e prevenção destas infeções.Pretende-se ainda estudar a aplicabilidade da tecnologia de Data Miningna criação de modelos de classificação capazes de prever a ocorrência deinfeções nosocomiais, na presença de determinados fatores de risco.O conhecimento obtido com a análise dos indicadores e as previsões efetuadaspode possibilitar a diminuição da incidência de infeção nosocomiale, consequentemente, a redução dos custos associados à sua ocorrência, bemcomo o aumento da segurança e do bem-estar dos doentes, ao permitir a tomadade decisões mais fundamentadas. A aplicação de Business Intelligencena área da saúde contribui para melhorar não só o fluxo de trabalho diárionas unidades de saúde, como também a qualidade dos cuidados prestados.",
    "similarity": 0.3206173328056985
  },
  {
    "text1": "One of the most accurate personality assessments available is the Goldberg’s ’The BigFive Personality Test’, which measures the five OCEAN dimensions: Openness, Conscientiousness, Extraversion, Agreeableness and Neuroticism. This assessment is performed bypresenting a total of forty adjectives requesting the subject to rate each word using a scaleof 1 to 9 indicating whether it accurately (9) describes herself or not (1). Nonetheless, scientific research has shown that this test may, accurately, suggest personality traits such asaggressive reactions, work performance, fitness on specific expertise areas and also mental illnesses. However, one big disadvantage of this test, it simply takes too much timeto perform, which can result on undesirable measurements. Indeed, several developmentshave been done in order to reduce the required effort to perform this test, an example isThe Mini Marker Test by Saucier. This study aims to propose a viable shorter alternative tothis by applying machine learning techniques, i.e., although measurement precision may bereduced, is it possible to build a much shorter version losing as little precision as possibleby just requiring the subject to select the adjectives that characterise him the most?For this study, it was developed a platform to collect data, requesting both the subject torate each adjective but also to select those he most identifies with. With this, the availabledata contains both ratings and the selections of the words that most characterise the subject.Three different machine learning architectures are developed and tested. Both regressionand classification approaches are considered. The main input for these architectures arethe words selected by each evaluated subject. Data collected by this work showed to beinsufficient, requiring the use of data augmentation techniques. For this, different versionsare proposed, one including the use of frequent itemset mining techniques. The proposedmachine learning architectures shown a very high precision, with an RMSE of around 7%.The results show the proposed solutions to be able to perform a shorter version of thistest with a minimum precision loss. It was also possible to define a list of common setsof selected words. Further research can be performed mainly on two different streamlines,i.e., strength the data collection process and develop an even shorter version of this test.",
    "text2": "The Energy-Split tool receives as input pieces of a very large molecular system and computesall intra and inter-molecular energies, separately calculating the energies of each fragmentand then the total energy of the molecule. It takes into account the connectivity informationamong atoms in a molecule to compute (i) the energy of all terms involving atoms covalentlybonded, namely bonds, angles, dihedral angles, and improper angles, and (ii) Coulomband the Van der Waals energies, that are independent of the atom’s connections, whichhave to be computed for every atom in the system. The required operations to obtain thetotal energy of a large molecule are computationally intensive, which require an efficienthigh-performance computing approach to obtain results in an acceptable time slot.The original Energy-Split Tcl code was thoroughly analyzed to be ported to a parallel andmore efficient C++ version. New data structures were defined with data locality features, totake advantage of the advanced features present in current laptop or server systems. Theseinclude the vector extensions to the scalar processors, an efficient on-chip memory hierarchy,and the inherent parallelism in multicore devices. To improve the Energy-Split’s sequentialvariant a parallel version was developed using auxiliary libraries. Both implementationswere tested on different multicore devices and optimized to take the most advantage of thefeatures in high performance computing.Significant results by applying professional performance engineering approaches, namely(i) by identifying the data values that can be represented as Boolean variables (such asvariables used in auxiliar data structures on the traversal algorithm that computes theEuclidean distance between atoms), leading to significant performance improvements due tothe reduced memory bottleneck (over 10 times faster), and (ii) using an adequate compressformat (CSR) to represent and operate on sparse matrices (namely matrices with Euclideandistances between atoms pairs, since all distances further the cut-off distance (user defined)are considered as zero, and these are the majority of values).After the first code optimizations, the performance of the sequential version was improvedby around 100 times when compared to the original version on a dual-socket server. Theparallel version improved up to 24 times, depending on the molecules tested, on the sameserver. The overall picture shows that the Energy-Split code is highly scalable, obtainingbetter results with larger molecule files, even when the atom’s arrangement influences thealgorithm’s performance.",
    "similarity": 0.30141237789765274
  },
  {
    "text1": "As urgências hospitalares têm por objetivo responder a emergências que surjam, seja dentro ou fora de horas e, por ser um serviço onde qualquer tipo de caso pode surgir e, sendo cada caso um caso, é extremamente importante garantir a obtenção do melhor atendimento.Isto aplica-se ainda mais quando se refere à Ala de Pediatria. Estes por receberem crianças de todo o tipo de idades têm de conseguir responder às diferentes necessidades e dificuldades, mas grande parte desse trabalho passa pelos pais/encarregados de educação que têm a função de informar os enfermeiros, ou médicos, dos pré-cuidados que tenham sido administrados, ou sintomas anteriores.Deste modo, esta dissertação apresenta a problemática, razões e solução encontrada, ao definir objetivos e ao estabelecer metas para lá chegar. É apresentado um breve estado de arte com as pesquisas e revisão de literatura mais relevantes na área do problema e identificação de soluções comuns. Ainda são apresentadas as metodologias de investigação que serão utilizadas, são ela Design Science Research e Proof of Concept, e as tecnologias a ser utilizadas, que passam por React para o frontend, Node JS para o backend e MySQL para a Base de Dados.Para terminar é demonstrado os artefactos criados, desde o levantamento de requisitos, passando pela arquitetura de software e terminando no Desenho e Desenvolvimento, todos estes foram ao longo da sua execução avaliados e feitos teste de usabilidade e viabilidade.",
    "text2": "A UN1Qnx, S.A., soluções de autenticidade ciber-físicas, é uma empresa sediada em Braga,que desenvolve e comercializa sistemas físicos, eletrónicos e cibernéticos de validação eautenticação de produtos, sendo o objetivo a proteção da marca e o combate à contrafação.Neste momento, a empresa possui um serviço de autenticação de produtos localizado numamáquina virtual na cloud, mais especificamente na Microsoft Azure. Contudo, a utilizaçãodeste serviço é intermitente e passa por períodos de inatividade. Porém, quando utilizado,cada execução do serviço é computacionalmente custosa, o que obriga à utilização de umamáquina virtual que tem em conta o caso de máxima utilização. Assim, nos intervalos entreutilizações os custos acumulam-se sem aproveitar os recursos alocados. Deste modo, estatese passa por otimizar a utilização dos recursos na cloud, tendo em vista tirar proveito daescalabilidade e elasticidade das tecnologias de computação na nuvem, bem como melhorara latência dos pedidos.A otimização dos recursos passa por comparar diferentes serviços de diferentes forne cedores e selecionar o que se apresenta como a melhor opção. A fim de realizar estascomparações, fez-se antes uma investigação baseada na metodologia Design Science Research.Primeiramente, explorou-se o ambiente da solução (computação na nuvem) e o ambientedo problema, isto é, qual a situação atual da empresa no que diz respeito ao funcionamentodo serviço de validação e dos recursos afetos ao mesmo.Em segundo lugar, fez-se uma averiguação sobre o estado da arte das tecnologias usadas,das tecnologias que poderiam vir a ser usadas e de outras empresas da mesma área, sobrequais os seus produtos e o seu modo de funcionamento. Por último, investigaram-se métodosde seleção e comparação entre várias opções.Em terceiro lugar, realizou-se a parte mais trabalhosa e demorada: o desenvolvimentoprático. Nesta fase realizaram-se testes de performance, a colocação do serviço num dockercontainer e a utilização de kubernetes. Ainda nesta última parte, houve vária experimentaçãocom diversas arquiteturas. Por fim, o sistema estabilizou numa arquitetura assíncrona, quefez reduzir os custos e, permitiu com que o serviço se adequasse melhor à quantidade detrabalho a processar.",
    "similarity": 0.3101869806094183
  },
  {
    "text1": "Nos últimos anos os sistemas distribuídos têm sofrido um crescimento exponencial. Estes sistemas, normalmente implementados na plataforma Java, são compostos por um vasto conjunto de componentes de middleware, os quais desempenham várias tarefas de comunicação e de coordenação. Esta tendência influencia a modelação e a arquitetura de novas aplicações cada vez mais complexas obrigando a um enorme esforço e a um custo elevado na avaliação do seu desempenho. A concorrência e a sua distribuição, bem como o facto de muitos problemas só se manifestarem pela grande escala em si, não permite que a sua avaliação seja feita com recurso a simples ferramentas que não tenham em conta estas características. Avaliação realista e controlada de aplicações distribuídas é ainda hoje muito difícil de alcançar, especialmente em cenários de larga escala. Modelos de simulação pura podem ser uma solução para este problema, mas criar modelos abstratos a partir de implementações reais nem sempre é possível ou mesmo desejável, sobretudo na fase de desenvolvimento na qual ainda podem não existir todos os componentes ou a sua funcionalidade estar incompleta. Para colmatar esta falha, nesta dissertação é apresentada o Minha, uma plataforma que permite uma avaliação realista das aplicações através da combinação de modelos abstratos de simulação e implementações reais num ambiente centralizado. Esta plataforma combina a execução de código real sob análise, com modelos de simulação do ambiente envolvente, isto é, da rede e da aplicação. Este sistema permite reproduzir as condições de um sistema em grande escala e através da manipulação de bytecode Java, suporta componentes de middleware inalterados. A utilidade deste sistema é demonstrada aplicando-o ao WS4D, uma pilha que cumpre a especificação Device Profile for Web Services.",
    "text2": "A capacidade de agregar dados é uma característica fundamental na conceção de sistemas de informação escaláveis, que permite a determinação de propriedades globais importantes de forma descentralizada, para a coordenação de aplicações distribuídas, ou para fins de monitorização.Agregados simples como mínimos/ máximos, contagens, somas e médias foram já extensivamente estudados no passado. No entanto, este tipo de agregados pode não ser suficiente para caracterizar distribuições de dados enviesadas e na presença de valores atípicos (outliers), tornando-se então relevante a determinação de uma estimativa dos valores na rede (e.g. histograma, função de distribuição cumulativa), dado que métricas como médias ou desvio padrão escondem em muitos casos alterações na propriedade monitorizada que são relevantes para decisão de controlo.São ainda relativamente escassos os trabalhos que se focam sobre a agregação de métricas mais expressivas. Uma proposta recente nesse domínio [SNSP10] refere atingir uma precisão nas estimativas superior à atingida em abordagens anteriores. Trata-se de um algoritmo para a determinação de funções cumulativas de distribuições.Apesar do contributo, essa proposta mostra limitações na tolerância a faltas e no suporte à monitorização contínua de propriedades, dado que para acompanhar alterações dos valores amostrados, a estratégia usada exige que o protocolo seja reiniciado periodicamente. Para além disso, os pressupostos dessa abordagem não admitem a perda de mensagens nem a sua duplicação.Assim, e tomando como ponto de partida o actual estado da arte, é apresentado nesta tese um algoritmo distribuído para a determinação de funções cumulativas de probabilidade em redes de larga escala. As suas principais vantagens são a imunidade à perda de mensagens, a velocidade de convergência e a precisão que se obtém na aproximação à distribuição original. É simultaneamente adaptável a alterações no valor amostrado e resiliente a dinamismo no número de nodos na rede. Usa também um mecanismo de quiesciência dos nodos assim que a variação local da estimativa é inferior a um determinado limiar. Nessa circunstância, o nodo deixa de transmitir. Isto leva à diminuição do número de mensagens trocadas entre nodos.As distribuições determinadas em todos os nodos permitem a tomada de decisões que tirem partido do facto de se estar a agregar uma função probabilística. Assim o nodo pode excluir outliers ou observar determinados quantis da propriedade. Para além disso, cada nodo da rede possui uma estimativa global sobre o estado geral da propriedade distribuída, o que lhe permite também a tomada de decisões com base em conhecimento local.São apresentados nesta tese resultados de simulação que confirmam a validade da abordagem seguida. É também apresentada uma revisão da literatura relacionada cujo âmbito incluiu as técnicas mais representativas da agregação de dados para métricas escalares e as técnicas de agregação de dados para métricas complexas.",
    "similarity": 0.3169052735133456
  },
  {
    "text1": "On a business context, it is responsibility of the Software Product Support Team analyze and solve, if necessary, problems that may arise on software products. Sometimes, the reported problems are not a real defect, i.e., sometimes the client does not have a full understanding about all features of the software product. The team must evaluate and analyze all the Problem Reports that arrive every day. As products are spread across different customers, it is normal to have Problem Reports that are very similar to others that have already been solved for other clients and/or by another member of the Support Team. This dissertation proposes the development of a system that is able to analyze a Problem Report and then provide past problems that are similar to the one being analyzed. An artificial intelligence technique, named Case-Based Reasoning, will be used to achieve such goals. Existent Case-Based Reasoning systems are neither complete nor adaptable to specific domains since the effort to adapt either the reasoning process or the knowledge representation mechanism, to a new domain, is too high. To address such drawbacks, a generic reasoning component will be designed and developed. This dissertation introduces a new approach to the typical Case-Based Reasoning cycle where is possible to handle default, unknown and incomplete data.",
    "text2": "Typically, testing an interactive system involves manually testing their possible interactions. Since this is a manual process, it becomes very costly to check all possible interactions. In safety critical interactive systems this task is essential. One way to overcome this problem is to use tools for systematic analysis. IVY Workbench is one of these tools. We plan to apply it to perform verification of Safety Critical Interactive Systems. The objectives for this dissertation are: development of a set of models of safety critical interactive systems; verification of relevant properties of the models; critical assessment of the modelling process and suggestion of improvements to the tool and language.",
    "similarity": 0.30401890353413896
  },
  {
    "text1": "On a business context, it is responsibility of the Software Product Support Team analyze and solve, if necessary, problems that may arise on software products. Sometimes, the reported problems are not a real defect, i.e., sometimes the client does not have a full understanding about all features of the software product. The team must evaluate and analyze all the Problem Reports that arrive every day. As products are spread across different customers, it is normal to have Problem Reports that are very similar to others that have already been solved for other clients and/or by another member of the Support Team. This dissertation proposes the development of a system that is able to analyze a Problem Report and then provide past problems that are similar to the one being analyzed. An artificial intelligence technique, named Case-Based Reasoning, will be used to achieve such goals. Existent Case-Based Reasoning systems are neither complete nor adaptable to specific domains since the effort to adapt either the reasoning process or the knowledge representation mechanism, to a new domain, is too high. To address such drawbacks, a generic reasoning component will be designed and developed. This dissertation introduces a new approach to the typical Case-Based Reasoning cycle where is possible to handle default, unknown and incomplete data.",
    "text2": "Every program starts from a model, an abstraction, which is iteratively re ned until we reach the nal result, the implementation. However, at the end, one must ask: does the nal program resemblein anyway the original model? Was the original idea correct to begin with? Formal methodsguarantee that those questions are answered positively, resorting to mathematical techniques. Inparticular, in this thesis we are interested on the second factor: veri cation of formal models.A trend of formal methods defends that they should be lightweight, resulting in a reducedcomplexity of the speci cation, and automated analysis. Alloy was proposed as a solution for thisproblem. In Alloy, the structures are described using a simple mathematical notation: relationallogic. A tool for model checking, automatic veri cation within a given scope, is also provided.However, sometimes model checking is not enough and the need arises to perform unboundedveri cations. The only way to do this is to mathematically prove that the speci cations are correct.As such, there is the need to nd a mathematical logic expressive enough to be able to representthe speci cations, while still being su ciently understandable.We see the point-free style, a style where there are no variables or quanti cations, as a kindof Laplace transform, where complex problems are made simple. Being Alloy completely relational,we believe that a point-free relational logic is the natural framework to reason about Alloyspeci cations.Our goal is to present a translation from Alloy speci cations to a point-free relational calculus,which can then be mathematically proven, either resorting to proof assistants or to manual proving.Since our motivation for the use of point-free is simplicity, we will focus on obtaining expressionsthat are simple enough for manipulation and proofs about them.",
    "similarity": 0.3259845838853427
  },
  {
    "text1": "Sendo certo que o recurso à tecnologia no ensino é cada vez mais notório, a utilização de sistemas informáticos de tutoria continua aquém do seu potencial, ainda que seja um tema abordado há já algumas décadas. Assim, surgiu a iniciativa Leonardo e o respetivo desenvolvimento de uma ferramenta computacional para sistemas de avaliação de conhecimento, com vista a ser aplicada, pelo menos, no suporte de processos de avaliação de alunos, na Universidade do Minho. De entre os módulos que caracterizam estes agentes de software, no contexto desta dissertação, destacam se a base de conhecimento, o mecanismo de raciocínio e o modelo do estudante. Dado que o esforço maior recai em habilitar os tutores artificiais à adaptação, em tempo real, da avaliação ao nível de conhecimento atual dos alunos, surge a necessidade de desenvolvimento de um mecanismo de raciocínio, que seja capaz de determinar, criteriosamente, o que deve ser apresentado de seguida num dado momento avaliativo. O trabalho desta dissertação focou-se na conceção e implementação de um sistema de avaliação baseado em conhecimento para o sistema Leonardo, com a capacidade de ajustar de forma dinâmica, à medida da perícia e conhecimento dos estudantes alvos do processo de avaliação, o seu comportamento, acompanhando de perto a evolução do processo de aprendizagem dos estudantes. Essencialmente, neste trabalho implementou-se a “máquina” de raciocínio para o sistema Leonardo poder sustentar de forma efetiva a avaliação de estudantes ao longo do tempo, numa ou mais áreas do conhecimento.",
    "text2": "Um sistema de raciocínio pode ser caracterizado como um agregado de componentes de software que realizam em conjunto processos de tomada de decisão complexos. Este tipo de sistema está bastante ligado a umadas áreas de trabalho mais mediáticas atualmente, a Inteligência Artificial. Algumas iniciativas de desenvolvimento dentro desta área tendem a incorporar este tipo de ferramenta em sistemas de avaliação, mais concretamente em tutores inteligentes, com o intuito de ajudar os estudantes no seu processo de aprendizagem. Nesta dissertação apresenta-se a conceção e a implementação de um conjunto de mecanismos de raciocínio baseado em casos e baseado em regras. Estes dois tipos de mecanismos foram idealizados para integrar o atual módulo de avaliação do sistema Leonardo, uma plataforma que complementa o estudo presencial dos alunos da Universidade do Minho. Os novos mecanismos, em particular os de raciocínio baseados em casos, complementam o processo de avaliação do sistema Leonardo aumentando as suas capacidades de raciocínio aquando da realização dos processos de avaliação estendendo as sessões de Quizz. Quanto aos mecanismos baseados em regras, estes representam uma importante camada entre o módulo de avaliação e a interface do tutor do sistema, visto que não permite apresentar questões de escolha múltipla na interface que não estejam de acordo com critérios estabelecidos por peritos. Nesta dissertação veremos como tais mecanismos foram fundamentados, desenvolvidos e integrados no sistema Leonardo.",
    "similarity": 0.3212435694499407
  },
  {
    "text1": "A deteção de danos na estrutura externa de veículos representa um desafio para os fornecedoresde serviços de viaturas de aluguer, especialmente os serviços mais recentes de mobilidade em que ainspeção de danos não é realizada no final de cada aluguer. À medida que estes serviços se tornam maispopulares e que mais pessoas deixam de ter necessidade de possuir um carro pessoal, espera-se queas empresas procurem formas de facilitar este tipo de inspeção de danos. Como tal, o objetivo principaldesta dissertação é desenvolver uma solução que os fabricantes de automóveis poderiam potencialmenteadotar. Esta solução envolve a criação de um algoritmo para detetar riscos em carros usando dados deáudio obtidos a partir de microfones.Este estudo explora a utilização de Aprendizagem Profunda na análise de imagens, por exemploespectrogramas, que são representativas de eventos de riscos. Para tal serão estudados e implementadosmétodos de transformação do sinal de áudio em imagens referentes a uma representação espectral doáudio e avaliar a capacidade de um algoritmo de Aprendizagem Profunda aprender a identificar este tipode eventos. O algoritmo é treinado tendo em conta a enorme variedade de sons que podem ser captadospelo microfone, considerando os infinitos ambientes possíveis a que um carro pode estar sujeito, devidoa uma condução diária.",
    "text2": "No presente trabalho foi desenvolvida uma solução de apoio a pessoas idosas, doentesou com limitações físicas, baseada em técnicas de aprendizagem automática e visão porcomputador. Os modelos de aprendizagem profunda utilizados resolvem problemas declassificação de imagens. Para desenvolver a solução proposta foi utilizada a linguagemPython e as bibliotecas TensorFlow, MediaPipe e OpenCV. Antes de treinar os modelos deaprendizagem automática, foram aplicadas técnicas de pré processamento às imagens,para as preparar para os modelos classificadores. A solução final desenvolvida combinaduas tarefas de classificação diferentes: a estimação da pose humana e o reconhecimentode expressões faciais. Para estimar a pose humana, primeiro utilizou-se um algoritmoque identifica a posição das articulações do corpo, sendo estas posições posteriormenteclassificadas com uma rede neuronal convolucional em três classes, queda, sentado e empé/a andar. Para efetuar o reconhecimento de expressões faciais utilizaram-se dois tiposde dados, os atributos de cor dos pixeis das imagens e os pontos de referência das facespreviamente identificadas. Estes dados foram depois classificados por uma rede neuronalhíbrida, que inclui uma rede completamente ligada a uma rede convolucional. A soluçãofinal proposta combina estes dois modelos, o que permite a partir de uma imagem de umapessoa, gerar um aviso se o modelo de estimação da pose detetar uma queda ou quando omodelo de reconhecimento de expressões faciais identificar uma expressão de dor. O modelode estimação da pose identificou a classe queda com uma precisão de 97%, um recall de 98%e uma acurácia de 97%. A expressão de dor foi identificada pelo modelo de reconhecimentode expressões faciais com uma precisão de 82%, um recall de 86% e uma acurácia de 92%.O maior desafio no reconhecimento da expressão foi a deteção da face nas imagens.",
    "similarity": 0.31071704282276014
  },
  {
    "text1": "The Energy-Split tool receives as input pieces of a very large molecular system and computesall intra and inter-molecular energies, separately calculating the energies of each fragmentand then the total energy of the molecule. It takes into account the connectivity informationamong atoms in a molecule to compute (i) the energy of all terms involving atoms covalentlybonded, namely bonds, angles, dihedral angles, and improper angles, and (ii) Coulomband the Van der Waals energies, that are independent of the atom’s connections, whichhave to be computed for every atom in the system. The required operations to obtain thetotal energy of a large molecule are computationally intensive, which require an efficienthigh-performance computing approach to obtain results in an acceptable time slot.The original Energy-Split Tcl code was thoroughly analyzed to be ported to a parallel andmore efficient C++ version. New data structures were defined with data locality features, totake advantage of the advanced features present in current laptop or server systems. Theseinclude the vector extensions to the scalar processors, an efficient on-chip memory hierarchy,and the inherent parallelism in multicore devices. To improve the Energy-Split’s sequentialvariant a parallel version was developed using auxiliary libraries. Both implementationswere tested on different multicore devices and optimized to take the most advantage of thefeatures in high performance computing.Significant results by applying professional performance engineering approaches, namely(i) by identifying the data values that can be represented as Boolean variables (such asvariables used in auxiliar data structures on the traversal algorithm that computes theEuclidean distance between atoms), leading to significant performance improvements due tothe reduced memory bottleneck (over 10 times faster), and (ii) using an adequate compressformat (CSR) to represent and operate on sparse matrices (namely matrices with Euclideandistances between atoms pairs, since all distances further the cut-off distance (user defined)are considered as zero, and these are the majority of values).After the first code optimizations, the performance of the sequential version was improvedby around 100 times when compared to the original version on a dual-socket server. Theparallel version improved up to 24 times, depending on the molecules tested, on the sameserver. The overall picture shows that the Energy-Split code is highly scalable, obtainingbetter results with larger molecule files, even when the atom’s arrangement influences thealgorithm’s performance.",
    "text2": "The 2D convection-diffusion is a well-known problem in scientific simulation that often usesa direct method to solve a system of N linear equations, which requires N3 operations.This problem can be solved using a more efficient computational method, known as thealternating direction implicit (ADI). It solves a system of N linear equations in 2N times withN operations each, implemented in two steps, one to solve row by row, the other column bycolumn. Each N operation is fully independent in each step, which opens an opportunity toan embarrassingly parallel solution. This method also explores the way matrices are stored incomputer memory, either in row-major or column-major, by splitting each iteration in two.The major bottleneck of this method is solving the system of linear equations. Thesesystems of linear equations can be described as tridiagonal matrices since the elements arealways stored on the three main diagonals of the matrices. Algorithms tailored for tridiagonalmatrices, can significantly improve the performance. These can be sequential (i.e. the Thomasalgorithm) or parallel (i.e. the cyclic reduction CR, and the parallel cyclic reduction PCR).Current vector extensions in conventional scalar processing units, such as x86-64 andARM devices, require the vector elements to be in contiguous memory locations to avoidperformance penalties. To overcome these limitations in dot products several approachesare proposed and evaluated in this work, both in general-purpose processing units and inspecific accelerators, namely NVidia GPUs.Profiling the code execution on a server based on x86-64 devices showed that the ADImethod needs a combination of CPU computation power and memory transfer speed. Thisis best showed on a server based on the Intel manycore device, KNL, where the algorithmscales until the memory bandwidth is no longer enough to feed all 64 computing cores. Adual-socket server based on 16-core Xeon Skylakes, with AVX-512 vector support, proved tobe a better choice: the algorithm executes in less time and scales better.The introduction of GPU computing to further improve the execution performance (andalso using other optimisation techniques, namely a different thread scheme and sharedmemory to speed up the process) showed better results for larger grid sizes (above 32Ki x32Ki). The CUDA development environment also showed a better performance than usingOpenCL, in most cases. The largest difference was using a hybrid CR-PCR, where the OpenCLcode displayed a major performance improvement when compared to CUDA. But even withthis speedup, the better average time for the ADI method on all tested configurations on aNVidia GPU was using CUDA on an available updated GPU (with a Pascal architecture) andthe CR as the auxiliary method.",
    "similarity": 0.3264537396121884
  },
  {
    "text1": "As técnicas de teste baseados em modelos (do inglês, Model Based Testing (MBT)) comparamo comportamento do sistema sob teste com o comportamento do modelo do sistema(o oráculo). A aplicação de MBT às interfaces gráficas do utilizador (do inglês, GraphicalUser Interface (GUI)) permite uma avaliação mais exaustiva e contínua do sistema, atravésda simulação de ações do utilizador com a interface gráfica. Desta forma, é possível reduzirsignificativamente o custo de avaliação do sistema, e identificar, eventualmente, erros deimplementação através da GUI, sem o envolvimento de utilizadores externos. Este processodecorre através da execução dos casos de teste, gerados a partir do modelo do sistema, naaplicação sobre teste. São estes casos de teste que verificam se a implementação está deacordo com o modelo, assegurando assim uma melhoria da qualidade do sistema desenvolvido.Esta dissertação descreve uma ferramenta de MBT para aplicações web, a TOM Framework.Parte da framework (TOM Generator) aproveita trabalho anteriormente desenvolvido,a outra (TOM Editor) é aqui apresentada. Os objetivos principais da frameworkpassam por automatizar e facilitar a criação de modelos do sistema que, posteriormente,são utilizados para gerar automaticamente casos de teste executáveis na interface gráficasobre teste. A captura e interpretação da interação do utilizador com a aplicação web sobreteste foi um dos desafios ultrapassados no desenvolvimento desta dissertação. No final damesma, encontra-se uma aplicação da framework a um caso de estudo.",
    "text2": "É cada vez mais importante que os Sistemas de Informação Hospitalar garantam umamelhoria na segurança e na qualidade dos cuidados médicos. Os pacientes neonatais epediátricos são mais vulneráveis que os pacientes adultos tornando essencial orientar asTecnologias de Informação para as suas necessidades.Erros na administração de medicamentos são os erros mais comuns e potencialmentemais nocivos nas instalações hospitalares, sendo a sua taxa de incidência maior na populaçãopediátrica. Neste sentido, torna-se essencial melhorar a segurança do paciente. Para alémdisto, é essencial ao profissional de saúde uma interligação da informação do paciente pelosdiferentes Sistemas de Informação que ele possui ao seu dispor.Esta dissertação tem como principal objetivo a finalização e implementação de uma plataformade apoio à decisão médica através do desenvolvimento de diversas ferramentas, queauxiliem os médicos nas suas atividades diárias e que contribuam para a diminuição dataxa de ocorrência de erro médico. Este desenvolvimento foi acompanhado por um médicopediatra do Centro Hospitalar do Porto.O sistema desenvolvido permite colmatar falhas existentes nos sistemas utilizados atualmenteem algumas unidades hospitalares e, deste modo, obter um sistema que permitisseuma troca de informação e uma comunicação entre os serviços de pediatria e neonatologiae os serviços de farmácia. Assim, é possível facilitar o trabalho diários dos profissionaisde saúde e, ainda, provocar uma diminuição nos efeitos adversos causados por erros demedicação.Sendo um processo acompanhado, a plataforma foi testada e melhorada ao longo dotempo de forma a obter um sistema final satisfatório. Por fim, é lançada uma avaliação aostestes realizados na aplicação.",
    "similarity": 0.306418678274634
  },
  {
    "text1": "A incontinência urinária, é um problema de saúde com múltiplas repercussões, que interferem negativamente na qualidade de vida dos doentes. Aliado a este facto, está a dificuldade em realizar diagnósticos corretos acerca do grau de incontinência. Sem um diagnóstico correto o tratamento, que já por si é complicado, incorre em dificuldades adicionais. Assim, tem-se assistido ao desenvolvimento de vários produtos para incontinência, cujo objetivo é melhorar a qualidade de vida dos pacientes, face aos danos causados pela doença. Tratam-se de sistemas concebidos para aumentar a autoestima das pessoas na sua presença em público, face ao receio de algum evento de incontinência. Nesse sentido, o principal objetivo deste trabalho, é a criação de um sistema de alarme para incontinentes, que é constituído por uma componente de deteção de líquido, incorporada em roupa interior específica para incontinentes e uma componente de geração de alarme, que corresponde a um dispositivo android . A comunicação entre os dois dispositivos é estabelecida, através do protocolo Bluetooth. A componente de deteção de líquido, inclui a implementação de um sensor de líquido baseado em materiais fibrosos, integrado no substrato têxtil específico para incontinentes. É também responsável por, processar a informação proveniente do sensor e por comunicar com o dispositivo android . Os resultados provenientes do sensor consistem na resistência elétrica produzida, relacionada com a quantidade de líquido libertado. Por sua vez, a componente de geração de alarme, é uma aplicação móvel, concretizada com o propósito de emitir alarmes, quando recebe sinais provenientes do dispositivo. Além disso, fornece uma interface de configuração do dispositivo de deteção, para o nível de alarme desejado. Permite ainda registar eventos de incontinência numa base de dados local. O trabalho desenvolvido tornou possível a conceção e implementação de um sistema de alarme para incontinentes, sendo que o nível de alarme pode ser configurado em função da quantidade de líquidos. A existência duma base de dados com registo de eventos permite a monitorização em modo offline por períodos mais longos.",
    "text2": "Nos últimos anos, cada vez mais pessoas que anteriormente viviam em zonas rurais migram para centros urbanos à procura de novas oportunidades. Face a este movimento, vários problemas e adversidades foram-se agravando, nomeadamente, o aumento do fluxo rodoviário, que cria problemas de trânsito, o aumento dos níveis de poluição, o acesso à saúde, entre outros. Desta forma, torna-se imperativo gerir de forma eficaz e sustentável os recursos, com a finalidade de melhorar a qualidade de vida dos habitantes destas cidades.Neste contexto, juntamente com os avanços tecnológicos que se tem observado, surge o conceito de Cidades Inteligentes, que recorrendo a redes de sensores recolhem todos os dados necessários para ”virtualizar” as cidades. Desse modo, a informação coletada está centralizada, para que assim seja possível gerir os recursos disponíveis de forma informada, responsável e eficiente, para que seja possível responder às necessidades da população. Com este trabalho, pretende-se estudar dois problemas concretos no âmbito das Cidades Inteligentes, nomeadamente na área do Transporte Inteligente, recorrendo à simulação de redes de sensores, constituídas por sensores de aceleração instalados na rede de transporte públicos da cidade, a partir da qual vão ser recolhidos dados. O primeiro problema que se tenciona solucionar está relacionado com a monitorização do estado do pavimento. Com os dados provenientes dos acelerómetros, espera-se ser possível estimar o estado de conservação das vias rodoviárias e, desta forma, as entidades responsáveispassam a ser capazes de realizar decisões informadas e apropriadas face ao estado de determinada estrada, procedendo assim à sua restauração caso necessário. Uma segunda vertente que se pretende explorar foca a monitorização da congestão das vias rodoviárias em que, com base na mesma rede de transportes, se projeta ser possível determinar os níveis de fluxo rodoviário. Por fim, é ainda expectável que beneficiando dos transportes públicos dos quais já se está a tirar proveito, seja plausível medir os níveis de poluição aérea.",
    "similarity": 0.30222314908083603
  },
  {
    "text1": "Metabolic reprogramming is recognized as a critical hallmark of cancer, influencing cancer initiation and progression. Emerging evidence suggests that the metabolism of non-cancer cells within the tumor microenvironment plays a pivotal role in modulating tumor development, underscoring the importance of metabolic variables for better understanding cancer. The main goal of this study is to identify genes exhibiting differential expression in cancer, with a specific emphasis on distinguishing between organs with high metabolic rates (brain, liver, and kidneys) and organs with low metabolic rates (bladder, colon, and skin), particularly focusing on genes encodingmitochondrial proteins. For this, we used two databases containing RNA-seq samples from normal and cancer tissues, obtained from the Genotype-Tissue Expression (GTEx) and The Cancer Genome Atlas (TCGA) projects, respectively. General Linear Models (GLMs) were applied for differential expression analysis, and hierarchical clustering e soft fuzzy clustering to identify distinct gene expression profiles. Our research showed that many of the differentially expressed mitochondrial genes, such as ACSM1and ACSM5, and PRODH, represent potential adaptations of cancer cells to metabolic and micro environmental stress. Additionally, FDX2, a crucial player in iron-sulfur protein biogenesis, and ACSM2B, responsible for catalyzing the activation of free fatty acids (FFAs) to CoA, showed substantial expression differences, highlighting the importance of these two pathways for the oncogenic process. The most sub stantial genetic expression differences were observed between normal and cancer tissues, rather than between high and low metabolic rate organs, suggesting that the signal from the metabolic rate could be masked by the pronounced changes that cancer induces in cells. Despite the unequal sample sizes and the usage of two different data sources, our findings provide valuable insights into the complex interplay between metabolism and gene expression in cancer.",
    "text2": "Due to global climate change, the temperatures of streams and rivers are increasing, negatively affecting aquatic life, including bivalve species. Freshwater mussels are vital components of rivers, streams, and lake ecosystems, participating in essential ecological roles such as nutrient cycling, and increasing water quality. Furthermore, they serve as essential ecosystem engineers, providing habitat to other organisms and supporting intricate food webs. Besides their biological importance, freshwater mussels are poorly studied in terms of genomics. In the present work, the Iberian dolphin freshwater mussel Unio delphinus Spengler, 1793 (Bivalvia: Unionoida) was used as a model species to investigate the effects of climate change in freshwater mussels. The primary objective of this thesis was to determine the gene expression patterns in a model species of freshwater mussels under the effects of thermal stress exacerbated by climate change, with an overall goal of understanding the potential consequences for freshwater mussel populations. Two different ecological experiments were performed: chronic and acute. The chronic experiments where temperatures were gradually increased to simulate a scenario of progressive increasing temperatures. The acute experiments where temperatures were rapidly increased to replicate the effects of a briefer extreme climatic event. To achieve this main goal, a comprehensive bioinformatic pipeline focused on transcriptomics analysis was developed using the R Bioconductor package to generate the differential gene expression profiles of these individuals under thermal stress. The bioinformatic methodology of this work differs from the past studies, by developing an R code compilation of three methods, EdgeR, limma, and DESeq2 for differential gene expression analysis in these organisms. The output of the present work provides a comprehensive overview of gene expression profile responses of U. delphinus under climate change scenarios. Additionally, the results revealed a wide range of pathways and the corresponding genes that are impacted by thermal stress, with a particular emphasis on the up-regulation of the genes ATP6V1A, ATP6V0A1, ATP6V0A, and ATP6V1. In the chronic experiments, and high temperatures, mussels expressed these genes and, interestingly, all the pathways that these genes included appeared up-regulated. The discovered genes and pathways provide vital insights into these organisms’ adaptation tactics and identify prospective targets for monitoring and conservation efforts.",
    "similarity": 0.30109055213403974
  },
  {
    "text1": "O Ancestors Notebook é uma ferramenta de apoio à gestão e organização de documentos e informaçõessobre a história e herança familiar. Tem como intuito oferecer diferentes potencialidades que facilitem todoo processo de registo e construção de um legado relativamente a uma ou mais genealogias específicas.O Ancestors Notebook funciona sobre o file-system Linux utilizando um conjunto de convenções,comandos e Domain Specific Languages (DSLs) para nomear e organizar diretorias e com um focoespecial em documentos com um formato específico - DGU - criados especialmente este toolkit. O seupropósito é trazer um controlo organizacional personalizado ao utilizador, contribuindo assim para umfluxo coerente de ideias sempre correlacionado com o aglomerar de dados de cariz genealógico.A organização dos dados passa pela definição de entidades representativas de vários elementos, paraaglutinar distintos formatos num só, de maneira a ter um maior segmento organizacional no sistema deficheiros. Definiu-se, também, a geração de templates genéricos para uma visualização mais agradávele familiar, exportável em formato PDF, denominados Caderno de Antepassados. Estes consideram umafuncionalidade de agregação e organização de documentos por entidades, contribuindo assim para ummaior leque de alternativas na definição dinâmica de opções de visualização.O Ancestors Notebook toolkit dispõe de um sistema de controlo de versões, cujo funcionamento estádependente de um sistema de representação de conhecimento sob forma de ontologia e um projectioneditor que permite visualizar e manipular a estrutura genealógica como está representada no sistema deficheiros.O toolkit é definido na linguagem de programação Python com definição de comandos disponíveis nosistema de ficheiros. Utilização de diferentes módulos Python para a definição de views para o utilizador.A criação de templates é feita usando o motor de geração de templatesJinja2. O toolkit é definido comopackage instalável através do pip.",
    "text2": "A resolução de problemas no âmbito de um domínio específico pode adotar técnicas e ideologias distintas. Para tal, é vital e imperativo elaborar uma análise contextual a todos os elementos pertencentes à teia de relações entre conceitos. Nesse sentido, o uso de uma ontologia permite construir uma rede semântica, no qual a mais importante premissa é a correta identificação dos conceitos e respetivos atributos. A automatização do processo de extração de ontologias permite construir ontologias mais escaláveis e uniformes, extraindo conhecimento assente nas mesmas premissas e padrões. No plano geral, uma extração automática facilita a análise e a leitura de informação de um problema apresentado numa linguagem própria. O trabalho desta dissertação focou-se na extração de conhecimento em textos não estruturados, mais concretamente, textos de culinária, com o intuito de disponibilizar uma ontologia que espelhasse o conhecimento interligado entre receitas. O verdadeiro desafio passa pela correta identificação de termos relevantes, com base em análise sintática, semântica, e linguística em geral, e pela formalização de relações entre os mesmos. A utilização de mecanismos de controlo e de automatização permitiu a extração do conhecimento presente nos textos não estruturados. Estes mecanismos foram aplicados conforme as características linguísticas inerentes aos documentos e restrições de domínio. A ontologia gerada pode ser consultada através de uma plataforma web, na qual o utilizador pode pesquisar os documentos importados no sistema e analisar a interligação entre receitas através da pesquisa por termos e por hiperligações que se encontram nos detalhes de cada registo de culinária.",
    "similarity": 0.3038041209729443
  },
  {
    "text1": "Esta dissertação está centrada na paralelização massiva da biblioteca Java Evolutionary Cornputation Library), JECoLi, que se foca no desenvolvimento de meta-heurísticas de otimização(e.g. Algoritmos Evolucionários (AEs)) na linguagem Java. Os AEs são um paradigma da Computação Evolucionária (CE) utilizados para resolver problemas complexos através de um método iterativo que evolui um conjunto de soluções (população) tendo em conta os princípios da teoria de evolução por seleção natural apresentada por Charles Darwin. Estes algoritmos estão divididos em duas categorias, AEs não estruturados e AEs estruturados. Os AEs não estruturados são caracterizados por uma população centralizada onde existe apenas um conjunto de soluções ao qual é aplicado o processo evolutivo. Por outro lado, os AEs estruturados contêm várias populações onde os processos evolutivos são conduzidos de forma independente, embora existindo troca de informação. Os algoritmos de ambas as categorias podem ser paralelizados de diferentes maneiras. Nesta dissertação, foram implementadas quatro versões paralelas da plataforma JECoLi de forma o menos invasiva possível, tendo em conta modelos paralelos já formulados: um modelo de paralelismo global; um modelo de ilhas em ambiente de memória partilhada; um modelo de ilhas em ambiente de memória distribuída; e um modelo híbrido. Estas implementações paralelas foram executadas no cluster Services and Advanced Research Cornputing with HTC/HPC clusters (SeARCH) utilizando o máximo de recursos computacionais possíveis de modo a realizar uma posterior análise dos resultados obtidos. Foram utilizados dois casos de estudo reais para validar as implementações paralelas, um problema de otimização de um bioprocesso de fermentação fed-batch e outro de otimização dos pesos de um protocolo de encaminhamento (OSP F). Cada uma das implementações paralelas foi testada nos dois casos de estudo, aplicando o máximo de paralelismo possível tendo em conta as limitações de cada caso de estudo, dos modelos paralelos e dos recursos disponíveis. Com estes testes concluí-se uma boa escalabilidade destes algoritmos, onde se destacam as implementações relativas ao modelo de ilhas em memória distribuída e ao modelo híbrido. Contudo, algumas configurações que originam maiores ganhos foram descartadas pois não produzem valores de aptidão aceitáveis.",
    "text2": "Durante várias décadas, o aumento do desempenho dos processadores era conseguidomaioritariamente através do aumento da frequência de relógio. Contudo, aumentar o desempenhoatravés do aumento da frequência tornou-se cada vez mais difícil conduzindoa problemas de consumo energético e dissipação de calor. Para resolver estes problemas,as arquiteturas mais recentes evoluíram num sentido de aumentar o número de processadores,e mais tarde, o número de núcleos. As arquiteturas de memória inicialmenteadotadas, designadas arquiteturas de acesso uniforme à memória (UMA), apresentaramalgumas limitações. Entre as arquiteturas UMA existentes, existe a arquitetura de multiprocessamentosimétrico (SMP). Esta arquitetura possui múltiplos processadores queacedem à memória principal utilizando um barramento partilhado pelos processadoresque conduziu a problemas de contenção no acesso à memória principal.As arquiteturas de acesso não uniforme à memória (NUMA) surgiram durante os anos90 com múltiplos bancos de memória. No entanto, os programadores que queiram tirartotal partido das vantagens desta arquitetura, terão que lidar com novos desafios ao nívelda programação, ao nível da afinidade dos fios de execução e das alocações de memória.Esta dissertação mostra que a forma como os algoritmos memory-bound acedem adados de memória principal numa arquitetura NUMA, pode ter impacto no seu desempenho.Um conjunto de testes foi utilizado para demonstrar em que medida várias técnicasde afinidade podem contribuir para aumentar o desempenho de aplicações Javae C em arquiteturas NUMA. Os testes realizados com recurso a diferentes abordagenstais como ferramentas do sistema operativo, opções da JVM, técnicas de programaçãoe até variáveis de afinidade para os compiladores, foram usados para aumentar a desempenhode dois casos de estudo em arquiteturas NUMA. A utilização destas abordagenspermitiram aumentar o desempenho com um ganho adicional de até 1.8 vezes para asimplementações em Java, e de até 2.16 vezes para as versões em C das mesmas aplicações.",
    "similarity": 0.30246395744145055
  }
]