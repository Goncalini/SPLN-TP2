# Autores
Autores

- PG55944 Gon√ßalo Costa
Costa
- PG56006 Rodrigo Novo
- PG56967 Jos√© Correia

# Sistema de Recupera√ß√£o de Informa√ß√£o - TP2 SPLN

Este documento descreve, em detalhe, a implementa√ß√£o de um sistema de Recupera√ß√£o de Informa√ß√£o baseado em embeddings de senten√ßas, desenvolvido para o **Trabalho Pr√°tico II da unidade curricular de Sistemas de Processamento de Linguagem Natural (SPLN)**, usando dados do RepositoriUM.

---

## üîç Objetivo Geral

Desenvolver um sistema capaz de:

* Indexar documentos acad√©micos a partir do RepositoriUM
* Calcular similaridade sem√¢ntica entre documentos
* Recuperar documentos relevantes com base numa query textual
* Avaliar o desempenho do sistema de retrieval

---

## üìÇ Estrutura Geral do Projeto

```
.
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ result.json   # Documentos processados em JSON
‚îÇ   ‚îú‚îÄ‚îÄ similarities.json  # Pares de treino (doc1, doc2, similarity)
‚îú‚îÄ‚îÄ models/                         # Modelos treinados ou checkpoints
‚îú‚îÄ‚îÄ parameters.py                  # Configura√ß√µes globais
‚îú‚îÄ‚îÄ scripts.py (diveros)           # C√≥digo principal do sistema
‚îî‚îÄ‚îÄ report.md                      # Este ficheiro
```

O projeto √© dividido em 5 scripts, cada um com uma fun√ß√£o espec√≠fica e modularizados de forma a conseguirem correr de forma independente.

---

## üìö Retrievel dos dados - Script `retrievel.py`

A extra√ß√£o de documentos √© feita a partir da API **OAI-PMH** do RepositoriUM:

* URL base: `https://repositorium.sdum.uminho.pt/oai/oai`
* Cole√ß√µes usadas: `msc`, `msc_di`
* Formato: `dim` (esquema de metadados)

Este script desempenha o papel de iterar sobre as cole√ß√µes e extrair os registos XML e armazen√°-los num √∫nico ficheiro XML.

---
## üìä Limpeza dos dados - Script `xml_to_json.py`

Os documentos s√£o convertidos de XML para JSON com os seguintes filtros:

* Abstracts com tamanho entre 50 e 2000 caracteres
* Elimina√ß√£o de registos incompletos
* Campos extraidos:

  * `id, title, abstract, authors/Autores (pode haver v√°rios), keywords, date, type, language, subjects_udc, subjects_fos, collections`
  
Este script l√™ o ficheiro XML encontra todos os registos `<record>` e para cada registo extrai os campos relevantes e verifica se o mesmo √© v√°lido segundo as regras definidas em cima e "limpa" e normaliza os campos necess√°rios.

---

## üöÄ Similaridade e Treino do modelo - Scripts `get_similarity.` e `model.py`

### ‚öñÔ∏è Similaridade

Este script carrega documentos (a partir do JSON criado no script anterior, calcula similaridade entre todos os pares poss√≠veis, guarda os pares mais semelhantes (acima de um certo limiar) num ficheiro de treino e mostrar estat√≠sticas sobre essas similaridades.

Como √© calculada a similaridade:

- Keywords (peso 45%), calculada por compara√ß√£o keywords + palavras do abstract, removendo stopwords e aquelas que s√£o mais raras e comuns

- UDC subjects (peso 25%), calculada por Jaccard entre subjects_udc

- FOS subjects (peso 20%), calculada por Jaccard entre subjects_fos

- Cole√ß√µes (peso 10%), calculada por Jaccard entre cole√ß√µes

Cada uma √© normalizada e ponderada. A soma d√° a pontua√ß√£o final de 0.0 a 1.0.

### üéì Embeddings

Modelos usados:

```python
"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
"all-MiniLM-L6-v2"
"distiluse-base-multilingual-cased-v2"
```

Este script carrega os dados de treino gerados no script anterior, treina um modelo SentenceTransformer, usando CosineSimilarityLoss, avalia o modelo com m√©tricas reais (MSE, MAE) e guarda o modelo treinado para uso posterior

### üéì Treino do Modelo

O modelo pode ser afinado com exemplos supervisionados:

* `similarities.json` cont√©m pares:

```json
{
  "text1": "Resumo do doc A",
  "text2": "Resumo do doc B",
  "similarity": 0.9
}
```

* O treino √© feito com o `SentenceTransformer` e `InputExample`

Par√¢metros usados:

```python
EPOCHS = 5
BATCH = 16
THRESHOLD_SIMILARITY = 0.3
```

√â importante destacar que, durante os testes preliminares, os modelos `all-MiniLM-L6-v2` e `distiluse-base-multilingual-cased-v2` demonstraram desempenho superior em termos de qualidade das similaridades geradas, especialmente quando combinados com batch sizes maiores e valores elevados para o n√∫mero de documentos recuperados por consulta. No entanto, tendo em conta as limita√ß√µes computacionais dos equipamentos utilizados pelos membros do grupo, n optou-se por adotar o modelo `paraphrase-multilingual-MiniLM-L12-v2`. Este modelo oferece um bom compromisso entre desempenho e efici√™ncia computacional, permitindo treinos com batch size 16 e 5 √©pocas, alcan√ßando resultados satisfat√≥rios dentro dos recursos dispon√≠veis.


---

## ü§ù Testes e User Engine - Script `search_engine.py`

O que este script faz √© carrega o modelo treinado (ou o modelo base se necess√°rio, em caso de falha num script anterior, carrega os documentos com metadados e resumos, calcula os embeddings de todos os documentos (para serem usados em pesquisa) e permite fazer consultas de texto livre e recuperar os documentos mais semelhantes


### Fun√ß√µes principais:

* `load_model()` - Carrega modelo base ou treinado
* `load_docss()` - Carrega os documentos JSON
* `get_embendiings()` - Gera embeddings dos resumos
* `get_docss(query, ...)` - Recupera documentos com base na query
* `fetch_results()` - Apresenta resultados formatados ao utilizador
* `search_query_by_user()` - Modo interativo com input do utilizador

### Exemplo de Output:

```
Query: "classifica√ß√£o de texto"
1. SCORE -  0.784
   TITLE - Classifica√ß√£o de documentos com SVM
   AUTHORS - JJ
   DATE - 2019
   ABSTRACT - Este trabalho aborda...
   KEYWORDS - machine learning, text classification
```

---

## ‚öñÔ∏è Avalia√ß√£o (Comentado no C√≥digo)


* Precision
* Recall
* F1 Score


---

## ‚öôÔ∏è Melhorias Futuras

* Usar modelo `e5` com prompt:

  * `"query: texto"` e `"passage: documento"`
* Re-ranker com `CrossEncoder` para melhorar top 10
* Indexa√ß√£o com faiss ou elasticsearch para rapidez
* Normaliza√ß√£o lexical, lematiza√ß√£o, filtros de linguagem
* Gera√ß√£o semi-autom√°tica de dados de treino com heur√≠sticas

---

## üõå Conclus√£o

Este sistema constitui um pipeline completo de Information Retrieval sobre o RepositoriUM, baseado em embeddings sem√¢nticos. Est√° preparado para ser expandido, re-treinado e melhorado com rerankers, modelos mais avan√ßados ou avalia√ß√£o formal.


